{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vayzenb/anaconda3/envs/ml/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "project_name = 'kornet'\n",
    "import os\n",
    "#get current working directory\n",
    "cwd = os.getcwd()\n",
    "git_dir = cwd.split(project_name)[0] + project_name\n",
    "import sys\n",
    "sys.path.append(git_dir)\n",
    "\n",
    "\n",
    "vone_dir = f'{cwd.split(project_name)[0]}vonenet'\n",
    "#cornet_dir = '/user_data/vayzenbe/GitHub_Repos/CORnet'\n",
    "vit_dir = f'{cwd.split(project_name)[0]}Cream/EfficientViT'\n",
    "baby_dir = f'{cwd.split(project_name)[0]}multimodal-baby'\n",
    "deepdive = f'{cwd.split(project_name)[0]}DeepDive'\n",
    "sys.path.insert(1, git_dir)\n",
    "sys.path.insert(1, vone_dir)\n",
    "#sys.path.insert(1, cornet_dir)\n",
    "sys.path.insert(1, vit_dir)\n",
    "sys.path.insert(1, baby_dir)\n",
    "sys.path.insert(1, deepdive)\n",
    "from deepdive.feature_extraction import get_empty_feature_maps, StimulusSet, get_all_feature_maps\n",
    "import vonenet\n",
    "#from torchvision.models import convnext_large, ConvNeXt_Large_Weights, vit_b_16, ViT_B_16_Weights\n",
    "#from torchvision.models import resnet50, ResNet50_Weights, resnext50_32x4d, ResNeXt50_32X4D_Weights\n",
    "#from torchvision.models import alexnet, AlexNet_Weights, vgg19, VGG19_Weights\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import load_stim\n",
    "from glob import glob as glob\n",
    "from model_loader import load_model as load_model\n",
    "#import two_stream.two_stream_dataloader\n",
    "#import two_stream.two_stream_nn\n",
    "\n",
    "#from classification.model.build import EfficientViT_M0\n",
    "\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from multimodal.multimodal_lit import MultiModalLitModel\n",
    "import open_clip\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /home/vayzenb/.cache/torch/hub/main.zip\n",
      "/home/vayzenb/anaconda3/envs/ml/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/vayzenb/anaconda3/envs/ml/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_resnet50_pretrain/dino_resnet50_pretrain.pth\" to /home/vayzenb/.cache/torch/hub/checkpoints/dino_resnet50_pretrain.pth\n",
      "100%|██████████| 90.0M/90.0M [00:00<00:00, 114MB/s] \n"
     ]
    }
   ],
   "source": [
    "model, _, _ = load_model('resnet50_dino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights, resnext50_32x4d, ResNeXt50_32X4D_Weights\n",
    "model = resnet50(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.conv3.weight\", \"module.layer1.0.bn3.weight\", \"module.layer1.0.bn3.bias\", \"module.layer1.0.bn3.running_mean\", \"module.layer1.0.bn3.running_var\", \"module.layer1.0.bn3.num_batches_tracked\", \"module.layer1.0.downsample.0.weight\", \"module.layer1.0.downsample.1.weight\", \"module.layer1.0.downsample.1.bias\", \"module.layer1.0.downsample.1.running_mean\", \"module.layer1.0.downsample.1.running_var\", \"module.layer1.0.downsample.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.conv3.weight\", \"module.layer1.1.bn3.weight\", \"module.layer1.1.bn3.bias\", \"module.layer1.1.bn3.running_mean\", \"module.layer1.1.bn3.running_var\", \"module.layer1.1.bn3.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.conv3.weight\", \"module.layer1.2.bn3.weight\", \"module.layer1.2.bn3.bias\", \"module.layer1.2.bn3.running_mean\", \"module.layer1.2.bn3.running_var\", \"module.layer1.2.bn3.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.conv3.weight\", \"module.layer2.0.bn3.weight\", \"module.layer2.0.bn3.bias\", \"module.layer2.0.bn3.running_mean\", \"module.layer2.0.bn3.running_var\", \"module.layer2.0.bn3.num_batches_tracked\", \"module.layer2.0.downsample.0.weight\", \"module.layer2.0.downsample.1.weight\", \"module.layer2.0.downsample.1.bias\", \"module.layer2.0.downsample.1.running_mean\", \"module.layer2.0.downsample.1.running_var\", \"module.layer2.0.downsample.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.conv3.weight\", \"module.layer2.1.bn3.weight\", \"module.layer2.1.bn3.bias\", \"module.layer2.1.bn3.running_mean\", \"module.layer2.1.bn3.running_var\", \"module.layer2.1.bn3.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.conv3.weight\", \"module.layer2.2.bn3.weight\", \"module.layer2.2.bn3.bias\", \"module.layer2.2.bn3.running_mean\", \"module.layer2.2.bn3.running_var\", \"module.layer2.2.bn3.num_batches_tracked\", \"module.layer2.3.conv1.weight\", \"module.layer2.3.bn1.weight\", \"module.layer2.3.bn1.bias\", \"module.layer2.3.bn1.running_mean\", \"module.layer2.3.bn1.running_var\", \"module.layer2.3.bn1.num_batches_tracked\", \"module.layer2.3.conv2.weight\", \"module.layer2.3.bn2.weight\", \"module.layer2.3.bn2.bias\", \"module.layer2.3.bn2.running_mean\", \"module.layer2.3.bn2.running_var\", \"module.layer2.3.bn2.num_batches_tracked\", \"module.layer2.3.conv3.weight\", \"module.layer2.3.bn3.weight\", \"module.layer2.3.bn3.bias\", \"module.layer2.3.bn3.running_mean\", \"module.layer2.3.bn3.running_var\", \"module.layer2.3.bn3.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.conv3.weight\", \"module.layer3.0.bn3.weight\", \"module.layer3.0.bn3.bias\", \"module.layer3.0.bn3.running_mean\", \"module.layer3.0.bn3.running_var\", \"module.layer3.0.bn3.num_batches_tracked\", \"module.layer3.0.downsample.0.weight\", \"module.layer3.0.downsample.1.weight\", \"module.layer3.0.downsample.1.bias\", \"module.layer3.0.downsample.1.running_mean\", \"module.layer3.0.downsample.1.running_var\", \"module.layer3.0.downsample.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.conv3.weight\", \"module.layer3.1.bn3.weight\", \"module.layer3.1.bn3.bias\", \"module.layer3.1.bn3.running_mean\", \"module.layer3.1.bn3.running_var\", \"module.layer3.1.bn3.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.conv3.weight\", \"module.layer3.2.bn3.weight\", \"module.layer3.2.bn3.bias\", \"module.layer3.2.bn3.running_mean\", \"module.layer3.2.bn3.running_var\", \"module.layer3.2.bn3.num_batches_tracked\", \"module.layer3.3.conv1.weight\", \"module.layer3.3.bn1.weight\", \"module.layer3.3.bn1.bias\", \"module.layer3.3.bn1.running_mean\", \"module.layer3.3.bn1.running_var\", \"module.layer3.3.bn1.num_batches_tracked\", \"module.layer3.3.conv2.weight\", \"module.layer3.3.bn2.weight\", \"module.layer3.3.bn2.bias\", \"module.layer3.3.bn2.running_mean\", \"module.layer3.3.bn2.running_var\", \"module.layer3.3.bn2.num_batches_tracked\", \"module.layer3.3.conv3.weight\", \"module.layer3.3.bn3.weight\", \"module.layer3.3.bn3.bias\", \"module.layer3.3.bn3.running_mean\", \"module.layer3.3.bn3.running_var\", \"module.layer3.3.bn3.num_batches_tracked\", \"module.layer3.4.conv1.weight\", \"module.layer3.4.bn1.weight\", \"module.layer3.4.bn1.bias\", \"module.layer3.4.bn1.running_mean\", \"module.layer3.4.bn1.running_var\", \"module.layer3.4.bn1.num_batches_tracked\", \"module.layer3.4.conv2.weight\", \"module.layer3.4.bn2.weight\", \"module.layer3.4.bn2.bias\", \"module.layer3.4.bn2.running_mean\", \"module.layer3.4.bn2.running_var\", \"module.layer3.4.bn2.num_batches_tracked\", \"module.layer3.4.conv3.weight\", \"module.layer3.4.bn3.weight\", \"module.layer3.4.bn3.bias\", \"module.layer3.4.bn3.running_mean\", \"module.layer3.4.bn3.running_var\", \"module.layer3.4.bn3.num_batches_tracked\", \"module.layer3.5.conv1.weight\", \"module.layer3.5.bn1.weight\", \"module.layer3.5.bn1.bias\", \"module.layer3.5.bn1.running_mean\", \"module.layer3.5.bn1.running_var\", \"module.layer3.5.bn1.num_batches_tracked\", \"module.layer3.5.conv2.weight\", \"module.layer3.5.bn2.weight\", \"module.layer3.5.bn2.bias\", \"module.layer3.5.bn2.running_mean\", \"module.layer3.5.bn2.running_var\", \"module.layer3.5.bn2.num_batches_tracked\", \"module.layer3.5.conv3.weight\", \"module.layer3.5.bn3.weight\", \"module.layer3.5.bn3.bias\", \"module.layer3.5.bn3.running_mean\", \"module.layer3.5.bn3.running_var\", \"module.layer3.5.bn3.num_batches_tracked\", \"module.layer4.0.conv1.weight\", \"module.layer4.0.bn1.weight\", \"module.layer4.0.bn1.bias\", \"module.layer4.0.bn1.running_mean\", \"module.layer4.0.bn1.running_var\", \"module.layer4.0.bn1.num_batches_tracked\", \"module.layer4.0.conv2.weight\", \"module.layer4.0.bn2.weight\", \"module.layer4.0.bn2.bias\", \"module.layer4.0.bn2.running_mean\", \"module.layer4.0.bn2.running_var\", \"module.layer4.0.bn2.num_batches_tracked\", \"module.layer4.0.conv3.weight\", \"module.layer4.0.bn3.weight\", \"module.layer4.0.bn3.bias\", \"module.layer4.0.bn3.running_mean\", \"module.layer4.0.bn3.running_var\", \"module.layer4.0.bn3.num_batches_tracked\", \"module.layer4.0.downsample.0.weight\", \"module.layer4.0.downsample.1.weight\", \"module.layer4.0.downsample.1.bias\", \"module.layer4.0.downsample.1.running_mean\", \"module.layer4.0.downsample.1.running_var\", \"module.layer4.0.downsample.1.num_batches_tracked\", \"module.layer4.1.conv1.weight\", \"module.layer4.1.bn1.weight\", \"module.layer4.1.bn1.bias\", \"module.layer4.1.bn1.running_mean\", \"module.layer4.1.bn1.running_var\", \"module.layer4.1.bn1.num_batches_tracked\", \"module.layer4.1.conv2.weight\", \"module.layer4.1.bn2.weight\", \"module.layer4.1.bn2.bias\", \"module.layer4.1.bn2.running_mean\", \"module.layer4.1.bn2.running_var\", \"module.layer4.1.bn2.num_batches_tracked\", \"module.layer4.1.conv3.weight\", \"module.layer4.1.bn3.weight\", \"module.layer4.1.bn3.bias\", \"module.layer4.1.bn3.running_mean\", \"module.layer4.1.bn3.running_var\", \"module.layer4.1.bn3.num_batches_tracked\", \"module.layer4.2.conv1.weight\", \"module.layer4.2.bn1.weight\", \"module.layer4.2.bn1.bias\", \"module.layer4.2.bn1.running_mean\", \"module.layer4.2.bn1.running_var\", \"module.layer4.2.bn1.num_batches_tracked\", \"module.layer4.2.conv2.weight\", \"module.layer4.2.bn2.weight\", \"module.layer4.2.bn2.bias\", \"module.layer4.2.bn2.running_mean\", \"module.layer4.2.bn2.running_var\", \"module.layer4.2.bn2.num_batches_tracked\", \"module.layer4.2.conv3.weight\", \"module.layer4.2.bn3.weight\", \"module.layer4.2.bn3.bias\", \"module.layer4.2.bn3.running_mean\", \"module.layer4.2.bn3.running_var\", \"module.layer4.2.bn3.num_batches_tracked\", \"module.fc.weight\", \"module.fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m resnet50(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/resnet50_imagenet_sketch_best_1.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m transform \u001b[38;5;241m=\u001b[39m ResNet50_Weights\u001b[38;5;241m.\u001b[39mDEFAULT\u001b[38;5;241m.\u001b[39mtransforms()\n\u001b[1;32m      7\u001b[0m layer_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetattr(model,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavgpool\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.conv3.weight\", \"module.layer1.0.bn3.weight\", \"module.layer1.0.bn3.bias\", \"module.layer1.0.bn3.running_mean\", \"module.layer1.0.bn3.running_var\", \"module.layer1.0.bn3.num_batches_tracked\", \"module.layer1.0.downsample.0.weight\", \"module.layer1.0.downsample.1.weight\", \"module.layer1.0.downsample.1.bias\", \"module.layer1.0.downsample.1.running_mean\", \"module.layer1.0.downsample.1.running_var\", \"module.layer1.0.downsample.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.conv3.weight\", \"module.layer1.1.bn3.weight\", \"module.layer1.1.bn3.bias\", \"module.layer1.1.bn3.running_mean\", \"module.layer1.1.bn3.running_var\", \"module.layer1.1.bn3.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.conv3.weight\", \"module.layer1.2.bn3.weight\", \"module.layer1.2.bn3.bias\", \"module.layer1.2.bn3.running_mean\", \"module.layer1.2.bn3.running_var\", \"module.layer1.2.bn3.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.conv3.weight\", \"module.layer2.0.bn3.weight\", \"module.layer2.0.bn3.bias\", \"module.layer2.0.bn3.running_mean\", \"module.layer2.0.bn3.running_var\", \"module.layer2.0.bn3.num_batches_tracked\", \"module.layer2.0.downsample.0.weight\", \"module.layer2.0.downsample.1.weight\", \"module.layer2.0.downsample.1.bias\", \"module.layer2.0.downsample.1.running_mean\", \"module.layer2.0.downsample.1.running_var\", \"module.layer2.0.downsample.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.conv3.weight\", \"module.layer2.1.bn3.weight\", \"module.layer2.1.bn3.bias\", \"module.layer2.1.bn3.running_mean\", \"module.layer2.1.bn3.running_var\", \"module.layer2.1.bn3.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.conv3.weight\", \"module.layer2.2.bn3.weight\", \"module.layer2.2.bn3.bias\", \"module.layer2.2.bn3.running_mean\", \"module.layer2.2.bn3.running_var\", \"module.layer2.2.bn3.num_batches_tracked\", \"module.layer2.3.conv1.weight\", \"module.layer2.3.bn1.weight\", \"module.layer2.3.bn1.bias\", \"module.layer2.3.bn1.running_mean\", \"module.layer2.3.bn1.running_var\", \"module.layer2.3.bn1.num_batches_tracked\", \"module.layer2.3.conv2.weight\", \"module.layer2.3.bn2.weight\", \"module.layer2.3.bn2.bias\", \"module.layer2.3.bn2.running_mean\", \"module.layer2.3.bn2.running_var\", \"module.layer2.3.bn2.num_batches_tracked\", \"module.layer2.3.conv3.weight\", \"module.layer2.3.bn3.weight\", \"module.layer2.3.bn3.bias\", \"module.layer2.3.bn3.running_mean\", \"module.layer2.3.bn3.running_var\", \"module.layer2.3.bn3.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.conv3.weight\", \"module.layer3.0.bn3.weight\", \"module.layer3.0.bn3.bias\", \"module.layer3.0.bn3.running_mean\", \"module.layer3.0.bn3.running_var\", \"module.layer3.0.bn3.num_batches_tracked\", \"module.layer3.0.downsample.0.weight\", \"module.layer3.0.downsample.1.weight\", \"module.layer3.0.downsample.1.bias\", \"module.layer3.0.downsample.1.running_mean\", \"module.layer3.0.downsample.1.running_var\", \"module.layer3.0.downsample.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.conv3.weight\", \"module.layer3.1.bn3.weight\", \"module.layer3.1.bn3.bias\", \"module.layer3.1.bn3.running_mean\", \"module.layer3.1.bn3.running_var\", \"module.layer3.1.bn3.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.conv3.weight\", \"module.layer3.2.bn3.weight\", \"module.layer3.2.bn3.bias\", \"module.layer3.2.bn3.running_mean\", \"module.layer3.2.bn3.running_var\", \"module.layer3.2.bn3.num_batches_tracked\", \"module.layer3.3.conv1.weight\", \"module.layer3.3.bn1.weight\", \"module.layer3.3.bn1.bias\", \"module.layer3.3.bn1.running_mean\", \"module.layer3.3.bn1.running_var\", \"module.layer3.3.bn1.num_batches_tracked\", \"module.layer3.3.conv2.weight\", \"module.layer3.3.bn2.weight\", \"module.layer3.3.bn2.bias\", \"module.layer3.3.bn2.running_mean\", \"module.layer3.3.bn2.running_var\", \"module.layer3.3.bn2.num_batches_tracked\", \"module.layer3.3.conv3.weight\", \"module.layer3.3.bn3.weight\", \"module.layer3.3.bn3.bias\", \"module.layer3.3.bn3.running_mean\", \"module.layer3.3.bn3.running_var\", \"module.layer3.3.bn3.num_batches_tracked\", \"module.layer3.4.conv1.weight\", \"module.layer3.4.bn1.weight\", \"module.layer3.4.bn1.bias\", \"module.layer3.4.bn1.running_mean\", \"module.layer3.4.bn1.running_var\", \"module.layer3.4.bn1.num_batches_tracked\", \"module.layer3.4.conv2.weight\", \"module.layer3.4.bn2.weight\", \"module.layer3.4.bn2.bias\", \"module.layer3.4.bn2.running_mean\", \"module.layer3.4.bn2.running_var\", \"module.layer3.4.bn2.num_batches_tracked\", \"module.layer3.4.conv3.weight\", \"module.layer3.4.bn3.weight\", \"module.layer3.4.bn3.bias\", \"module.layer3.4.bn3.running_mean\", \"module.layer3.4.bn3.running_var\", \"module.layer3.4.bn3.num_batches_tracked\", \"module.layer3.5.conv1.weight\", \"module.layer3.5.bn1.weight\", \"module.layer3.5.bn1.bias\", \"module.layer3.5.bn1.running_mean\", \"module.layer3.5.bn1.running_var\", \"module.layer3.5.bn1.num_batches_tracked\", \"module.layer3.5.conv2.weight\", \"module.layer3.5.bn2.weight\", \"module.layer3.5.bn2.bias\", \"module.layer3.5.bn2.running_mean\", \"module.layer3.5.bn2.running_var\", \"module.layer3.5.bn2.num_batches_tracked\", \"module.layer3.5.conv3.weight\", \"module.layer3.5.bn3.weight\", \"module.layer3.5.bn3.bias\", \"module.layer3.5.bn3.running_mean\", \"module.layer3.5.bn3.running_var\", \"module.layer3.5.bn3.num_batches_tracked\", \"module.layer4.0.conv1.weight\", \"module.layer4.0.bn1.weight\", \"module.layer4.0.bn1.bias\", \"module.layer4.0.bn1.running_mean\", \"module.layer4.0.bn1.running_var\", \"module.layer4.0.bn1.num_batches_tracked\", \"module.layer4.0.conv2.weight\", \"module.layer4.0.bn2.weight\", \"module.layer4.0.bn2.bias\", \"module.layer4.0.bn2.running_mean\", \"module.layer4.0.bn2.running_var\", \"module.layer4.0.bn2.num_batches_tracked\", \"module.layer4.0.conv3.weight\", \"module.layer4.0.bn3.weight\", \"module.layer4.0.bn3.bias\", \"module.layer4.0.bn3.running_mean\", \"module.layer4.0.bn3.running_var\", \"module.layer4.0.bn3.num_batches_tracked\", \"module.layer4.0.downsample.0.weight\", \"module.layer4.0.downsample.1.weight\", \"module.layer4.0.downsample.1.bias\", \"module.layer4.0.downsample.1.running_mean\", \"module.layer4.0.downsample.1.running_var\", \"module.layer4.0.downsample.1.num_batches_tracked\", \"module.layer4.1.conv1.weight\", \"module.layer4.1.bn1.weight\", \"module.layer4.1.bn1.bias\", \"module.layer4.1.bn1.running_mean\", \"module.layer4.1.bn1.running_var\", \"module.layer4.1.bn1.num_batches_tracked\", \"module.layer4.1.conv2.weight\", \"module.layer4.1.bn2.weight\", \"module.layer4.1.bn2.bias\", \"module.layer4.1.bn2.running_mean\", \"module.layer4.1.bn2.running_var\", \"module.layer4.1.bn2.num_batches_tracked\", \"module.layer4.1.conv3.weight\", \"module.layer4.1.bn3.weight\", \"module.layer4.1.bn3.bias\", \"module.layer4.1.bn3.running_mean\", \"module.layer4.1.bn3.running_var\", \"module.layer4.1.bn3.num_batches_tracked\", \"module.layer4.2.conv1.weight\", \"module.layer4.2.bn1.weight\", \"module.layer4.2.bn1.bias\", \"module.layer4.2.bn1.running_mean\", \"module.layer4.2.bn1.running_var\", \"module.layer4.2.bn1.num_batches_tracked\", \"module.layer4.2.conv2.weight\", \"module.layer4.2.bn2.weight\", \"module.layer4.2.bn2.bias\", \"module.layer4.2.bn2.running_mean\", \"module.layer4.2.bn2.running_var\", \"module.layer4.2.bn2.num_batches_tracked\", \"module.layer4.2.conv3.weight\", \"module.layer4.2.bn3.weight\", \"module.layer4.2.bn3.bias\", \"module.layer4.2.bn3.running_mean\", \"module.layer4.2.bn3.running_var\", \"module.layer4.2.bn3.num_batches_tracked\", \"module.fc.weight\", \"module.fc.bias\". "
     ]
    }
   ],
   "source": [
    "weights_dir = f'/mnt/DataDrive3/vlad/kornet/modelling/weights'\n",
    "model = resnet50(weights=None)\n",
    "\n",
    "checkpoint = torch.load(f'{weights_dir}/resnet50_imagenet_sketch_best_1.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "transform = ResNet50_Weights.DEFAULT.transforms()\n",
    "layer_call = \"getattr(model,'avgpool')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 14,\n",
       " 'arch': 'resnet50',\n",
       " 'state_dict': OrderedDict([('module.conv1.weight',\n",
       "               tensor([[[[-6.7425e-04,  1.3004e-02,  4.1607e-02,  ...,  5.3603e-02,\n",
       "                          -1.8749e-02,  1.5226e-02],\n",
       "                         [-7.1417e-02,  3.4239e-02,  6.1854e-02,  ...,  8.7955e-02,\n",
       "                           2.2081e-02, -6.1213e-02],\n",
       "                         [ 4.1784e-02, -2.7154e-01,  3.6395e-01,  ..., -1.5513e-01,\n",
       "                           1.9652e-01, -7.4958e-02],\n",
       "                         ...,\n",
       "                         [-1.0779e-01,  3.5464e-01, -4.2913e-01,  ...,  6.3482e-01,\n",
       "                          -5.5145e-01,  2.1330e-01],\n",
       "                         [ 8.2388e-03, -1.7560e-01,  6.1114e-01,  ...,  4.7938e-01,\n",
       "                          -5.3496e-02, -7.1345e-02],\n",
       "                         [ 4.5681e-02, -1.1858e-01,  2.4585e-02,  ..., -3.3613e-01,\n",
       "                           1.7427e-01, -4.0522e-02]],\n",
       "               \n",
       "                        [[ 1.7564e-02,  1.9389e-02, -1.3117e-02,  ...,  9.0949e-02,\n",
       "                          -6.0066e-02,  2.9906e-02],\n",
       "                         [-4.4167e-02,  3.2326e-02,  7.0768e-02,  ...,  1.1854e-01,\n",
       "                           2.0608e-02, -3.5691e-02],\n",
       "                         [ 3.4730e-02, -2.6245e-01,  3.8876e-01,  ..., -2.1751e-01,\n",
       "                           3.0186e-01, -1.0465e-01],\n",
       "                         ...,\n",
       "                         [-1.1611e-01,  5.0013e-01, -6.1587e-01,  ...,  8.8345e-01,\n",
       "                          -7.3624e-01,  2.3004e-01],\n",
       "                         [-2.7495e-02, -1.2872e-01,  6.8704e-01,  ...,  6.2675e-01,\n",
       "                          -4.3405e-02, -7.5714e-02],\n",
       "                         [ 6.7711e-02, -9.8023e-02,  6.9231e-02,  ..., -3.8074e-01,\n",
       "                           2.1781e-01, -6.5657e-02]],\n",
       "               \n",
       "                        [[ 1.5024e-02,  3.3794e-02, -2.9438e-02,  ...,  5.1473e-02,\n",
       "                          -4.9543e-02,  4.7337e-02],\n",
       "                         [-1.0405e-02,  5.5957e-02, -2.8278e-02,  ...,  8.7101e-02,\n",
       "                          -2.4874e-02,  2.4449e-02],\n",
       "                         [ 2.8890e-02, -1.3368e-01,  2.3669e-01,  ..., -8.3291e-03,\n",
       "                           8.9753e-02, -5.1641e-02],\n",
       "                         ...,\n",
       "                         [-9.8223e-02,  2.2699e-01, -1.9339e-01,  ...,  3.8350e-01,\n",
       "                          -4.2951e-01,  1.7333e-01],\n",
       "                         [ 3.9226e-02, -2.2484e-01,  4.5507e-01,  ...,  2.8748e-01,\n",
       "                          -3.5369e-02, -6.3658e-02],\n",
       "                         [ 5.8567e-02, -3.7943e-02, -4.3851e-02,  ..., -2.2519e-01,\n",
       "                           1.6340e-01, -4.8885e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.8942e-02,  1.1276e-02,  6.1525e-03,  ...,  6.5291e-03,\n",
       "                          -1.5495e-02, -4.7735e-02],\n",
       "                         [-9.0795e-03, -2.2298e-02, -2.1148e-02,  ...,  3.9371e-03,\n",
       "                          -1.4593e-02, -3.9159e-03],\n",
       "                         [-3.1668e-02, -1.4455e-01, -2.5394e-01,  ..., -2.3757e-01,\n",
       "                          -1.1600e-01, -3.2387e-02],\n",
       "                         ...,\n",
       "                         [ 1.2860e-01,  4.3958e-01,  6.3923e-01,  ...,  6.0344e-01,\n",
       "                           3.2345e-01,  1.5123e-01],\n",
       "                         [-1.2481e-01, -4.2014e-01, -6.8515e-01,  ..., -5.5688e-01,\n",
       "                          -2.5554e-01, -8.7806e-02],\n",
       "                         [-1.3378e-02,  8.4459e-03,  1.6231e-02,  ...,  1.8833e-02,\n",
       "                          -3.6873e-02, -4.8478e-02]],\n",
       "               \n",
       "                        [[-2.1224e-02,  3.2803e-04,  4.5704e-03,  ..., -1.4764e-02,\n",
       "                          -1.4698e-02, -3.0409e-02],\n",
       "                         [-3.3739e-03, -2.3421e-02, -2.9405e-02,  ..., -7.4045e-03,\n",
       "                          -2.4319e-02,  5.9754e-03],\n",
       "                         [-4.9311e-02, -1.8795e-01, -2.9984e-01,  ..., -2.7270e-01,\n",
       "                          -1.5039e-01, -4.8557e-02],\n",
       "                         ...,\n",
       "                         [ 1.8908e-01,  4.5389e-01,  6.8372e-01,  ...,  6.5954e-01,\n",
       "                           3.5826e-01,  2.1003e-01],\n",
       "                         [-1.8260e-01, -5.2190e-01, -7.9877e-01,  ..., -6.4653e-01,\n",
       "                          -3.1492e-01, -1.3027e-01],\n",
       "                         [-2.6515e-02, -3.5806e-03,  1.4308e-02,  ...,  1.7284e-02,\n",
       "                          -7.8910e-03, -3.2570e-02]],\n",
       "               \n",
       "                        [[-2.2333e-02, -1.0261e-02,  2.4291e-03,  ..., -2.0883e-02,\n",
       "                          -1.4588e-02, -9.3245e-03],\n",
       "                         [-1.1219e-02, -1.5673e-02, -2.5917e-03,  ...,  1.0726e-02,\n",
       "                          -2.1487e-02, -1.7465e-02],\n",
       "                         [-1.5210e-03, -7.0191e-02, -9.3729e-02,  ..., -7.9401e-02,\n",
       "                          -2.3065e-02,  7.4137e-03],\n",
       "                         ...,\n",
       "                         [ 4.6390e-02,  1.6049e-01,  3.2603e-01,  ...,  2.4379e-01,\n",
       "                           1.1212e-01,  6.4326e-02],\n",
       "                         [-4.0118e-02, -2.0625e-01, -3.2800e-01,  ..., -2.5671e-01,\n",
       "                          -9.3407e-02, -7.9756e-03],\n",
       "                         [-9.3790e-03,  4.4667e-02,  8.0512e-02,  ...,  3.7550e-02,\n",
       "                          -1.2945e-02, -4.9354e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.2618e-02, -2.9172e-02, -2.1160e-02,  ...,  2.5634e-03,\n",
       "                          -3.1580e-02, -3.4101e-02],\n",
       "                         [-1.2380e-02,  3.3671e-03, -2.4189e-03,  ..., -2.5505e-02,\n",
       "                          -2.1577e-02,  1.3572e-02],\n",
       "                         [-4.7184e-02, -1.9342e-02, -1.4603e-02,  ..., -1.0683e-02,\n",
       "                          -3.0043e-02, -3.3687e-02],\n",
       "                         ...,\n",
       "                         [-2.1108e-02, -3.7507e-02, -3.5991e-02,  ...,  2.0152e-01,\n",
       "                           7.0645e-02, -4.7108e-02],\n",
       "                         [ 4.5904e-03, -3.1929e-02, -4.6621e-02,  ...,  5.6602e-02,\n",
       "                           5.7613e-03, -3.9034e-02],\n",
       "                         [ 1.5544e-02, -4.2798e-02, -5.7833e-02,  ..., -2.4156e-02,\n",
       "                          -4.0683e-02, -5.6307e-02]],\n",
       "               \n",
       "                        [[-3.3792e-02, -2.5191e-02, -4.3321e-02,  ..., -2.6440e-02,\n",
       "                          -5.4965e-02, -2.1273e-02],\n",
       "                         [-1.8901e-02,  8.1244e-03,  1.2900e-02,  ...,  4.5569e-02,\n",
       "                           1.0566e-02,  4.9974e-02],\n",
       "                         [-8.9132e-02, -3.1159e-04,  9.1146e-02,  ...,  2.9370e-01,\n",
       "                           1.3866e-01,  6.0946e-02],\n",
       "                         ...,\n",
       "                         [-4.2648e-02,  3.6998e-02,  2.4858e-01,  ...,  7.8415e-01,\n",
       "                           4.2164e-01,  1.2280e-01],\n",
       "                         [-3.9161e-02, -2.7314e-02,  1.1525e-01,  ...,  4.4780e-01,\n",
       "                           1.7074e-01,  2.6812e-02],\n",
       "                         [-1.9004e-02, -1.2398e-02,  4.5914e-03,  ...,  1.5609e-01,\n",
       "                           3.9065e-02,  4.9498e-02]],\n",
       "               \n",
       "                        [[ 3.1529e-02,  1.1134e-02,  3.6735e-02,  ...,  4.1002e-02,\n",
       "                           4.2372e-02,  2.7077e-02],\n",
       "                         [ 1.6265e-02, -6.0535e-03,  3.7982e-02,  ..., -2.4563e-02,\n",
       "                           1.9661e-02,  1.1024e-03],\n",
       "                         [ 1.4895e-02,  2.0089e-02,  1.9698e-02,  ..., -3.3930e-01,\n",
       "                          -1.2471e-01,  8.5782e-03],\n",
       "                         ...,\n",
       "                         [ 7.0859e-02, -2.1197e-02, -3.2710e-01,  ..., -1.0017e+00,\n",
       "                          -5.0108e-01, -5.0915e-02],\n",
       "                         [ 7.7690e-02,  3.6849e-02, -1.1379e-01,  ..., -5.0834e-01,\n",
       "                          -1.9439e-01,  8.5633e-03],\n",
       "                         [ 6.3129e-02, -1.5593e-02,  3.4184e-03,  ..., -6.1665e-02,\n",
       "                           5.0634e-02,  5.3389e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-3.3890e-02,  4.7342e-02,  4.6656e-02,  ...,  1.0134e-01,\n",
       "                           3.7536e-02,  4.8692e-02],\n",
       "                         [ 4.8070e-02,  2.3523e-01,  3.8743e-01,  ...,  5.5218e-01,\n",
       "                           4.7211e-01,  3.1171e-01],\n",
       "                         [-1.6476e-02,  1.4052e-01,  3.3357e-01,  ...,  6.3458e-01,\n",
       "                           5.2666e-01,  3.1285e-01],\n",
       "                         ...,\n",
       "                         [-2.1689e-02, -6.5071e-02, -1.7311e-01,  ..., -3.4271e-01,\n",
       "                          -2.9628e-01, -1.7079e-01],\n",
       "                         [ 4.8198e-04, -1.5249e-01, -3.3274e-01,  ..., -6.4507e-01,\n",
       "                          -5.6630e-01, -2.9954e-01],\n",
       "                         [-7.6128e-02, -2.0653e-01, -3.6361e-01,  ..., -6.1479e-01,\n",
       "                          -5.2718e-01, -3.1756e-01]],\n",
       "               \n",
       "                        [[ 2.3104e-02,  3.6494e-02,  7.2710e-03,  ...,  2.5877e-02,\n",
       "                           8.0854e-03,  1.1225e-02],\n",
       "                         [ 2.6207e-03,  2.2745e-02, -3.7156e-02,  ..., -1.1703e-01,\n",
       "                          -8.3601e-02, -5.8563e-02],\n",
       "                         [-2.4341e-02, -3.2985e-02, -8.4403e-02,  ..., -6.8962e-02,\n",
       "                          -5.4585e-02, -3.6057e-02],\n",
       "                         ...,\n",
       "                         [ 1.4059e-02,  3.8314e-02, -2.3912e-04,  ...,  2.0229e-02,\n",
       "                           2.0905e-03,  5.3630e-02],\n",
       "                         [-5.8509e-03,  5.0603e-02,  5.9572e-02,  ...,  5.2966e-02,\n",
       "                           4.8143e-02,  8.2046e-02],\n",
       "                         [-2.8987e-02,  5.9044e-02,  5.0177e-02,  ...,  6.8391e-02,\n",
       "                           7.1289e-02,  7.8922e-02]],\n",
       "               \n",
       "                        [[ 3.6475e-02,  1.3096e-02, -6.0136e-03,  ..., -4.0037e-02,\n",
       "                          -3.8852e-02, -2.2928e-02],\n",
       "                         [-3.7875e-02, -1.2548e-01, -2.6372e-01,  ..., -5.3663e-01,\n",
       "                          -4.3444e-01, -2.5277e-01],\n",
       "                         [ 3.1401e-02, -9.5164e-02, -3.3164e-01,  ..., -5.7344e-01,\n",
       "                          -4.5948e-01, -2.5366e-01],\n",
       "                         ...,\n",
       "                         [-1.1092e-02,  9.0470e-02,  1.5983e-01,  ...,  3.2113e-01,\n",
       "                           2.6297e-01,  1.8436e-01],\n",
       "                         [-4.2268e-02,  1.5925e-01,  3.1154e-01,  ...,  5.8803e-01,\n",
       "                           4.6570e-01,  2.9630e-01],\n",
       "                         [ 1.2115e-02,  1.9016e-01,  3.4477e-01,  ...,  5.0320e-01,\n",
       "                           4.3383e-01,  2.7977e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-7.1775e-02, -1.1967e-02,  1.3524e-01,  ..., -2.8762e-02,\n",
       "                           6.5526e-03, -4.4825e-02],\n",
       "                         [ 1.8600e-02,  1.4840e-01,  2.1900e-01,  ..., -7.3349e-02,\n",
       "                           4.0495e-02, -6.1988e-02],\n",
       "                         [ 1.4262e-01,  2.5851e-01, -1.3993e-01,  ..., -1.6807e-01,\n",
       "                           2.5016e-01,  2.8956e-03],\n",
       "                         ...,\n",
       "                         [-2.1593e-02, -9.6745e-02, -2.0377e-01,  ...,  1.8151e+00,\n",
       "                           4.1605e-01, -4.1045e-01],\n",
       "                         [ 3.6132e-02,  8.5484e-02,  1.4744e-01,  ...,  4.9965e-01,\n",
       "                          -7.1761e-01, -5.5080e-01],\n",
       "                         [ 2.7193e-03, -1.1495e-02, -5.7575e-03,  ..., -2.5437e-01,\n",
       "                          -5.6322e-01,  1.5845e-02]],\n",
       "               \n",
       "                        [[ 3.4628e-02, -3.2113e-02, -3.2664e-02,  ..., -2.4703e-02,\n",
       "                          -1.8660e-02, -3.0697e-02],\n",
       "                         [-2.3001e-02, -1.0507e-01, -2.5377e-02,  ...,  1.0411e-02,\n",
       "                          -4.2155e-02, -8.4043e-03],\n",
       "                         [-2.3274e-02, -3.2790e-02,  2.3958e-01,  ...,  6.2581e-02,\n",
       "                          -8.4446e-03,  2.1125e-02],\n",
       "                         ...,\n",
       "                         [-1.5768e-02, -2.6698e-02,  6.8861e-02,  ..., -5.9712e-01,\n",
       "                          -1.5573e-01,  5.2750e-02],\n",
       "                         [-9.3921e-03, -6.9163e-02, -4.0234e-03,  ..., -2.0183e-01,\n",
       "                           1.5148e-01,  1.7313e-01],\n",
       "                         [ 4.7100e-02,  1.8765e-02,  4.7386e-02,  ..., -1.1347e-02,\n",
       "                           1.6661e-01,  8.1954e-02]],\n",
       "               \n",
       "                        [[ 4.1741e-03,  1.2255e-02, -1.2712e-01,  ...,  3.0024e-02,\n",
       "                          -3.3415e-02, -4.1579e-02],\n",
       "                         [ 5.6896e-02, -3.3822e-02, -1.7736e-01,  ...,  6.2124e-02,\n",
       "                          -5.1915e-02,  2.5147e-02],\n",
       "                         [-8.3197e-02, -2.1832e-01, -6.6634e-02,  ...,  9.5262e-02,\n",
       "                          -2.3094e-01, -5.4226e-02],\n",
       "                         ...,\n",
       "                         [ 2.6644e-02,  5.7476e-02,  1.0617e-01,  ..., -1.2164e+00,\n",
       "                          -2.1773e-01,  3.5417e-01],\n",
       "                         [-1.6548e-02, -6.5040e-02, -1.9215e-01,  ..., -3.6359e-01,\n",
       "                           5.0231e-01,  3.4686e-01],\n",
       "                         [ 3.6111e-02,  2.8202e-02, -4.8715e-02,  ...,  2.3972e-01,\n",
       "                           3.6592e-01, -7.6417e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.6492e-02, -1.0466e-03, -1.6502e-02,  ..., -2.4876e-02,\n",
       "                          -1.0779e-03,  2.6557e-02],\n",
       "                         [ 2.6787e-02,  3.5330e-02,  3.0446e-02,  ...,  7.9430e-02,\n",
       "                          -7.3451e-02, -5.3868e-02],\n",
       "                         [-2.7125e-02,  2.4561e-02, -1.2446e-01,  ...,  1.8539e-01,\n",
       "                           2.5403e-01,  4.0220e-02],\n",
       "                         ...,\n",
       "                         [ 9.3072e-03, -2.6223e-02,  2.2635e-02,  ...,  2.8811e-01,\n",
       "                          -8.7414e-02,  2.4707e-02],\n",
       "                         [-1.8641e-02, -1.9110e-02, -1.4991e-01,  ...,  4.1360e-02,\n",
       "                           7.4508e-02, -5.1084e-02],\n",
       "                         [-1.8684e-03,  1.5142e-02,  5.1577e-02,  ..., -3.6080e-02,\n",
       "                          -1.8904e-02,  1.7384e-03]],\n",
       "               \n",
       "                        [[-4.2233e-02,  8.8384e-03,  8.5122e-02,  ..., -3.9495e-02,\n",
       "                          -5.6604e-02, -1.0364e-02],\n",
       "                         [-7.2304e-02, -9.9498e-02, -2.8457e-02,  ...,  4.4115e-01,\n",
       "                           1.2816e-01, -2.8704e-02],\n",
       "                         [-4.9065e-02, -1.0078e-01, -5.4925e-01,  ...,  1.4899e-01,\n",
       "                           5.7670e-01,  3.6429e-01],\n",
       "                         ...,\n",
       "                         [ 7.5374e-02,  7.8762e-02,  3.4767e-01,  ...,  4.6230e-01,\n",
       "                          -4.4955e-01, -3.2480e-01],\n",
       "                         [-3.8390e-02, -6.5866e-02, -1.9387e-01,  ...,  3.6978e-01,\n",
       "                           3.1618e-01, -1.0157e-01],\n",
       "                         [-3.8168e-02, -1.2632e-02, -1.2708e-02,  ..., -7.4156e-02,\n",
       "                           9.6128e-02,  6.3231e-02]],\n",
       "               \n",
       "                        [[-2.1559e-02,  4.3873e-02,  7.3636e-02,  ..., -8.1712e-02,\n",
       "                          -5.6768e-02,  1.6631e-02],\n",
       "                         [-7.9305e-02, -1.0386e-01, -1.2461e-02,  ...,  3.1403e-01,\n",
       "                          -3.0004e-02, -9.9542e-02],\n",
       "                         [-4.9989e-02, -5.9851e-02, -4.1365e-01,  ...,  1.8324e-01,\n",
       "                           4.8112e-01,  1.8249e-01],\n",
       "                         ...,\n",
       "                         [ 6.2892e-02,  8.5775e-03,  1.7971e-01,  ...,  3.8049e-01,\n",
       "                          -3.7606e-01, -2.7717e-01],\n",
       "                         [-2.0757e-02, -2.6523e-02, -1.6550e-01,  ...,  2.9129e-01,\n",
       "                           3.1619e-01, -5.6119e-02],\n",
       "                         [-2.7931e-02,  5.0471e-03,  5.2171e-03,  ..., -6.6221e-02,\n",
       "                           8.9810e-02,  8.8122e-02]]]], device='cuda:0')),\n",
       "              ('module.bn1.weight',\n",
       "               tensor([1.3749, 2.2499, 2.2629, 1.9897, 4.3275, 1.9525, 1.5218, 2.0490, 2.5960,\n",
       "                       1.9595, 1.6477, 1.9351, 6.3974, 2.4913, 1.8292, 2.1624, 1.6735, 2.1032,\n",
       "                       1.5787, 7.0308, 2.1753, 1.6066, 2.2542, 2.0863, 5.6169, 2.1183, 2.3400,\n",
       "                       2.0942, 1.4097, 8.8559, 1.6061, 1.9231, 5.8821, 2.0782, 2.2141, 2.0230,\n",
       "                       1.6336, 1.9423, 1.6170, 6.7453, 2.0742, 4.4007, 1.6839, 1.6156, 1.7494,\n",
       "                       1.5666, 1.6497, 1.6906, 1.4012, 1.9021, 1.3695, 1.3977, 4.1612, 1.4523,\n",
       "                       2.5041, 1.7900, 2.0173, 2.2833, 2.3991, 2.3213, 1.5375, 2.1615, 1.3696,\n",
       "                       1.5996], device='cuda:0')),\n",
       "              ('module.bn1.bias',\n",
       "               tensor([ 2.8925,  2.0931,  3.8543,  1.3616, -4.2325,  2.4393,  2.5466,  2.2919,\n",
       "                        1.1214,  1.9119,  2.5436,  6.0210, -6.1094,  1.0593,  2.3769,  5.0819,\n",
       "                        4.4564,  9.4188,  2.7366, 13.9435,  2.3881,  2.5085,  2.1894,  1.9921,\n",
       "                       -8.1740,  1.9892,  3.9595,  1.6142,  2.9908, 22.1347,  2.1520,  2.4570,\n",
       "                       -9.2102,  1.6895,  2.4197,  2.4733,  2.4303,  2.1523,  2.5268, 14.9916,\n",
       "                        1.7783, -2.9818,  2.5154,  2.7146,  2.5149,  2.5303,  2.2169,  2.3968,\n",
       "                        2.9655,  2.5597,  2.7051,  2.7732, -4.1168,  2.4677,  1.2475,  2.0837,\n",
       "                        2.0644,  3.7828,  4.6628,  2.5196,  2.4877,  1.8107,  2.7092,  2.5604],\n",
       "                      device='cuda:0')),\n",
       "              ('module.bn1.running_mean',\n",
       "               tensor([-7.1299e-03, -6.2973e-02, -9.9811e-01,  8.6138e-02,  1.0144e+00,\n",
       "                        1.8599e-01,  2.0167e-01,  1.0817e-01, -2.3991e-02, -2.0891e-01,\n",
       "                       -2.9674e-01, -2.4945e-01, -3.5499e+00,  1.3465e-01, -1.8909e-01,\n",
       "                        1.5902e-01,  2.1744e-01,  1.4316e-01,  1.0222e-01,  6.8391e+00,\n",
       "                       -2.4530e-01, -2.7652e-01, -4.8513e-01, -2.0243e-01,  1.1314e+00,\n",
       "                       -5.3988e-02,  7.5359e-01, -2.0987e-01, -3.9598e-02, -9.3128e+00,\n",
       "                       -4.8529e-01,  1.8568e-02,  1.4549e+00,  2.1339e-01, -1.1934e+00,\n",
       "                       -4.4424e-01, -2.3811e-04, -2.5576e-03, -1.4545e-01,  5.3029e+00,\n",
       "                        1.8751e-01, -2.1387e+00, -5.1109e-02, -2.3420e-02,  3.2034e-01,\n",
       "                       -1.9174e-01,  3.7158e-02, -5.2226e-02,  1.8406e-01,  4.9486e-03,\n",
       "                        7.3438e-02,  3.3885e-01, -1.3677e+00,  2.4227e-01,  6.3861e-02,\n",
       "                        1.0925e-01,  4.5887e-02,  1.1196e-01,  3.9361e-01, -1.0255e-01,\n",
       "                       -2.4694e-01,  1.7281e-01, -3.9567e-01, -8.4114e-02], device='cuda:0')),\n",
       "              ('module.bn1.running_var',\n",
       "               tensor([  0.7887,   7.2522,   7.0235,   8.7120,   4.2936,   2.7725,   2.0166,\n",
       "                         6.1042,  24.4916,   3.4500,   2.9984,   1.4639,  33.8029,  23.7300,\n",
       "                         2.9856,   9.9243,   3.4277,   3.1256,   1.2817, 127.2270,   8.4679,\n",
       "                         2.7021,  12.3284,   1.4638,   5.9581,   7.7944,   5.1174,   7.1404,\n",
       "                         0.5491, 235.9369,   1.4231,   2.7812,   6.4155,   1.5846,   6.3359,\n",
       "                         6.0374,   3.1984,   2.6065,   2.8872,  80.0436,   1.3456,  15.0277,\n",
       "                         2.8517,   2.7902,   3.2456,   2.7617,   3.3875,   3.0476,   0.7546,\n",
       "                         2.9068,   0.7252,   0.4738,  11.6284,   1.7722,  21.6086,   2.0322,\n",
       "                         5.9668,   6.9527,   6.8426,  16.3076,   2.6374,   1.5315,   0.5834,\n",
       "                         2.8434], device='cuda:0')),\n",
       "              ('module.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.0.conv1.weight',\n",
       "               tensor([[[[ 0.0832]],\n",
       "               \n",
       "                        [[ 0.0898]],\n",
       "               \n",
       "                        [[-0.0247]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0363]],\n",
       "               \n",
       "                        [[ 0.0232]],\n",
       "               \n",
       "                        [[ 0.0313]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0172]],\n",
       "               \n",
       "                        [[-0.4213]],\n",
       "               \n",
       "                        [[-0.0105]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0213]],\n",
       "               \n",
       "                        [[-0.0102]],\n",
       "               \n",
       "                        [[ 0.0132]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0151]],\n",
       "               \n",
       "                        [[ 0.1200]],\n",
       "               \n",
       "                        [[-0.0015]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0420]],\n",
       "               \n",
       "                        [[ 0.0109]],\n",
       "               \n",
       "                        [[-0.0151]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0305]],\n",
       "               \n",
       "                        [[ 0.0712]],\n",
       "               \n",
       "                        [[-0.1321]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0379]],\n",
       "               \n",
       "                        [[-0.0512]],\n",
       "               \n",
       "                        [[-0.0903]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0095]],\n",
       "               \n",
       "                        [[ 0.0793]],\n",
       "               \n",
       "                        [[ 0.1940]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0788]],\n",
       "               \n",
       "                        [[ 0.0367]],\n",
       "               \n",
       "                        [[-0.0719]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2444]],\n",
       "               \n",
       "                        [[ 0.0834]],\n",
       "               \n",
       "                        [[ 0.0241]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0222]],\n",
       "               \n",
       "                        [[-0.0304]],\n",
       "               \n",
       "                        [[-0.3260]]]], device='cuda:0')),\n",
       "              ('module.layer1.0.bn1.weight',\n",
       "               tensor([2.8525, 3.1562, 1.5534, 3.0840, 1.4639, 1.0700, 2.7598, 2.5009, 1.3084,\n",
       "                       1.2281, 2.4436, 1.8843, 1.0678, 3.7060, 1.0794, 1.2967, 1.3949, 3.0140,\n",
       "                       2.8760, 3.3403, 1.1321, 2.4864, 1.1529, 2.2104, 1.0593, 1.7831, 3.2081,\n",
       "                       1.1735, 3.2213, 4.1079, 3.6149, 2.4596, 3.5050, 5.2427, 2.9639, 2.5382,\n",
       "                       3.0221, 2.9212, 1.4537, 2.9789, 1.7081, 1.6754, 1.3726, 4.7680, 1.4494,\n",
       "                       0.9715, 3.4918, 2.4343, 3.0851, 1.4771, 1.4345, 0.8975, 4.5970, 1.3344,\n",
       "                       2.3518, 4.7013, 1.1563, 1.7711, 1.3380, 1.3494, 2.0653, 2.1755, 1.3792,\n",
       "                       3.6552], device='cuda:0')),\n",
       "              ('module.layer1.0.bn1.bias',\n",
       "               tensor([-5.8523e-01, -1.4860e+00, -1.0912e+00, -8.3680e-01, -5.8545e-01,\n",
       "                        7.0882e-01, -9.3757e-01, -3.5737e-01,  1.1585e+00,  9.7773e-01,\n",
       "                       -1.9424e-01,  6.6440e-01,  1.2772e+00, -2.2231e+00,  1.3402e+00,\n",
       "                        1.5534e+00,  3.5725e-01, -9.6798e-01, -7.8639e-01, -2.0274e+00,\n",
       "                        1.0987e+00,  3.2003e-01,  9.8006e-01,  6.1008e-01,  1.7964e+00,\n",
       "                        3.0230e+00, -1.3029e+00,  1.8296e+00, -4.5943e-01, -3.9459e+00,\n",
       "                        7.3318e+00, -9.7545e-01, -1.8285e+00, -6.9440e+00, -3.2597e-01,\n",
       "                       -2.4555e-03, -5.6192e-01, -1.4641e+00,  4.8262e-01, -2.3405e+00,\n",
       "                        1.6955e-01, -1.6217e+00,  1.2755e+00, -2.6842e+00,  1.2958e+00,\n",
       "                        1.0254e+00, -1.5033e+00, -1.5863e-01,  6.8026e+00,  2.4582e-01,\n",
       "                        5.9228e-01,  1.2464e+00, -2.4781e+00,  1.7189e+00, -2.0984e+00,\n",
       "                       -5.0888e+00,  7.5993e-01,  4.5199e-01,  1.3483e+00,  1.2950e+00,\n",
       "                        3.2895e+00, -1.1126e+00,  1.2732e+00, -1.4011e+00], device='cuda:0')),\n",
       "              ('module.layer1.0.bn1.running_mean',\n",
       "               tensor([ -9.4447,  -2.6256,   9.5557,  -9.8969,   2.4447,  -1.3135,  -7.9219,\n",
       "                        -4.6589,  -4.2546,   8.8155, -25.6512,  -1.7187,  -6.9646, -13.0498,\n",
       "                        -5.2645,  -1.9183, -12.5862,  -7.1538, -12.5715,   1.4787,  -2.5115,\n",
       "                        -4.3485,  -6.0870,  -4.7279,  -3.9341,   2.4410, -10.4789,   1.6495,\n",
       "                        -8.6043,  14.5492, -15.8827, -10.8765,  -1.5801,  17.5323, -10.4643,\n",
       "                        -4.2824,  -8.7141,  -7.2023,  -3.8998,   5.0623,  -4.8136,   7.2625,\n",
       "                        -2.0913,  -5.0398,  -6.5971,  -2.6203,  -5.9990,  -3.6263, -24.3049,\n",
       "                       -23.1718, -11.7641,  -4.6944, -11.3177,  -3.5478, -16.8393,  13.2511,\n",
       "                        -6.3080,  -3.1645,  -4.7378,   0.5061,  38.7327, -25.0525,  21.3272,\n",
       "                       -10.7743], device='cuda:0')),\n",
       "              ('module.layer1.0.bn1.running_var',\n",
       "               tensor([ 23.8398,  23.1033,   7.5422,  29.3796,   2.4166,   2.7001,  18.7055,\n",
       "                        15.8404,   7.2981,   5.5299,  18.1454,   6.7154,   2.0529,  41.9677,\n",
       "                         3.8918,   9.3163,  16.0518,  24.0908,  21.2938,  25.8257,   2.6262,\n",
       "                        27.6644,   2.3000,  19.1218,   3.8438,  19.0514,  18.2675,  11.7526,\n",
       "                        38.8833,  62.1562, 416.2205,  19.0424,  27.3932,  69.8511,  25.6651,\n",
       "                        28.1183,  27.0251,  21.1036,   6.7909,  42.3180,   6.8697,   3.7523,\n",
       "                         3.9475,  50.7411,   7.2230,   2.2630,  25.7065,  19.9031, 239.3938,\n",
       "                        30.3923,  18.9051,   1.8580,  59.3308,   4.8660,   9.3211,  73.4340,\n",
       "                         2.8534,  21.8907,   9.0168,   7.6976, 139.2561,  16.3323,  32.6308,\n",
       "                        40.9503], device='cuda:0')),\n",
       "              ('module.layer1.0.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.0.conv2.weight',\n",
       "               tensor([[[[-2.5367e-02,  1.5634e-02, -1.9193e-02],\n",
       "                         [ 3.0842e-02,  1.0938e-01,  3.7912e-02],\n",
       "                         [-2.2272e-02,  1.9999e-02, -2.6071e-02]],\n",
       "               \n",
       "                        [[-4.3924e-03, -7.4589e-03, -5.8152e-03],\n",
       "                         [-5.2602e-03,  2.4876e-02, -2.9421e-04],\n",
       "                         [ 2.9195e-03,  1.2672e-03, -5.7543e-03]],\n",
       "               \n",
       "                        [[ 7.0246e-03,  1.3019e-02,  8.6861e-03],\n",
       "                         [-7.5999e-03, -2.4992e-02, -1.7137e-02],\n",
       "                         [ 2.1516e-02,  2.0124e-02,  2.4482e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.7341e-02, -7.0805e-03, -5.7566e-03],\n",
       "                         [ 9.5524e-03,  2.3935e-02,  9.0845e-04],\n",
       "                         [ 2.5731e-02,  2.7250e-02, -1.6511e-04]],\n",
       "               \n",
       "                        [[ 6.2055e-02, -7.0790e-03,  4.7551e-02],\n",
       "                         [-2.6234e-02, -1.4609e-01, -6.3758e-02],\n",
       "                         [ 2.1726e-02, -4.0937e-02,  1.5489e-02]],\n",
       "               \n",
       "                        [[-3.2545e-03,  1.7377e-04, -1.1730e-02],\n",
       "                         [-1.4422e-03,  5.3801e-02,  7.7222e-03],\n",
       "                         [-2.3896e-02, -5.1549e-03, -4.1266e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4689e-02,  1.0975e-02,  5.1598e-03],\n",
       "                         [-1.2735e-02,  3.5290e-02,  2.5320e-02],\n",
       "                         [-2.2504e-02,  2.6379e-02,  9.8312e-03]],\n",
       "               \n",
       "                        [[-6.2246e-04,  5.7756e-02,  3.3279e-02],\n",
       "                         [ 4.3898e-02,  1.7477e-01,  6.1678e-02],\n",
       "                         [-1.7512e-02,  4.6404e-02,  6.7475e-04]],\n",
       "               \n",
       "                        [[ 1.8208e-02, -3.7945e-02, -3.3038e-02],\n",
       "                         [ 4.4738e-02,  7.7677e-02,  7.5930e-02],\n",
       "                         [ 3.6564e-02,  4.4450e-02,  4.1839e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.2470e-02,  2.8734e-02,  2.1095e-02],\n",
       "                         [ 3.2541e-02,  5.6001e-02,  3.5716e-02],\n",
       "                         [ 2.5301e-02,  3.1106e-02,  2.1292e-02]],\n",
       "               \n",
       "                        [[-5.3576e-02, -6.9559e-02, -8.5345e-02],\n",
       "                         [-4.4641e-02, -4.8396e-02, -5.6427e-02],\n",
       "                         [-3.6394e-02, -3.3167e-02, -5.7271e-02]],\n",
       "               \n",
       "                        [[ 2.5275e-03,  7.6724e-02,  9.4160e-03],\n",
       "                         [ 4.3250e-02,  2.4485e-01,  7.7655e-02],\n",
       "                         [-1.0317e-02,  6.9899e-02,  6.3930e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.6944e-02, -4.4111e-03,  3.4030e-02],\n",
       "                         [ 3.6547e-02, -6.1811e-02,  3.2373e-03],\n",
       "                         [ 2.6998e-02,  1.4094e-02,  2.8813e-02]],\n",
       "               \n",
       "                        [[-4.1467e-02,  2.2439e-02, -9.2047e-03],\n",
       "                         [-3.0045e-02,  4.8182e-02,  3.3586e-02],\n",
       "                         [ 1.1821e-02,  2.1463e-03,  1.1782e-02]],\n",
       "               \n",
       "                        [[ 7.3521e-03, -4.3333e-02, -1.7553e-02],\n",
       "                         [-4.8830e-02,  9.7222e-02, -2.0448e-02],\n",
       "                         [ 4.2798e-02,  7.9159e-02,  3.3459e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.4830e-03, -3.9677e-03, -1.5082e-02],\n",
       "                         [ 4.5017e-02, -4.9037e-02, -3.3540e-03],\n",
       "                         [-2.2936e-02,  1.5054e-02, -4.0422e-02]],\n",
       "               \n",
       "                        [[-2.1868e-02, -6.0437e-02, -7.1210e-02],\n",
       "                         [-1.1985e-01,  1.5933e-01, -8.3884e-02],\n",
       "                         [-2.8279e-02,  5.5007e-03,  1.1561e-02]],\n",
       "               \n",
       "                        [[ 3.6868e-02,  2.8105e-02,  4.2205e-03],\n",
       "                         [-9.8365e-03, -2.8228e-02, -3.0911e-02],\n",
       "                         [ 3.1324e-02,  5.9420e-03,  2.6852e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.4931e-02,  6.8965e-02, -9.9141e-03],\n",
       "                         [ 1.2771e-01,  9.6586e-02, -2.4963e-02],\n",
       "                         [ 3.8745e-02,  1.3247e-02, -3.6632e-02]],\n",
       "               \n",
       "                        [[-6.7078e-02, -1.5285e-02, -3.8468e-02],\n",
       "                         [ 1.3098e-02,  2.3603e-01, -5.8544e-03],\n",
       "                         [-1.5130e-02, -4.1815e-02, -3.5459e-02]],\n",
       "               \n",
       "                        [[-5.2084e-04,  8.9625e-03,  4.4846e-02],\n",
       "                         [-4.2666e-02, -3.1453e-02, -3.2570e-02],\n",
       "                         [ 1.6199e-02, -8.4211e-03, -3.5787e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.4394e-02,  3.9905e-02,  4.3731e-02],\n",
       "                         [ 2.3170e-02,  6.6278e-02,  1.9921e-02],\n",
       "                         [ 9.3851e-03,  5.6821e-03,  5.8064e-03]],\n",
       "               \n",
       "                        [[-1.1699e-03, -5.4501e-02,  1.8321e-02],\n",
       "                         [-4.4267e-02, -6.9799e-02, -1.4260e-02],\n",
       "                         [ 2.5546e-02,  8.1269e-03,  5.2748e-02]],\n",
       "               \n",
       "                        [[ 4.3703e-02,  2.1119e-02, -5.2213e-02],\n",
       "                         [ 2.3532e-03,  1.9773e-01,  4.1200e-02],\n",
       "                         [-6.5432e-02, -2.2878e-02,  1.0451e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0940e-02, -3.1890e-03,  2.1304e-03],\n",
       "                         [ 2.2783e-02,  7.0015e-03,  8.3288e-03],\n",
       "                         [-1.8646e-02, -3.1682e-03,  1.4024e-02]],\n",
       "               \n",
       "                        [[-1.8383e-02, -1.4206e-03,  8.6167e-03],\n",
       "                         [-2.2112e-02,  3.0389e-02,  3.1780e-04],\n",
       "                         [ 8.5095e-03, -4.3317e-04, -1.3360e-02]],\n",
       "               \n",
       "                        [[ 2.5641e-02,  2.2410e-03,  4.6334e-02],\n",
       "                         [-5.4571e-02, -1.0414e-01, -5.6443e-02],\n",
       "                         [-2.5400e-03,  1.2166e-02,  4.3626e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.3831e-03,  1.5545e-02,  1.5576e-02],\n",
       "                         [ 1.2057e-02, -1.2679e-02, -8.6405e-03],\n",
       "                         [-7.7940e-03, -3.3716e-03, -1.7630e-02]],\n",
       "               \n",
       "                        [[-4.6322e-02, -1.1747e-01, -4.5503e-02],\n",
       "                         [-2.1722e-02, -5.4973e-02,  1.0238e-02],\n",
       "                         [ 3.5147e-02,  1.7078e-02,  3.8025e-02]],\n",
       "               \n",
       "                        [[-1.2215e-03,  2.1363e-02,  3.1090e-02],\n",
       "                         [ 3.6864e-02,  2.3507e-02,  3.0214e-02],\n",
       "                         [-2.4550e-02, -2.1736e-02,  7.9246e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3583e-02, -4.0732e-03,  9.0307e-03],\n",
       "                         [ 4.1571e-02, -5.5034e-04,  2.4833e-02],\n",
       "                         [ 6.3652e-02,  7.2665e-03,  1.3653e-02]],\n",
       "               \n",
       "                        [[ 8.6119e-03,  4.4260e-03,  1.2091e-02],\n",
       "                         [ 4.1531e-02, -1.4969e-03, -2.2573e-02],\n",
       "                         [ 2.5775e-02,  2.5995e-02,  4.8058e-03]],\n",
       "               \n",
       "                        [[-7.2671e-03,  5.4106e-03,  1.1083e-02],\n",
       "                         [ 6.6956e-02, -7.2328e-03, -3.6767e-02],\n",
       "                         [ 3.2195e-02,  8.6831e-03,  1.1559e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.1848e-02,  9.1571e-04,  2.2399e-02],\n",
       "                         [-5.5333e-03, -1.2995e-02,  3.1209e-02],\n",
       "                         [-1.5858e-02, -1.7691e-02,  1.6005e-02]],\n",
       "               \n",
       "                        [[-2.9021e-02, -1.2345e-02,  2.5232e-02],\n",
       "                         [ 2.5115e-03, -3.6820e-02, -7.6094e-02],\n",
       "                         [-5.0456e-02, -3.2182e-02, -1.9108e-02]],\n",
       "               \n",
       "                        [[ 1.4612e-02,  2.0514e-03, -1.4289e-02],\n",
       "                         [ 1.4626e-02, -1.2402e-02, -2.2884e-02],\n",
       "                         [ 2.1068e-02, -4.7486e-02, -1.6910e-02]]]], device='cuda:0')),\n",
       "              ('module.layer1.0.bn2.weight',\n",
       "               tensor([1.1506, 3.9194, 4.3295, 1.5306, 0.6438, 0.8293, 1.4014, 1.7964, 4.6989,\n",
       "                       3.7418, 1.1990, 2.1168, 0.7649, 2.2984, 0.7622, 1.4895, 1.6580, 2.0954,\n",
       "                       0.9527, 0.8438, 0.7138, 0.9164, 0.9977, 1.0449, 1.5596, 1.3813, 1.7904,\n",
       "                       1.0582, 1.4111, 0.6362, 1.3955, 2.6699, 1.0089, 2.2113, 0.6592, 1.4398,\n",
       "                       1.7926, 0.6421, 0.6903, 0.8911, 2.9099, 3.3033, 3.9584, 1.1593, 1.2630,\n",
       "                       1.0030, 1.1477, 0.8650, 1.4076, 0.7364, 0.6113, 1.0883, 0.6608, 2.2383,\n",
       "                       0.6445, 1.6450, 1.3428, 1.3903, 1.4501, 0.6295, 0.7911, 1.0519, 1.0904,\n",
       "                       1.0973], device='cuda:0')),\n",
       "              ('module.layer1.0.bn2.bias',\n",
       "               tensor([ -0.5086,  -8.5038,   9.7529,   0.4284,   1.8425,   1.3586,  -1.9343,\n",
       "                        -1.3407,  10.9334,  10.1033,   1.1444,  -3.6397,   3.0661,   4.9139,\n",
       "                         2.2378,  -0.7167,  -1.4116,  -2.8235,   0.6730,   0.3552,   1.3815,\n",
       "                        -0.4730,  -0.7648,   0.6326,   0.3878,  -2.1817,  -2.3635,  -0.9744,\n",
       "                         0.5442,   0.8477,   0.5852,   6.6849,   0.7573,  -3.9347,   1.8361,\n",
       "                         0.5752,  -2.9887,   2.7161,   3.1140,   0.1040,   7.2184, -14.2441,\n",
       "                        10.1186,   0.4820,   0.3273,   0.5027,  -0.1353,   0.6495,  -1.4852,\n",
       "                         3.0154,   0.9061,   0.7630,   0.8480,   4.6634,   2.6435,   0.3925,\n",
       "                        -1.3541,   0.6296,   0.1902,   2.5683,   3.4584,  -0.5109,   0.8028,\n",
       "                         0.2713], device='cuda:0')),\n",
       "              ('module.layer1.0.bn2.running_mean',\n",
       "               tensor([  4.2090,  -2.3284,   1.0010,   4.0716,   1.0854,   1.5812,   1.9802,\n",
       "                         1.8195,   3.5636,  -0.7525,  -4.8360,   0.8998,   0.1417,  -8.9361,\n",
       "                         1.9969,  -0.4341,  -2.5495, -23.1545,   6.1150,   3.4904,   5.9049,\n",
       "                         2.7645,  -1.1255,   1.8623,   6.0802,   0.8883,   2.3452,   2.2698,\n",
       "                         8.2092,   0.9256,   4.0772,  -1.8310,   2.5295,   0.3421,   1.4944,\n",
       "                         6.1832,   0.5475,   4.2118,  -1.0518,   2.6191,   1.0971, -10.7304,\n",
       "                        -7.7507,   2.9665,  -1.4020,   5.1397,  -1.8640,   7.6717,   0.0706,\n",
       "                        -1.6281,  -1.2498,   4.5861,  -0.3683,  -0.4095,   3.8762,   7.4357,\n",
       "                        -4.8289,   7.1827,   6.3019,  -7.0274,   0.4751,   1.9153,   3.5643,\n",
       "                         5.0408], device='cuda:0')),\n",
       "              ('module.layer1.0.bn2.running_var',\n",
       "               tensor([  6.2310,   5.1252,  74.5398,  37.5133,   4.7036,   2.7560,   3.8694,\n",
       "                         7.7220, 221.7683, 149.4532,   6.0997,   4.5901,   2.0720,  44.0154,\n",
       "                         2.9659,  17.7358,   5.7281,   9.1721,   4.2310,   4.3437,   2.9064,\n",
       "                         5.9768,   4.0068,   9.5656,  28.3874,   1.4565,   4.0031,   4.2799,\n",
       "                        15.9403,   3.8032,  17.6228,  35.7202,   3.9966,   7.2172,   1.5005,\n",
       "                        19.2886,   8.0650,   3.9327,  11.0302,   3.6187,  25.7073,  19.5571,\n",
       "                        67.0943,   9.6511,  20.6725,   5.5427,   6.3271,   4.8123,   2.0134,\n",
       "                         4.1998,   7.9742,  10.0168,   2.2692,  18.9976,   5.7254,  31.7025,\n",
       "                         2.3321,  24.1352,  26.9755,   7.6061,   4.8104,   2.3276,   8.9986,\n",
       "                         5.2546], device='cuda:0')),\n",
       "              ('module.layer1.0.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.0.conv3.weight',\n",
       "               tensor([[[[ 4.1042e-02]],\n",
       "               \n",
       "                        [[-2.2290e-02]],\n",
       "               \n",
       "                        [[ 1.8926e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.5936e-04]],\n",
       "               \n",
       "                        [[ 3.3669e-02]],\n",
       "               \n",
       "                        [[-2.8964e-05]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.0847e-02]],\n",
       "               \n",
       "                        [[ 4.4612e-02]],\n",
       "               \n",
       "                        [[-7.7061e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.4078e-02]],\n",
       "               \n",
       "                        [[-5.6977e-01]],\n",
       "               \n",
       "                        [[-1.1554e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0036e-03]],\n",
       "               \n",
       "                        [[ 3.9812e-02]],\n",
       "               \n",
       "                        [[ 7.9406e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.5870e-02]],\n",
       "               \n",
       "                        [[-6.5018e-02]],\n",
       "               \n",
       "                        [[-1.1753e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 7.4822e-02]],\n",
       "               \n",
       "                        [[ 1.3033e-01]],\n",
       "               \n",
       "                        [[-1.9281e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.2672e-02]],\n",
       "               \n",
       "                        [[-1.3398e-02]],\n",
       "               \n",
       "                        [[ 5.3492e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.6028e-02]],\n",
       "               \n",
       "                        [[-9.4866e-02]],\n",
       "               \n",
       "                        [[ 3.0836e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.6331e-02]],\n",
       "               \n",
       "                        [[ 8.2096e-03]],\n",
       "               \n",
       "                        [[-2.8704e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.0122e-01]],\n",
       "               \n",
       "                        [[-1.4701e-03]],\n",
       "               \n",
       "                        [[ 4.3732e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.3287e-02]],\n",
       "               \n",
       "                        [[ 6.6345e-03]],\n",
       "               \n",
       "                        [[ 3.2607e-02]]]], device='cuda:0')),\n",
       "              ('module.layer1.0.bn3.weight',\n",
       "               tensor([ 6.0338,  3.7093,  1.5832,  1.8510,  2.4746,  5.5776,  2.0581,  5.5824,\n",
       "                        2.4029,  3.2823,  2.2925,  4.0089,  2.4547,  2.8926,  3.5960,  2.8610,\n",
       "                        2.5226,  4.8337,  2.9065,  2.6353,  2.8065,  5.3233,  3.3440,  4.1002,\n",
       "                        3.5369,  4.1315,  2.7131,  1.2966,  3.5926,  4.6342,  3.1414,  2.5142,\n",
       "                        2.4282,  4.1465,  1.7643,  3.0939,  2.9137,  1.8127,  1.7075,  2.4931,\n",
       "                        4.8299,  2.1560,  1.5192,  4.8436,  1.9008,  0.4646,  0.7051,  1.2652,\n",
       "                        3.6604,  0.2414,  3.4106,  1.7664,  3.9947,  4.7677,  5.8714,  1.7773,\n",
       "                        2.4952,  1.4917,  1.7774,  5.0875,  1.0205,  4.2073,  6.3215,  2.5328,\n",
       "                        3.8301,  5.7363,  3.0094,  0.9088,  2.3288,  4.5785,  0.7467,  3.7324,\n",
       "                        1.7955,  2.2797,  3.0012,  2.1168,  1.5159,  5.1511,  1.1634,  4.1627,\n",
       "                        4.3508,  0.5618,  0.0385,  3.0568,  1.8824,  5.3987,  2.4899,  3.1732,\n",
       "                        3.7571,  5.7001,  1.0993,  3.5962,  1.1307,  1.9147,  2.5074,  2.3506,\n",
       "                        2.4115,  1.2433,  2.1737,  3.0036,  1.1520, -1.4916,  2.8476,  3.1125,\n",
       "                        2.6362,  5.3606,  2.5246,  2.0957,  1.6064,  1.5046,  5.3545,  3.9587,\n",
       "                        1.5958,  6.1653,  2.5548,  2.3402,  6.0127,  3.7785,  2.0644,  0.4025,\n",
       "                        2.7218,  2.2349,  3.2361,  2.6429,  5.7688,  4.9867,  4.9867,  0.1960,\n",
       "                        1.9727,  3.6761,  3.6162,  3.1150,  5.6093,  2.5357,  7.5538,  2.1149,\n",
       "                        2.8023,  3.8456,  6.3787,  2.8947,  2.5156,  3.9629,  3.7687,  1.5502,\n",
       "                        2.5763,  2.3912,  5.2813,  5.5622,  3.3871,  2.8824,  4.5568,  3.4564,\n",
       "                        1.6831,  3.9185,  5.6281,  2.4982,  0.9468,  0.4286,  2.9824,  2.8429,\n",
       "                        2.4106,  6.4084,  3.9640,  4.4746,  1.1150,  1.2876,  5.6701,  0.8405,\n",
       "                        3.1925,  6.2394,  0.7675,  4.0406,  3.7398,  1.6489,  2.0361,  3.2955,\n",
       "                        2.9773,  0.1519,  2.0914,  0.3692,  5.0870,  1.4290,  3.2176,  2.3372,\n",
       "                        1.0619,  3.9581,  4.0300,  1.8715,  5.6711,  2.8939,  2.3229,  5.3115,\n",
       "                        2.1441,  3.5101,  2.1201,  2.0471,  0.7599,  6.1982,  5.5847,  5.7457,\n",
       "                        2.5774,  3.5702,  6.7608,  2.0258,  3.1982,  5.7451,  0.0583,  3.2719,\n",
       "                        3.6437,  3.6411,  2.8516,  3.3010,  4.8944,  4.4797,  3.5620,  2.0940,\n",
       "                        3.5513,  5.5036,  0.2080,  3.2510,  2.8821,  3.9188,  1.1282,  4.3001,\n",
       "                        1.6551,  2.6132,  5.7843,  5.2705,  2.9822,  3.5686,  5.2120,  2.7144,\n",
       "                        0.8252,  4.0523,  6.0338,  2.3837,  2.0530,  1.9734,  5.2742,  1.8355,\n",
       "                        3.0321,  1.0647,  1.8406,  4.7154,  2.7874,  3.1502,  3.3742,  1.8533,\n",
       "                        4.4695,  6.4974,  0.6151,  2.4378,  3.5301,  6.0520,  4.6040,  3.2229],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer1.0.bn3.bias',\n",
       "               tensor([ 2.3546e-01, -1.6620e-01,  8.3207e-02, -1.0370e-01,  2.9988e-01,\n",
       "                        2.1317e-01, -9.0665e-01,  9.6451e-01, -1.7827e-02, -3.2768e-01,\n",
       "                       -3.1758e-01,  3.6302e-01,  7.0268e-01, -1.3713e+00,  2.6793e-01,\n",
       "                        1.8610e-01,  4.5852e-01,  1.0120e+00,  3.8054e-01, -4.5801e-02,\n",
       "                       -1.5319e-01, -1.6307e-01,  7.6082e-02,  3.7855e-01,  9.6311e-02,\n",
       "                        2.0810e-01, -7.8294e-02, -9.6362e-02,  1.8764e-01,  6.3421e-01,\n",
       "                       -5.4922e-01,  3.7878e-02, -4.5776e-01,  1.1067e+00,  2.0919e-01,\n",
       "                        8.5866e-01,  2.5298e-01,  9.1096e-02, -1.4358e-02,  1.4791e-01,\n",
       "                        3.7426e-01,  2.4550e-01, -2.5742e-01, -4.4934e-01,  1.2071e+00,\n",
       "                       -1.7906e+00, -1.4789e+00, -6.4716e-02,  1.1959e-01, -4.5561e-01,\n",
       "                        2.9454e-01, -3.3883e-01, -6.7595e-01,  3.4310e-01,  1.5330e-01,\n",
       "                        1.9440e-01, -1.2296e-02,  4.9381e-01, -6.8041e-03, -3.2731e-01,\n",
       "                       -1.0084e+00,  2.3899e+00, -2.4461e-02, -4.9196e-01, -3.8949e-02,\n",
       "                       -2.2297e-03, -5.2689e-01, -2.5298e-01,  8.7243e-02,  6.9762e-01,\n",
       "                       -1.3417e+00,  3.9074e-01,  1.7660e-02,  1.7762e-01, -1.3251e-01,\n",
       "                        5.3409e-01,  7.2290e-02,  4.2239e-01, -2.2870e+00,  1.6573e+00,\n",
       "                       -3.2820e-01, -2.0338e-01,  1.4607e+00,  2.5626e-01,  5.1940e-02,\n",
       "                        2.0793e-01,  3.6744e-02, -5.8545e-02,  2.4031e-01,  5.6120e-01,\n",
       "                        2.2076e-01,  1.7379e-01, -3.0075e-01, -3.5482e-01, -4.0325e-02,\n",
       "                        3.4374e-03,  4.4694e-02, -1.2970e+00,  2.6024e-01, -5.0168e-01,\n",
       "                       -1.9707e-01,  6.7229e-01, -1.4389e-01, -1.9458e-01,  1.9383e-01,\n",
       "                        6.8676e-01,  5.5491e-02,  4.8783e-01,  3.9068e-01,  6.3583e-02,\n",
       "                        2.2160e-02, -1.6673e-01, -7.1460e-02,  6.5797e-01, -6.0148e-01,\n",
       "                       -4.0996e-01, -6.6733e-01, -2.8378e-01, -7.4491e-01, -1.7306e+00,\n",
       "                       -7.7696e-01,  2.2120e-01, -2.7536e-03, -2.6442e-01, -7.9681e-01,\n",
       "                        9.0919e-01, -4.1642e-01, -6.2780e-02, -1.4550e-01, -4.7371e-01,\n",
       "                       -8.3001e-02, -1.5650e+00, -6.0826e-02, -3.4618e-01,  1.2594e-01,\n",
       "                        1.8166e-01,  5.3516e-01, -8.0788e-01, -4.1138e-01,  3.8423e-01,\n",
       "                       -2.5369e-01,  2.1028e+00,  5.2658e-01, -8.7385e-01, -3.1333e+00,\n",
       "                       -5.1176e-02,  4.2756e-02, -9.8258e-01, -5.9303e-01,  6.5094e-02,\n",
       "                        5.0569e-01,  4.7191e-02,  1.1274e-01, -2.7303e-01,  3.3496e-01,\n",
       "                        2.7231e-01, -6.4580e-01, -8.0042e-01,  1.1280e-02, -1.0103e-01,\n",
       "                       -1.1748e-01, -6.1622e-01,  1.5047e-01,  2.5875e-02, -1.1643e+00,\n",
       "                        9.8647e-02,  6.1678e-01, -4.3155e-01,  8.0646e-01, -1.6631e-01,\n",
       "                       -1.1954e+00, -5.4721e-01, -5.4398e-01,  1.0677e-01,  2.7033e-01,\n",
       "                        1.5063e-01,  4.6397e-01, -5.6366e-01,  1.8072e-01, -4.6392e-01,\n",
       "                       -5.4111e-04, -2.2803e+00,  9.4096e-01,  6.9753e-01,  2.7759e-01,\n",
       "                        3.7102e-01, -3.8810e-01,  2.7637e-01,  3.8891e-01, -2.5167e-01,\n",
       "                        1.0170e+00,  4.1323e-01,  6.3874e-02, -1.7096e-01, -1.3872e+00,\n",
       "                        4.6139e-02, -8.5055e-01,  1.5845e-03,  4.0606e-01, -4.0571e-02,\n",
       "                       -6.4761e-01,  1.5491e-01, -6.5580e-01, -2.5743e-01,  1.4896e+00,\n",
       "                       -2.6580e-01, -4.1620e-01,  4.5654e-01,  5.2339e-01, -4.0435e-01,\n",
       "                        4.1892e-01,  2.0483e-01, -5.9555e-01, -3.3193e-02,  9.6833e-01,\n",
       "                        1.5607e-01, -3.5127e-01, -2.4695e-01, -6.3479e-01, -2.5885e-01,\n",
       "                        2.6597e-01, -2.9930e-01, -1.2752e+00,  1.4192e-01,  8.3347e-01,\n",
       "                        1.5909e-01, -5.7373e-01,  1.2977e-02,  1.6227e-01,  1.1688e-01,\n",
       "                       -6.0914e-01, -5.6410e-02, -6.8760e-01, -9.0335e-01,  2.9500e-01,\n",
       "                       -3.5718e-01, -6.6605e-02,  1.2960e+00, -4.1190e-02, -3.2992e+00,\n",
       "                        5.9931e-01,  2.0473e+00, -1.9710e-02,  8.9855e-02, -2.7499e-04,\n",
       "                        7.7255e-01,  2.0514e-02, -5.1109e-01, -6.0976e-01, -2.9517e-01,\n",
       "                        5.5314e-01,  4.4238e-01,  2.2680e-01, -1.0013e-01,  7.9082e-01,\n",
       "                       -2.2741e+00], device='cuda:0')),\n",
       "              ('module.layer1.0.bn3.running_mean',\n",
       "               tensor([-4.6519e+00,  1.3225e+00,  2.0458e+00,  4.6942e-01,  3.1840e+00,\n",
       "                       -1.5098e+00, -3.2156e+00,  3.3272e-01, -7.0516e-01, -1.3481e+00,\n",
       "                        2.3637e+00, -1.2563e-01,  9.7947e+00, -1.4437e+00, -7.7504e-01,\n",
       "                       -3.5017e+00, -3.5656e+00, -3.6239e-01, -1.8094e+00, -4.8769e-02,\n",
       "                       -1.9639e+00,  1.0735e+00, -4.2197e+00,  4.5512e+00, -5.0067e+00,\n",
       "                        2.1441e-02,  1.0562e+00, -1.2097e+00,  1.5881e+00, -1.9017e+00,\n",
       "                        3.7795e+00,  1.0479e+00,  8.2922e-01,  6.9924e+00,  1.8475e+00,\n",
       "                       -5.7683e+00, -1.3270e+00,  3.8841e+00,  3.0355e+00, -1.3656e+00,\n",
       "                       -7.0338e+00,  1.4480e+00,  9.7909e-01,  1.4546e+00, -5.3049e+00,\n",
       "                        1.5429e+00,  6.4914e-01,  1.5223e+00, -3.9621e-01, -7.1272e-02,\n",
       "                        3.8343e+00, -1.8664e+00, -8.4621e-01,  1.3676e+00, -6.9714e-01,\n",
       "                        8.8751e-01,  1.6014e+00, -1.8150e+00, -2.0998e-01,  2.5785e+00,\n",
       "                        1.3924e+00,  1.3094e+00, -1.5836e-01, -3.6943e+00,  3.9013e+00,\n",
       "                        2.3937e+00,  4.8097e+00, -7.3314e-01, -9.4754e-01, -1.0346e+00,\n",
       "                       -2.8683e+00, -4.3456e+00,  2.6833e+00, -3.2478e+00, -1.6885e+00,\n",
       "                        1.8433e-01,  6.0188e-01, -2.5801e+00,  3.1744e+00, -1.3757e+00,\n",
       "                        3.5311e+00,  4.8948e-01, -6.3620e-02, -1.7889e+00, -1.1757e+00,\n",
       "                        3.3656e+00,  2.0316e+00, -3.1029e+00, -2.5800e+00, -1.3309e+00,\n",
       "                        3.5365e-02, -3.2912e+00, -2.1297e+00, -2.5662e-01, -1.1434e+00,\n",
       "                       -5.8870e-01, -2.4543e+00,  2.3102e+00, -6.6959e+00,  7.5339e-01,\n",
       "                       -8.1127e-01, -2.5732e+00,  1.4068e+00,  8.2725e-01, -2.0431e+00,\n",
       "                       -7.7235e-01, -2.6166e+00,  3.0671e+00,  2.8085e+00,  4.6572e-01,\n",
       "                       -1.5412e+00,  2.8101e+00, -6.8142e-01, -4.3125e+00,  2.1321e+00,\n",
       "                       -3.1265e+00, -2.2640e-02, -6.0840e-01,  5.3274e-01, -9.3145e-01,\n",
       "                       -1.8750e+00, -3.6314e-01,  2.9866e+00, -9.4839e-01, -2.0907e+00,\n",
       "                       -1.3941e+00, -9.5030e-01,  2.5344e+00, -8.2256e-01, -4.7054e-01,\n",
       "                       -3.2392e+00,  2.8740e+00, -3.0915e+00, -3.4192e+00, -1.0524e+00,\n",
       "                       -7.4482e-01, -1.1223e+00, -6.5335e-01,  1.3781e+00,  1.9231e+00,\n",
       "                        9.0206e-01,  1.9193e+00, -4.8452e+00, -1.0635e-01,  2.4700e+00,\n",
       "                       -4.6729e+00, -3.8667e+00, -5.3205e-01,  6.1189e-01,  1.2790e-01,\n",
       "                        6.4040e+00, -7.5125e+00, -5.1817e-01,  3.6782e+00, -5.0734e+00,\n",
       "                       -1.4841e+00,  8.2578e-01,  5.2340e-01,  6.4696e-01, -2.5901e-01,\n",
       "                        8.5056e-01, -3.7958e+00, -9.0219e-01,  1.0192e+00, -1.2802e-05,\n",
       "                        3.1233e+00, -2.0160e+00, -1.1538e+00,  3.3250e+00, -2.2207e+00,\n",
       "                       -1.3020e-04, -3.7028e-01, -2.7718e-01,  2.0711e+00, -9.8621e-01,\n",
       "                        6.5673e-01,  2.4362e+00,  4.0173e-07, -2.9327e-01,  2.6591e-02,\n",
       "                       -1.7241e+00,  3.9284e-08, -1.0236e+00,  1.0745e-01,  1.8862e+00,\n",
       "                       -3.9887e-01, -1.2842e+00, -1.2600e+00, -2.1492e+00,  3.2209e-01,\n",
       "                        2.3592e+00, -3.2225e+00,  2.3696e+00, -1.6651e+00,  4.1378e+00,\n",
       "                       -2.7803e+00,  8.0189e-01,  9.3857e-01, -5.6984e-01, -7.2965e-01,\n",
       "                        1.2171e+00, -2.7385e-02, -4.3729e+00,  2.0110e+00, -6.5416e-01,\n",
       "                        2.2401e-03,  1.6415e-06, -1.1504e+00, -1.8390e+00, -1.4985e+00,\n",
       "                       -8.5482e-01, -1.7244e-01, -1.2124e+00,  1.9658e+00, -4.0133e+00,\n",
       "                        2.3156e-01,  6.0066e+00, -2.1448e+00, -5.8063e-01,  2.1549e-01,\n",
       "                       -1.2742e+00, -6.3878e-01,  4.7079e-09, -3.1441e+00,  1.8908e+00,\n",
       "                        4.0816e+00, -6.5600e-02, -7.4247e+00, -1.3728e+00, -4.0400e+00,\n",
       "                        1.3853e+00,  9.4716e-01, -7.7341e-09, -1.6203e+00, -2.2593e+00,\n",
       "                       -1.3387e+00, -3.4947e+00, -6.9971e-01, -3.0009e+00, -6.7345e-01,\n",
       "                       -5.7298e-01,  3.5282e+00,  6.1593e-01, -5.0227e+00,  1.9301e+00,\n",
       "                       -6.9380e+00, -3.0442e-02,  1.1544e+00, -2.8224e+00, -6.6474e+00,\n",
       "                       -3.1940e+00, -2.6671e+00, -7.5612e-01, -1.3400e+00, -6.1458e-01,\n",
       "                       -4.9258e-01], device='cuda:0')),\n",
       "              ('module.layer1.0.bn3.running_var',\n",
       "               tensor([2.6276e+01, 2.8438e+00, 9.9514e-01, 3.0895e+00, 8.9886e+00, 2.7798e+01,\n",
       "                       1.8119e+00, 3.2355e+01, 9.0750e+00, 3.9010e+00, 1.5474e+00, 1.2955e+01,\n",
       "                       2.3482e+00, 1.7035e+00, 9.0120e+00, 5.9160e+00, 3.2205e+00, 2.7244e+01,\n",
       "                       2.7233e+00, 4.8913e+00, 3.5858e+00, 1.5226e+01, 5.7552e+00, 1.4027e+01,\n",
       "                       6.4980e+00, 1.4273e+01, 2.6740e+00, 1.1933e+00, 8.7783e+00, 1.7636e+01,\n",
       "                       5.2059e+00, 4.0645e+00, 2.2265e+00, 2.5571e+01, 1.4201e+00, 7.1326e+00,\n",
       "                       6.3675e+00, 3.0538e+00, 8.1683e-01, 2.6535e+00, 1.1328e+01, 2.8746e+00,\n",
       "                       1.3252e+00, 1.0413e+01, 2.9810e+00, 8.3301e-01, 1.5922e-01, 8.5837e-01,\n",
       "                       6.4472e+00, 9.5509e-02, 1.0592e+01, 1.5111e+00, 9.4644e+00, 2.2061e+01,\n",
       "                       2.4781e+01, 9.8962e-01, 1.6136e+00, 1.7781e+00, 6.3390e+00, 1.0147e+01,\n",
       "                       1.9495e-01, 3.5816e+01, 2.6675e+01, 3.0603e+00, 6.5193e+00, 2.0703e+01,\n",
       "                       3.8155e+00, 1.7687e+00, 1.2611e+00, 2.1146e+01, 1.7685e-01, 6.3217e+00,\n",
       "                       2.0282e+00, 1.5731e+00, 5.3319e+00, 1.1304e+01, 6.9897e-01, 2.7523e+01,\n",
       "                       1.9539e-01, 2.4308e+01, 9.6232e+00, 4.0311e-01, 9.0344e-02, 6.2606e+00,\n",
       "                       1.4055e+00, 1.7225e+01, 2.9527e+00, 2.9223e+00, 1.1398e+01, 2.7741e+01,\n",
       "                       8.6522e-01, 6.6342e+00, 8.8883e-01, 1.8675e+00, 2.2788e+00, 4.2412e+00,\n",
       "                       4.5697e+00, 4.3490e-01, 3.3711e+00, 3.2364e+00, 9.2806e-01, 1.5899e+01,\n",
       "                       3.5059e+00, 2.1229e+00, 4.5483e+00, 2.4109e+01, 1.6252e+01, 1.5867e+01,\n",
       "                       1.8683e+00, 7.4562e-01, 2.8697e+01, 7.1465e+00, 2.1943e+00, 3.6614e+01,\n",
       "                       1.0653e+00, 3.4863e+00, 1.1230e+01, 1.0194e+01, 2.4992e+00, 6.0964e-02,\n",
       "                       1.6568e+00, 5.6721e+00, 2.4098e+01, 3.5026e+00, 1.1348e+01, 2.5187e+01,\n",
       "                       1.2125e+01, 1.3700e-01, 2.6365e+00, 4.5381e+00, 1.0780e+01, 7.3525e-01,\n",
       "                       1.8806e+01, 1.3813e+00, 4.5479e+01, 3.9839e+00, 5.1299e+00, 5.9328e+00,\n",
       "                       2.1587e+01, 4.1568e+00, 5.3365e+00, 3.4815e+01, 1.1415e+01, 3.0470e+00,\n",
       "                       1.6595e+00, 1.1440e+00, 1.8547e+01, 6.4269e+00, 6.3640e+00, 6.2038e+00,\n",
       "                       1.1678e+01, 6.1377e+00, 1.1820e+00, 1.6892e+00, 1.9806e+01, 9.0919e+00,\n",
       "                       5.0309e-01, 3.1961e-02, 3.8325e+00, 2.7384e+00, 3.3407e+00, 1.3982e+01,\n",
       "                       5.9218e+00, 1.4912e+01, 1.0630e-10, 8.1707e-01, 2.6118e+01, 6.9967e-01,\n",
       "                       1.8010e+01, 2.5073e+01, 3.1547e-08, 1.1137e+01, 8.3645e+00, 4.8835e+00,\n",
       "                       3.9497e+00, 7.4933e+00, 5.1879e+00, 3.5363e-11, 3.6518e+00, 7.4530e-02,\n",
       "                       2.9087e+01, 5.0910e-16, 5.9106e+00, 8.9491e+00, 1.4531e+00, 1.1404e+01,\n",
       "                       7.1867e+00, 4.4505e+00, 2.7254e+01, 3.2183e+00, 7.5931e+00, 2.1284e+01,\n",
       "                       1.8847e+00, 6.9777e+00, 5.6174e-01, 3.4933e+00, 1.9280e-01, 1.7894e+01,\n",
       "                       2.0093e+01, 2.0488e+01, 5.6782e+00, 4.1927e+00, 1.3318e+01, 2.7222e+00,\n",
       "                       1.2049e+01, 1.7660e+01, 1.5986e-11, 1.9882e+01, 7.5806e+00, 6.6835e+00,\n",
       "                       2.0261e+01, 5.8945e+00, 1.0407e+01, 9.0427e+00, 7.7896e+00, 2.3597e+00,\n",
       "                       1.8483e+00, 1.1872e+01, 1.5611e-02, 6.2345e+00, 7.6343e+00, 8.1655e+00,\n",
       "                       2.0028e-16, 6.7343e+00, 3.6300e+00, 4.7410e+00, 1.1059e+01, 1.6518e+01,\n",
       "                       4.4759e+00, 1.1094e+01, 9.1711e+00, 5.4584e+00, 4.6900e-17, 2.8269e+00,\n",
       "                       2.7103e+01, 3.8732e+00, 1.2740e+00, 1.1593e+01, 1.6650e+01, 8.0407e-01,\n",
       "                       7.9330e+00, 1.1051e+00, 1.5283e+00, 2.0686e+01, 5.4361e+00, 4.5139e+00,\n",
       "                       3.9241e+00, 1.8603e+00, 6.6679e+00, 1.4281e+01, 5.8671e-01, 3.5101e+00,\n",
       "                       8.8503e+00, 1.7822e+01, 2.7771e+01, 6.4651e-01], device='cuda:0')),\n",
       "              ('module.layer1.0.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.0.downsample.0.weight',\n",
       "               tensor([[[[ 0.0345]],\n",
       "               \n",
       "                        [[-0.0703]],\n",
       "               \n",
       "                        [[ 0.0345]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0954]],\n",
       "               \n",
       "                        [[ 0.1371]],\n",
       "               \n",
       "                        [[ 0.2293]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0103]],\n",
       "               \n",
       "                        [[ 0.0289]],\n",
       "               \n",
       "                        [[ 0.0728]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.3220]],\n",
       "               \n",
       "                        [[-0.1975]],\n",
       "               \n",
       "                        [[-0.0528]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0042]],\n",
       "               \n",
       "                        [[ 0.0181]],\n",
       "               \n",
       "                        [[ 0.0678]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0361]],\n",
       "               \n",
       "                        [[ 0.0043]],\n",
       "               \n",
       "                        [[ 0.0711]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.2889]],\n",
       "               \n",
       "                        [[-0.1061]],\n",
       "               \n",
       "                        [[ 0.0146]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0244]],\n",
       "               \n",
       "                        [[ 0.0254]],\n",
       "               \n",
       "                        [[ 0.0534]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.4695]],\n",
       "               \n",
       "                        [[ 0.0247]],\n",
       "               \n",
       "                        [[ 0.0378]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0098]],\n",
       "               \n",
       "                        [[-0.0236]],\n",
       "               \n",
       "                        [[-0.0256]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1318]],\n",
       "               \n",
       "                        [[-0.0296]],\n",
       "               \n",
       "                        [[-0.0519]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0174]],\n",
       "               \n",
       "                        [[ 0.1206]],\n",
       "               \n",
       "                        [[-0.0115]]]], device='cuda:0')),\n",
       "              ('module.layer1.0.downsample.1.weight',\n",
       "               tensor([6.7798, 3.6483, 1.4581, 2.1727, 2.5946, 5.8577, 3.8754, 5.8930, 3.1221,\n",
       "                       3.9549, 2.8514, 4.3461, 2.3901, 3.5648, 4.0489, 2.9012, 2.5249, 5.2509,\n",
       "                       2.6717, 2.4345, 3.0848, 5.6064, 3.1895, 4.2528, 4.1290, 4.4221, 2.5936,\n",
       "                       1.4226, 3.7944, 4.8924, 3.5432, 2.5210, 2.5223, 4.4790, 1.7175, 2.8997,\n",
       "                       3.1097, 2.0139, 1.5342, 2.5586, 4.8876, 2.2819, 1.3942, 5.3425, 1.7388,\n",
       "                       2.9769, 2.5609, 1.5715, 3.7163, 0.4282, 3.6163, 2.0450, 4.8434, 4.9841,\n",
       "                       5.9858, 1.9257, 2.9397, 1.5687, 0.2698, 5.2811, 0.8299, 4.5228, 6.5906,\n",
       "                       3.2513, 4.0837, 6.3558, 3.9046, 2.4167, 2.7639, 4.9171, 1.9622, 3.3936,\n",
       "                       1.7192, 2.2743, 3.4115, 2.5937, 1.5921, 5.7749, 1.1861, 4.5282, 5.2822,\n",
       "                       0.8546, 2.4076, 3.3386, 1.8260, 5.5963, 2.4311, 3.2553, 3.4620, 6.0473,\n",
       "                       1.0274, 3.8115, 1.4218, 2.1757, 2.6341, 2.7386, 2.4938, 1.2329, 2.3352,\n",
       "                       3.2549, 1.5856, 2.1993, 3.0866, 3.5490, 2.6259, 5.5536, 3.4459, 2.5929,\n",
       "                       1.7808, 1.4833, 5.8416, 3.9525, 1.6911, 6.5166, 3.1937, 2.5694, 7.1607,\n",
       "                       4.5378, 3.1243, 1.5886, 3.7025, 2.5727, 3.7390, 2.8568, 6.9795, 5.1332,\n",
       "                       6.0481, 0.5422, 2.5191, 4.0452, 3.9433, 4.7023, 5.7770, 2.8441, 7.8242,\n",
       "                       2.0298, 2.7379, 4.7739, 7.1697, 3.1347, 1.4619, 4.3102, 3.5433, 3.9687,\n",
       "                       4.5204, 2.5165, 6.0180, 6.1497, 4.1843, 2.8473, 4.4624, 3.8831, 1.6310,\n",
       "                       4.2335, 5.7704, 2.9281, 1.0023, 0.5511, 2.7301, 3.0846, 2.4444, 7.6622,\n",
       "                       4.1271, 4.5672, 1.1884, 1.2008, 5.9538, 0.9583, 3.5367, 7.0050, 0.5963,\n",
       "                       5.0792, 4.3288, 0.3715, 2.3425, 3.4835, 2.8323, 0.2680, 2.1096, 0.5062,\n",
       "                       5.5760, 0.6455, 3.0295, 2.6453, 1.0192, 4.1066, 4.6494, 2.2234, 6.1911,\n",
       "                       3.6030, 2.4667, 5.4623, 2.2686, 4.0843, 0.4757, 2.0650, 0.9356, 6.6574,\n",
       "                       5.8671, 6.1026, 3.2752, 3.2005, 8.0364, 2.3540, 3.6805, 6.2104, 0.3132,\n",
       "                       3.5789, 3.5587, 4.3745, 3.3083, 3.2847, 5.4027, 4.2831, 3.3308, 2.1704,\n",
       "                       3.0622, 6.2494, 0.7973, 3.4610, 3.1824, 4.6473, 0.6599, 3.9465, 1.8686,\n",
       "                       2.6440, 6.6161, 5.8590, 3.0514, 3.8124, 6.0263, 3.1380, 0.4124, 4.7934,\n",
       "                       6.7059, 2.6323, 2.2536, 2.1683, 5.7913, 2.8197, 3.3292, 0.8502, 1.9964,\n",
       "                       5.2823, 3.2867, 2.9370, 3.1255, 2.4197, 5.6550, 7.2496, 0.1980, 2.5454,\n",
       "                       3.7045, 6.4317, 5.0470, 1.9616], device='cuda:0')),\n",
       "              ('module.layer1.0.downsample.1.bias',\n",
       "               tensor([ 2.3546e-01, -1.6620e-01,  8.3207e-02, -1.0370e-01,  2.9988e-01,\n",
       "                        2.1317e-01, -9.0665e-01,  9.6451e-01, -1.7827e-02, -3.2768e-01,\n",
       "                       -3.1758e-01,  3.6302e-01,  7.0268e-01, -1.3713e+00,  2.6793e-01,\n",
       "                        1.8610e-01,  4.5852e-01,  1.0120e+00,  3.8054e-01, -4.5801e-02,\n",
       "                       -1.5319e-01, -1.6307e-01,  7.6082e-02,  3.7855e-01,  9.6311e-02,\n",
       "                        2.0810e-01, -7.8294e-02, -9.6362e-02,  1.8764e-01,  6.3421e-01,\n",
       "                       -5.4922e-01,  3.7878e-02, -4.5776e-01,  1.1067e+00,  2.0919e-01,\n",
       "                        8.5866e-01,  2.5298e-01,  9.1096e-02, -1.4358e-02,  1.4791e-01,\n",
       "                        3.7426e-01,  2.4550e-01, -2.5742e-01, -4.4934e-01,  1.2071e+00,\n",
       "                       -1.7906e+00, -1.4789e+00, -6.4716e-02,  1.1959e-01, -4.5561e-01,\n",
       "                        2.9454e-01, -3.3883e-01, -6.7595e-01,  3.4310e-01,  1.5330e-01,\n",
       "                        1.9440e-01, -1.2296e-02,  4.9381e-01, -6.8041e-03, -3.2731e-01,\n",
       "                       -1.0084e+00,  2.3899e+00, -2.4461e-02, -4.9196e-01, -3.8949e-02,\n",
       "                       -2.2297e-03, -5.2689e-01, -2.5298e-01,  8.7243e-02,  6.9762e-01,\n",
       "                       -1.3417e+00,  3.9074e-01,  1.7660e-02,  1.7762e-01, -1.3251e-01,\n",
       "                        5.3409e-01,  7.2290e-02,  4.2239e-01, -2.2870e+00,  1.6573e+00,\n",
       "                       -3.2820e-01, -2.0338e-01,  1.4607e+00,  2.5626e-01,  5.1940e-02,\n",
       "                        2.0793e-01,  3.6744e-02, -5.8545e-02,  2.4031e-01,  5.6120e-01,\n",
       "                        2.2076e-01,  1.7379e-01, -3.0075e-01, -3.5482e-01, -4.0325e-02,\n",
       "                        3.4374e-03,  4.4694e-02, -1.2970e+00,  2.6024e-01, -5.0168e-01,\n",
       "                       -1.9707e-01,  6.7229e-01, -1.4389e-01, -1.9458e-01,  1.9383e-01,\n",
       "                        6.8676e-01,  5.5491e-02,  4.8783e-01,  3.9068e-01,  6.3583e-02,\n",
       "                        2.2160e-02, -1.6673e-01, -7.1460e-02,  6.5797e-01, -6.0148e-01,\n",
       "                       -4.0996e-01, -6.6733e-01, -2.8378e-01, -7.4491e-01, -1.7306e+00,\n",
       "                       -7.7696e-01,  2.2120e-01, -2.7536e-03, -2.6442e-01, -7.9681e-01,\n",
       "                        9.0919e-01, -4.1642e-01, -6.2780e-02, -1.4550e-01, -4.7371e-01,\n",
       "                       -8.3001e-02, -1.5650e+00, -6.0826e-02, -3.4618e-01,  1.2594e-01,\n",
       "                        1.8166e-01,  5.3516e-01, -8.0788e-01, -4.1138e-01,  3.8423e-01,\n",
       "                       -2.5369e-01,  2.1028e+00,  5.2658e-01, -8.7385e-01, -3.1333e+00,\n",
       "                       -5.1176e-02,  4.2756e-02, -9.8258e-01, -5.9303e-01,  6.5094e-02,\n",
       "                        5.0569e-01,  4.7191e-02,  1.1274e-01, -2.7303e-01,  3.3496e-01,\n",
       "                        2.7231e-01, -6.4580e-01, -8.0042e-01,  1.1280e-02, -1.0103e-01,\n",
       "                       -1.1748e-01, -6.1622e-01,  1.5047e-01,  2.5875e-02, -1.1643e+00,\n",
       "                        9.8647e-02,  6.1678e-01, -4.3155e-01,  8.0646e-01, -1.6631e-01,\n",
       "                       -1.1954e+00, -5.4721e-01, -5.4398e-01,  1.0677e-01,  2.7033e-01,\n",
       "                        1.5063e-01,  4.6397e-01, -5.6366e-01,  1.8072e-01, -4.6392e-01,\n",
       "                       -5.4111e-04, -2.2803e+00,  9.4096e-01,  6.9753e-01,  2.7759e-01,\n",
       "                        3.7102e-01, -3.8810e-01,  2.7637e-01,  3.8891e-01, -2.5167e-01,\n",
       "                        1.0170e+00,  4.1323e-01,  6.3874e-02, -1.7096e-01, -1.3872e+00,\n",
       "                        4.6139e-02, -8.5055e-01,  1.5845e-03,  4.0606e-01, -4.0571e-02,\n",
       "                       -6.4761e-01,  1.5491e-01, -6.5580e-01, -2.5743e-01,  1.4896e+00,\n",
       "                       -2.6580e-01, -4.1620e-01,  4.5654e-01,  5.2339e-01, -4.0435e-01,\n",
       "                        4.1892e-01,  2.0483e-01, -5.9555e-01, -3.3193e-02,  9.6833e-01,\n",
       "                        1.5607e-01, -3.5127e-01, -2.4695e-01, -6.3479e-01, -2.5885e-01,\n",
       "                        2.6597e-01, -2.9930e-01, -1.2752e+00,  1.4192e-01,  8.3347e-01,\n",
       "                        1.5909e-01, -5.7373e-01,  1.2977e-02,  1.6227e-01,  1.1688e-01,\n",
       "                       -6.0914e-01, -5.6410e-02, -6.8760e-01, -9.0335e-01,  2.9500e-01,\n",
       "                       -3.5718e-01, -6.6605e-02,  1.2960e+00, -4.1190e-02, -3.2992e+00,\n",
       "                        5.9931e-01,  2.0473e+00, -1.9710e-02,  8.9855e-02, -2.7499e-04,\n",
       "                        7.7255e-01,  2.0514e-02, -5.1109e-01, -6.0976e-01, -2.9517e-01,\n",
       "                        5.5314e-01,  4.4238e-01,  2.2680e-01, -1.0013e-01,  7.9082e-01,\n",
       "                       -2.2741e+00], device='cuda:0')),\n",
       "              ('module.layer1.0.downsample.1.running_mean',\n",
       "               tensor([-3.5902e+00, -4.0160e+00, -2.9914e+00, -3.1863e+00, -5.9761e-01,\n",
       "                        5.8535e-01, -6.0594e+00, -1.4582e+00, -4.3712e-01, -6.8180e+00,\n",
       "                       -3.8045e+00, -3.3297e+01,  1.0705e+01, -3.4036e+00, -5.7092e+00,\n",
       "                       -6.1376e-03,  7.4659e-01, -7.5197e-01, -1.4630e+01,  5.7544e+00,\n",
       "                       -2.3904e+00, -2.5664e+00,  3.0567e+00,  6.0575e+00, -1.4596e+00,\n",
       "                        1.2049e+01,  2.7560e+00, -1.5395e+00, -7.4778e+00,  3.3402e+00,\n",
       "                       -7.2378e+00, -4.7026e-01, -8.1492e+00,  9.0303e-01, -9.0468e-01,\n",
       "                        4.6552e-01, -3.8349e+00,  9.9304e+00,  3.8896e+00,  7.6361e+00,\n",
       "                        2.5278e-01,  2.4188e+00, -8.3614e-01,  6.9416e-01, -3.5377e+00,\n",
       "                        2.6563e+01, -3.5578e+00, -1.3885e+00, -1.6830e+00,  9.8720e-01,\n",
       "                       -3.6719e+00, -4.4037e+00, -2.6618e+00,  2.5989e+00, -1.0621e+00,\n",
       "                        1.3937e-01, -5.6795e+00, -6.2825e-01,  2.0911e+00, -6.0960e+00,\n",
       "                        4.1281e+00,  1.3816e+00, -1.7574e+00, -6.2247e+00, -7.4832e+00,\n",
       "                       -1.2336e+00, -7.2329e+00, -2.8491e+01, -2.0654e+00,  9.5580e-01,\n",
       "                       -5.7182e-01,  1.4291e+00, -1.5580e-01, -1.2612e+00, -1.2305e+00,\n",
       "                       -7.2232e+00,  2.3262e+00, -1.1890e+01, -2.5919e-01, -7.6036e-01,\n",
       "                       -9.3222e+00,  1.3251e+00, -5.2454e+01, -2.4247e+00, -4.8524e+00,\n",
       "                       -3.3775e-02,  2.1257e+00, -7.6113e+00, -4.0643e+00,  2.7605e+00,\n",
       "                        4.3272e+00, -1.2297e+01,  2.1018e+00, -2.0464e+00,  2.0889e+00,\n",
       "                       -2.2407e+01,  2.5516e+00,  1.4489e+00,  2.8276e+00, -5.3372e+00,\n",
       "                        1.1458e+00, -1.9234e+00, -1.1107e+01, -9.5181e+00,  9.2567e+00,\n",
       "                        1.5945e+00, -4.6770e-01,  1.3327e+00,  7.0396e-01,  8.6327e-01,\n",
       "                       -4.2295e+00, -6.1020e-01, -7.1346e-01, -2.1319e+00, -1.1210e+01,\n",
       "                       -3.4623e+00, -2.4859e+00, -5.2825e+00, -7.8459e+00, -3.3436e+00,\n",
       "                       -5.1388e+00,  9.8650e-01, -5.1869e+00, -4.8711e+00, -8.7563e+00,\n",
       "                       -1.1416e+01, -7.2739e+00, -1.2379e+00, -6.0046e+00, -8.8654e+00,\n",
       "                       -9.3657e+00,  2.8361e+00, -3.8733e+00, -9.5387e+00, -2.3901e+01,\n",
       "                       -3.4530e-01,  6.7615e+00, -5.7504e+00, -4.5408e+00,  3.2815e+00,\n",
       "                        1.3093e+01,  1.1846e+00, -7.9119e+00,  6.7915e+00, -9.5887e+00,\n",
       "                       -4.7846e+00, -1.6672e+00, -9.5651e+00, -5.3513e+00, -1.3477e+00,\n",
       "                       -2.3891e+00, -4.1696e+00,  1.0337e+00, -3.1511e+00,  2.5853e+00,\n",
       "                       -5.3961e+00,  5.7379e+00,  1.0871e+00,  9.2380e-01, -8.3323e+00,\n",
       "                       -1.9667e+00, -2.8385e+00, -6.1991e+00, -3.9145e+00, -5.0115e-05,\n",
       "                        2.7589e+00, -2.7707e+00,  5.7898e+00, -4.8904e+00,  7.8722e-01,\n",
       "                        6.1194e-04, -3.0527e+00, -3.2695e+00,  1.1088e+00, -1.4354e+01,\n",
       "                       -3.5008e+00,  5.2262e-01,  1.2165e-05, -1.6099e+00, -7.0900e-01,\n",
       "                       -4.9135e+00,  4.9534e-08,  1.4816e+00, -6.1303e+00,  7.0988e+00,\n",
       "                       -1.2235e+00,  2.8357e+00, -5.4615e+00, -4.9067e+00, -1.3909e+01,\n",
       "                       -1.6115e+01,  8.0439e-01,  1.4853e+00, -1.6996e+00,  4.7211e+00,\n",
       "                       -1.0828e+00,  3.5982e+00, -4.0325e+00, -3.4667e-01, -2.0573e+00,\n",
       "                       -5.8011e+00, -6.6156e+00, -2.0590e+00, -3.5886e+00, -6.1502e-01,\n",
       "                       -2.8845e+00, -6.3235e-06, -3.4389e+00, -1.7268e+00, -6.2003e+00,\n",
       "                       -1.3048e+01, -3.0336e+00, -5.1287e+00,  3.0092e-01, -1.3035e+00,\n",
       "                        3.3897e-01,  5.4457e+00, -1.2237e+00,  2.1846e+00,  1.5138e+00,\n",
       "                       -8.2711e-01, -4.9181e+00,  4.1234e-08, -1.1384e+01, -1.4483e+00,\n",
       "                        2.0904e+00, -1.2838e+00, -2.0682e+00, -8.4329e+00, -1.1650e+01,\n",
       "                       -4.6453e+00, -2.3428e+00, -2.9103e-08, -6.1176e-01, -8.1170e+00,\n",
       "                       -4.8233e+00, -4.6086e+00, -4.8880e+00, -4.4001e+00,  3.2477e+00,\n",
       "                       -5.4665e+00,  1.0508e+01, -2.1466e+00, -5.6338e+00, -1.1084e+01,\n",
       "                        3.7124e-01,  6.4738e-01, -6.9675e+00,  1.5184e+00,  1.9916e+00,\n",
       "                        5.1819e+00, -8.5135e+00,  2.8411e+00, -1.2429e+00, -3.4181e-02,\n",
       "                        1.6912e+00], device='cuda:0')),\n",
       "              ('module.layer1.0.downsample.1.running_var',\n",
       "               tensor([6.7791e+01, 3.5001e+01, 1.4645e+01, 1.8564e+01, 6.0433e+01, 8.4669e+01,\n",
       "                       1.8727e+01, 7.3315e+01, 5.3017e+01, 1.3566e+01, 9.3743e+00, 6.4146e+01,\n",
       "                       2.4029e+01, 5.4821e+00, 4.6711e+01, 3.4806e+01, 2.0597e+01, 6.8126e+01,\n",
       "                       3.3908e+01, 3.3347e+01, 1.0448e+01, 7.5262e+01, 2.9658e+01, 3.5104e+01,\n",
       "                       1.9812e+01, 4.8512e+01, 2.2221e+01, 8.6235e+00, 3.8394e+01, 3.7599e+01,\n",
       "                       4.0704e+01, 2.0310e+01, 1.7710e+01, 1.2415e+02, 1.4003e+01, 6.1108e+01,\n",
       "                       4.0748e+01, 8.5515e+00, 1.3220e+01, 2.2274e+01, 3.1464e+01, 1.3334e+01,\n",
       "                       5.9878e+00, 2.6510e+01, 1.7783e+01, 5.8379e+01, 2.4114e+00, 3.8595e+00,\n",
       "                       5.4775e+01, 1.3136e+00, 5.3990e+01, 1.3215e+01, 2.7872e+01, 5.4160e+01,\n",
       "                       6.0096e+01, 1.6721e+01, 2.7610e+01, 1.6757e+01, 3.4461e+00, 9.5917e+01,\n",
       "                       1.2204e+00, 1.1548e+02, 6.1825e+01, 8.4133e+00, 3.3267e+01, 1.1950e+02,\n",
       "                       2.1677e+01, 5.2621e+01, 2.3903e+01, 6.3179e+01, 1.5495e+00, 7.6965e+01,\n",
       "                       1.3293e+01, 1.9986e+01, 1.7071e+01, 7.1521e+01, 8.1814e+00, 5.2067e+01,\n",
       "                       2.0198e+00, 7.2004e+01, 5.4389e+01, 1.5113e+00, 2.3178e+02, 3.8556e+01,\n",
       "                       5.4518e+00, 3.9142e+01, 1.9017e+01, 2.1654e+01, 1.0054e+02, 6.5178e+01,\n",
       "                       7.6347e+00, 3.4908e+01, 4.3583e+00, 2.0185e+01, 1.2534e+01, 8.0927e+00,\n",
       "                       3.0649e+01, 2.2527e+00, 1.5176e+01, 3.4607e+01, 3.9131e+00, 3.8312e+01,\n",
       "                       1.0379e+01, 1.8386e+01, 3.5027e+01, 5.8157e+01, 3.0365e+01, 7.1761e+01,\n",
       "                       1.0863e+01, 9.0983e+00, 8.7639e+01, 4.6319e+01, 4.0320e+00, 9.6313e+01,\n",
       "                       1.1993e+01, 2.5243e+01, 2.6339e+01, 2.6828e+01, 1.1061e+01, 1.0386e+00,\n",
       "                       9.3367e+00, 1.8973e+01, 9.8563e+01, 1.5771e+01, 2.7987e+01, 5.6286e+01,\n",
       "                       2.0542e+01, 1.1299e+00, 1.1807e+01, 4.0837e+01, 5.4825e+01, 1.1818e+01,\n",
       "                       8.5204e+01, 1.5934e+01, 1.0706e+02, 1.8206e+01, 5.5068e+01, 3.5770e+01,\n",
       "                       8.6128e+01, 1.6404e+01, 1.0208e+01, 1.0596e+02, 1.0459e+02, 6.5294e+01,\n",
       "                       1.9834e+01, 1.2880e+01, 4.2745e+01, 7.0261e+01, 2.6813e+01, 4.2072e+01,\n",
       "                       3.7309e+01, 3.0895e+01, 1.5829e+01, 1.4840e+01, 4.6941e+01, 2.9825e+01,\n",
       "                       7.8544e+00, 3.4641e-01, 4.2043e+01, 1.2111e+01, 1.6075e+01, 3.3806e+01,\n",
       "                       3.0639e+01, 1.4558e+02, 7.2511e-10, 8.5586e+00, 5.2802e+01, 2.7122e+00,\n",
       "                       8.0691e+01, 4.8422e+01, 1.8284e-07, 3.8819e+01, 3.4297e+01, 5.6886e+00,\n",
       "                       1.9392e+01, 3.7700e+01, 3.0250e+01, 1.0263e-10, 2.6458e+01, 3.5499e-01,\n",
       "                       7.7114e+01, 4.1609e-15, 9.6988e+01, 2.8297e+01, 1.6855e+01, 2.9941e+01,\n",
       "                       2.5000e+01, 1.9545e+01, 1.0060e+02, 3.7284e+01, 2.8880e+01, 4.3055e+01,\n",
       "                       1.3544e+01, 9.6889e+00, 5.4210e-01, 1.3890e+01, 1.1112e+00, 4.3064e+01,\n",
       "                       3.7420e+01, 4.8546e+01, 2.5159e+01, 6.1831e+01, 3.4552e+01, 2.3788e+01,\n",
       "                       6.0416e+01, 1.1389e+02, 1.1017e-10, 5.3593e+01, 1.1331e+02, 2.3705e+01,\n",
       "                       3.5101e+01, 3.2812e+01, 4.4432e+01, 1.0591e+02, 1.0316e+02, 2.3295e+01,\n",
       "                       2.8857e+01, 3.9696e+01, 1.0886e+00, 4.7078e+01, 1.4446e+01, 2.4018e+01,\n",
       "                       1.3378e-15, 7.1659e+01, 2.1628e+01, 3.1677e+01, 3.3737e+01, 4.3831e+01,\n",
       "                       1.8035e+01, 6.5735e+01, 4.1781e+01, 1.4062e+01, 1.4755e-16, 2.2687e+01,\n",
       "                       4.0329e+01, 2.9072e+01, 1.1392e+01, 3.3873e+01, 6.3693e+01, 4.4470e+00,\n",
       "                       3.1672e+01, 1.6112e+01, 1.1121e+01, 3.2988e+01, 3.7477e+01, 8.2071e+01,\n",
       "                       4.5148e+01, 1.3942e+01, 2.3359e+01, 4.9474e+01, 2.7775e+00, 1.9366e+01,\n",
       "                       5.9311e+01, 9.4142e+01, 8.6480e+01, 3.0642e+00], device='cuda:0')),\n",
       "              ('module.layer1.0.downsample.1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.1.conv1.weight',\n",
       "               tensor([[[[ 7.8780e-03]],\n",
       "               \n",
       "                        [[ 1.1906e-01]],\n",
       "               \n",
       "                        [[-5.5234e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4431e-02]],\n",
       "               \n",
       "                        [[-1.7209e-02]],\n",
       "               \n",
       "                        [[ 1.8440e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.7717e-02]],\n",
       "               \n",
       "                        [[-7.9964e-02]],\n",
       "               \n",
       "                        [[-2.3827e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.5460e-02]],\n",
       "               \n",
       "                        [[ 1.4805e-01]],\n",
       "               \n",
       "                        [[ 3.2074e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.3888e-11]],\n",
       "               \n",
       "                        [[-1.2669e-11]],\n",
       "               \n",
       "                        [[-2.8826e-11]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.3379e-11]],\n",
       "               \n",
       "                        [[ 6.8638e-12]],\n",
       "               \n",
       "                        [[ 6.0157e-12]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.4297e-02]],\n",
       "               \n",
       "                        [[ 3.1504e-02]],\n",
       "               \n",
       "                        [[ 2.3262e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.9679e-01]],\n",
       "               \n",
       "                        [[-2.6677e-01]],\n",
       "               \n",
       "                        [[-7.9428e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.7184e-02]],\n",
       "               \n",
       "                        [[-1.4251e-01]],\n",
       "               \n",
       "                        [[ 1.7968e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.7045e-02]],\n",
       "               \n",
       "                        [[ 3.4611e-02]],\n",
       "               \n",
       "                        [[ 2.9053e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.5161e-03]],\n",
       "               \n",
       "                        [[-2.9314e-02]],\n",
       "               \n",
       "                        [[ 2.3338e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.6178e-02]],\n",
       "               \n",
       "                        [[ 2.1111e-02]],\n",
       "               \n",
       "                        [[-6.0049e-02]]]], device='cuda:0')),\n",
       "              ('module.layer1.1.bn1.weight',\n",
       "               tensor([1.6835, 1.5844, 1.8882, 2.2980, 1.3449, 2.4517, 3.7076, 1.5863, 1.9124,\n",
       "                       1.4267, 1.3356, 1.4194, 1.3486, 1.4898, 1.7484, 2.9648, 1.3345, 2.9199,\n",
       "                       1.4991, 3.1656, 2.0852, 3.7661, 2.5125, 2.1377, 2.6025, 2.1671, 1.7719,\n",
       "                       2.2672, 1.4588, 2.1759, 1.7758, 2.5296, 2.1147, 1.8340, 1.3251, 2.4380,\n",
       "                       1.7144, 6.9549, 1.4458, 1.6822, 1.5092, 1.3550, 1.9768, 1.8000, 1.6991,\n",
       "                       2.0966, 1.9756, 3.1804, 1.5798, 1.3124, 2.2795, 1.7550, 1.8560, 2.2127,\n",
       "                       1.3500, 2.8474, 3.2061, 1.2425, 1.4927, 2.5047, 1.8968, 1.3809, 1.3857,\n",
       "                       2.6950], device='cuda:0')),\n",
       "              ('module.layer1.1.bn1.bias',\n",
       "               tensor([-0.2902,  1.0187, -4.6143, -0.7552,  1.6827, -1.4102, -6.0006,  0.7430,\n",
       "                        0.0714,  0.3288,  2.5534,  1.6293,  1.4347,  1.8951, -0.1334, -2.1590,\n",
       "                        0.9096, -1.4070,  0.7561, -1.8839, -0.3165, -3.2018, -1.9048, -0.0440,\n",
       "                       -1.8297, -0.1997,  0.7109, -0.8898,  0.5310, -0.1347, -1.0040, -0.6650,\n",
       "                       -0.0304, -0.6213,  2.2823, -0.2963, -0.2200, -9.6683,  1.1440, -0.0149,\n",
       "                        0.7598,  1.2076,  0.2269,  0.1533,  1.1195, -0.1919, -0.6775, -2.4065,\n",
       "                        1.4207,  0.7639, -0.3617, -0.2162, -0.1886, -0.6591,  2.6356, -1.5737,\n",
       "                       -2.1057,  0.3464,  1.8917, -1.4561,  0.0334,  3.1529,  1.4090, -2.8954],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer1.1.bn1.running_mean',\n",
       "               tensor([ 3.8384e-01, -9.1622e-01, -9.0593e-10,  1.4365e+00, -8.8639e-01,\n",
       "                        7.2911e-01,  9.4286e-01,  5.5991e-01,  4.6496e-01,  6.7990e-01,\n",
       "                        3.8079e-01, -3.0715e-01,  1.0727e+00, -4.7804e+00,  1.8080e+00,\n",
       "                        2.4518e+00,  5.8213e-01, -2.0961e+00, -6.8727e-01, -1.0568e+00,\n",
       "                        1.0141e+00, -2.5186e+00, -1.7281e+00, -3.5880e-01, -6.7461e-01,\n",
       "                        6.8396e-01, -9.2584e-01, -1.3768e-01, -4.9430e-01, -4.7137e-01,\n",
       "                       -1.3370e+00, -7.9377e-01, -1.4680e-01, -9.3072e-01,  1.6973e+00,\n",
       "                       -6.0382e-01, -6.2006e-01, -5.6350e+00, -8.6359e-01, -5.5398e-01,\n",
       "                        8.5087e-01, -5.7311e-01, -1.5790e-01,  2.5441e+00,  7.5182e-01,\n",
       "                        5.6333e-01, -1.3007e+00, -1.0792e+00, -1.2272e+00,  9.4121e-01,\n",
       "                        9.3029e-01, -9.1621e-01, -1.2957e+00,  7.4536e-01, -2.6918e+00,\n",
       "                        1.1392e+00,  1.1656e+00, -2.1034e+00, -1.1995e+00, -1.2390e-01,\n",
       "                       -9.8296e-01,  1.1968e+00, -1.2798e-01, -3.3307e-02], device='cuda:0')),\n",
       "              ('module.layer1.1.bn1.running_var',\n",
       "               tensor([1.5906e+00, 5.7923e+00, 1.0295e-19, 6.5373e+00, 3.0947e+00, 2.4286e+00,\n",
       "                       1.9519e+00, 4.8205e+00, 4.8335e+00, 1.9477e+00, 1.6587e+00, 3.4024e+00,\n",
       "                       1.8066e+00, 2.2255e+00, 2.5618e+00, 1.9708e+00, 1.9197e+00, 5.2152e+00,\n",
       "                       5.0386e+00, 5.2590e+00, 3.2957e+00, 3.2005e+00, 1.5976e+00, 6.5041e+00,\n",
       "                       2.5725e+00, 3.2990e+00, 1.7317e+00, 4.0086e+00, 1.3146e+00, 7.2714e+00,\n",
       "                       1.6665e+00, 6.8761e+00, 6.6498e+00, 1.7988e+00, 1.1515e+00, 6.9947e+00,\n",
       "                       3.0621e+00, 2.0267e+00, 6.1101e+00, 1.7988e+00, 1.4585e+00, 1.2543e+00,\n",
       "                       5.8374e+00, 3.2751e+00, 1.9433e+00, 6.4550e+00, 1.4864e+00, 3.1009e+00,\n",
       "                       7.9409e+00, 1.5665e+00, 3.2464e+00, 2.0065e+00, 2.3673e+00, 5.6666e+00,\n",
       "                       3.9508e+00, 4.0298e+00, 5.1411e+00, 2.0089e+00, 5.4452e+00, 3.3523e+00,\n",
       "                       3.7782e+00, 3.4973e+00, 1.7611e+00, 1.0096e+00], device='cuda:0')),\n",
       "              ('module.layer1.1.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.1.conv2.weight',\n",
       "               tensor([[[[ 3.4144e-02, -2.3184e-02,  4.3015e-02],\n",
       "                         [-4.3556e-02,  1.0982e-02, -1.4384e-02],\n",
       "                         [ 4.4782e-02,  4.5727e-02,  4.8668e-03]],\n",
       "               \n",
       "                        [[ 1.9641e-02, -9.1370e-02,  9.9713e-03],\n",
       "                         [ 6.5915e-02, -9.6658e-02, -3.5988e-02],\n",
       "                         [ 5.3070e-02, -1.4600e-02,  4.2167e-03]],\n",
       "               \n",
       "                        [[ 1.6096e-13,  5.6165e-12,  2.2871e-12],\n",
       "                         [-6.6579e-12, -2.4523e-12, -2.7622e-12],\n",
       "                         [-7.5979e-12, -8.7581e-12, -5.8374e-12]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.8233e-03, -6.0136e-02,  4.1443e-02],\n",
       "                         [ 1.1109e-01, -1.1496e-01,  2.2760e-02],\n",
       "                         [ 2.2315e-02, -2.2844e-02, -2.2596e-02]],\n",
       "               \n",
       "                        [[-5.1411e-02, -5.5161e-02,  8.6723e-02],\n",
       "                         [ 6.1566e-02, -6.6336e-02, -1.0134e-02],\n",
       "                         [ 2.2138e-02,  6.1954e-02, -7.4323e-02]],\n",
       "               \n",
       "                        [[ 7.8418e-03, -2.0977e-03, -2.2677e-02],\n",
       "                         [-2.8045e-02,  1.4095e-02, -2.0992e-02],\n",
       "                         [ 2.2148e-02, -6.2577e-02, -2.4362e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0723e-02,  8.6250e-02,  8.0780e-02],\n",
       "                         [-3.5774e-02, -6.5236e-02,  2.5118e-04],\n",
       "                         [ 3.4845e-02,  1.8177e-02,  3.4151e-02]],\n",
       "               \n",
       "                        [[-4.5237e-02, -5.0227e-02, -2.9256e-02],\n",
       "                         [ 6.7003e-02,  7.8427e-02, -3.9421e-02],\n",
       "                         [ 9.0451e-02,  5.4251e-03, -3.6489e-02]],\n",
       "               \n",
       "                        [[-5.8640e-12, -2.3935e-12,  1.0719e-11],\n",
       "                         [-2.6477e-12,  6.7506e-14,  6.9574e-12],\n",
       "                         [ 7.2030e-13, -1.4645e-12, -5.7006e-12]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.1852e-02, -3.4181e-02, -1.0825e-01],\n",
       "                         [ 4.4778e-02,  4.6546e-02, -1.0422e-02],\n",
       "                         [-7.1384e-02, -2.8868e-02,  8.4407e-02]],\n",
       "               \n",
       "                        [[-7.2017e-02, -3.5125e-02, -1.1823e-02],\n",
       "                         [-3.1779e-02,  6.7276e-02,  3.6715e-02],\n",
       "                         [-4.4710e-02,  7.7358e-02,  1.3944e-01]],\n",
       "               \n",
       "                        [[-3.5352e-02,  2.4496e-02, -6.8592e-03],\n",
       "                         [ 1.0987e-02,  1.1693e-02, -3.7775e-03],\n",
       "                         [ 1.2333e-02, -9.2445e-03, -2.2913e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6466e-02, -1.7759e-02,  2.8510e-02],\n",
       "                         [-6.4642e-03,  6.1195e-02,  7.6516e-03],\n",
       "                         [-2.2580e-02, -2.1924e-02, -1.2820e-02]],\n",
       "               \n",
       "                        [[ 1.4499e-02, -1.3907e-02, -3.2276e-02],\n",
       "                         [ 2.0333e-02, -1.2301e-01,  6.9769e-02],\n",
       "                         [ 3.8219e-02, -8.3211e-02, -2.6541e-02]],\n",
       "               \n",
       "                        [[ 6.4232e-11,  7.0468e-11,  6.5507e-11],\n",
       "                         [ 7.6423e-11,  8.8348e-11,  7.2633e-11],\n",
       "                         [ 7.1704e-11,  7.6879e-11,  7.5938e-11]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.5529e-02,  8.9664e-02,  4.0903e-02],\n",
       "                         [-1.8358e-02, -2.6703e-01,  9.1252e-02],\n",
       "                         [-2.4328e-02,  8.5072e-03, -1.8840e-02]],\n",
       "               \n",
       "                        [[-3.8457e-02, -4.3159e-02, -4.5646e-03],\n",
       "                         [-4.9918e-02,  1.0275e-01, -4.8010e-02],\n",
       "                         [-1.0311e-02, -4.8376e-02, -3.8367e-02]],\n",
       "               \n",
       "                        [[-6.6874e-03,  1.6726e-02, -2.7082e-02],\n",
       "                         [ 1.0589e-02,  2.0320e-02, -6.6872e-03],\n",
       "                         [-1.4627e-02, -2.4189e-02, -1.0386e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 7.2634e-02,  2.7381e-02,  6.9575e-02],\n",
       "                         [-2.5827e-02, -8.3274e-02, -8.2139e-02],\n",
       "                         [ 6.1406e-02,  1.6714e-02,  7.9085e-02]],\n",
       "               \n",
       "                        [[ 6.0421e-02,  7.8688e-02,  5.3081e-02],\n",
       "                         [ 5.9546e-02, -3.1181e-03, -5.1462e-03],\n",
       "                         [ 3.6981e-02,  1.2586e-01,  5.6565e-02]],\n",
       "               \n",
       "                        [[ 1.0122e-11,  1.6450e-12,  5.9216e-12],\n",
       "                         [ 7.2774e-12,  6.9514e-12,  5.5724e-12],\n",
       "                         [ 6.2718e-12,  1.0720e-11,  6.3197e-12]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.0023e-02,  5.5109e-02,  1.5599e-02],\n",
       "                         [-5.3415e-02,  1.2684e-02, -3.1033e-02],\n",
       "                         [-6.4948e-02,  2.0207e-02, -2.7249e-02]],\n",
       "               \n",
       "                        [[-5.0225e-02, -2.7949e-02, -2.5271e-02],\n",
       "                         [-4.2480e-03, -2.1871e-02,  8.9730e-03],\n",
       "                         [ 3.3136e-02,  9.5833e-02,  5.5083e-02]],\n",
       "               \n",
       "                        [[ 1.3959e-02, -2.9934e-03,  2.3370e-02],\n",
       "                         [-6.9264e-03,  2.7361e-02,  3.5551e-04],\n",
       "                         [ 1.2177e-02, -5.0316e-02, -2.0077e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.9693e-02,  6.2302e-02, -1.0516e-02],\n",
       "                         [-5.8957e-02,  1.6473e-01, -5.3318e-02],\n",
       "                         [-6.0149e-02,  3.0457e-02, -8.1385e-02]],\n",
       "               \n",
       "                        [[-3.2495e-02,  1.2751e-01,  5.2880e-02],\n",
       "                         [-3.5025e-02,  4.6596e-02,  1.3554e-02],\n",
       "                         [-1.2352e-02,  6.0202e-02, -1.6998e-02]],\n",
       "               \n",
       "                        [[ 2.2144e-12, -4.1810e-12,  4.4565e-12],\n",
       "                         [-1.5656e-12, -1.0188e-12, -3.0319e-12],\n",
       "                         [ 2.0780e-12, -2.6120e-13,  1.1438e-12]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.3428e-02, -8.5392e-02, -1.2752e-01],\n",
       "                         [-3.4515e-02, -7.0957e-02, -1.1060e-01],\n",
       "                         [ 1.3336e-02, -3.7432e-02, -1.8252e-01]],\n",
       "               \n",
       "                        [[-2.1598e-03, -3.1879e-02, -2.3291e-02],\n",
       "                         [-2.6635e-02, -6.3787e-03, -2.7017e-02],\n",
       "                         [ 9.0539e-03, -1.9420e-02, -5.9580e-02]],\n",
       "               \n",
       "                        [[ 2.4889e-03, -3.8778e-02, -4.2146e-02],\n",
       "                         [ 1.8347e-02,  1.1592e-02, -2.5547e-02],\n",
       "                         [-1.7871e-02,  8.0341e-04, -3.1384e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.4410e-02, -2.7257e-02, -7.5474e-03],\n",
       "                         [ 1.0240e-01,  7.4729e-02,  2.1273e-02],\n",
       "                         [-2.8706e-02,  2.2131e-03, -5.9690e-03]],\n",
       "               \n",
       "                        [[-1.5858e-02,  4.7654e-02,  2.8603e-02],\n",
       "                         [ 4.6893e-02, -1.1889e-01,  5.0496e-02],\n",
       "                         [ 1.7556e-02,  3.3464e-02,  3.2043e-02]],\n",
       "               \n",
       "                        [[-3.7888e-12, -7.0996e-12, -3.0787e-12],\n",
       "                         [-7.1682e-12, -6.2458e-12, -8.7570e-12],\n",
       "                         [-1.2207e-11, -1.4818e-11, -1.0655e-11]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.7112e-02, -2.9048e-02, -3.8321e-02],\n",
       "                         [-5.9777e-02,  1.1358e-01, -2.4037e-02],\n",
       "                         [-5.3128e-02, -5.8394e-02, -4.9729e-02]],\n",
       "               \n",
       "                        [[ 6.0440e-02,  4.5819e-02,  2.3158e-02],\n",
       "                         [ 6.7562e-02, -1.0285e-01,  4.3283e-02],\n",
       "                         [ 1.9942e-02,  4.6048e-02,  3.0913e-02]],\n",
       "               \n",
       "                        [[-3.5276e-02, -2.5458e-02, -2.9273e-02],\n",
       "                         [-8.9958e-03,  1.8997e-02,  1.8380e-02],\n",
       "                         [-1.9175e-02,  1.7504e-02, -2.6039e-02]]]], device='cuda:0')),\n",
       "              ('module.layer1.1.bn2.weight',\n",
       "               tensor([1.9655, 1.6095, 2.2024, 1.3204, 1.3685, 1.3214, 3.4719, 1.7417, 2.1434,\n",
       "                       1.8251, 2.0342, 1.8073, 1.1682, 1.7259, 1.5342, 1.6840, 1.1673, 1.9133,\n",
       "                       1.4766, 2.0215, 1.5185, 1.9667, 1.3452, 2.0425, 1.7244, 2.7786, 1.9029,\n",
       "                       1.8916, 2.7741, 1.5024, 1.1815, 1.6835, 2.0824, 1.4336, 1.3058, 2.0886,\n",
       "                       1.9943, 1.3288, 1.9888, 1.3095, 1.8577, 1.6934, 1.3513, 2.0322, 1.4047,\n",
       "                       2.9922, 1.2875, 1.6935, 1.8918, 1.5371, 1.1609, 1.6877, 1.9563, 1.7780,\n",
       "                       1.3070, 2.1953, 2.2320, 1.3264, 3.3296, 1.8944, 1.9164, 1.9820, 3.6893,\n",
       "                       3.7930], device='cuda:0')),\n",
       "              ('module.layer1.1.bn2.bias',\n",
       "               tensor([-0.6730,  0.9175, -1.4370,  3.2310,  3.6040,  3.5506, -3.7565,  0.6329,\n",
       "                       -0.5294,  1.0511, -0.4616,  0.7440,  3.9675,  0.3666,  1.6276,  2.1603,\n",
       "                        2.9828, -0.0149,  3.4571, -0.1558,  1.7835, -0.1776,  3.2777, -0.7525,\n",
       "                       -0.5928, -1.6492,  0.6284, -0.4745, -2.0349,  1.3862,  3.4085,  0.9318,\n",
       "                       -0.5146,  2.6313,  4.5993, -0.7438,  0.5956,  3.4007, -0.0241,  3.3000,\n",
       "                       -0.4741,  0.8549,  1.1686, -0.1716,  2.6251, -2.7015,  4.2309,  0.5178,\n",
       "                        0.6875,  3.6669,  2.0131,  0.8042,  0.0380,  0.4020,  2.0371, -1.7283,\n",
       "                       -1.1361,  2.7205, -4.2599,  0.4928,  0.0402, -0.0819, -4.5015, -4.7299],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer1.1.bn2.running_mean',\n",
       "               tensor([-9.0896e-01, -2.7966e-01, -3.8111e+00,  2.3944e+00,  3.5773e+00,\n",
       "                        1.2281e+00, -4.6395e+00,  1.1642e+00,  2.1151e-02,  9.0229e-01,\n",
       "                       -2.1103e+00,  1.1376e+00,  1.2456e+00, -1.2989e-01,  1.1109e+00,\n",
       "                        1.6455e+00,  6.9581e-01, -1.9694e+00,  2.2949e+00, -8.9632e-01,\n",
       "                        2.9052e+00, -1.6899e+00, -1.2146e+00, -1.5852e+00,  1.3938e+00,\n",
       "                       -4.7692e+00, -3.0466e-01, -2.3526e+00, -1.9092e+00, -7.9274e-05,\n",
       "                       -4.6475e-01,  4.7135e-01, -6.3023e-01,  6.5176e-01, -9.5076e-01,\n",
       "                       -3.7830e+00,  7.4016e-01, -2.2763e-01,  1.9991e-01,  2.3568e-01,\n",
       "                       -9.2341e-01,  1.3440e-01, -1.4975e+00, -1.4623e+00,  2.6085e+00,\n",
       "                       -1.9046e+00,  2.4438e+00,  8.2528e-01,  7.5493e-01,  3.0703e+00,\n",
       "                        9.4025e-01, -1.8312e+00, -1.5427e+00,  5.8948e-01,  1.0893e+00,\n",
       "                       -5.1098e+00, -2.4420e+00, -1.4886e-01, -4.9799e+00, -3.1615e-01,\n",
       "                       -1.4633e+00, -6.3254e-01, -3.9708e+00, -1.9283e+00], device='cuda:0')),\n",
       "              ('module.layer1.1.bn2.running_var',\n",
       "               tensor([2.8111, 8.0848, 2.2818, 5.6892, 7.0731, 6.2578, 4.6431, 8.4283, 4.0000,\n",
       "                       9.7447, 3.6405, 8.8574, 3.4591, 7.6361, 5.4769, 8.3928, 3.9660, 6.5708,\n",
       "                       6.2582, 5.2069, 5.7634, 4.9271, 4.7125, 2.5765, 5.0566, 4.4136, 9.1903,\n",
       "                       3.5326, 3.2956, 5.6088, 4.5890, 8.2684, 4.6193, 5.5702, 5.0578, 3.4104,\n",
       "                       8.4909, 5.3865, 4.8489, 4.9306, 2.7603, 7.7882, 5.6113, 6.9106, 6.3298,\n",
       "                       3.3251, 4.8310, 7.7935, 9.3150, 8.4958, 4.2059, 5.8806, 6.1732, 7.6262,\n",
       "                       5.2324, 4.5694, 3.6430, 5.8390, 5.3504, 9.8206, 6.4273, 7.3359, 3.5825,\n",
       "                       2.4501], device='cuda:0')),\n",
       "              ('module.layer1.1.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.1.conv3.weight',\n",
       "               tensor([[[[ 0.0306]],\n",
       "               \n",
       "                        [[ 0.0383]],\n",
       "               \n",
       "                        [[ 0.0233]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.1129]],\n",
       "               \n",
       "                        [[-0.0739]],\n",
       "               \n",
       "                        [[-0.1539]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1218]],\n",
       "               \n",
       "                        [[-0.0777]],\n",
       "               \n",
       "                        [[-0.0223]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0715]],\n",
       "               \n",
       "                        [[-0.0446]],\n",
       "               \n",
       "                        [[ 0.0062]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0122]],\n",
       "               \n",
       "                        [[ 0.0154]],\n",
       "               \n",
       "                        [[-0.0105]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0474]],\n",
       "               \n",
       "                        [[-0.0513]],\n",
       "               \n",
       "                        [[-0.0659]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0057]],\n",
       "               \n",
       "                        [[ 0.0295]],\n",
       "               \n",
       "                        [[ 0.1122]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0137]],\n",
       "               \n",
       "                        [[-0.1396]],\n",
       "               \n",
       "                        [[-0.0688]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0614]],\n",
       "               \n",
       "                        [[-0.0404]],\n",
       "               \n",
       "                        [[ 0.0937]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0059]],\n",
       "               \n",
       "                        [[-0.0462]],\n",
       "               \n",
       "                        [[ 0.0729]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0971]],\n",
       "               \n",
       "                        [[ 0.0365]],\n",
       "               \n",
       "                        [[ 0.0067]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0098]],\n",
       "               \n",
       "                        [[-0.0362]],\n",
       "               \n",
       "                        [[ 0.0122]]]], device='cuda:0')),\n",
       "              ('module.layer1.1.bn3.weight',\n",
       "               tensor([ 3.0046e-01,  1.6221e+00,  1.4484e+00,  2.3330e+00, -9.9537e-03,\n",
       "                        4.9529e-01, -1.1237e-02,  1.5910e-01, -1.5501e-02,  1.8733e+00,\n",
       "                        1.9292e+00,  7.0106e-03,  8.4670e-01,  1.8684e+00,  4.7534e-01,\n",
       "                        1.1237e+00,  1.2531e+00,  5.0752e-01,  1.4535e+00,  1.8692e+00,\n",
       "                        1.0041e+00,  9.1349e-01,  3.5773e-01,  6.4620e-03,  6.3092e-01,\n",
       "                        3.6957e-01,  1.2339e+00,  2.1671e+00,  1.2991e+00,  3.4529e-01,\n",
       "                        1.9711e+00,  1.5765e+00,  1.8547e+00,  1.6297e-01,  2.4801e+00,\n",
       "                        7.4519e-01,  1.4664e+00,  1.3247e+00,  2.0852e+00,  1.6159e+00,\n",
       "                        1.9916e-01,  1.5308e+00,  3.0066e+00,  4.4716e-01,  1.2048e+00,\n",
       "                        4.5024e-01,  7.0272e+00,  1.2834e+00,  1.3574e+00,  2.1695e+00,\n",
       "                       -3.2664e-03,  2.4944e+00,  1.9816e+00,  2.2047e-03, -1.1273e-01,\n",
       "                        1.5594e+00,  2.1972e+00,  2.0852e+00,  1.7920e-02,  7.0028e-01,\n",
       "                        2.4865e+00,  3.4282e-01,  5.2758e-01,  1.7011e+00,  1.1100e+00,\n",
       "                        5.7628e-01,  1.7373e+00,  1.2499e+00,  1.0693e+00,  8.1184e-01,\n",
       "                        2.7914e+00,  7.6187e-01,  1.3944e+00,  1.2816e+00,  1.2596e+00,\n",
       "                        2.6020e-03,  3.0870e+00,  6.6729e-03,  2.0835e+00,  5.8796e-01,\n",
       "                        7.5190e-01,  1.5776e+00, -5.8777e-03,  1.4138e+00,  9.4269e-01,\n",
       "                        3.9262e-01,  1.1273e+00,  1.2772e+00,  7.8229e-01,  5.2500e-01,\n",
       "                        2.3524e+00,  9.7578e-01,  3.2306e+00,  2.6385e+00,  9.7252e-01,\n",
       "                        8.8072e-01,  1.5560e+00,  2.7818e+00,  7.6455e-01,  2.9568e-01,\n",
       "                        1.0436e+00,  4.8830e-03,  1.8387e+00,  1.4985e+00,  1.3004e+00,\n",
       "                        4.7314e-01,  4.7182e-03, -2.4176e-03,  1.5762e+00,  2.2000e+00,\n",
       "                        7.1614e-01,  1.6175e+00,  1.8378e+00,  4.4342e-01,  1.7640e+00,\n",
       "                        1.6548e+00,  6.6555e-01,  1.6659e+00,  2.2837e+00,  1.4939e+00,\n",
       "                        3.4515e+00,  1.9289e+00, -5.5511e-04,  1.2333e+00,  5.6953e+00,\n",
       "                       -1.3310e-01,  1.3711e+00,  1.0640e+00,  2.5394e+00,  1.0299e+00,\n",
       "                        8.5688e-01,  2.1397e+00,  5.8733e-01,  1.7292e+00,  2.8806e-01,\n",
       "                        1.1180e+00,  1.7354e+00,  2.0707e+00,  4.7644e-01,  1.3418e-01,\n",
       "                        3.7761e-01,  3.2057e-01,  9.8716e-01,  1.6641e-01,  2.2759e+00,\n",
       "                        1.4477e+00,  4.2331e-01,  3.1215e-01,  1.5721e+00,  9.5097e-01,\n",
       "                        2.1236e-01,  7.2187e-01,  2.0967e+00,  1.2340e+00,  5.9098e-01,\n",
       "                        3.9191e-01,  7.3674e-01,  2.4849e+00,  1.2379e+00,  1.5759e+00,\n",
       "                        1.4680e+00,  7.6469e-01,  9.1788e-01,  9.4228e-01,  1.0419e+00,\n",
       "                        1.9993e+00,  7.5591e-01,  1.1421e+00, -4.0245e-01,  4.3114e-01,\n",
       "                        1.6214e+00,  1.5265e+00,  1.8980e+00,  1.6569e-01,  1.0126e+00,\n",
       "                        2.0592e+00,  1.6533e+00,  1.3445e+00,  1.1485e+00,  1.7533e+00,\n",
       "                        6.7530e-01,  2.4183e+00,  1.0053e+00,  1.3582e+00,  1.3594e+00,\n",
       "                        3.0542e-01,  1.3418e+00,  1.1571e+00,  4.6083e-01,  2.7909e-01,\n",
       "                        5.0918e-03,  4.0195e-01,  1.2358e+00,  1.9020e+00,  1.0537e+00,\n",
       "                        2.2607e+00,  1.9071e+00,  4.7114e-01,  8.3934e-01,  1.7002e-02,\n",
       "                        1.9075e+00,  1.1168e+00,  1.0527e+00,  3.0008e+00,  6.5944e-01,\n",
       "                        5.1691e-01,  2.7367e+00,  3.2144e-03,  1.1936e+00,  1.0543e+00,\n",
       "                       -4.3049e-03,  1.2193e+00,  8.5584e-01,  8.8365e-01,  7.4647e-01,\n",
       "                        9.7951e-01,  1.3446e+00,  2.4416e-01,  1.2236e+00,  1.8437e+00,\n",
       "                        1.6138e+00,  1.0181e+00,  1.3471e+00,  1.1164e+00,  1.0273e+00,\n",
       "                        1.2583e+00,  7.3559e-01,  1.9633e-01,  1.7733e+00,  8.5824e-01,\n",
       "                        5.5437e-01,  1.8549e+00,  1.4933e+00,  2.0382e+00,  6.4831e-04,\n",
       "                        1.3784e+00,  1.8789e+00,  1.1380e-01,  4.7559e-01,  3.5851e-01,\n",
       "                        1.4425e+00,  7.8104e-01,  3.2973e+00,  6.6459e-01,  1.4905e-03,\n",
       "                        1.0781e+00,  8.2663e-01,  2.0934e+00,  3.8002e-01,  4.0837e-01,\n",
       "                        2.5866e+00,  1.1434e+00,  9.6785e-01,  3.6802e-01,  4.8013e-01,\n",
       "                        1.0883e+00], device='cuda:0')),\n",
       "              ('module.layer1.1.bn3.bias',\n",
       "               tensor([-3.8139e-01, -1.1352e+00,  1.0187e-01, -9.3587e-01,  3.0905e-01,\n",
       "                       -1.3609e-01,  8.9031e-02, -6.9865e-01,  6.9611e-02, -3.2716e-01,\n",
       "                       -6.8619e-01,  1.6672e-02, -1.0259e+00, -1.0709e+00, -3.8578e-01,\n",
       "                       -9.7303e-01, -1.2566e+00, -1.1542e+00,  1.8015e+00, -7.5855e-02,\n",
       "                        3.5373e-01,  3.4165e-01,  9.4456e-01,  4.1903e-03,  5.6933e-01,\n",
       "                       -8.8317e-02, -4.4712e-01, -3.3476e-01, -9.9739e-01, -2.8357e-01,\n",
       "                       -9.1857e-01, -9.7165e-01, -1.3457e+00,  1.0117e-01, -1.3276e+00,\n",
       "                        2.1820e+00, -1.3821e+00,  1.1623e-01, -7.6699e-01, -7.6498e-01,\n",
       "                       -2.1264e-02, -1.3544e+00, -6.1146e-02,  3.9836e-02, -1.2274e+00,\n",
       "                        1.2412e+00, -5.2201e+00, -4.2594e-01, -1.1450e+00,  3.2540e+00,\n",
       "                        5.3371e-02, -3.7592e-01, -1.8683e+00,  6.6285e-01,  3.9531e-01,\n",
       "                       -3.1231e-01, -1.2955e+00, -3.0807e-01,  4.8035e-02,  1.4836e-01,\n",
       "                       -1.2231e+00, -1.8361e+00, -1.3555e-01, -3.0572e-01, -6.9649e-01,\n",
       "                       -9.0006e-02, -3.0861e+00,  2.4303e+00, -9.3342e-01, -9.0322e-02,\n",
       "                       -1.2978e+00, -2.7312e-01, -5.1041e-01, -8.2551e-01,  5.8434e-01,\n",
       "                        2.4620e-01, -6.5011e-01, -1.1342e-02, -8.8965e-01, -1.7201e+00,\n",
       "                        4.9099e-01, -3.0988e-01,  2.0391e-02, -1.6255e+00, -2.7372e-01,\n",
       "                       -5.6306e-02, -1.0867e+00, -1.0370e+00,  3.9609e-02,  7.1283e-02,\n",
       "                       -1.0338e+00, -2.9309e-01, -3.8920e-01, -4.3081e-01,  4.6748e-02,\n",
       "                        7.0832e-01, -2.1364e-01, -2.0479e+00, -5.5722e-02,  1.1894e-01,\n",
       "                        9.7024e-02,  4.8253e-03, -5.3574e-01,  5.5434e-02, -7.1527e-01,\n",
       "                       -2.0631e-02,  4.5033e-03,  1.2776e-02, -5.9868e-01, -6.2953e-01,\n",
       "                        4.9694e-01, -1.0566e+00, -2.5635e-01, -1.6038e-01, -1.2388e+00,\n",
       "                       -5.4004e-01, -2.1170e-01, -1.8484e-01, -5.0422e-01, -5.9250e-01,\n",
       "                       -3.1193e+00, -1.5055e+00,  7.8799e-03,  2.3448e-01, -4.8056e+00,\n",
       "                        5.4001e-01, -9.7272e-01,  1.7835e-01, -2.3760e+00,  2.0056e-01,\n",
       "                        1.3641e+00, -2.2327e+00,  9.7759e-01, -6.1030e-01,  4.4936e-01,\n",
       "                       -7.1201e-01, -1.1681e-01, -1.1276e+00,  1.1261e-01,  1.7890e-01,\n",
       "                        5.8892e-02, -1.5016e+00, -4.6257e-01, -3.2094e-03, -7.9946e-01,\n",
       "                       -9.1960e-01, -5.7307e-02, -4.0751e-02, -1.3818e+00,  3.4741e-01,\n",
       "                       -9.8051e-02, -3.7281e-01, -1.3010e+00, -1.3551e+00, -3.7296e-01,\n",
       "                        8.5830e-01, -9.3524e-01, -7.8331e-01,  6.0745e-02, -8.2750e-01,\n",
       "                       -5.9628e-02, -4.3558e-01, -6.6686e-01,  6.9964e-02,  2.6319e+00,\n",
       "                       -8.2855e-01, -6.3503e-01,  2.8361e-01,  5.2176e-01, -1.0326e-01,\n",
       "                       -1.5159e+00, -5.9983e-01, -2.8315e-01,  4.8521e-01, -6.4329e-01,\n",
       "                       -1.2705e+00, -7.0264e-01, -1.1692e-02, -6.1931e-01, -6.8663e-01,\n",
       "                        3.5913e-01, -3.9506e+00, -8.1453e-01, -1.2623e+00,  4.3030e+00,\n",
       "                       -3.6977e-01,  3.6994e-01,  5.3729e-01, -5.6196e-01, -2.7931e-02,\n",
       "                        3.3033e-03,  4.8221e-01, -1.1451e+00,  1.0020e-01, -7.7999e-01,\n",
       "                       -2.1457e+00, -1.8109e+00, -3.9980e-02, -3.3926e-01,  9.2612e-02,\n",
       "                       -1.2075e+00, -9.0870e-01, -4.6349e-01, -8.2429e-01, -1.6770e+00,\n",
       "                        1.5255e-01,  3.1010e-01,  1.6233e-02, -6.3255e-02,  7.1075e-01,\n",
       "                        8.5505e-03,  1.9248e-01, -1.1422e-01, -6.9548e-02, -3.5087e-01,\n",
       "                       -4.9712e-01, -8.7207e-01,  2.5889e-02, -6.8791e-01, -2.6361e-02,\n",
       "                        2.5914e-01, -6.0643e-01, -7.5080e-01, -6.3385e-01,  3.1282e+00,\n",
       "                       -1.3287e+00, -3.1158e-01, -1.1785e-01, -4.1348e-01, -1.9689e-01,\n",
       "                        1.1709e-01, -1.1513e+00, -1.4831e+00, -2.1888e+00,  1.7384e-03,\n",
       "                        3.4178e+00, -1.0454e+00,  6.9359e-02,  4.3545e-02,  1.4316e+00,\n",
       "                       -2.2160e-01,  3.4725e-01, -6.0822e-01,  4.4363e-01,  6.4728e-03,\n",
       "                       -7.3907e-01, -5.2817e-02,  2.1926e-01, -3.8311e-02, -9.4011e-02,\n",
       "                       -1.5227e+00, -4.9368e-01, -7.3375e-01,  3.3297e-02,  5.5131e-01,\n",
       "                       -6.4695e-01], device='cuda:0')),\n",
       "              ('module.layer1.1.bn3.running_mean',\n",
       "               tensor([-1.5784e+00,  5.4863e-01, -1.9001e+00, -6.5392e-01, -1.9424e-01,\n",
       "                       -2.3049e+00,  2.1627e-01,  2.1403e+00, -5.6621e-02, -4.0855e+00,\n",
       "                        8.9775e-01,  7.1315e-02,  9.8300e-01,  1.7510e+00, -8.0163e-01,\n",
       "                       -9.6016e-01, -5.0930e-01, -2.0515e+00,  1.8312e+00, -5.3448e-01,\n",
       "                        1.6536e-01,  6.3934e-01, -1.1767e+00, -1.4903e-02,  3.1018e-01,\n",
       "                       -7.6408e-01, -3.1094e+00, -6.3033e-01, -1.1385e+00,  5.7391e-01,\n",
       "                       -4.6235e-01, -2.3453e+00, -9.1882e-01,  7.3724e-02, -8.0570e-01,\n",
       "                        3.0559e+00,  1.5449e-01, -1.4639e+00,  1.5006e+00, -5.2216e-03,\n",
       "                       -4.5245e-01, -2.8318e+00, -5.8313e-01, -2.4970e+00, -4.7080e-01,\n",
       "                       -4.3960e-01, -5.7851e-01, -2.2987e+00, -1.1607e+00,  1.9933e+00,\n",
       "                       -9.4270e-03,  7.0292e-01, -3.2581e+00, -1.9779e-01,  8.4708e-02,\n",
       "                       -5.0111e-01, -1.5453e+00, -1.4474e-01,  9.3822e-03, -2.8306e+00,\n",
       "                        7.0718e-01,  6.9851e-02, -9.6039e-01, -1.4467e+00, -6.0144e-01,\n",
       "                       -4.0050e-01, -2.1617e-01,  1.6308e+00, -8.5282e-01, -1.2206e+00,\n",
       "                       -5.6004e-01, -1.4979e+00, -7.8138e-01, -4.4388e-01, -1.5563e+00,\n",
       "                        5.4932e-02, -1.3826e+00, -4.8660e-02, -3.1959e+00, -1.2197e-01,\n",
       "                        1.2482e+00, -4.6686e-01,  2.3998e-02,  4.6710e-02, -3.6513e-01,\n",
       "                        2.8858e+00, -1.2246e+00,  3.9070e-01, -1.2080e+00,  6.6820e-01,\n",
       "                        4.2172e-01,  3.6743e-01, -1.1103e+00, -3.6776e-01, -3.7340e-01,\n",
       "                        1.5966e+00, -2.5414e+00, -3.3634e+00,  3.7715e-01, -1.5151e+00,\n",
       "                       -2.1799e+00, -4.9084e-02,  4.4212e-01, -3.4572e+00,  2.2991e-01,\n",
       "                       -2.8186e+00, -2.2278e-01, -4.8156e-02,  5.0459e-02, -1.5430e+00,\n",
       "                        5.3037e-01, -1.3592e+00, -4.5846e-01, -1.3686e+00, -1.2038e+00,\n",
       "                        9.2390e-01, -1.5143e+00, -1.3867e+00, -4.1227e+00,  1.4386e-01,\n",
       "                       -3.4892e+00,  8.4660e-01, -5.7065e-02, -4.0669e-01, -3.6291e+00,\n",
       "                        7.1702e-01, -5.1285e-01, -1.5128e+00,  1.1850e+00,  1.9418e+00,\n",
       "                        1.6318e+00,  4.8244e-01,  2.5087e+00, -1.5904e+00,  1.5202e+00,\n",
       "                        6.2821e-01, -2.4850e+00,  2.9174e+00,  2.1501e+00,  4.8464e-01,\n",
       "                        7.7541e-01, -1.1346e+00, -6.0759e-01, -6.3336e-02, -6.4755e-01,\n",
       "                        3.4024e-01, -3.6811e-01, -6.2151e-01, -1.8582e+00, -2.9037e-01,\n",
       "                       -6.5156e-01, -1.4668e+00, -2.5961e+00,  1.4459e-01, -8.1733e-01,\n",
       "                       -2.7556e+00,  1.0390e+00,  3.1882e-01, -3.0330e+00,  1.1162e+00,\n",
       "                        1.8918e-01, -3.3499e-01,  1.9927e+00,  9.4279e-01,  1.6530e+00,\n",
       "                       -3.6079e+00, -1.7436e+00,  9.7249e-01,  3.9099e+00, -1.6329e+00,\n",
       "                       -6.9514e-01, -1.2751e+00,  3.8347e+00, -6.4204e-01, -8.8389e-01,\n",
       "                       -1.9616e+00,  1.5964e+00,  1.6741e+00,  4.7981e-01, -1.5737e+00,\n",
       "                        4.0762e-02, -1.2712e+00, -7.3065e-01, -3.2134e+00,  3.8426e+00,\n",
       "                        9.0361e-01,  2.1425e-01,  1.3500e+00, -5.0359e-01, -1.0897e-01,\n",
       "                       -1.1680e-01, -2.9625e+00, -3.4376e+00, -6.0761e+00, -5.9023e-01,\n",
       "                       -9.1098e-02, -2.3144e+00, -3.3139e-01, -9.3528e-01,  1.5601e-01,\n",
       "                       -1.6186e+00, -1.7564e+00,  4.9247e-01, -1.5397e+00,  3.0604e+00,\n",
       "                        1.1856e+00, -1.1481e+00, -8.1135e-02, -2.6566e+00,  8.4225e-01,\n",
       "                        2.5914e-02, -2.3051e+00, -1.7067e+00, -2.6386e+00,  3.6653e-01,\n",
       "                        3.4286e-01, -8.2445e-01,  7.5772e-01, -1.6186e-02,  1.2476e+00,\n",
       "                       -2.3792e+00,  1.2005e+00, -4.7311e-01,  5.0503e-01, -5.8048e-02,\n",
       "                       -1.3031e+00, -1.0198e+00, -3.9459e-01,  2.4318e-01, -1.1063e+00,\n",
       "                       -1.0921e+00, -3.1316e+00, -7.1358e-02, -2.9782e+00, -8.7545e-03,\n",
       "                       -5.2308e-03,  9.4464e-01, -5.7490e-01,  1.7572e+00, -7.2446e-01,\n",
       "                       -2.6268e+00, -5.0433e-01, -2.7702e-01,  1.1256e+00, -4.2947e-02,\n",
       "                        7.6511e-01, -1.3110e-01,  1.7261e-01, -1.5639e+00, -8.6829e-01,\n",
       "                        1.1151e+00, -1.8679e+00, -4.1512e-01, -1.7059e+00, -1.8376e+00,\n",
       "                        4.9165e-02], device='cuda:0')),\n",
       "              ('module.layer1.1.bn3.running_var',\n",
       "               tensor([0.2470, 1.0550, 1.0415, 1.5645, 0.0385, 0.5564, 0.0131, 0.2637, 0.0673,\n",
       "                       1.0765, 0.8164, 0.0146, 0.6056, 0.9298, 0.3191, 0.7125, 0.6671, 0.6302,\n",
       "                       1.8953, 2.0104, 0.4496, 0.6680, 0.4912, 0.0139, 0.5313, 0.3920, 0.7670,\n",
       "                       1.7489, 0.6231, 0.3576, 1.0339, 0.9442, 0.7336, 0.2595, 1.5512, 1.0541,\n",
       "                       0.6587, 0.6791, 1.6062, 0.9608, 0.1401, 0.7651, 2.1886, 0.4106, 1.1461,\n",
       "                       0.9189, 1.1328, 0.5850, 0.9916, 3.6804, 0.0180, 1.9281, 1.0987, 0.0050,\n",
       "                       0.1349, 1.1933, 1.3449, 2.3231, 0.0467, 1.0328, 1.0966, 0.5427, 0.3985,\n",
       "                       1.1155, 0.5136, 0.7076, 0.3066, 1.5958, 0.3612, 0.9475, 1.0256, 0.7608,\n",
       "                       0.9073, 0.7260, 0.8167, 0.0550, 2.7537, 0.0161, 1.0631, 0.8647, 1.0779,\n",
       "                       0.7717, 0.0602, 0.7146, 0.5379, 0.2782, 0.6195, 0.5910, 0.9181, 1.0404,\n",
       "                       2.2516, 0.6850, 2.5446, 2.3412, 0.4186, 0.4196, 0.9157, 0.9865, 0.5448,\n",
       "                       0.3628, 0.5036, 0.0512, 0.8600, 0.8059, 0.7207, 0.6091, 0.0419, 0.0577,\n",
       "                       0.9169, 1.7296, 0.6123, 0.8572, 1.2508, 0.4632, 0.9846, 0.6325, 0.4220,\n",
       "                       1.5024, 1.9415, 0.5919, 1.5864, 1.0037, 0.0405, 0.6656, 2.4233, 0.1576,\n",
       "                       0.6703, 0.6643, 0.7666, 0.8149, 0.6057, 0.3829, 1.0807, 0.6597, 0.5608,\n",
       "                       0.6564, 2.0693, 0.6643, 0.6692, 0.1131, 0.4803, 0.4746, 1.1453, 0.2277,\n",
       "                       1.5011, 0.6480, 0.3685, 0.2136, 0.6331, 1.0769, 0.2154, 0.7969, 1.3011,\n",
       "                       0.5543, 0.4022, 0.2927, 0.4097, 1.9356, 1.1153, 0.7258, 1.0465, 0.6149,\n",
       "                       0.5447, 1.2637, 1.0049, 1.3026, 0.7015, 0.9085, 1.2673, 0.3551, 0.5158,\n",
       "                       0.8750, 1.1553, 0.3681, 0.5618, 0.7235, 1.2947, 0.8850, 0.6428, 0.8166,\n",
       "                       0.5631, 0.3921, 1.6612, 1.1251, 2.4605, 0.3359, 0.5197, 0.7131, 0.5432,\n",
       "                       0.3857, 0.0218, 0.5312, 0.4833, 1.0907, 0.3512, 0.9278, 0.9427, 0.4281,\n",
       "                       0.7153, 0.0066, 0.9580, 0.9595, 0.9190, 2.5354, 0.9461, 0.7187, 2.2926,\n",
       "                       0.0321, 1.6157, 0.6198, 0.0232, 1.0984, 0.5319, 0.9138, 0.8307, 0.7002,\n",
       "                       0.4736, 0.2500, 0.5020, 1.8345, 0.8437, 0.5584, 0.4982, 1.1084, 1.2617,\n",
       "                       0.6967, 0.4580, 0.1130, 1.4870, 0.4192, 0.3534, 1.1952, 0.4408, 0.6877,\n",
       "                       0.0151, 1.6842, 0.8710, 0.1934, 0.4223, 0.3282, 0.8627, 0.8239, 2.7100,\n",
       "                       0.4302, 0.0124, 1.3123, 0.6382, 1.6337, 0.2520, 0.4686, 1.4579, 0.6405,\n",
       "                       0.5574, 0.4495, 0.8829, 0.2856], device='cuda:0')),\n",
       "              ('module.layer1.1.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.2.conv1.weight',\n",
       "               tensor([[[[ 0.0148]],\n",
       "               \n",
       "                        [[ 0.0018]],\n",
       "               \n",
       "                        [[-0.0307]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0199]],\n",
       "               \n",
       "                        [[ 0.0171]],\n",
       "               \n",
       "                        [[-0.0517]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0171]],\n",
       "               \n",
       "                        [[ 0.0045]],\n",
       "               \n",
       "                        [[ 0.0030]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0554]],\n",
       "               \n",
       "                        [[ 0.0432]],\n",
       "               \n",
       "                        [[-0.0247]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1967]],\n",
       "               \n",
       "                        [[ 0.0046]],\n",
       "               \n",
       "                        [[ 0.0306]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0368]],\n",
       "               \n",
       "                        [[ 0.0040]],\n",
       "               \n",
       "                        [[ 0.0165]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0133]],\n",
       "               \n",
       "                        [[ 0.0235]],\n",
       "               \n",
       "                        [[-0.0046]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0194]],\n",
       "               \n",
       "                        [[-0.0099]],\n",
       "               \n",
       "                        [[-0.0455]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0549]],\n",
       "               \n",
       "                        [[-0.0106]],\n",
       "               \n",
       "                        [[ 0.0178]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0237]],\n",
       "               \n",
       "                        [[ 0.0430]],\n",
       "               \n",
       "                        [[ 0.0181]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0111]],\n",
       "               \n",
       "                        [[ 0.0110]],\n",
       "               \n",
       "                        [[ 0.0521]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0623]],\n",
       "               \n",
       "                        [[ 0.0026]],\n",
       "               \n",
       "                        [[-0.0512]]]], device='cuda:0')),\n",
       "              ('module.layer1.2.bn1.weight',\n",
       "               tensor([1.3954, 1.9138, 1.6301, 1.6171, 1.6671, 1.3141, 1.8823, 1.7864, 1.6757,\n",
       "                       1.4860, 1.8123, 1.2800, 1.2406, 1.6825, 2.7135, 1.4630, 1.6460, 1.7497,\n",
       "                       2.8910, 1.2438, 1.3146, 2.2736, 1.8346, 1.6127, 2.0548, 1.6063, 3.1341,\n",
       "                       1.4744, 1.8937, 1.9267, 1.7008, 3.3303, 1.3453, 1.3596, 1.2178, 1.3987,\n",
       "                       1.4652, 2.3218, 1.3133, 1.7448, 2.0615, 1.8245, 1.6579, 1.9161, 1.1282,\n",
       "                       1.7110, 1.5379, 1.8618, 2.0899, 1.9845, 1.6728, 1.4695, 1.4482, 2.0185,\n",
       "                       4.3729, 3.0129, 1.9140, 1.8858, 2.0335, 2.0293, 2.0076, 1.7073, 1.7656,\n",
       "                       1.7999], device='cuda:0')),\n",
       "              ('module.layer1.2.bn1.bias',\n",
       "               tensor([ 0.6267, -0.2298,  0.3848,  0.7318,  0.7067,  1.2720, -0.0387, -0.7357,\n",
       "                        0.6383,  1.0706, -0.0345,  1.0935,  1.8867,  0.3508, -3.3561,  0.7162,\n",
       "                       -0.0118,  0.2374, -2.8569,  1.1127,  1.4294, -1.1294, -0.2289,  0.3728,\n",
       "                       -1.7857,  0.6131, -1.8980, -0.0574,  0.4671, -0.3837,  1.0687, -7.7635,\n",
       "                        1.9642,  1.0893,  3.5756,  0.9265,  0.4969, -1.3115,  1.4049,  0.7174,\n",
       "                       -0.3415, -0.6983, -0.2621, -0.9956,  2.1738,  0.5574,  0.6403, -0.2134,\n",
       "                       -0.6588, -0.6177,  0.4005,  0.6642,  0.6879, -1.4920, -8.7019, -3.2065,\n",
       "                       -0.9098, -0.6782, -0.2287, -0.9539, -1.2087, -0.0105,  0.5953,  0.0419],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer1.2.bn1.running_mean',\n",
       "               tensor([ 0.8733,  0.4447, -1.5184, -0.5929, -2.5999,  2.3500, -0.5670, -1.9984,\n",
       "                        1.2846,  4.0095, -0.9535,  0.3758, -1.1781, -0.7967, -0.2171, -0.0914,\n",
       "                        0.3585,  1.2470, -1.6810, -0.1541, -0.5527, -2.4791, -0.4268, -0.8692,\n",
       "                       -0.3185, -0.7195, -2.9161, -0.0711, -1.9356, -3.0232, -0.8290,  0.1852,\n",
       "                        0.2294,  1.3136,  0.5164,  0.7095,  2.9292, -1.3079,  0.5854,  0.0952,\n",
       "                        0.4577, -2.3300, -0.2387, -0.6636, -0.8829,  0.4102,  1.6596,  0.5655,\n",
       "                       -2.2071, -1.9442,  1.0085, -2.2950,  0.5611, -1.6050, -1.6621, -3.4385,\n",
       "                       -3.1927, -1.1530, -1.6648,  1.7216, -3.3093,  0.3386, -0.7406, -0.9780],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer1.2.bn1.running_var',\n",
       "               tensor([3.0034, 4.7120, 2.9697, 3.7446, 3.0198, 2.9751, 4.9078, 3.3232, 5.0244,\n",
       "                       5.2399, 4.7535, 2.6706, 2.6571, 3.6586, 2.2408, 4.5427, 3.8242, 3.5745,\n",
       "                       3.1193, 3.0036, 3.2658, 3.2169, 4.9526, 3.5005, 2.1034, 5.2290, 4.2851,\n",
       "                       2.8751, 3.2681, 4.3338, 4.3616, 1.6959, 8.2029, 3.0629, 4.8759, 3.6698,\n",
       "                       3.4660, 3.2680, 3.7489, 4.9836, 5.6337, 2.8368, 4.0994, 2.8496, 2.2082,\n",
       "                       4.0094, 5.0782, 4.4312, 3.8089, 3.4044, 4.6411, 3.2805, 4.9877, 2.8562,\n",
       "                       1.6104, 3.1220, 2.9501, 3.0547, 3.5134, 2.5863, 3.6730, 4.2971, 3.5256,\n",
       "                       3.1319], device='cuda:0')),\n",
       "              ('module.layer1.2.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.2.conv2.weight',\n",
       "               tensor([[[[ 2.2017e-02,  1.1996e-03,  1.5652e-02],\n",
       "                         [ 2.5797e-02,  1.7626e-02, -2.6005e-02],\n",
       "                         [-9.9668e-03, -5.1444e-03, -2.7748e-02]],\n",
       "               \n",
       "                        [[ 1.1797e-02, -3.0945e-02,  6.8914e-03],\n",
       "                         [-3.4003e-02,  3.4670e-02, -3.8588e-02],\n",
       "                         [-1.9407e-02, -1.9454e-02,  1.9221e-02]],\n",
       "               \n",
       "                        [[ 1.7361e-02, -1.0427e-02,  1.2057e-03],\n",
       "                         [-3.8171e-03,  2.5178e-02,  1.3818e-02],\n",
       "                         [ 3.1543e-02, -1.7075e-02, -1.0920e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.9802e-02, -2.0394e-02,  3.4814e-02],\n",
       "                         [ 7.7902e-02, -3.8639e-02, -9.6262e-02],\n",
       "                         [ 4.3284e-02,  5.5072e-02, -6.6463e-02]],\n",
       "               \n",
       "                        [[ 3.3240e-02, -5.2272e-02,  1.4611e-02],\n",
       "                         [-3.1191e-02,  1.9182e-02,  1.0278e-02],\n",
       "                         [-2.4953e-02,  4.5807e-02, -2.4405e-02]],\n",
       "               \n",
       "                        [[-8.3468e-03, -2.9425e-03,  4.8389e-02],\n",
       "                         [ 7.6263e-02, -1.2726e-01,  1.0315e-01],\n",
       "                         [ 7.8978e-02, -9.8208e-02,  4.7324e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2946e-02,  4.3796e-02, -1.8071e-02],\n",
       "                         [ 5.1808e-02,  4.3896e-02, -1.3945e-01],\n",
       "                         [ 6.7256e-02, -2.4785e-02, -1.7491e-02]],\n",
       "               \n",
       "                        [[ 1.2759e-02,  2.3825e-02, -4.2040e-02],\n",
       "                         [-6.0060e-03,  1.5340e-02,  2.2600e-02],\n",
       "                         [ 9.5107e-03, -2.6227e-03, -4.2580e-02]],\n",
       "               \n",
       "                        [[-5.4328e-03, -5.5122e-02,  2.3790e-02],\n",
       "                         [-1.7798e-03,  2.4248e-02, -4.6521e-03],\n",
       "                         [ 1.9366e-02, -1.7271e-02,  7.8215e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.2693e-02, -4.7576e-02, -6.1797e-02],\n",
       "                         [-1.8419e-03,  1.9065e-01,  9.6538e-03],\n",
       "                         [-3.8924e-02, -3.8042e-02,  1.7558e-02]],\n",
       "               \n",
       "                        [[ 3.1428e-02,  9.1699e-03, -2.1224e-02],\n",
       "                         [ 8.6734e-02, -1.0056e-01, -3.4277e-02],\n",
       "                         [ 5.1490e-02, -3.9753e-02,  4.0115e-02]],\n",
       "               \n",
       "                        [[-3.6633e-03,  4.7066e-02, -3.4600e-02],\n",
       "                         [ 8.1606e-02,  4.4424e-02,  6.5056e-03],\n",
       "                         [ 1.3661e-02, -4.6031e-02, -6.1588e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.8182e-02,  3.5560e-02, -1.2804e-02],\n",
       "                         [ 1.6064e-02, -2.1720e-04, -5.4592e-02],\n",
       "                         [-1.1488e-03, -2.0811e-02,  1.0934e-02]],\n",
       "               \n",
       "                        [[-7.6883e-02, -1.5757e-01, -1.1668e-02],\n",
       "                         [-1.4165e-01,  5.0702e-02,  1.8386e-01],\n",
       "                         [ 9.5650e-02,  1.2799e-01,  6.1046e-02]],\n",
       "               \n",
       "                        [[ 1.1274e-02, -4.9351e-02, -7.2827e-02],\n",
       "                         [-9.4224e-02, -3.8905e-02,  1.0304e-01],\n",
       "                         [-5.9165e-03,  9.7840e-02, -4.1144e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.4380e-02, -4.5429e-02, -5.5551e-02],\n",
       "                         [-1.3540e-01, -1.6280e-01, -8.5744e-03],\n",
       "                         [-3.7861e-02,  4.7517e-02,  1.2840e-01]],\n",
       "               \n",
       "                        [[-2.1650e-02, -1.8886e-01, -4.8475e-04],\n",
       "                         [ 4.3558e-02,  2.9927e-01,  1.4781e-03],\n",
       "                         [-3.1990e-02, -1.2670e-01,  3.7987e-02]],\n",
       "               \n",
       "                        [[ 9.1033e-02,  7.3707e-02, -2.0516e-02],\n",
       "                         [-1.3220e-01, -1.3065e-01,  8.8029e-02],\n",
       "                         [ 4.2427e-02,  2.1868e-02, -5.6129e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-9.7689e-02,  3.2125e-02,  3.9406e-02],\n",
       "                         [-7.3690e-02,  1.7134e-02, -2.6581e-02],\n",
       "                         [-1.3784e-02,  7.7794e-02, -2.9794e-02]],\n",
       "               \n",
       "                        [[-6.3288e-03,  1.5884e-02,  1.1183e-02],\n",
       "                         [-1.0372e-02,  3.9064e-02,  5.3554e-02],\n",
       "                         [-2.8664e-02,  2.5944e-02,  3.6459e-03]],\n",
       "               \n",
       "                        [[ 2.4589e-02,  7.2982e-03, -1.5312e-02],\n",
       "                         [ 2.3351e-02, -5.1217e-02,  8.0417e-02],\n",
       "                         [ 2.9072e-02, -1.6533e-01,  2.5752e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.5924e-02,  3.2091e-04, -4.7351e-03],\n",
       "                         [ 5.3375e-02,  7.3438e-02, -5.2485e-03],\n",
       "                         [ 1.6963e-02, -5.7337e-03,  1.2593e-05]],\n",
       "               \n",
       "                        [[-1.6497e-02, -1.5099e-02,  2.6302e-02],\n",
       "                         [ 1.6126e-02, -5.1769e-02, -2.2164e-02],\n",
       "                         [ 2.3674e-02, -3.0188e-02,  6.4937e-03]],\n",
       "               \n",
       "                        [[-5.9949e-03, -1.9155e-02,  2.0140e-02],\n",
       "                         [-4.3288e-02, -6.2281e-02, -4.1623e-02],\n",
       "                         [ 1.1737e-02,  3.4183e-04, -2.1139e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.8243e-02, -1.6080e-04,  9.9311e-03],\n",
       "                         [-9.3768e-02,  3.1980e-02,  8.8310e-02],\n",
       "                         [ 6.3592e-03, -3.1856e-02, -9.0388e-03]],\n",
       "               \n",
       "                        [[-8.4820e-02, -2.2584e-02, -9.3991e-02],\n",
       "                         [ 2.5930e-02, -8.2511e-02,  3.9559e-02],\n",
       "                         [-2.1871e-02,  7.5244e-03, -6.5513e-02]],\n",
       "               \n",
       "                        [[ 1.4416e-02, -1.1511e-02,  5.8014e-02],\n",
       "                         [-4.3982e-02, -2.5730e-02,  4.7957e-03],\n",
       "                         [ 1.1726e-02, -3.5143e-02, -2.4076e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.7724e-03,  4.5101e-02,  4.3523e-02],\n",
       "                         [-2.5646e-02,  6.3740e-03, -7.3062e-02],\n",
       "                         [-4.2419e-02, -5.3564e-02,  8.3645e-02]],\n",
       "               \n",
       "                        [[-9.1153e-02, -2.1684e-02,  1.4834e-01],\n",
       "                         [ 1.4932e-01,  3.8082e-02, -1.5149e-01],\n",
       "                         [-1.2601e-01, -5.8511e-02,  6.7238e-02]],\n",
       "               \n",
       "                        [[-6.8254e-03,  7.6902e-02,  1.2278e-01],\n",
       "                         [-3.6599e-02, -2.4605e-01, -9.0578e-02],\n",
       "                         [ 1.2074e-01,  1.4338e-01,  1.4617e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0849e-02,  2.1476e-02,  1.0355e-02],\n",
       "                         [-1.2482e-01,  3.7400e-03, -6.1767e-02],\n",
       "                         [ 5.8916e-03,  4.8976e-02, -8.6734e-03]],\n",
       "               \n",
       "                        [[ 3.8729e-02,  8.0419e-02, -6.2530e-02],\n",
       "                         [ 6.8324e-02, -3.0857e-03, -1.8134e-02],\n",
       "                         [ 9.1150e-02,  2.9177e-02,  1.5283e-02]],\n",
       "               \n",
       "                        [[-1.3608e-02,  1.5802e-01, -1.6574e-03],\n",
       "                         [ 1.4992e-01, -1.4018e-03,  5.7825e-02],\n",
       "                         [ 2.1046e-03, -3.1322e-01,  3.1087e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.4445e-02, -3.1613e-03, -2.8687e-02],\n",
       "                         [-4.8407e-03,  5.3084e-02, -5.7988e-02],\n",
       "                         [-4.8729e-02,  1.0093e-01,  1.1611e-01]],\n",
       "               \n",
       "                        [[-5.8172e-03, -1.3395e-01,  1.7060e-03],\n",
       "                         [-1.9286e-02, -1.9699e-02,  1.6771e-01],\n",
       "                         [ 3.1591e-03, -1.4233e-03,  1.6425e-02]],\n",
       "               \n",
       "                        [[ 1.2209e-04,  2.4726e-02,  1.0423e-01],\n",
       "                         [ 2.8692e-05, -1.3929e-01, -2.1517e-03],\n",
       "                         [-4.1336e-02, -5.8246e-02, -2.7873e-02]]]], device='cuda:0')),\n",
       "              ('module.layer1.2.bn2.weight',\n",
       "               tensor([1.5079, 1.4472, 1.7381, 1.6846, 1.1605, 1.4135, 3.8862, 1.1401, 0.9600,\n",
       "                       1.1614, 0.9535, 2.5098, 1.0606, 1.4374, 1.4928, 1.8389, 1.1195, 1.7253,\n",
       "                       1.4677, 1.6292, 1.6992, 1.1342, 1.1161, 1.8186, 1.7475, 1.8044, 1.5223,\n",
       "                       1.2667, 1.8444, 1.3813, 1.7666, 1.3496, 1.4791, 3.4795, 1.8435, 1.7731,\n",
       "                       1.4697, 1.6927, 1.4144, 1.8346, 1.7156, 1.1023, 1.8588, 1.5318, 1.7186,\n",
       "                       1.4312, 1.7361, 1.2019, 1.1286, 1.5027, 1.0888, 1.6202, 1.7083, 1.0826,\n",
       "                       1.8878, 1.7007, 1.1735, 1.6408, 0.9880, 1.9098, 1.4586, 1.2721, 1.8557,\n",
       "                       1.1497], device='cuda:0')),\n",
       "              ('module.layer1.2.bn2.bias',\n",
       "               tensor([-2.3608e-01, -7.0076e-02, -4.5872e-01, -5.0734e-01,  4.6213e+00,\n",
       "                        3.7276e-01, -5.1841e+00,  2.3512e+00,  2.6953e+00,  1.0641e+00,\n",
       "                        3.0854e+00, -1.3287e+01,  4.3328e+00,  2.5729e-01, -6.1723e-01,\n",
       "                       -5.7655e-01,  3.6303e+00, -6.7784e-01, -1.1576e-01, -3.8218e-01,\n",
       "                       -4.8608e-01,  2.5492e+00,  8.1849e-01, -5.9740e-01, -6.9557e-01,\n",
       "                       -5.1951e-01, -2.0144e-01,  8.8188e-01, -7.9577e-01,  4.8920e-01,\n",
       "                       -4.4411e-01,  6.4655e-01, -6.8715e-01, -3.8177e+00, -6.3100e-01,\n",
       "                       -6.7006e-01,  3.9775e-02, -4.5191e-01,  2.7146e-01, -7.4720e-01,\n",
       "                       -4.7635e-01,  2.9180e+00, -8.2596e-01,  2.7709e-01, -1.5370e-01,\n",
       "                        1.1168e-02, -4.0742e-01,  4.1921e+00,  2.8359e+00, -2.3013e-01,\n",
       "                        4.1132e+00, -4.6822e-01, -8.1256e-01,  8.4734e-01, -6.2880e-01,\n",
       "                       -3.6615e-01,  3.0084e+00, -4.2621e-01,  3.8936e+00, -6.5001e-01,\n",
       "                       -6.6166e-02,  5.6852e-01, -6.4131e-01,  4.2079e+00], device='cuda:0')),\n",
       "              ('module.layer1.2.bn2.running_mean',\n",
       "               tensor([ 1.0303e-01, -7.6592e-01, -4.0689e-01, -5.9914e-02, -9.9442e-01,\n",
       "                        1.4662e+00, -4.2875e+00,  8.5516e-01, -1.2693e+00,  1.3375e+00,\n",
       "                       -1.5795e+00, -1.9137e+00,  1.8994e+00,  1.9666e-01, -7.8130e-01,\n",
       "                       -5.3392e-01, -6.8975e+00, -4.6918e-01, -1.3992e+00,  3.8095e-01,\n",
       "                       -2.5423e-01, -1.5761e+00,  1.1157e-02, -1.2710e+00, -1.5992e-03,\n",
       "                        6.6086e-01, -1.3194e+00, -2.9077e-01, -8.0715e-01, -1.6114e+00,\n",
       "                       -1.6594e+00, -2.7391e+00,  4.5427e-02, -2.1607e+00, -8.8891e-01,\n",
       "                       -7.7795e-01, -4.8600e-01, -2.1324e+00,  1.4650e+00, -1.2560e+00,\n",
       "                       -1.4605e+00, -8.5223e-01, -1.2706e+00,  1.8547e+00, -8.7090e-01,\n",
       "                       -1.6489e+00, -5.1536e-01,  8.0529e-01, -1.4686e+00, -5.5756e-01,\n",
       "                        1.2783e+00, -5.9383e-01, -1.7989e+00, -2.8504e-01, -1.3415e+00,\n",
       "                       -1.6380e+00,  2.3521e+00, -5.9260e-01,  3.0095e+00, -1.0837e+00,\n",
       "                        4.3105e-02, -1.4799e+00, -5.4600e-01, -2.0549e+00], device='cuda:0')),\n",
       "              ('module.layer1.2.bn2.running_var',\n",
       "               tensor([2.1922, 4.4725, 5.0940, 3.6472, 5.2496, 5.2408, 3.2544, 7.6824, 5.3891,\n",
       "                       4.5432, 2.5763, 2.3544, 4.1757, 4.4291, 2.9520, 3.6976, 5.7039, 4.1225,\n",
       "                       4.0851, 5.2420, 4.4479, 5.4028, 3.6633, 3.7487, 4.1637, 4.0777, 4.3242,\n",
       "                       6.1774, 3.4141, 3.7448, 5.2475, 4.6964, 3.3444, 3.8958, 4.8901, 3.9915,\n",
       "                       4.6855, 3.0713, 4.4433, 3.8054, 3.8679, 3.8178, 2.9407, 5.4161, 7.6685,\n",
       "                       4.5294, 5.9024, 5.0044, 5.0964, 3.5308, 6.2457, 3.5640, 3.2256, 3.3619,\n",
       "                       3.8917, 3.6442, 5.1567, 4.0571, 3.5392, 4.7060, 3.4053, 5.7449, 3.8064,\n",
       "                       5.4050], device='cuda:0')),\n",
       "              ('module.layer1.2.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer1.2.conv3.weight',\n",
       "               tensor([[[[-0.0372]],\n",
       "               \n",
       "                        [[ 0.0744]],\n",
       "               \n",
       "                        [[-0.0754]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0896]],\n",
       "               \n",
       "                        [[ 0.1195]],\n",
       "               \n",
       "                        [[ 0.0016]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0307]],\n",
       "               \n",
       "                        [[-0.0679]],\n",
       "               \n",
       "                        [[-0.0353]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0051]],\n",
       "               \n",
       "                        [[-0.0249]],\n",
       "               \n",
       "                        [[-0.0304]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0068]],\n",
       "               \n",
       "                        [[-0.0080]],\n",
       "               \n",
       "                        [[-0.0288]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0323]],\n",
       "               \n",
       "                        [[ 0.0350]],\n",
       "               \n",
       "                        [[-0.0046]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0191]],\n",
       "               \n",
       "                        [[-0.0057]],\n",
       "               \n",
       "                        [[ 0.0360]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0131]],\n",
       "               \n",
       "                        [[ 0.0164]],\n",
       "               \n",
       "                        [[ 0.0539]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0140]],\n",
       "               \n",
       "                        [[ 0.0237]],\n",
       "               \n",
       "                        [[ 0.0003]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0311]],\n",
       "               \n",
       "                        [[ 0.0064]],\n",
       "               \n",
       "                        [[ 0.0408]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0198]],\n",
       "               \n",
       "                        [[ 0.0177]],\n",
       "               \n",
       "                        [[-0.0310]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.1236]],\n",
       "               \n",
       "                        [[-0.0337]],\n",
       "               \n",
       "                        [[ 0.0042]]]], device='cuda:0')),\n",
       "              ('module.layer1.2.bn3.weight',\n",
       "               tensor([ 4.0826e-01,  4.4383e-01,  1.6538e+00,  1.5270e+00,  1.4350e-01,\n",
       "                        1.1118e+00, -9.4470e-04,  4.1431e-03,  4.9747e-03,  1.5904e+00,\n",
       "                        2.5307e+00, -2.2829e-02,  5.4329e-01,  2.1231e+00,  6.0307e-01,\n",
       "                        6.4986e-01,  3.6067e+00,  5.0924e-01,  8.8714e-01,  1.4733e+00,\n",
       "                        2.4873e+00,  2.2069e-01, -1.5017e-01,  2.6818e-03,  1.5409e+00,\n",
       "                       -9.7454e-02, -1.7954e-02,  2.0402e+00,  1.8290e+00,  9.3771e-01,\n",
       "                        2.5095e+00,  2.0247e+00,  3.1665e+00, -2.1832e-01,  2.5007e+00,\n",
       "                        2.5702e-01,  2.2632e+00,  1.1667e+00,  1.5077e+00,  1.8857e+00,\n",
       "                        2.5557e-01,  2.2481e+00,  7.5231e-01,  1.6496e-01,  1.7437e+00,\n",
       "                        7.0833e-03,  5.0733e+00,  1.9180e+00,  7.5680e-01,  1.2157e+00,\n",
       "                        5.7783e-03,  8.7680e-01,  1.2090e+00,  2.9682e-02,  2.7623e-01,\n",
       "                        2.2457e+00,  1.9389e+00,  1.9022e+00, -1.9342e-02,  1.8270e-01,\n",
       "                        2.4250e+00,  4.9182e-01,  7.3004e-01,  2.2459e+00,  1.8443e+00,\n",
       "                        4.1286e-01,  2.6880e+00,  5.6049e-01,  2.8732e+00,  5.3805e-01,\n",
       "                        9.1271e-01,  6.7315e-01,  1.8176e+00,  3.6739e+00,  2.0276e+00,\n",
       "                       -1.0965e-02,  6.6257e-01,  1.1428e-01,  2.7487e+00,  4.1246e-01,\n",
       "                        4.2943e-01,  2.2082e+00,  4.1260e-02,  1.8082e+00,  2.2126e+00,\n",
       "                        3.2332e-01,  2.8336e+00,  2.0186e+00,  1.1541e+00,  5.5711e-02,\n",
       "                        1.4586e+00,  8.3439e-01,  9.9395e-01,  9.1041e-01,  2.0505e+00,\n",
       "                        2.5979e+00,  1.8347e+00,  8.3446e-01,  2.3777e+00, -2.6693e-02,\n",
       "                        2.3633e+00,  1.5874e-03,  3.6428e+00,  1.7678e+00,  2.0468e+00,\n",
       "                        2.2679e-01,  1.8540e-03, -2.4151e-03,  2.0495e+00,  1.4084e+00,\n",
       "                        6.0912e-01,  2.7539e-01,  2.0102e+00,  2.3296e-01,  2.6344e+00,\n",
       "                        3.1845e+00,  5.5917e-01,  9.6672e-01,  1.5080e+00,  3.6207e+00,\n",
       "                        2.0001e+00,  2.3966e+00,  6.3562e-03,  2.3376e+00,  2.7762e+00,\n",
       "                        1.5275e-02,  1.8801e+00,  2.4199e+00,  3.2428e+00,  1.8744e+00,\n",
       "                        8.2119e-01,  1.6855e+00, -1.2562e-02,  3.5926e+00,  1.3460e-01,\n",
       "                        2.0682e+00,  7.5599e-01,  1.7445e+00,  1.4445e-02, -2.5525e-01,\n",
       "                        2.5514e-01,  4.6979e-01,  1.0408e+00,  1.9819e-02,  1.6260e+00,\n",
       "                        2.7349e+00,  5.8250e-01,  6.5157e-02,  1.8910e+00,  2.1158e+00,\n",
       "                        1.8179e-01,  1.7215e+00,  2.6472e+00,  1.8502e+00,  3.5752e-01,\n",
       "                        1.4215e+00,  6.6304e-01,  1.1464e+00,  2.3015e+00,  2.2621e+00,\n",
       "                        2.1842e+00,  3.8552e-01,  6.8861e-01,  9.4188e-01,  2.6231e+00,\n",
       "                        1.9801e+00,  2.6319e-01,  2.0585e+00, -1.5477e-01,  2.5030e-01,\n",
       "                        2.9259e+00,  6.2406e-01,  1.2141e+00, -8.3306e-03,  2.1687e+00,\n",
       "                        4.0594e-01, -1.7824e-01,  2.1526e+00,  1.9685e+00,  3.2245e+00,\n",
       "                        6.9119e-01,  2.6330e+00,  8.9762e-01,  1.4888e+00, -8.8510e-03,\n",
       "                        5.0531e-01,  2.0580e+00,  1.8953e+00,  4.7747e-01,  2.6006e-03,\n",
       "                        1.2725e-03,  3.4546e-01,  4.2356e+00,  1.2573e+00,  1.3382e+00,\n",
       "                        3.2912e+00,  1.5051e+00,  7.6967e-01,  4.0964e-01,  6.7379e-01,\n",
       "                        2.5283e+00,  4.3515e-01,  4.8769e-01,  1.2302e+00,  1.2069e+00,\n",
       "                        1.1332e-01,  5.9102e-01,  1.3031e-03,  6.7716e-01,  2.6634e+00,\n",
       "                        5.2407e-03, -5.9917e-02,  2.7799e+00,  1.0993e+00,  7.0477e-01,\n",
       "                        1.9758e+00,  2.1569e+00,  2.8276e-01,  2.4778e+00,  1.6896e+00,\n",
       "                        1.7775e+00,  1.4091e+00,  2.3764e+00,  4.4861e-01,  1.0449e+00,\n",
       "                        2.0397e+00,  4.7837e-01,  7.3329e-02,  6.4427e-01,  4.4460e-01,\n",
       "                        2.4970e+00,  1.0801e+00,  2.3025e+00,  1.2545e+00, -4.6013e-02,\n",
       "                        2.4395e-01,  2.4810e+00, -9.2456e-04,  4.9043e-01,  1.0852e-01,\n",
       "                        2.6729e+00,  1.4919e+00,  1.1290e+00,  1.6928e-01, -3.0525e-03,\n",
       "                        8.5643e-01,  2.2350e+00,  1.2361e+00,  2.1368e-01,  4.2219e-01,\n",
       "                        1.4092e+00,  2.0899e+00,  7.9159e-01,  3.0558e-01, -5.9164e-02,\n",
       "                        1.0690e+00], device='cuda:0')),\n",
       "              ('module.layer1.2.bn3.bias',\n",
       "               tensor([-3.8796e-01,  9.5888e-01, -9.7748e-01, -5.3435e-01,  4.2889e-01,\n",
       "                       -5.0816e-01, -6.4858e-02,  2.2647e-01, -3.1639e-02, -1.8694e+00,\n",
       "                       -2.1543e+00, -5.8637e-03,  1.1566e+00, -4.6775e-01,  8.5729e-01,\n",
       "                        1.9547e+00, -2.6501e+00, -4.5145e-01, -1.7848e+00, -8.2553e-01,\n",
       "                       -2.0213e+00, -8.7979e-03,  2.3224e-01,  1.1522e-01, -1.5368e+00,\n",
       "                        1.5355e-01,  3.7426e-01, -8.0315e-01, -2.2425e+00,  1.1621e-02,\n",
       "                       -9.8933e-01, -6.9935e-01, -1.9721e+00,  4.1154e-01, -1.5390e+00,\n",
       "                        1.2529e-01, -1.1758e+00, -1.0487e+00, -4.8150e-01, -1.8875e+00,\n",
       "                       -3.6586e-01, -1.0129e+00, -1.7312e+00, -1.5966e-01, -1.2353e+00,\n",
       "                        2.1411e-01, -5.8919e+00, -1.3586e+00, -4.8720e-01,  1.0285e+00,\n",
       "                       -3.0027e-02, -4.0367e-01, -3.7279e-01,  2.9461e-01,  2.4155e-01,\n",
       "                       -2.2325e+00, -1.8461e+00, -2.2287e+00,  7.4722e-03, -4.9592e-02,\n",
       "                       -1.6192e+00, -1.0950e+00, -2.4629e-01, -1.3982e+00, -2.0769e+00,\n",
       "                       -3.8860e-01, -4.9192e-01,  6.2060e-01, -2.0005e+00, -2.4259e-01,\n",
       "                       -5.3184e-01, -5.6399e-01, -1.2878e+00, -3.1835e+00, -1.6277e+00,\n",
       "                        1.1293e-01, -1.0965e+00, -1.0309e-01, -1.7486e+00, -3.5129e-01,\n",
       "                       -1.5554e-01, -1.4871e+00,  3.8925e-04, -9.1516e-01, -5.1395e-02,\n",
       "                        6.2953e-01, -1.7408e+00, -8.8965e-01, -5.1236e-01, -4.1897e-02,\n",
       "                       -8.0203e-01, -8.5666e-01, -1.6554e+00, -4.2784e-01, -1.3401e+00,\n",
       "                       -2.2994e+00, -1.4571e+00, -5.2902e-01, -1.2350e+00, -2.9642e-02,\n",
       "                       -1.6870e+00, -1.2626e-03, -3.5569e+00, -1.8375e+00, -1.9746e+00,\n",
       "                       -3.0561e-01,  2.6557e-02,  2.2747e-01, -2.2351e+00, -7.5711e-01,\n",
       "                        3.3381e-01,  6.7549e-01, -1.2952e+00, -2.2981e-01, -1.9466e+00,\n",
       "                       -2.8272e+00, -2.3840e-01, -6.4260e-01, -3.9992e-01, -2.7398e+00,\n",
       "                       -1.4940e+00, -1.6837e+00,  2.2802e-02, -2.0112e+00, -2.2925e+00,\n",
       "                        1.7812e-01, -1.2775e-01, -6.8986e-01, -1.6678e+00, -5.8172e-01,\n",
       "                        1.1564e+00, -8.6762e-01,  2.1870e-01, -3.4480e+00,  3.1091e-01,\n",
       "                       -1.6212e+00, -8.0152e-02, -1.9560e+00,  1.0705e-01,  3.1206e-01,\n",
       "                        5.7142e-01, -1.0987e+00, -5.9508e-01,  9.1413e-02, -2.1411e-01,\n",
       "                       -1.5753e+00, -4.9733e-01, -4.9107e-02,  1.5797e-01, -1.8626e+00,\n",
       "                       -2.5034e-01, -8.7525e-01, -2.2132e+00, -3.9213e-01,  1.2203e-01,\n",
       "                        1.7742e+00,  9.9625e-01,  1.3189e-02, -2.1810e+00, -2.4003e+00,\n",
       "                       -1.6827e+00, -9.9713e-02, -5.5759e-01, -3.5631e-01,  2.7005e+00,\n",
       "                       -9.3767e-01,  4.5590e-01, -1.1286e+00,  8.0659e-02, -2.6958e-01,\n",
       "                       -1.1920e+00,  1.8518e+00, -1.3057e+00,  7.2792e-02, -8.2882e-01,\n",
       "                        8.0004e-01, -1.3668e-01, -1.4109e+00, -1.3162e+00, -2.2147e+00,\n",
       "                        3.0506e-01, -5.8240e-01,  1.4326e-01,  3.9536e-01,  2.8229e-01,\n",
       "                        1.6459e+00, -2.8191e+00, -2.4595e+00, -1.9880e-01,  1.1159e-02,\n",
       "                        1.3262e-04,  4.0050e-01, -3.7836e+00, -2.4676e+00,  3.2132e+00,\n",
       "                       -2.5105e+00,  1.4071e+00, -3.3117e-01, -1.2857e-01, -2.2282e-01,\n",
       "                       -1.1476e+00,  1.1843e+00, -1.1021e-02, -1.1325e+00, -6.2436e-01,\n",
       "                       -7.4097e-02, -1.6148e+00, -6.0646e-06, -6.1809e-01, -2.3088e+00,\n",
       "                       -6.4509e-04, -8.2060e-03, -2.7040e+00, -4.9079e-01, -6.5960e-01,\n",
       "                       -1.2544e+00, -2.0777e+00,  1.6950e-01, -9.1421e-01, -1.0309e+00,\n",
       "                       -2.7811e+00, -1.5813e-01, -2.4262e-01,  7.4650e-01,  1.6394e+00,\n",
       "                       -1.2175e+00, -4.1762e-02,  2.1285e-01, -2.3241e-01,  7.0197e-01,\n",
       "                       -2.4147e+00,  6.5922e-01, -2.1609e-01,  4.8152e-01, -2.3850e-02,\n",
       "                        7.9414e-01, -1.4351e+00,  6.6324e-02, -1.0394e-01,  3.7135e-01,\n",
       "                       -3.8063e+00, -4.3479e+00, -1.8358e+00,  8.3640e-02,  1.9520e-01,\n",
       "                        5.0706e-01, -1.7120e+00, -1.1005e+00, -3.1688e-01,  1.2205e-01,\n",
       "                       -1.3277e+00, -1.7531e+00,  1.7020e+00, -2.4724e-01,  1.4407e-01,\n",
       "                       -1.2618e+00], device='cuda:0')),\n",
       "              ('module.layer1.2.bn3.running_mean',\n",
       "               tensor([-2.2501e-01, -8.4570e-01,  4.0516e-01,  4.0083e-02, -6.4093e-01,\n",
       "                       -2.2428e+00,  4.7247e-02, -1.3567e-02, -4.1384e-03, -1.3274e+00,\n",
       "                        6.0994e-01,  4.8693e-02,  2.3095e-01, -9.7049e-01,  8.5824e-01,\n",
       "                       -5.2627e-01, -3.2292e+00,  1.0819e-01,  8.5138e-01, -3.7926e-01,\n",
       "                       -8.1359e-01, -6.0231e-02,  4.6927e-01, -2.7372e-02, -3.6377e-01,\n",
       "                       -1.2063e-01,  6.1650e-03, -8.4307e-01,  8.1575e-02, -1.1079e+00,\n",
       "                        2.3577e+00,  1.0468e+00,  1.7417e+00,  8.6950e-02, -4.9970e-01,\n",
       "                        2.6720e+00,  1.3822e+00, -1.2998e+00, -2.0635e-01, -1.1902e+00,\n",
       "                        9.2806e-01, -8.8554e-01, -8.9381e-01,  1.8812e-01,  5.1483e-01,\n",
       "                       -4.8322e-02, -1.0735e+00, -4.3729e-01, -6.8625e-01, -6.0185e-01,\n",
       "                        1.2559e-02, -1.1503e+00,  6.1509e-01,  1.1412e-01, -9.7962e-01,\n",
       "                        2.6078e-01, -7.6832e-02,  8.5533e-01,  1.6194e-02, -3.4908e-01,\n",
       "                       -1.0906e+00, -1.9435e+00,  1.6206e+00,  6.7364e-01, -3.1732e+00,\n",
       "                       -5.5688e-01,  3.3717e+00,  9.5541e-01, -1.5307e+00, -9.4086e-01,\n",
       "                       -8.4335e-01,  8.6562e-01, -1.5862e+00, -1.5227e+00, -3.2213e-01,\n",
       "                       -1.2813e-01, -1.6586e-01,  4.1473e-01,  1.1306e+00,  1.2521e-01,\n",
       "                       -1.2081e-01,  1.3066e+00,  1.2409e-01,  1.0505e+00,  6.4253e-02,\n",
       "                       -5.0975e-02, -1.4673e+00, -2.6133e+00, -4.3515e-01, -8.2460e-02,\n",
       "                       -6.5611e-01,  1.0143e+00, -1.4257e+00, -8.2098e-01, -6.0164e-01,\n",
       "                       -1.5016e+00,  6.0932e-01, -7.6259e-01, -2.8317e+00,  2.3945e-02,\n",
       "                        1.3976e+00, -5.3683e-02, -9.7965e-01, -6.7989e-02, -3.0082e-01,\n",
       "                        7.0478e-01, -5.4765e-02, -2.3069e-02, -3.1002e-01, -9.1483e-02,\n",
       "                        1.0833e+00, -5.2171e-01,  2.5209e-01,  3.8718e-01, -1.0440e+00,\n",
       "                        2.8381e-01,  5.5488e-01,  9.6888e-01,  1.5062e+00, -2.4637e+00,\n",
       "                        2.8696e-01,  1.9105e+00, -6.1838e-02, -8.8588e-02, -2.4924e-02,\n",
       "                        8.5211e-03,  1.2271e-01,  4.1371e-02, -2.6960e-01,  9.3097e-01,\n",
       "                        2.3328e+00, -6.3875e-01,  9.6710e-03, -2.6130e+00,  4.9065e-01,\n",
       "                        9.1734e-01,  4.1185e-02,  5.2436e-01,  1.1007e-01, -6.9990e-01,\n",
       "                       -1.3647e+00, -2.5558e+00,  8.2953e-01, -1.3356e-02, -1.2071e+00,\n",
       "                       -1.2165e+00, -2.5620e-01, -2.5693e-01, -9.0144e-01,  1.6494e-01,\n",
       "                        6.8299e-01,  1.7003e-01, -1.8242e+00, -1.5662e+00, -5.0618e-01,\n",
       "                        3.2243e+00, -5.9951e-01, -2.6515e-01, -1.5053e+00,  5.7284e-01,\n",
       "                       -3.5740e-01,  2.3012e-01,  1.0730e-01,  1.2653e+00, -1.9073e-01,\n",
       "                       -1.7613e+00,  5.3967e-01, -7.4020e-01,  1.1657e-01, -1.0157e+00,\n",
       "                       -4.0149e+00,  6.1565e-01,  9.3692e-01, -1.8307e-02, -9.1137e-01,\n",
       "                        2.0949e-01, -1.2683e-01,  1.6401e-01, -4.8986e-01,  1.6755e+00,\n",
       "                        1.4771e+00, -2.7488e+00,  3.4545e-02,  8.2413e-01,  7.7614e-02,\n",
       "                       -6.1647e-01,  2.3231e-01, -1.0311e+00, -1.4283e+00,  4.5765e-03,\n",
       "                        5.8731e-03, -5.5892e-01,  1.3204e+00, -4.1576e-01,  1.8714e-01,\n",
       "                        2.9966e-02,  4.6552e+00, -8.4658e-01, -6.1270e-02, -1.3329e+00,\n",
       "                        6.2900e-01, -1.0069e+00,  3.7559e-01,  2.3285e-01, -2.5608e-01,\n",
       "                       -4.2658e-01, -1.1048e+00,  2.9207e-02,  1.4277e+00, -5.9590e-01,\n",
       "                       -1.0533e-02, -4.8555e-02, -6.3290e-01,  1.4206e-01, -4.7518e-01,\n",
       "                        1.4436e+00,  1.3511e-01,  2.2239e-02, -1.4893e+00,  4.7315e-02,\n",
       "                        1.3060e+00, -1.4098e+00, -4.1609e+00, -1.3801e+00,  1.4629e+00,\n",
       "                       -5.7700e-01,  3.4317e-01,  3.5858e-01,  1.0865e+00, -1.8765e+00,\n",
       "                       -1.3640e+00, -1.3066e+00, -5.1946e+00, -4.0446e+00, -6.3502e-02,\n",
       "                        8.8005e-01,  2.4312e+00, -6.1870e-02,  2.5686e+00, -1.8862e-01,\n",
       "                       -7.4107e-01,  3.0139e-01, -1.1129e+00,  3.4919e-01, -1.1206e-02,\n",
       "                        2.0296e-01, -5.3501e-01, -4.7980e-01,  6.0964e-01,  2.0986e-01,\n",
       "                        6.4232e-02,  1.4548e-01, -9.4702e-01,  1.9627e+00,  5.5412e-03,\n",
       "                        2.0282e-01], device='cuda:0')),\n",
       "              ('module.layer1.2.bn3.running_var',\n",
       "               tensor([0.2217, 0.1946, 0.4357, 0.5814, 0.2550, 0.6275, 0.0070, 0.0112, 0.0454,\n",
       "                       0.3823, 0.5546, 0.0316, 0.2476, 0.9079, 0.2150, 0.2601, 0.6736, 0.3451,\n",
       "                       0.8486, 0.9541, 0.6011, 0.1431, 0.0920, 0.0117, 0.7178, 0.1333, 0.0080,\n",
       "                       0.7406, 0.5492, 0.3899, 0.6766, 0.7720, 0.8171, 0.4137, 0.8110, 0.2047,\n",
       "                       0.7305, 0.3720, 0.4719, 0.4319, 0.2670, 0.4174, 0.2037, 0.0604, 0.6272,\n",
       "                       0.0191, 0.8027, 0.6096, 0.3815, 1.4451, 0.0170, 0.2433, 0.4301, 0.0293,\n",
       "                       0.2414, 0.6125, 0.4698, 0.5615, 0.0366, 0.1020, 0.5595, 0.5268, 0.3416,\n",
       "                       0.6231, 0.5627, 0.2245, 1.1236, 0.3743, 0.5258, 0.2292, 0.2409, 0.2597,\n",
       "                       0.5710, 0.7440, 0.6555, 0.0634, 0.1964, 0.1079, 0.8707, 0.3001, 0.4567,\n",
       "                       0.6998, 0.1717, 0.6187, 0.8546, 0.1102, 0.8368, 0.7391, 0.9745, 0.0353,\n",
       "                       0.5028, 0.3217, 0.3000, 0.2559, 0.5525, 0.6636, 0.6628, 0.2129, 0.5813,\n",
       "                       0.0306, 0.6148, 0.0752, 0.7020, 0.5123, 0.5451, 0.2067, 0.0472, 0.0652,\n",
       "                       0.5308, 0.4090, 0.3136, 0.1203, 0.6455, 0.1949, 0.8209, 0.6530, 0.2150,\n",
       "                       0.4254, 0.5516, 0.7545, 0.4030, 0.6849, 0.0613, 0.7213, 0.5578, 0.0272,\n",
       "                       0.5021, 0.8770, 1.1639, 0.7859, 0.3583, 0.5282, 0.0245, 0.5843, 0.2290,\n",
       "                       0.8321, 0.3731, 0.1922, 0.0206, 0.1241, 0.1718, 0.4414, 1.1747, 0.0154,\n",
       "                       0.7578, 0.7317, 0.2431, 0.0275, 0.6823, 1.1333, 0.1366, 1.3734, 0.7233,\n",
       "                       0.5883, 0.1263, 0.5581, 0.4600, 0.4404, 0.7045, 0.5013, 0.7188, 0.1778,\n",
       "                       0.1832, 0.8198, 2.7802, 0.6488, 0.1665, 0.7174, 0.2439, 0.0989, 1.0072,\n",
       "                       0.2518, 0.3039, 0.0295, 0.7328, 0.1422, 0.0653, 0.5888, 0.7842, 0.8123,\n",
       "                       0.3285, 0.9953, 0.4676, 0.6107, 0.0160, 0.3056, 0.3096, 0.5038, 0.6072,\n",
       "                       0.0114, 0.0232, 0.1642, 0.8336, 0.2806, 0.8173, 0.7291, 0.6096, 0.5247,\n",
       "                       0.2979, 0.3588, 0.7713, 0.2371, 0.3994, 0.3137, 0.7695, 0.0722, 0.1661,\n",
       "                       0.0336, 0.3464, 0.7565, 0.0292, 0.0104, 0.8617, 0.7426, 0.2932, 0.9086,\n",
       "                       0.8234, 0.1775, 0.8980, 0.8000, 0.3705, 0.3698, 0.7126, 0.2166, 0.8212,\n",
       "                       0.6858, 0.1952, 0.0263, 0.2194, 0.2143, 0.8284, 0.5240, 0.6771, 0.5084,\n",
       "                       0.0446, 0.2142, 0.5888, 0.0412, 0.4465, 0.0940, 0.4708, 0.6021, 0.2746,\n",
       "                       0.0630, 0.0177, 0.4632, 1.0512, 0.4162, 0.0652, 0.2523, 0.3731, 0.4522,\n",
       "                       0.3345, 0.2433, 0.0880, 0.2576], device='cuda:0')),\n",
       "              ('module.layer1.2.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.0.conv1.weight',\n",
       "               tensor([[[[-1.4206e-01]],\n",
       "               \n",
       "                        [[ 2.1702e-04]],\n",
       "               \n",
       "                        [[-7.5638e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.4420e-01]],\n",
       "               \n",
       "                        [[ 8.0004e-02]],\n",
       "               \n",
       "                        [[-9.9645e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.2796e-03]],\n",
       "               \n",
       "                        [[-3.6652e-02]],\n",
       "               \n",
       "                        [[-3.3883e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.4468e-02]],\n",
       "               \n",
       "                        [[ 1.5444e-02]],\n",
       "               \n",
       "                        [[ 2.9281e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.3245e-02]],\n",
       "               \n",
       "                        [[-8.7073e-02]],\n",
       "               \n",
       "                        [[-4.0937e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.8853e-02]],\n",
       "               \n",
       "                        [[ 1.4670e-02]],\n",
       "               \n",
       "                        [[-1.6352e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0662e-03]],\n",
       "               \n",
       "                        [[ 8.9506e-02]],\n",
       "               \n",
       "                        [[ 2.0161e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.6925e-02]],\n",
       "               \n",
       "                        [[ 3.0245e-01]],\n",
       "               \n",
       "                        [[-9.0097e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.3488e-02]],\n",
       "               \n",
       "                        [[-2.9439e-03]],\n",
       "               \n",
       "                        [[-1.9006e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2131e-02]],\n",
       "               \n",
       "                        [[-7.4929e-03]],\n",
       "               \n",
       "                        [[-5.6042e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.0718e-01]],\n",
       "               \n",
       "                        [[-4.0720e-03]],\n",
       "               \n",
       "                        [[-2.0196e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.4029e-01]],\n",
       "               \n",
       "                        [[ 1.5249e-02]],\n",
       "               \n",
       "                        [[-2.6967e-02]]]], device='cuda:0')),\n",
       "              ('module.layer2.0.bn1.weight',\n",
       "               tensor([2.8693, 2.2227, 2.6636, 2.0986, 2.6465, 2.4660, 1.9896, 3.7177, 4.1172,\n",
       "                       2.9650, 2.9152, 3.4628, 2.9932, 2.4016, 2.1065, 1.9782, 1.8550, 2.9871,\n",
       "                       2.1596, 2.9991, 2.3244, 2.4551, 3.2527, 4.3887, 3.5088, 2.3670, 1.9058,\n",
       "                       2.4341, 2.5140, 4.7256, 2.8276, 2.9204, 2.2916, 3.0779, 3.8790, 2.3718,\n",
       "                       2.5998, 2.7401, 1.8664, 2.5983, 1.6434, 2.5003, 4.1826, 2.6176, 2.5973,\n",
       "                       3.7511, 2.9384, 2.9483, 3.5387, 3.1569, 2.3209, 2.3076, 3.7742, 3.1474,\n",
       "                       2.1315, 2.2949, 1.7491, 2.1069, 2.9084, 2.0909, 2.6924, 2.0683, 2.3015,\n",
       "                       2.8123, 2.0516, 3.0291, 2.8713, 2.6604, 2.5121, 2.4468, 2.6032, 3.1720,\n",
       "                       3.2948, 2.6782, 2.1057, 2.2320, 2.5290, 2.4561, 2.7564, 2.1078, 4.1157,\n",
       "                       2.6952, 2.3727, 2.6462, 2.4133, 1.6948, 3.0306, 3.3420, 2.1177, 3.4789,\n",
       "                       4.1188, 2.3650, 3.1306, 2.6654, 2.1352, 2.2188, 2.2286, 1.7932, 2.3710,\n",
       "                       1.4187, 1.7903, 1.8412, 2.7799, 2.2440, 2.4342, 2.4394, 3.0968, 2.1384,\n",
       "                       3.4211, 3.0130, 2.7928, 1.7891, 2.7084, 1.9083, 2.7700, 2.3376, 2.4015,\n",
       "                       2.7266, 3.2622, 1.9169, 2.1984, 2.2803, 2.6608, 2.5374, 2.7023, 2.7774,\n",
       "                       3.1652, 2.3347], device='cuda:0')),\n",
       "              ('module.layer2.0.bn1.bias',\n",
       "               tensor([-1.4587, -0.4540, -1.4465,  0.8160, -1.8653, -1.0551, -0.3613, -2.8831,\n",
       "                       -3.1462, -1.9522, -2.3336, -3.0805, -2.1739, -1.2010, -0.8489,  0.9340,\n",
       "                       -0.0172, -2.5631, -0.6570, -1.5833, -1.1268, -1.7328, -2.8566, -3.3575,\n",
       "                       -2.4667, -1.2279,  0.6072, -0.7817, -1.1623, -4.2152, -1.2196, -1.9116,\n",
       "                       -1.0797, -1.6885, -2.4847, -1.5187, -0.8652, -1.4888,  0.1103, -1.4392,\n",
       "                        0.6227, -1.0676, -4.2443, -1.9703, -1.2051, -3.4539, -1.1392, -0.8746,\n",
       "                       -3.0522, -1.8340, -1.1316, -0.3889, -4.5055, -2.2634, -0.0812, -0.9051,\n",
       "                        0.5803, -0.7956, -1.9590, -0.3044, -1.2838, -0.3043, -0.2663, -1.5571,\n",
       "                        0.2720, -1.7898, -1.9128, -1.0274, -1.2905, -1.5668, -1.1983, -2.7618,\n",
       "                       -2.7271, -1.0318, -0.7748, -0.9710, -1.4114, -1.1466, -1.2541, -0.4447,\n",
       "                       -3.6646, -0.7283, -0.4813, -1.1709, -1.5364,  0.9420, -2.4656, -2.3178,\n",
       "                       -0.6056, -2.6599, -3.5244, -1.0242, -1.5070, -1.7217, -0.7851, -1.4529,\n",
       "                       -0.6697,  0.4418, -1.1053,  1.0283,  1.3477,  0.2307, -2.2671, -0.4839,\n",
       "                       -0.9240, -1.6389, -1.8784, -0.4442, -1.9272, -2.0259, -2.4456, -0.1294,\n",
       "                       -1.4874,  0.1388, -1.1247, -1.5019, -0.4582, -0.7530, -2.4618, -0.4155,\n",
       "                       -1.1476, -0.6350, -1.3651, -1.4121, -1.2487, -1.3631, -2.5650, -0.2649],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.0.bn1.running_mean',\n",
       "               tensor([ 3.8805,  0.4651,  0.6591,  0.8832, -2.2598, -0.4593, -1.0924, -0.6508,\n",
       "                       -2.4386,  0.7981, -2.8167,  0.1747, -3.0716, -1.7839, -0.4524, -0.2330,\n",
       "                        0.1426, -0.8117, -0.3355, -1.6238, -3.4438, -0.5038,  0.1874,  3.3360,\n",
       "                        1.7834, -0.9648,  0.4390, -0.1900, -3.1338, -1.2314, -1.8694, -2.6064,\n",
       "                       -0.9520,  4.5484,  2.8959,  1.1383, -2.2716, -0.2670,  1.5216, -2.9786,\n",
       "                        0.1109,  3.0850, -0.9090, -2.0397, -0.0606, -2.7197,  0.3005,  0.0610,\n",
       "                       -4.7749, -0.3656, -1.0535,  1.1616, -0.7100,  0.3928, -1.7316, -0.4086,\n",
       "                        1.9448, -0.4908,  3.2334,  0.6048,  0.7288,  0.7243, -1.2524, -0.4020,\n",
       "                       -1.2227, -0.7340, -1.1125,  0.9340, -1.4365, -1.4261, -1.1750, -4.3903,\n",
       "                       -1.8050, -3.1413, -1.0280, -1.9026, -2.3008,  1.5659, -1.2853,  0.5814,\n",
       "                        0.4789,  0.1589, -0.7324, -0.1283, -1.9773, -1.1644, -0.5931, -0.3083,\n",
       "                       -0.9487, -0.3895,  2.1617, -3.0699, -0.7807,  1.2505,  1.3628, -2.0347,\n",
       "                       -1.4524,  1.1543, -2.1063,  0.7734,  1.5878,  1.8296,  0.1387,  2.5129,\n",
       "                       -2.7984, -2.8365, -1.8284, -0.6438,  1.3209, -0.3545, -1.3454,  0.7180,\n",
       "                       -1.4497,  1.9155, -1.9368, -1.2434,  1.2190,  1.0001, -0.2161, -0.8820,\n",
       "                       -0.5374, -0.1050, -1.3362, -0.9183, -1.8814, -3.8622, -1.3279,  1.7342],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.0.bn1.running_var',\n",
       "               tensor([ 5.7448,  8.6423,  4.4434, 10.5381,  4.0423,  5.6121,  7.5775,  3.7745,\n",
       "                        8.0545,  5.4695,  3.8093,  3.9785,  5.2267,  4.5909,  4.2408,  9.4188,\n",
       "                        5.0201,  3.4183,  4.0870,  6.5188,  7.4643,  3.2176,  3.1726,  6.2949,\n",
       "                        7.5518,  4.5038,  6.2395,  4.8488,  4.5469,  7.2505,  7.1291,  6.1533,\n",
       "                        3.5929,  7.2328,  8.2057,  2.4507,  8.3758,  6.8172,  9.1023,  4.7950,\n",
       "                        6.0568,  4.2030,  3.8775,  3.9417,  5.3096,  3.1136,  8.3717,  8.6282,\n",
       "                        7.2338,  5.9338,  4.3575,  5.0663,  3.7009,  7.1492,  8.8565,  4.7874,\n",
       "                        9.4074,  4.6065,  6.1308,  8.3509,  5.1615,  5.6382,  5.8663,  5.4911,\n",
       "                        6.0140,  5.6817,  4.9321,  5.4250,  5.1472,  5.4200,  4.5959,  5.3658,\n",
       "                        7.7088,  7.8315,  4.8358,  6.0256,  5.6630,  5.6717,  6.7505,  3.4511,\n",
       "                        7.9723,  6.7789,  6.3769,  5.5734,  4.5275,  6.7377,  6.3202,  6.5126,\n",
       "                        6.1226,  3.5297,  3.2100,  4.8815,  5.9952,  4.7436,  4.5881,  2.8853,\n",
       "                        4.6195,  6.6688,  7.4443,  6.1463,  9.6228,  6.4810,  4.6004,  4.3333,\n",
       "                        6.3316,  3.9885,  4.2885,  5.4028,  8.8017,  6.5269,  3.3855,  5.3342,\n",
       "                        4.3390,  8.3585,  6.7044,  3.4825,  7.5343,  7.9122,  5.2808,  4.6902,\n",
       "                        3.9944,  5.4394,  5.7415,  3.2601,  5.5267,  4.8203,  6.1728,  7.9670],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.0.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.0.conv2.weight',\n",
       "               tensor([[[[-3.0748e-02, -2.6858e-02, -3.4494e-02],\n",
       "                         [-6.1384e-02, -2.6638e-02, -7.3126e-02],\n",
       "                         [-3.6340e-02, -3.9948e-02, -5.1717e-02]],\n",
       "               \n",
       "                        [[-1.4460e-02, -1.1712e-03,  1.2881e-02],\n",
       "                         [ 1.1477e-02,  8.7258e-03, -1.9749e-02],\n",
       "                         [ 8.4306e-03,  1.4647e-03, -1.2459e-02]],\n",
       "               \n",
       "                        [[ 2.7443e-02, -2.4137e-02, -1.0948e-02],\n",
       "                         [ 4.5292e-02,  4.5718e-02,  5.9018e-02],\n",
       "                         [-1.3557e-05, -3.5662e-02, -1.8501e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.2963e-02,  1.1451e-02,  6.1675e-03],\n",
       "                         [ 2.9010e-02,  4.0453e-03, -4.1026e-03],\n",
       "                         [ 1.3675e-02,  2.8662e-02,  9.1605e-03]],\n",
       "               \n",
       "                        [[ 1.2863e-01, -6.8192e-03, -1.1481e-01],\n",
       "                         [ 1.7043e-01,  1.1241e-01, -4.6651e-02],\n",
       "                         [ 1.0477e-01,  2.3848e-01,  1.6160e-01]],\n",
       "               \n",
       "                        [[ 4.1203e-02,  2.4838e-02,  1.7286e-02],\n",
       "                         [ 3.6975e-02,  3.8233e-03,  1.4957e-02],\n",
       "                         [ 1.9932e-03,  8.5064e-03,  6.7673e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.2215e-02, -4.5814e-03, -3.2403e-02],\n",
       "                         [ 5.6754e-02,  1.9669e-02, -6.5932e-02],\n",
       "                         [ 7.5601e-02,  2.8436e-02, -2.6914e-02]],\n",
       "               \n",
       "                        [[ 9.3641e-02,  8.0191e-02,  4.2442e-02],\n",
       "                         [ 8.4114e-02, -4.9993e-02,  1.4983e-01],\n",
       "                         [ 6.4792e-02,  1.7057e-01,  1.8209e-01]],\n",
       "               \n",
       "                        [[-6.3329e-03,  2.9342e-02,  7.2273e-02],\n",
       "                         [-1.5361e-02, -7.1260e-03,  7.6127e-02],\n",
       "                         [-1.2927e-02,  2.2583e-02,  1.1660e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.8585e-02,  4.0703e-02,  1.4569e-02],\n",
       "                         [ 5.9921e-02,  2.1151e-02,  4.5786e-02],\n",
       "                         [ 3.7504e-02,  2.4651e-02, -3.7300e-03]],\n",
       "               \n",
       "                        [[-4.9569e-02, -6.0255e-02, -3.4145e-02],\n",
       "                         [-3.1109e-02, -4.2567e-02, -4.4150e-02],\n",
       "                         [ 9.0822e-03, -4.3188e-02, -5.4482e-02]],\n",
       "               \n",
       "                        [[ 1.5966e-02,  3.3822e-02,  7.8063e-02],\n",
       "                         [ 2.4720e-02,  2.0846e-02,  9.6756e-02],\n",
       "                         [ 4.5064e-03,  2.5202e-02,  5.2198e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.8583e-02,  3.1875e-02,  4.1457e-02],\n",
       "                         [ 2.5932e-02,  5.7395e-02,  6.4389e-02],\n",
       "                         [ 2.2593e-02,  1.4639e-03, -2.9541e-02]],\n",
       "               \n",
       "                        [[ 5.7071e-02,  7.9742e-02,  2.7676e-02],\n",
       "                         [ 3.3521e-03, -3.5584e-02, -4.2254e-02],\n",
       "                         [-1.9609e-02, -8.7423e-03, -2.6455e-02]],\n",
       "               \n",
       "                        [[-1.1510e-02,  2.5819e-02,  8.4182e-04],\n",
       "                         [-2.1585e-02,  3.8847e-03, -9.7394e-03],\n",
       "                         [-1.7894e-02, -4.4561e-02, -4.9062e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.6233e-03, -1.1633e-02, -1.8069e-02],\n",
       "                         [-6.4029e-03, -1.8269e-02, -3.0392e-02],\n",
       "                         [-2.6245e-03, -1.1976e-02,  1.4295e-02]],\n",
       "               \n",
       "                        [[-7.7587e-04, -2.0375e-02, -3.9841e-02],\n",
       "                         [ 2.7659e-02, -3.9390e-02, -2.5328e-02],\n",
       "                         [-3.7954e-03, -2.3366e-02, -2.0619e-02]],\n",
       "               \n",
       "                        [[ 5.7242e-02,  7.1504e-02,  1.0613e-01],\n",
       "                         [-3.5427e-02, -3.9435e-03,  7.7295e-02],\n",
       "                         [-4.1935e-02, -5.5790e-02, -1.3056e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.8089e-02,  2.6907e-02,  1.2375e-02],\n",
       "                         [ 1.4400e-02,  4.8559e-02,  4.0095e-02],\n",
       "                         [-2.2148e-02, -2.8911e-02, -2.2555e-02]],\n",
       "               \n",
       "                        [[-5.7352e-03, -3.4557e-02, -3.8424e-02],\n",
       "                         [ 4.2596e-02,  1.3838e-02,  1.6360e-02],\n",
       "                         [ 2.1024e-02,  2.6094e-02,  1.6824e-02]],\n",
       "               \n",
       "                        [[-1.2288e-02, -3.6593e-02, -4.1217e-02],\n",
       "                         [-1.8178e-02, -5.1980e-02, -7.6097e-02],\n",
       "                         [-2.6293e-02, -5.5694e-02, -2.6310e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.2998e-02, -2.3588e-02, -1.9045e-02],\n",
       "                         [-1.2253e-02, -4.9283e-02, -2.8942e-02],\n",
       "                         [ 5.4273e-02,  3.4572e-02,  3.1379e-02]],\n",
       "               \n",
       "                        [[ 2.0595e-02,  3.1671e-02,  2.0246e-02],\n",
       "                         [ 1.3874e-02, -4.4744e-04, -2.3501e-02],\n",
       "                         [-1.5561e-03,  2.8672e-02,  1.7830e-02]],\n",
       "               \n",
       "                        [[-3.7607e-02, -1.2507e-02, -2.8552e-02],\n",
       "                         [-3.4220e-02, -8.3803e-02, -5.1722e-02],\n",
       "                         [ 9.5837e-02,  1.8718e-01,  1.1436e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.1417e-02,  2.8794e-02,  1.8494e-02],\n",
       "                         [ 7.8616e-02,  6.2506e-02,  6.3432e-02],\n",
       "                         [ 5.3074e-02,  4.9518e-02,  6.2160e-02]],\n",
       "               \n",
       "                        [[ 3.3429e-02, -1.1821e-02,  6.7250e-03],\n",
       "                         [ 2.8989e-02, -2.4350e-02, -5.0329e-02],\n",
       "                         [-1.6079e-02, -5.8514e-02, -5.2313e-02]],\n",
       "               \n",
       "                        [[-3.1162e-02, -2.7742e-02,  1.1450e-02],\n",
       "                         [-1.5752e-02,  1.2914e-03, -1.1014e-02],\n",
       "                         [-2.7322e-02, -1.5828e-02, -2.9438e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.0494e-02, -8.2468e-02, -6.8566e-02],\n",
       "                         [-8.8172e-02, -4.9457e-02, -5.5400e-02],\n",
       "                         [-5.9602e-02, -5.7002e-02, -2.2363e-02]],\n",
       "               \n",
       "                        [[-2.0606e-03, -1.3369e-02, -3.6956e-02],\n",
       "                         [-3.0742e-02,  2.5486e-02,  1.0508e-02],\n",
       "                         [-3.0456e-02, -1.7395e-02,  1.3708e-02]],\n",
       "               \n",
       "                        [[-1.2545e-02,  1.7867e-02,  1.9524e-02],\n",
       "                         [-1.2838e-03,  1.3098e-02,  1.3759e-02],\n",
       "                         [ 1.8360e-02,  4.0740e-02,  2.2643e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2594e-02, -3.9522e-02, -2.2585e-02],\n",
       "                         [-5.8145e-02, -1.1384e-01, -6.1241e-02],\n",
       "                         [-6.4415e-02, -9.1120e-02, -6.1820e-02]],\n",
       "               \n",
       "                        [[-3.0140e-02, -3.9454e-02,  2.0789e-02],\n",
       "                         [-6.0632e-02, -5.1415e-02, -3.7823e-03],\n",
       "                         [-1.8678e-02,  9.3270e-03,  2.3229e-02]],\n",
       "               \n",
       "                        [[-7.1430e-03,  7.7524e-04, -1.0447e-02],\n",
       "                         [-5.7552e-03, -1.0267e-02,  4.4545e-03],\n",
       "                         [-4.0520e-03, -3.6956e-02, -1.6073e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.5386e-03,  5.0159e-03,  7.6984e-03],\n",
       "                         [ 1.2503e-02,  5.8682e-03,  3.8194e-04],\n",
       "                         [ 3.0358e-02,  6.3682e-03,  7.0462e-03]],\n",
       "               \n",
       "                        [[ 3.3491e-02,  3.2174e-02,  4.8466e-03],\n",
       "                         [ 1.9528e-04,  4.5035e-02,  2.6277e-02],\n",
       "                         [-9.3009e-03, -3.2246e-02, -2.9657e-03]],\n",
       "               \n",
       "                        [[-1.3889e-01, -8.0469e-03, -1.2811e-02],\n",
       "                         [-1.0451e-01,  7.2311e-02,  1.1925e-02],\n",
       "                         [-3.2277e-02,  1.1843e-02,  3.3245e-02]]]], device='cuda:0')),\n",
       "              ('module.layer2.0.bn2.weight',\n",
       "               tensor([1.6001, 1.4105, 1.8277, 1.2140, 1.8874, 1.2127, 1.2333, 1.2373, 1.6905,\n",
       "                       1.9071, 1.7408, 1.7428, 1.9192, 1.6341, 4.4095, 1.8404, 1.6593, 2.0451,\n",
       "                       2.0786, 1.9416, 1.2441, 1.2918, 1.2003, 2.1864, 1.2552, 1.2908, 1.2138,\n",
       "                       1.1959, 2.4636, 1.6148, 1.7247, 1.6794, 1.7644, 1.5261, 1.2335, 1.7554,\n",
       "                       1.3090, 1.6258, 1.2491, 1.6283, 1.2493, 1.9683, 2.1547, 1.9441, 2.0549,\n",
       "                       1.9838, 1.8216, 1.3771, 2.0665, 1.9943, 1.9525, 1.7857, 2.0120, 1.3941,\n",
       "                       1.2999, 1.2740, 2.3747, 2.0872, 1.8375, 2.0693, 1.8137, 1.6853, 1.3375,\n",
       "                       2.1428, 1.9867, 1.1895, 1.3242, 2.2530, 1.9679, 2.0319, 2.9104, 1.9464,\n",
       "                       2.6409, 1.8623, 2.3375, 2.0574, 2.2072, 1.2520, 1.8486, 1.9331, 1.9139,\n",
       "                       1.8463, 2.5061, 2.0623, 1.4753, 1.8324, 2.4119, 2.0023, 3.0011, 1.2485,\n",
       "                       1.7387, 1.7283, 1.9259, 1.3460, 1.2780, 1.2093, 1.6898, 2.4427, 1.3137,\n",
       "                       1.8246, 2.1280, 1.8959, 1.2807, 1.8434, 1.2014, 2.2778, 1.4243, 1.6771,\n",
       "                       1.5431, 1.3147, 1.1773, 2.1696, 2.5883, 1.2373, 2.1043, 1.9266, 2.0217,\n",
       "                       2.1932, 1.8725, 1.8560, 1.8451, 2.7876, 1.2197, 1.2263, 1.3088, 1.9582,\n",
       "                       1.1900, 1.2619], device='cuda:0')),\n",
       "              ('module.layer2.0.bn2.bias',\n",
       "               tensor([ 0.1542,  2.6047,  0.2578,  3.4270, -0.2439,  3.4234,  4.0074,  2.5588,\n",
       "                        1.0485, -0.2902, -0.1960, -0.0053, -0.4915,  0.3825, -3.6327, -0.2882,\n",
       "                       -0.7044, -1.0540,  0.7151, -0.8477,  3.5445,  3.0460,  3.7038,  0.1673,\n",
       "                        2.1837,  3.6004,  3.5896,  2.2658, -0.6398,  0.4139,  0.2364, -0.3922,\n",
       "                        0.0430,  1.3895,  3.7035,  1.4131,  2.1630,  0.2246,  2.6416,  1.3391,\n",
       "                        3.5592,  1.0901, -0.4430, -0.3902, -0.4645,  0.0454,  0.1297,  2.9669,\n",
       "                       -0.7685, -0.1342,  1.2790,  0.2133, -0.7819,  3.0418,  3.5354,  2.7321,\n",
       "                       -0.9614, -0.9714, -0.2074,  0.7006,  0.7047,  1.2261,  2.7810, -0.9408,\n",
       "                       -0.6903,  3.0374,  3.1938, -1.3142, -0.7339, -0.3567, -1.8075, -0.3599,\n",
       "                       -2.1940, -0.1671, -0.5913, -0.5236, -0.3166,  3.6235, -0.0201, -0.3096,\n",
       "                       -0.0456,  0.0906, -0.6785, -0.2543,  0.6191, -0.5304, -1.2681, -0.3607,\n",
       "                       -1.3628,  3.0118,  0.9355,  0.8507, -0.0929,  2.3315,  2.6513,  3.1217,\n",
       "                        1.5219, -0.9184,  1.9592,  0.9490, -0.8827, -0.1809,  3.5155,  0.8181,\n",
       "                        1.9090, -0.2414,  2.3512, -0.1162,  1.4776,  1.5731,  2.1522, -0.4036,\n",
       "                       -1.3967,  1.8219, -0.8952,  0.6915, -0.4339, -0.9079,  1.1212,  0.5318,\n",
       "                       -0.9706, -1.3324,  3.6248,  4.0517,  2.0862,  0.0893,  3.2379,  3.3553],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.0.bn2.running_mean',\n",
       "               tensor([ 1.1248e+00,  2.0166e+00,  5.8317e-01, -1.0705e+00, -2.1993e-01,\n",
       "                        3.4114e-01, -9.7732e-01,  3.1448e-01, -1.6777e+00,  9.1403e-02,\n",
       "                       -4.4135e-01, -2.0670e+00, -1.1004e+00, -1.4419e+00, -6.1830e+00,\n",
       "                       -3.9857e-01, -1.5681e+00, -2.0425e+00, -1.9226e+00, -2.3846e+00,\n",
       "                       -3.6583e-02,  2.9037e+00, -6.5076e-01, -6.9244e-01,  3.3971e+00,\n",
       "                       -1.3564e+00,  5.2748e-01, -7.6235e-01, -2.4449e+00, -1.1288e+00,\n",
       "                       -6.8488e-01, -7.9258e-01, -7.1074e-01, -1.5762e+00, -1.0220e+00,\n",
       "                        1.3465e+00,  1.0298e+00, -3.5320e-01,  9.5443e-01, -8.3878e-02,\n",
       "                        1.1841e+00, -1.7246e+00, -1.1432e+00, -7.1245e-01, -1.8186e+00,\n",
       "                       -2.4245e-01, -1.8746e+00,  2.9717e+00, -9.6540e-01, -1.5366e+00,\n",
       "                       -1.9362e+00, -1.4908e+00, -2.5720e+00,  3.1448e-01,  2.0783e+00,\n",
       "                        1.5466e+00, -5.9981e-01, -3.1669e+00, -6.0457e-01, -1.3678e+00,\n",
       "                       -1.9829e+00, -1.0006e+00,  1.6344e+00, -1.0602e+00, -2.1969e-01,\n",
       "                        6.1725e-01,  1.0093e+00, -1.9442e+00, -1.4872e+00,  2.0968e-01,\n",
       "                       -2.3461e+00, -6.2025e-01, -2.2771e+00, -3.6990e-02, -1.5444e+00,\n",
       "                       -4.1813e-01, -3.1448e+00, -2.7192e-01, -2.1165e+00, -1.7924e-01,\n",
       "                       -3.0206e+00,  9.4457e-02, -2.6861e+00, -3.6737e-01, -2.0986e-01,\n",
       "                       -9.0042e-01,  1.6891e-01, -9.5462e-01, -2.7856e+00,  2.3830e-01,\n",
       "                       -1.9676e+00, -1.1402e+00, -1.3571e+00,  1.3832e+00,  6.8215e-01,\n",
       "                       -1.3636e+00,  3.0785e-01, -5.9948e-01,  1.4453e+00, -2.5644e-01,\n",
       "                       -4.7087e-01,  4.3127e-02,  4.2489e-01,  1.5737e-01,  1.1819e+00,\n",
       "                       -2.6584e+00,  1.1642e+00, -4.2622e-03,  1.1120e+00,  3.0954e-01,\n",
       "                        2.1723e+00, -1.7865e+00, -2.2662e+00, -7.6498e-01, -1.8235e+00,\n",
       "                        3.9516e-01, -1.8687e-01, -1.6878e+00, -1.9874e-01, -2.4959e-01,\n",
       "                       -1.2398e+00, -4.0969e+00, -8.1512e-01, -8.4251e-01,  4.1866e+00,\n",
       "                       -1.3128e+00, -1.0717e-01,  1.1641e+00], device='cuda:0')),\n",
       "              ('module.layer2.0.bn2.running_var',\n",
       "               tensor([ 4.6697, 12.6068,  8.8398,  5.0018,  8.2355,  8.2288,  6.4489,  8.2378,\n",
       "                       17.5373,  4.9786,  5.0184, 17.3573,  6.9378, 10.8205, 15.6921,  5.3002,\n",
       "                        8.3708,  4.6073, 16.8270,  5.0605, 16.1735, 12.7857,  6.2654, 18.9998,\n",
       "                       12.6562,  9.1775,  5.1209,  7.6056, 17.8537, 10.2924,  9.5165,  5.9623,\n",
       "                        7.4029,  9.8001,  5.3472, 13.6354,  5.7653, 18.6939,  8.0435, 20.7894,\n",
       "                        6.4872, 20.3912,  6.3238,  7.3691,  9.4550,  8.9120, 10.5987, 11.7116,\n",
       "                        8.0017,  8.2932, 23.4782, 14.2919,  8.0288,  9.3538, 14.8190, 14.7824,\n",
       "                        5.1471,  7.3468,  7.5066, 17.8091, 10.9703, 13.4712,  9.9236,  7.1928,\n",
       "                        6.5879,  5.6454, 10.0762,  4.7493,  6.9571,  8.9887,  6.3663,  5.9801,\n",
       "                        5.4376,  7.2026,  6.3045,  6.5383,  7.5378,  6.6555,  7.7195,  5.9080,\n",
       "                       12.4896,  7.9551, 17.0462,  7.6215, 11.6398,  6.2650,  4.7893,  5.7307,\n",
       "                       15.3388,  6.5899, 11.3938, 10.2935,  8.9954, 11.1708,  7.8714,  7.3261,\n",
       "                       14.7414,  5.6276, 13.9294, 13.2992,  4.6099,  6.1123,  8.8511, 24.1239,\n",
       "                       10.4311, 13.7718, 10.5521,  7.6495, 25.7636, 14.6881, 15.4314,  8.2884,\n",
       "                        6.0827,  7.2733,  6.4274, 24.0145,  6.7897,  7.7135, 32.5021, 12.2476,\n",
       "                        3.9558, 13.0077,  9.6916, 12.1432,  9.8368,  8.9644,  5.8841,  8.8889],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.0.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.0.conv3.weight',\n",
       "               tensor([[[[ 0.0050]],\n",
       "               \n",
       "                        [[ 0.0682]],\n",
       "               \n",
       "                        [[ 0.0129]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0757]],\n",
       "               \n",
       "                        [[-0.1003]],\n",
       "               \n",
       "                        [[-0.0582]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0171]],\n",
       "               \n",
       "                        [[ 0.0118]],\n",
       "               \n",
       "                        [[-0.0029]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0011]],\n",
       "               \n",
       "                        [[-0.0113]],\n",
       "               \n",
       "                        [[-0.0214]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0246]],\n",
       "               \n",
       "                        [[-0.1316]],\n",
       "               \n",
       "                        [[-0.0040]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0131]],\n",
       "               \n",
       "                        [[ 0.0320]],\n",
       "               \n",
       "                        [[ 0.0748]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0257]],\n",
       "               \n",
       "                        [[ 0.0703]],\n",
       "               \n",
       "                        [[-0.0136]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0481]],\n",
       "               \n",
       "                        [[ 0.0217]],\n",
       "               \n",
       "                        [[ 0.0151]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0112]],\n",
       "               \n",
       "                        [[ 0.0565]],\n",
       "               \n",
       "                        [[ 0.0155]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0279]],\n",
       "               \n",
       "                        [[ 0.0874]],\n",
       "               \n",
       "                        [[-0.0781]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0239]],\n",
       "               \n",
       "                        [[-0.0498]],\n",
       "               \n",
       "                        [[ 0.0716]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0186]],\n",
       "               \n",
       "                        [[-0.0247]],\n",
       "               \n",
       "                        [[ 0.0909]]]], device='cuda:0')),\n",
       "              ('module.layer2.0.bn3.weight',\n",
       "               tensor([ 7.7069e-01,  1.2924e-01,  6.5561e-01,  1.2319e-01,  9.0235e-01,\n",
       "                        2.0721e+00,  2.0116e+00,  1.6638e-02, -2.5580e-02,  1.6035e+00,\n",
       "                        1.4213e+00,  1.5421e+00,  1.7051e+00,  8.4794e-01,  7.3240e-01,\n",
       "                        1.5083e+00,  1.9205e+00,  1.7437e+00,  2.3955e+00,  1.9815e+00,\n",
       "                        2.7914e-01,  1.3610e+00,  4.4109e-01,  1.9733e+00,  1.2035e+00,\n",
       "                        2.5695e+00,  2.9963e+00,  1.7267e+00,  3.3914e-01,  7.6323e-02,\n",
       "                        2.1126e+00,  1.1834e-02,  1.3462e+00,  1.2999e+00,  1.7782e+00,\n",
       "                        3.7309e-01,  6.6168e-01,  8.6608e-01,  2.2393e+00,  8.0781e-01,\n",
       "                        1.3834e+00,  8.0868e-01,  4.8044e-01,  2.0089e+00,  1.0738e+00,\n",
       "                        1.0422e+00,  1.7940e+00,  1.5126e+00,  3.0627e-01,  1.3015e+00,\n",
       "                        6.6538e-01,  1.7086e+00,  1.0259e+00,  1.6886e+00,  3.4914e+00,\n",
       "                        1.5533e+00,  1.1874e+00,  1.6202e+00,  1.1776e+00,  1.3211e+00,\n",
       "                        1.1046e+00,  7.5371e-01,  5.6739e-01,  3.0548e-01,  8.1085e-01,\n",
       "                        3.1317e-01,  1.6168e+00,  7.8408e-01,  1.2230e+00,  9.4573e-01,\n",
       "                        1.2757e+00,  1.5193e+00,  6.8834e-01,  1.3815e+00,  1.5763e+00,\n",
       "                        1.8041e+00,  1.5321e+00,  2.0338e+00,  1.4763e+00,  1.2580e+00,\n",
       "                        1.9488e+00,  1.1703e+00,  1.0745e+00,  1.6585e-02,  1.1042e+00,\n",
       "                        1.1890e+00,  6.8388e-01,  4.9956e-01,  1.9539e+00,  1.1168e+00,\n",
       "                        3.3726e-01,  6.0099e-01,  2.0783e+00,  9.6537e-01, -3.1543e-03,\n",
       "                        1.7774e+00,  1.8292e+00,  1.4132e+00,  3.1140e-01,  2.6987e+00,\n",
       "                        1.5689e+00,  1.7019e+00,  1.8796e+00,  3.0603e-01,  1.5793e+00,\n",
       "                        1.6526e+00,  1.8273e+00,  1.3283e+00,  4.1269e-01,  1.4151e+00,\n",
       "                        1.7703e+00,  5.6559e-02,  2.2924e+00,  1.6533e+00,  8.6788e-01,\n",
       "                        1.9630e+00,  7.6719e-01,  2.3924e+00,  1.6580e+00,  1.7205e+00,\n",
       "                        1.2883e+00,  1.9038e+00,  1.5637e+00,  7.5488e-01,  1.9207e+00,\n",
       "                        1.5668e+00,  1.8932e-01,  1.4321e+00,  1.1557e+00,  4.4653e-01,\n",
       "                        2.1786e+00,  9.1084e-01,  2.9897e+00, -1.6886e-01, -5.0911e-02,\n",
       "                        2.7242e+00,  1.1142e+00,  9.9580e-01,  2.2489e+00,  1.5246e+00,\n",
       "                        1.2586e+00,  1.1449e+00,  3.3074e-03,  1.1363e+00,  1.4884e+00,\n",
       "                        6.3856e-01,  1.8716e+00,  1.3092e+00,  4.5491e-01,  7.3583e-01,\n",
       "                        9.0814e-01, -8.5865e-04,  1.9155e+00,  1.3869e+00,  9.8123e-01,\n",
       "                        1.8727e+00,  1.6826e+00,  1.8611e-01,  1.8127e+00,  1.1537e+00,\n",
       "                        1.6420e+00,  1.3733e+00,  2.0017e+00,  7.4303e-01,  1.0548e+00,\n",
       "                        1.4734e+00,  1.7305e+00,  2.2314e+00,  6.3788e-01,  3.7940e-01,\n",
       "                        7.1458e-01,  2.2047e+00,  2.3384e+00,  2.6786e-01,  7.4051e-01,\n",
       "                        1.5867e+00,  5.5773e-01,  1.7113e+00,  4.4046e-01,  1.3594e+00,\n",
       "                        1.1679e+00,  2.4527e+00,  1.0702e+00,  4.6224e-01,  1.1136e+00,\n",
       "                        1.0942e+00,  3.9475e-01,  3.4529e-01,  5.4940e-01,  1.1775e+00,\n",
       "                        3.1672e+00,  1.2839e+00,  1.9827e+00,  1.1755e+00,  1.2299e+00,\n",
       "                        8.1434e-01,  6.0298e-01,  1.4741e+00,  5.5347e-01,  2.7149e+00,\n",
       "                        1.8860e+00,  1.4616e+00,  1.2931e+00,  8.4253e-01,  6.9127e-01,\n",
       "                        1.8765e+00,  9.7066e-01,  1.9244e+00,  4.3617e-01,  3.1987e-01,\n",
       "                        1.0198e+00,  6.0475e-01,  1.7214e+00,  2.7468e+00,  2.1337e+00,\n",
       "                        1.0576e+00,  2.2776e-01,  1.5418e+00,  1.5935e+00,  1.8030e+00,\n",
       "                        1.8311e+00, -7.1893e-04,  1.0988e+00,  5.6216e-03,  6.0775e-01,\n",
       "                        1.5422e+00,  3.0809e+00,  1.4612e+00,  3.9491e-01,  1.7697e+00,\n",
       "                        1.0706e+00,  3.5108e-01,  7.5774e-01,  5.4472e-01,  2.5148e+00,\n",
       "                        5.0539e-01,  7.6816e-01,  1.6095e+00,  1.5891e+00,  1.6021e+00,\n",
       "                        3.7561e-01,  8.9141e-01, -6.1429e-03,  5.5415e-01,  2.1623e+00,\n",
       "                        4.7033e+00,  4.5509e-01,  1.5650e+00,  1.7870e+00,  1.6577e+00,\n",
       "                        2.1346e+00,  3.0471e-01,  1.6589e+00,  1.8535e+00, -3.0076e-02,\n",
       "                        1.3630e+00,  2.1911e+00,  1.8578e+00,  1.0828e+00,  1.5510e-01,\n",
       "                        8.0712e-01,  1.4725e+00,  2.1920e+00,  1.0562e+00,  1.8588e+00,\n",
       "                        5.4970e-01,  1.6220e+00,  1.2700e+00,  2.6454e+00,  2.6498e+00,\n",
       "                        1.5508e+00,  2.3490e+00,  1.3413e+00,  1.8477e+00,  1.3945e+00,\n",
       "                        1.4476e+00,  1.5827e+00,  1.4551e+00,  2.4500e+00,  1.6845e+00,\n",
       "                        1.9992e+00,  1.4147e+00,  2.7742e+00,  2.2516e+00,  1.1872e+00,\n",
       "                        9.4551e-02,  2.0324e+00,  8.8717e-01,  1.0793e+00,  1.7990e+00,\n",
       "                        8.1910e-01,  1.7933e+00,  1.4307e+00,  9.4710e-01,  9.8704e-01,\n",
       "                        1.3660e+00,  1.6998e+00,  2.0929e+00,  1.7815e+00,  5.0736e-01,\n",
       "                        5.9426e-01,  1.0764e+00,  1.5014e+00,  1.3042e+00,  1.8784e+00,\n",
       "                        1.0266e+00,  5.8479e-01,  2.3479e+00,  2.6502e+00, -3.0649e-02,\n",
       "                        1.2933e+00,  5.4600e-01,  1.9764e+00,  9.6930e-01,  1.8422e+00,\n",
       "                        1.1752e+00,  1.6058e+00,  1.8838e+00,  2.9529e+00,  2.4306e+00,\n",
       "                        1.6439e+00,  1.9007e+00,  8.3177e-01,  1.3797e+00,  1.1948e+00,\n",
       "                        1.5220e+00,  1.0956e+00,  1.1731e+00,  4.3641e-01,  2.5813e+00,\n",
       "                        1.5308e+00,  2.3602e+00,  2.9983e+00,  3.7506e-01,  1.9513e+00,\n",
       "                        3.4296e-01,  1.7175e+00,  1.8479e+00,  2.9962e-01,  1.5428e+00,\n",
       "                        1.5770e+00,  9.5040e-01,  3.3509e-01,  1.1493e+00,  2.2789e+00,\n",
       "                        1.4299e+00,  6.8688e-01,  1.2078e+00,  1.9069e-01,  4.0950e-01,\n",
       "                        2.7917e+00,  2.1789e-01,  1.8656e+00,  6.8655e-01,  1.1541e+00,\n",
       "                        2.4830e-01,  1.5162e+00,  2.4266e+00,  1.6958e+00,  9.4743e-01,\n",
       "                        9.6844e-01,  9.9704e-01,  1.3941e+00,  7.1240e-01,  1.2962e+00,\n",
       "                        1.1096e+00,  5.1861e-01,  9.5065e-01,  1.1651e+00,  1.8315e+00,\n",
       "                        1.5613e+00,  4.8264e-01,  1.0970e+00,  1.6558e+00,  7.9766e-01,\n",
       "                        1.6897e+00,  2.8724e+00,  8.1769e-01,  1.9238e+00,  1.0095e+00,\n",
       "                        2.1963e+00,  1.3141e+00,  1.9170e+00,  1.3470e+00,  1.6541e+00,\n",
       "                        1.3636e+00,  4.9203e+00,  1.8009e+00,  1.9238e+00,  1.7725e-01,\n",
       "                        1.4842e+00,  1.2664e+00,  1.0932e+00,  1.5680e+00,  1.6372e-01,\n",
       "                        8.7541e-01,  4.7984e-01,  1.9940e+00,  1.7448e+00,  1.3267e+00,\n",
       "                        1.9776e+00,  1.1293e+00,  2.9577e-02,  1.8804e+00,  5.0388e-01,\n",
       "                        1.7794e+00,  2.3642e+00,  1.8988e+00,  1.9364e+00,  1.6394e+00,\n",
       "                        1.9006e+00,  8.0330e-01,  1.4184e+00,  9.1805e-01,  8.1636e-01,\n",
       "                       -1.0522e-02,  9.1394e-01,  2.4851e+00,  1.5797e+00,  1.5966e+00,\n",
       "                        3.7890e-01,  1.6380e+00,  1.5502e+00,  1.4262e+00,  6.0734e-01,\n",
       "                        2.8687e-01,  2.4292e+00,  1.2697e+00,  1.9565e-01,  1.7433e+00,\n",
       "                        5.7658e-01,  2.2557e+00,  1.7809e+00,  1.7226e+00,  1.9299e+00,\n",
       "                        9.6844e-01,  3.0481e-01,  1.6059e+00,  2.0008e+00,  1.7123e+00,\n",
       "                        8.7356e-01,  8.0462e-01,  5.4385e-01,  2.0248e+00,  1.3498e+00,\n",
       "                        1.2218e+00,  3.4270e-01, -3.1991e-03,  1.3759e+00,  8.4376e-01,\n",
       "                        2.9109e-01,  5.2204e-01,  9.0363e-01,  3.6286e-01,  1.1943e+00,\n",
       "                        1.8560e+00, -2.2557e-03,  3.8725e-01,  1.4438e+00,  6.3486e-02,\n",
       "                        3.7214e+00,  1.7841e+00,  2.2486e+00,  1.4094e+00,  1.3203e+00,\n",
       "                        1.9404e+00,  1.8973e+00,  1.9593e+00,  6.8237e-01,  5.0746e-03,\n",
       "                        1.8615e+00,  4.7867e-04,  2.1220e+00,  1.1024e+00,  1.0998e+00,\n",
       "                        1.8307e+00,  1.5784e+00,  2.0365e+00,  4.8303e-01,  4.3521e-01,\n",
       "                        8.1707e-01,  1.0949e+00,  1.7758e+00,  8.2944e-01,  1.1130e+00,\n",
       "                        1.0363e+00,  1.8578e+00,  1.0858e+00,  1.5269e+00,  1.7395e+00,\n",
       "                        1.5697e+00,  1.4594e+00,  3.0461e-01,  1.8267e+00,  6.6947e-02,\n",
       "                        2.6959e+00,  2.7949e-01,  1.0133e+00,  1.8988e+00,  2.3447e+00,\n",
       "                        9.7101e-01,  2.9115e+00,  2.5260e-01,  1.5082e+00,  9.5499e-01,\n",
       "                        1.8357e+00,  1.2742e+00,  2.0722e+00,  8.0715e-01,  2.4580e-01,\n",
       "                        1.6077e+00,  1.6321e+00], device='cuda:0')),\n",
       "              ('module.layer2.0.bn3.bias',\n",
       "               tensor([ 1.0809e+00, -3.0315e-02,  2.8153e-01,  1.4746e+00,  4.7188e-01,\n",
       "                       -1.5038e+00, -1.0071e+00,  7.9982e-01,  2.7085e-01, -8.9895e-01,\n",
       "                       -5.1581e-01,  6.8084e-01,  3.6415e-02,  9.8837e-01, -1.4467e-01,\n",
       "                        1.5405e-02,  2.6122e-01, -1.2125e-01, -5.5974e-01,  9.3647e-02,\n",
       "                        6.3245e-01,  1.0125e+00,  6.0901e-01,  6.4187e-02,  2.6991e-01,\n",
       "                       -8.7144e-01, -2.8670e+00, -1.8525e-01,  1.1547e-01,  4.2889e-01,\n",
       "                       -7.9998e-02,  7.6441e-01, -3.9532e-01, -8.9226e-01,  2.2905e-01,\n",
       "                        3.4378e-01, -1.2855e-01, -6.5842e-01, -4.1325e-02,  7.5139e-02,\n",
       "                       -1.3431e-01,  1.1416e+00, -1.7002e-01, -2.5417e-01,  7.7385e-01,\n",
       "                       -1.3059e-01,  2.1584e-01, -4.4475e-01, -3.7663e-01,  6.8462e-01,\n",
       "                       -1.9542e-01, -3.9480e-01,  2.7223e-01, -1.2298e-01, -1.1123e+00,\n",
       "                        2.8769e-01, -7.7139e-02, -2.7886e-02,  1.6780e+00,  6.7910e-01,\n",
       "                        8.9299e-02,  1.6365e+00,  7.9914e-01, -2.0325e-02,  1.3075e+00,\n",
       "                        1.9173e-01,  9.2440e-02,  3.9322e-01, -2.8898e-01,  2.0312e-02,\n",
       "                        6.7906e-01,  5.5346e-01, -4.6170e-01,  2.4608e-01,  3.8600e-01,\n",
       "                        2.8175e-01,  5.9328e-01, -1.2813e-01,  3.7116e-01, -2.2548e-02,\n",
       "                       -2.5736e-01, -1.4799e+00,  1.1060e-01,  6.8994e-01, -1.6637e-01,\n",
       "                       -2.7342e-01,  8.9918e-01,  4.8021e-02,  1.3042e-01, -3.2328e-01,\n",
       "                        4.1550e-01,  4.6456e-01, -2.8418e-01,  6.1189e-02,  8.9195e-01,\n",
       "                       -3.0963e-01, -1.2689e+00, -8.0968e-01,  5.3008e-01, -8.9457e-01,\n",
       "                        1.5925e-01,  2.2345e-01, -1.0544e+00,  1.4189e+00,  7.2028e-01,\n",
       "                        1.2886e+00, -6.2229e-01, -2.5329e-02,  6.3757e-01,  4.0249e-01,\n",
       "                        6.3843e-01,  6.8351e-01,  4.5042e-02, -2.1809e+00,  1.5726e-01,\n",
       "                        4.9972e-02,  3.3311e-03, -9.5910e-02,  4.1535e-01,  3.1305e-01,\n",
       "                        6.4943e-01, -5.4612e-01, -2.9553e-01,  4.0277e-01,  4.2023e-02,\n",
       "                        4.4813e-01, -2.8188e-01, -4.1896e-01, -3.1057e-03,  3.9666e-01,\n",
       "                       -1.9791e+00,  7.9424e-01, -2.0726e+00,  9.3555e-02,  1.5233e+00,\n",
       "                       -1.1421e+00,  3.1087e-01, -2.9666e-01, -2.3040e-02,  2.2237e-01,\n",
       "                        1.7655e-01, -1.3976e-01,  3.9635e-01, -6.5272e-02, -1.0332e-01,\n",
       "                       -8.9918e-01,  3.1976e-01, -2.4607e-01,  1.1249e+00, -2.5654e-02,\n",
       "                        2.7472e-01,  1.4277e+00, -4.5358e-01, -3.6558e-01,  6.7207e-01,\n",
       "                        3.7530e-01, -3.4852e-01,  2.7023e-01,  2.9044e-01,  9.1824e-01,\n",
       "                        1.5136e+00,  2.9602e-01,  1.7530e-02,  5.2219e-01, -1.0413e+00,\n",
       "                        7.6232e-01,  1.9160e+00, -1.2677e-01, -2.3376e-01,  8.8821e-01,\n",
       "                        1.2054e+00, -1.3117e+00, -4.9689e-01,  2.7999e-01,  2.7991e-01,\n",
       "                       -3.7335e-01,  9.1585e-01,  5.4545e-02,  5.8474e-01, -9.3122e-02,\n",
       "                       -7.2718e-01, -2.0092e+00,  4.5062e-01, -7.8585e-02,  3.1200e-01,\n",
       "                       -3.3226e-01, -5.7938e-02,  7.0017e-01,  1.1702e-01,  7.1021e-01,\n",
       "                       -1.5695e-01,  1.0040e-01,  3.2217e-01, -8.5834e-01, -5.2042e-02,\n",
       "                        1.4155e-01, -2.6004e-01,  5.1560e-01,  2.6118e-02, -2.5246e+00,\n",
       "                        2.5692e-02,  1.2242e-01, -8.0526e-02,  1.5103e+00,  6.6825e-01,\n",
       "                       -2.2605e-02, -1.2382e-01,  3.3804e-01, -2.8252e-01,  1.1481e+00,\n",
       "                        6.9842e-01, -5.6502e-02,  7.6579e-02, -3.0323e+00, -1.1574e+00,\n",
       "                       -1.8801e-01,  4.3011e-01,  6.1014e-01,  4.2796e-01, -8.8325e-01,\n",
       "                       -8.9881e-02,  1.7947e+00,  1.1329e+00,  6.8842e-01, -1.6585e-01,\n",
       "                        5.9048e-01, -1.3127e+00,  2.9708e-01, -2.8185e-01,  1.4783e-01,\n",
       "                       -6.5718e-01, -1.6449e-01, -6.5662e-02,  5.1452e-01, -5.1768e-01,\n",
       "                       -1.8984e-01, -8.8312e-01,  5.9653e-01, -5.3214e-01,  1.1759e-01,\n",
       "                       -5.1262e-01,  6.5306e-03,  8.9281e-01,  1.4979e+00, -1.9638e-01,\n",
       "                       -2.5643e-01,  1.0957e+00,  2.7874e-01,  3.2442e-01, -1.6529e-01,\n",
       "                       -1.6891e-02,  1.4823e+00, -3.9621e-01, -3.2408e-02,  3.9397e-01,\n",
       "                       -2.4317e-01, -3.6628e-02,  2.1651e-01, -6.3848e-02,  1.4070e+00,\n",
       "                        2.4907e-01,  4.2776e-01, -2.7506e-01, -2.1483e-02,  2.3036e-01,\n",
       "                        8.0908e-03,  2.7001e-01,  7.3900e-02, -1.2147e+00, -1.0647e+00,\n",
       "                        6.4578e-01, -8.8255e-02,  2.5730e-02, -1.0125e+00, -6.6847e-01,\n",
       "                        5.6958e-01,  3.2737e-01, -3.9062e-01,  2.2613e-01,  1.8980e-01,\n",
       "                       -7.6783e-02,  7.2748e-01, -7.9067e-01, -4.9375e-01,  2.0554e+00,\n",
       "                        1.3202e+00,  3.9793e-01,  4.4682e-01, -1.6122e-01, -2.9584e-01,\n",
       "                        3.8042e-01, -1.5435e+00, -3.5087e-01,  2.3283e-01, -2.9071e-01,\n",
       "                        2.7956e-01,  2.3475e-01,  1.9140e-01,  1.3580e-01,  2.7327e-02,\n",
       "                        1.1081e-01,  1.6594e-01,  4.3294e-01,  1.9648e-01, -5.2789e-01,\n",
       "                        1.5043e-01,  8.6146e-02, -1.9945e-01, -4.1030e-01,  7.3292e-01,\n",
       "                        1.8577e-01, -3.9622e-01, -2.2586e-01,  7.5460e-01, -2.6644e-01,\n",
       "                        5.7006e-01,  5.3266e-01,  1.8059e-01, -1.5729e+00, -2.7386e-01,\n",
       "                        1.6308e+00,  4.4836e-02,  1.2409e+00,  3.3160e-01,  4.4087e-01,\n",
       "                        3.1558e-01, -2.4024e-02, -2.8401e-01,  1.8291e-01, -9.7965e-01,\n",
       "                       -4.0968e-01, -3.4322e-01, -1.0394e+00, -1.0647e-01, -2.7585e-02,\n",
       "                        5.4202e-01,  3.9868e-01, -2.2026e-01,  2.0406e-01,  5.9089e-01,\n",
       "                       -7.9010e-01, -1.0750e+00, -1.7676e-01, -1.5238e-02, -4.2603e-01,\n",
       "                        3.0441e-01,  6.7503e-01,  7.0302e-01, -1.4221e-01, -3.3557e-01,\n",
       "                       -2.2767e+00,  1.5617e+00, -7.1530e-02,  2.0548e-01,  1.6233e-01,\n",
       "                        1.1150e+00,  4.2633e-01,  7.6298e-02, -6.8362e-01, -4.0859e-01,\n",
       "                       -3.8593e-02,  1.2182e-01, -3.9051e-01,  2.5168e-01, -8.5634e-01,\n",
       "                       -1.3586e-01,  2.2884e-01,  4.0071e-03, -8.2556e-02, -3.0511e-01,\n",
       "                        1.7151e-01,  5.3805e-02, -3.6289e-01,  3.1557e-01,  1.4266e-01,\n",
       "                        4.4080e-01, -1.3566e+00,  5.4765e-01,  2.3003e-01, -1.7049e+00,\n",
       "                       -6.1743e-01, -1.4884e-01, -4.7866e-01,  7.8897e-01,  5.2511e-01,\n",
       "                        2.4760e-01, -2.7946e+00,  1.9080e-01, -4.2253e-01, -2.1424e-02,\n",
       "                       -2.6971e-02, -2.5089e-01,  8.5989e-03,  1.6489e-01, -4.0590e-01,\n",
       "                        9.4156e-01, -8.6597e-02, -2.0895e+00,  5.0151e-01,  1.7388e+00,\n",
       "                       -7.9711e-02, -2.1064e-01, -2.4428e-01, -9.0910e-01,  7.9914e-01,\n",
       "                       -5.6778e-01, -8.8710e-02,  2.2034e-01,  5.0027e-01, -2.3000e-01,\n",
       "                        6.2162e-02, -3.6402e-01,  7.6766e-02,  7.8833e-01,  9.2906e-01,\n",
       "                        1.1940e-01,  5.9794e-01, -6.2823e-01,  2.9073e-01,  4.0978e-01,\n",
       "                        3.4036e-01, -1.3960e+00,  4.4549e-01,  4.9904e-01,  1.6251e-01,\n",
       "                        3.1329e-01, -2.2192e+00, -1.3720e-01,  6.7641e-01,  6.8439e-02,\n",
       "                       -3.9092e-01, -8.4912e-01,  1.0163e-01,  2.2517e-01,  2.3772e-01,\n",
       "                        1.0244e-01,  6.9556e-01, -4.3664e-02, -4.6642e-01, -1.4499e+00,\n",
       "                       -2.8768e-01,  1.5136e-01,  7.9443e-02, -1.1511e+00,  1.5488e+00,\n",
       "                        7.7104e-01,  5.0940e-01,  1.3300e+00,  6.8715e-01,  3.5815e-01,\n",
       "                        1.0070e+00,  1.5929e+00, -3.4754e-01, -2.1671e-01,  5.9907e-01,\n",
       "                        2.0920e-01,  1.9054e+00,  1.3976e-01,  5.6816e-01,  1.9224e+00,\n",
       "                       -5.2902e-01,  1.8200e-01, -4.0280e-01, -3.3683e-01,  6.9148e-01,\n",
       "                       -9.7326e-01, -4.3399e-01, -4.9867e-01,  3.3268e-01,  1.3803e+00,\n",
       "                        6.6392e-02,  1.6347e+00, -2.1434e-01, -5.7458e-01,  1.5437e+00,\n",
       "                       -2.7289e-01,  1.6493e-01,  2.5279e-03,  6.3751e-01,  6.2154e-01,\n",
       "                       -1.6839e-01,  1.4136e+00, -1.0316e-01, -7.7531e-01, -3.2485e-01,\n",
       "                        1.6573e-01, -1.2888e+00, -1.4382e-01,  7.6234e-02,  5.2578e-01,\n",
       "                        3.0421e-01,  9.9666e-01,  3.0267e-01,  3.4918e-01,  1.1211e+00,\n",
       "                       -3.1662e+00, -1.5814e-01, -7.1677e-01, -1.3891e+00, -4.4473e-01,\n",
       "                       -1.1762e-01, -2.0214e+00,  3.3152e-01,  1.0108e-01, -2.1978e-01,\n",
       "                        1.2607e-01, -2.8173e-01,  3.0459e-01,  9.0234e-01,  9.2093e-01,\n",
       "                        4.0415e-01, -8.0689e-02], device='cuda:0')),\n",
       "              ('module.layer2.0.bn3.running_mean',\n",
       "               tensor([ 3.9978e+00, -5.3270e-02,  7.8011e-02, -1.9015e-01, -1.3043e+00,\n",
       "                       -5.7475e-01,  1.7828e+00, -3.7814e-01, -2.3327e-01, -5.4477e-01,\n",
       "                        1.3321e+00,  2.4793e-01,  5.8035e-01, -9.6313e-01,  2.2078e+00,\n",
       "                       -1.5003e+00, -1.6058e+00,  2.7677e+00, -7.4683e-01,  1.9191e-01,\n",
       "                        1.6193e+00,  3.1247e+00,  1.4034e+00, -1.4657e-01, -1.2529e+00,\n",
       "                        2.7792e-01, -2.9815e-01, -9.7815e-01,  1.6660e-01,  7.6252e-01,\n",
       "                       -2.6779e-01, -3.5704e-02,  4.5865e-01,  6.7913e-01, -5.8496e-01,\n",
       "                        4.4502e+00,  1.7507e-01,  2.3347e-01,  1.1962e+00,  1.2120e+00,\n",
       "                        1.5516e+00, -4.2247e-01, -4.9360e-01,  3.2727e-01,  8.4851e-01,\n",
       "                        1.1495e+00, -5.9744e-01,  1.2962e+00, -6.1389e-01,  1.5085e+00,\n",
       "                        1.3776e-01, -3.6721e-01,  5.1737e-01,  1.0384e-01, -3.3167e+00,\n",
       "                        3.2579e+00,  6.3767e-01, -4.5875e+00,  1.0371e+00,  2.0917e+00,\n",
       "                        1.6485e+00,  3.5405e+00, -1.5017e+00,  6.4130e-01,  2.4691e+00,\n",
       "                       -2.3817e-01,  1.8927e-01,  1.3503e+00,  2.6530e-02,  1.5014e-01,\n",
       "                       -1.4201e+00, -1.2668e+00,  1.4519e+00,  5.1112e-01,  1.4073e+00,\n",
       "                        3.5154e+00, -2.1607e+00,  2.1595e-01, -3.4546e+00,  1.9331e+00,\n",
       "                       -4.5443e-01, -1.1613e-01,  2.1777e-03,  1.7626e-01, -2.6759e+00,\n",
       "                       -7.1071e-01,  6.5301e-01,  3.7386e+00,  9.1656e-02,  6.8104e-01,\n",
       "                        9.7662e-01, -1.0344e+00, -1.3125e-01, -8.2367e-01,  1.1660e-02,\n",
       "                        3.7575e-01, -2.3538e+00, -1.4010e+00,  8.8436e-01, -6.9317e-01,\n",
       "                       -2.8047e+00, -7.3204e-01,  1.3951e-01,  1.6884e+00, -1.2320e+00,\n",
       "                        9.3709e-01, -7.1764e-01, -1.2052e+00,  7.9631e-01, -4.9725e+00,\n",
       "                       -4.6022e-01,  6.8081e-02, -3.6877e+00, -1.2555e+00, -3.2331e-01,\n",
       "                        1.3199e+00, -9.7514e-01,  1.2137e+00,  1.1190e+00,  1.5812e+00,\n",
       "                       -1.7415e+00,  6.8647e-01,  3.5713e+00, -4.4980e-01, -9.0385e-01,\n",
       "                        3.7546e+00,  1.1641e+00,  1.6299e+00, -4.5227e-01,  2.3817e+00,\n",
       "                       -7.3119e-01,  3.5440e-02, -6.3878e-01, -1.9333e-01, -5.2496e-01,\n",
       "                        4.2332e-01,  1.6619e+00, -6.0139e-01,  2.3771e-01,  1.1366e+00,\n",
       "                        1.2485e+00,  1.7921e-01,  9.9050e-02,  1.7897e+00,  2.6932e+00,\n",
       "                       -3.5620e-01,  1.5738e+00, -1.3795e+00, -2.4409e-01,  1.2665e+00,\n",
       "                       -1.2963e+00, -6.2418e-02, -1.3063e-01, -4.3628e-01,  2.3560e+00,\n",
       "                        3.3351e-02,  2.0420e+00, -1.7520e-01, -6.2008e-01,  7.4614e-01,\n",
       "                        4.1669e+00, -1.8773e+00, -2.8177e+00,  1.7745e+00, -3.1412e-01,\n",
       "                        1.9684e+00, -1.3368e+00,  6.5214e-01, -1.4320e+00, -2.1410e+00,\n",
       "                        3.0138e-01,  2.0985e+00, -1.7909e+00,  3.8903e-01, -9.7471e-01,\n",
       "                        1.6191e+00,  1.0744e+00,  6.1195e-01, -7.2255e-02,  1.5982e+00,\n",
       "                        2.5335e+00, -1.6246e+00,  7.8070e-01,  3.7244e-01,  1.4624e+00,\n",
       "                        1.1970e+00,  5.8495e-01, -1.1245e+00, -9.5536e-01,  6.5706e-02,\n",
       "                       -6.9603e-01,  3.4979e+00,  1.3820e+00,  1.0938e-01, -3.5561e-01,\n",
       "                        3.7511e-01, -7.8203e-01,  9.0946e-01,  6.7423e-02, -7.8510e-01,\n",
       "                        4.1515e-01,  1.7680e-01, -3.7986e-01, -3.6530e+00, -2.3666e+00,\n",
       "                       -1.1053e+00, -1.1731e+00,  1.9045e+00, -2.8146e-01, -3.1053e-01,\n",
       "                        2.0899e+00,  1.2225e-01,  7.8955e-01, -7.5744e-01, -4.3978e-01,\n",
       "                        1.8379e+00, -1.1143e+00, -4.7147e-01, -8.9719e-01,  1.4821e+00,\n",
       "                        1.6869e+00, -1.6760e-03, -2.0883e+00,  1.5012e-01, -4.6289e-01,\n",
       "                        1.6657e+00, -1.7567e+00,  8.9409e-01,  1.1714e+00,  2.3167e-01,\n",
       "                        8.9968e-02,  6.2173e-01,  8.1800e-01,  1.2938e+00, -1.3612e+00,\n",
       "                        8.5132e-01,  2.8719e-01,  3.8869e-01, -1.7967e+00, -9.3881e-02,\n",
       "                       -6.2697e-02,  1.0738e+00, -2.0449e-02,  2.8524e+00, -7.0181e-01,\n",
       "                        7.8351e-01,  7.4349e-01,  5.6852e-01,  9.1896e-01, -2.7097e-01,\n",
       "                       -1.3981e-01, -4.7355e-01,  3.4801e-01, -5.4922e-02, -4.3683e-01,\n",
       "                       -4.4885e-01,  8.0333e-02, -4.0830e+00, -1.8829e-01, -6.7616e-01,\n",
       "                       -4.0493e-01, -1.3562e-01, -9.6070e-01, -1.3883e+00,  2.0376e+00,\n",
       "                        3.4135e-01, -6.6273e-01,  8.3187e-01,  2.6758e-01,  2.2412e-01,\n",
       "                       -1.2962e-01,  1.0159e+00, -6.9396e-01, -2.9583e-01, -3.7059e-01,\n",
       "                       -1.1377e+00, -6.7585e-01,  3.8539e-01,  1.0820e+00, -1.5806e+00,\n",
       "                       -2.9454e-01, -6.6918e-01, -4.7054e-01,  9.6750e-02,  1.9647e-01,\n",
       "                        1.2912e+00,  2.9108e-01,  1.4620e+00, -5.4954e-01, -7.1379e-01,\n",
       "                       -8.6536e-01, -4.4082e-01, -2.8631e-01,  3.9460e-02,  1.2936e+00,\n",
       "                        6.0552e-01, -8.2468e-01,  2.5356e-01,  4.8024e-01, -3.6822e-01,\n",
       "                        2.4363e-01, -8.6928e-03,  9.1100e-01,  2.7906e+00,  4.2476e+00,\n",
       "                        1.0851e+00, -4.9596e-01,  7.2849e-01,  7.3767e-01, -6.5388e-02,\n",
       "                        2.9317e+00,  5.7001e-01, -1.0169e+00,  4.3631e-01, -1.8866e+00,\n",
       "                       -8.8869e-01, -1.0513e+00,  1.9536e-01, -4.4782e-01,  3.8364e-01,\n",
       "                        2.1363e+00, -7.5740e-01, -1.7456e+00, -5.5942e-02, -1.2774e+00,\n",
       "                       -1.8043e+00, -6.7748e-01, -8.8736e-01,  6.4440e-01,  6.2364e-01,\n",
       "                       -6.4499e-02,  2.3118e-01, -2.2883e+00, -1.7353e+00, -1.4631e+00,\n",
       "                        3.4473e-01,  3.5085e-02, -2.6377e-01, -3.4633e-01, -2.1886e+00,\n",
       "                       -1.2171e+00,  2.8562e-01, -1.2046e+00,  9.3984e-01,  8.3672e-01,\n",
       "                        8.0318e-01, -1.3295e+00,  8.0864e-01,  6.4234e-02,  5.3822e-01,\n",
       "                        2.8660e-01,  5.0563e-02,  1.3021e+00,  8.7650e-01,  1.8186e+00,\n",
       "                       -4.1771e-01,  1.2298e+00, -4.0147e-01,  2.0586e-01, -4.1505e-01,\n",
       "                        9.2316e-01,  3.4682e-01,  1.1875e+00,  8.1076e-01, -1.6048e+00,\n",
       "                       -8.1390e-01, -1.2162e+00,  5.3729e-01,  7.4504e-01,  6.7020e-01,\n",
       "                       -3.5631e+00,  4.8730e-01,  1.3757e+00,  3.5393e-01,  5.8106e-01,\n",
       "                        2.2581e-01, -2.0086e+00,  7.3473e-02,  1.4136e-01,  1.1011e+00,\n",
       "                       -9.1535e-01, -2.9113e-01, -1.0465e+00,  1.4053e+00,  4.0395e-02,\n",
       "                       -2.6998e+00, -7.7485e-01, -7.3372e-01, -1.4406e+00,  6.1405e-01,\n",
       "                        4.7181e-01,  2.5753e+00, -2.9764e-01,  2.9121e-01, -1.6906e-06,\n",
       "                        6.9621e-01,  2.0269e-01, -2.4450e-01, -8.8612e-01,  3.2951e-01,\n",
       "                       -1.1510e-01,  3.7370e-01,  3.9867e-01,  5.7784e-01, -4.9585e-01,\n",
       "                        1.1255e+00,  4.4223e-01, -9.2785e-01, -3.1145e+00,  3.4041e+00,\n",
       "                       -1.8869e+00,  8.4379e-02,  1.8747e+00,  1.6851e+00,  1.8746e+00,\n",
       "                       -2.1354e-03,  3.9972e-01, -2.2531e+00,  5.4428e-01,  1.9317e+00,\n",
       "                       -3.5144e-01, -5.9504e-01,  1.8279e+00, -1.7761e+00, -1.0895e+00,\n",
       "                        3.6581e-01,  1.8035e+00, -9.4530e-01,  8.6800e-01,  4.7509e-01,\n",
       "                       -5.4552e-01, -1.0660e+00,  6.6156e-02, -2.5569e-01,  8.7185e-01,\n",
       "                        3.7582e-01, -1.3282e+00, -3.4576e-01,  1.9986e-01, -1.8817e-01,\n",
       "                        4.0023e-01,  3.4446e-01,  1.5434e-01, -1.9491e+00, -3.2086e-01,\n",
       "                        1.6131e+00, -6.0237e-01, -1.2614e-01, -2.7712e+00,  5.4761e-01,\n",
       "                       -7.4294e-01, -5.4119e-01,  8.7866e-01, -4.1416e-02,  1.6329e+00,\n",
       "                        1.7578e+00,  1.8785e-02, -1.1863e+00,  8.4240e-01, -1.1377e-01,\n",
       "                       -6.9872e-01,  1.0102e+00,  8.6639e-02,  1.0856e+00, -6.8513e-02,\n",
       "                       -1.5772e-01, -1.0154e+00, -8.7272e-02,  5.7305e-01, -3.7695e-02,\n",
       "                        9.4169e-01, -6.9663e-02,  7.1870e+00,  2.0426e+00,  2.2169e+00,\n",
       "                       -5.4230e-01, -8.2536e-01, -1.3273e+00,  1.1970e+00, -1.3030e-01,\n",
       "                        1.9085e+00, -1.3664e+00, -1.9084e+00,  2.9325e-01,  1.5460e+00,\n",
       "                        3.9627e-01, -7.3866e-01,  4.1444e-01, -4.5919e-01, -1.3747e+00,\n",
       "                       -1.3367e+00, -1.4573e+00, -6.7364e-01, -1.4043e+00, -1.1230e-01,\n",
       "                        1.6359e+00,  1.6251e+00,  9.4728e-01, -2.9710e-01,  3.9319e-01,\n",
       "                       -1.2185e-01, -9.9724e-01,  3.3051e-01,  8.5751e-01,  2.2136e+00,\n",
       "                        3.9071e-01,  1.8409e+00,  1.1988e-01, -1.7364e-01, -2.4059e-01,\n",
       "                        6.6348e-01,  1.1354e+00], device='cuda:0')),\n",
       "              ('module.layer2.0.bn3.running_var',\n",
       "               tensor([9.3081e-01, 6.4895e-02, 3.8264e-01, 1.0777e-01, 7.9556e-01, 6.9610e-01,\n",
       "                       6.4786e-01, 2.6026e-02, 3.0951e-02, 5.9443e-01, 9.9127e-01, 2.2888e+00,\n",
       "                       1.5124e+00, 1.5487e+00, 3.7600e-01, 8.2873e-01, 1.3234e+00, 9.9650e-01,\n",
       "                       1.0084e+00, 2.7340e+00, 4.6446e-01, 2.1766e+00, 2.1509e-01, 2.4338e+00,\n",
       "                       7.3249e-01, 1.3293e+00, 4.1585e-01, 6.8310e-01, 2.4980e-01, 8.1952e-02,\n",
       "                       8.4869e-01, 1.0968e-02, 3.9637e-01, 3.0925e-01, 1.3975e+00, 1.2309e+00,\n",
       "                       3.1593e-01, 2.8462e-01, 1.0881e+00, 6.9896e-01, 5.2805e-01, 2.4434e+00,\n",
       "                       3.4919e-01, 1.0122e+00, 7.6748e-01, 3.7085e-01, 2.3985e+00, 4.4096e-01,\n",
       "                       9.0641e-02, 1.5802e+00, 2.8822e-01, 1.1739e+00, 9.7024e-01, 1.2479e+00,\n",
       "                       1.0375e+00, 2.4895e+00, 5.9382e-01, 9.2487e-01, 2.9595e+00, 1.0423e+00,\n",
       "                       7.7925e-01, 2.5034e+00, 3.8779e-01, 2.6813e-01, 1.1197e+00, 2.5318e-01,\n",
       "                       5.8907e-01, 8.8834e-01, 5.9899e-01, 5.1920e-01, 6.3938e-01, 7.6026e-01,\n",
       "                       2.5653e-01, 6.1171e-01, 1.3313e+00, 1.2996e+00, 2.1665e+00, 1.5605e+00,\n",
       "                       1.6688e+00, 7.3922e-01, 1.0678e+00, 3.2772e-01, 6.2948e-01, 1.8100e-02,\n",
       "                       4.7457e-01, 4.4710e-01, 5.8302e-01, 2.4398e-01, 1.9075e+00, 4.7878e-01,\n",
       "                       3.5948e-01, 2.8852e-01, 1.3402e+00, 8.4095e-01, 6.6189e-03, 1.2886e+00,\n",
       "                       8.0613e-01, 3.4520e-01, 2.7658e-01, 8.1731e-01, 1.0588e+00, 1.0009e+00,\n",
       "                       5.4553e-01, 3.1540e-01, 1.5022e+00, 4.5132e+00, 6.5475e-01, 8.3441e-01,\n",
       "                       2.6533e-01, 9.7839e-01, 2.3607e+00, 3.4669e-02, 9.9716e-01, 3.6900e-01,\n",
       "                       5.3374e-01, 1.4697e+00, 4.9103e-01, 2.6291e+00, 1.6455e+00, 1.0049e+00,\n",
       "                       1.1541e+00, 5.9066e-01, 7.9488e-01, 4.1393e-01, 1.7416e+00, 9.4316e-01,\n",
       "                       1.2230e-01, 5.8730e-01, 9.8799e-01, 2.5319e-01, 7.6472e-01, 8.2888e-01,\n",
       "                       6.0458e-01, 8.8812e-02, 5.9750e-02, 1.2543e+00, 9.8972e-01, 3.9364e-01,\n",
       "                       1.4130e+00, 8.6278e-01, 5.9138e-01, 6.0810e-01, 6.4660e-03, 6.5656e-01,\n",
       "                       5.1028e-01, 1.9629e-01, 2.9075e+00, 6.5426e-01, 5.2882e-01, 4.7458e-01,\n",
       "                       6.8722e-01, 1.3256e-02, 6.4229e-01, 5.8771e-01, 1.8039e+00, 2.9957e+00,\n",
       "                       4.7488e-01, 1.7467e-01, 1.2485e+00, 1.8169e+00, 2.0205e+00, 8.0428e-01,\n",
       "                       7.9325e-01, 4.5374e-01, 1.3193e-01, 1.3274e+00, 2.3450e+00, 1.3441e+00,\n",
       "                       3.4284e-01, 4.3933e-01, 2.0852e+00, 5.9914e-01, 1.5382e+00, 1.4601e-01,\n",
       "                       4.2338e-01, 5.6252e-01, 5.5567e-01, 9.8304e-01, 3.5480e-01, 7.4560e-01,\n",
       "                       2.7151e-01, 6.5382e-01, 7.5785e-01, 1.5215e-01, 6.8656e-01, 4.6387e-01,\n",
       "                       1.5245e-01, 2.7213e-01, 3.0633e-01, 1.0329e+00, 1.4254e+00, 1.1245e+00,\n",
       "                       1.3585e+00, 4.2137e-01, 4.3053e-01, 5.1407e-01, 1.8208e-01, 1.8539e+00,\n",
       "                       4.1015e-01, 4.2746e-01, 9.7739e-01, 1.5249e+00, 1.0283e+00, 2.6713e+00,\n",
       "                       9.0168e-01, 1.2266e+00, 5.6102e-01, 1.4956e+00, 1.9113e-01, 2.8966e-01,\n",
       "                       5.4998e-01, 2.1427e-01, 1.6297e+00, 6.2964e-01, 6.2379e-01, 4.5373e-01,\n",
       "                       1.8141e-01, 1.2988e+00, 2.1311e+00, 8.4533e-01, 7.6251e-01, 1.2618e-02,\n",
       "                       1.0281e+00, 1.2243e-02, 2.3845e-01, 1.1518e+00, 7.1114e-01, 1.0910e+00,\n",
       "                       1.2206e-01, 7.1575e-01, 2.0711e-01, 3.6739e-01, 2.7935e-01, 5.3788e-01,\n",
       "                       1.1211e+00, 1.7826e-01, 2.7939e-01, 2.2713e+00, 8.5644e-01, 1.8948e+00,\n",
       "                       1.1234e-01, 4.4328e-01, 1.8860e-02, 1.3891e+00, 1.2407e+00, 2.8492e+00,\n",
       "                       1.4607e+00, 1.3949e+00, 1.6262e+00, 5.9607e-01, 2.2086e+00, 5.4631e-01,\n",
       "                       7.4240e-01, 1.5755e+00, 3.3639e-02, 7.4929e-01, 1.7420e+00, 1.7775e+00,\n",
       "                       8.0076e-01, 1.3370e-01, 6.4376e-01, 7.6510e-01, 1.3660e+00, 7.2793e-01,\n",
       "                       2.2478e+00, 3.2883e-01, 7.3267e-01, 5.9859e-01, 9.7989e-01, 7.3598e-01,\n",
       "                       1.2861e+00, 2.0856e+00, 6.5067e-01, 3.2134e-01, 3.0553e-01, 8.9149e-01,\n",
       "                       1.5094e+00, 5.2998e-01, 1.8268e+00, 1.0600e+00, 8.3667e-01, 1.2083e+00,\n",
       "                       6.1302e-01, 9.9201e-01, 1.1660e+00, 1.1627e-01, 1.7357e+00, 7.8786e-01,\n",
       "                       7.1220e-01, 1.0471e+00, 5.7519e-01, 7.0970e-01, 5.0038e-01, 7.7589e-01,\n",
       "                       3.9798e-01, 1.0348e+00, 8.0957e-01, 1.6731e+00, 7.7885e-01, 2.4534e-01,\n",
       "                       3.6657e-01, 4.8763e-01, 1.1283e+00, 8.7127e-01, 8.9047e-01, 7.0272e-01,\n",
       "                       2.8112e-01, 1.2439e+00, 1.8801e+00, 2.8912e-02, 2.1489e+00, 1.5149e-01,\n",
       "                       8.0212e-01, 8.2543e-01, 5.9842e-01, 1.2494e+00, 2.3119e+00, 1.2659e+00,\n",
       "                       6.3448e-01, 2.2397e+00, 2.4735e+00, 6.7607e-01, 1.1419e+00, 1.9868e+00,\n",
       "                       8.4939e-01, 9.0286e-01, 4.0274e-01, 6.1861e-01, 2.9058e-01, 1.1124e+00,\n",
       "                       4.5404e-01, 1.2485e+00, 9.2950e-01, 1.6326e-01, 7.7386e-01, 2.1030e-01,\n",
       "                       1.1356e+00, 9.9289e-01, 1.5466e-01, 9.8508e-01, 5.1182e-01, 4.8017e-01,\n",
       "                       1.8935e-01, 5.4275e-01, 1.1319e+00, 7.7517e-01, 3.2731e-01, 1.3264e+00,\n",
       "                       7.5065e-02, 1.3445e-01, 2.9234e-01, 2.6117e-01, 9.3527e-01, 5.2021e-01,\n",
       "                       5.7820e-01, 3.0846e-01, 1.0536e+00, 2.5431e+00, 4.3313e-01, 2.3691e-01,\n",
       "                       6.6665e-01, 5.9132e-01, 6.2560e-01, 5.1727e-01, 6.1527e-01, 5.4830e-01,\n",
       "                       3.0164e-01, 9.8981e-01, 3.0365e-01, 7.8427e-01, 1.2629e+00, 4.8784e-01,\n",
       "                       5.1591e-01, 1.0350e+00, 1.0307e+00, 1.9180e+00, 1.1993e+00, 6.4035e-01,\n",
       "                       1.0846e+00, 1.7787e-01, 1.6745e+00, 9.1028e-01, 6.6057e-01, 1.4183e+00,\n",
       "                       1.9134e+00, 1.0101e+00, 9.7087e-01, 2.1651e+00, 1.2290e+00, 1.3004e-01,\n",
       "                       7.9223e-01, 7.9369e-01, 5.0070e-01, 1.4616e+00, 9.5497e-13, 7.2103e-01,\n",
       "                       1.7114e-01, 4.7368e-01, 1.1546e+00, 2.0048e+00, 8.9724e-01, 5.2827e-01,\n",
       "                       2.5601e-02, 6.5978e-01, 4.3548e-01, 7.0655e-01, 1.4317e+00, 2.1266e+00,\n",
       "                       1.1837e+00, 1.0442e+00, 1.4039e+00, 5.7939e-01, 5.9036e-01, 7.6945e-01,\n",
       "                       6.0177e-01, 6.7255e-03, 8.6615e-01, 1.4772e+00, 1.6802e+00, 1.5108e+00,\n",
       "                       2.9978e-01, 4.6161e-01, 2.0329e+00, 8.6122e-01, 3.2501e-01, 2.5562e-01,\n",
       "                       5.6878e-01, 6.0888e-01, 1.1171e-01, 7.5073e-01, 2.2814e-01, 6.1204e-01,\n",
       "                       9.8393e-01, 1.4239e+00, 1.3645e+00, 6.1648e-01, 2.4191e-01, 7.6466e-01,\n",
       "                       8.7448e-01, 4.3002e-01, 4.4116e-01, 4.5832e-01, 1.9683e-01, 9.7759e-01,\n",
       "                       1.6322e+00, 9.4664e-01, 2.6635e-01, 1.5750e-02, 1.6763e+00, 5.5329e-01,\n",
       "                       1.7668e-01, 8.1770e-01, 3.3548e-01, 8.7062e-02, 6.7058e-01, 7.8695e-01,\n",
       "                       1.2615e-02, 2.5596e-01, 2.7877e+00, 9.5884e-02, 1.5176e+00, 1.4258e+00,\n",
       "                       1.0520e+00, 5.3878e-01, 1.1841e+00, 1.0836e+00, 1.0313e+00, 6.7224e-01,\n",
       "                       7.2691e-01, 1.2532e-02, 1.6998e+00, 1.9164e-02, 1.0614e+00, 3.4811e-01,\n",
       "                       3.1619e+00, 1.1637e+00, 1.0465e+00, 1.2242e+00, 6.7535e-01, 4.5639e-01,\n",
       "                       2.7170e-01, 9.6344e-01, 8.1667e-01, 1.8941e-01, 1.0727e+00, 4.7678e-01,\n",
       "                       6.2608e-01, 3.2551e-01, 7.7376e-01, 1.3366e+00, 1.1816e+00, 9.0628e-01,\n",
       "                       1.5685e-01, 1.0065e+00, 5.3948e-02, 5.8903e-01, 1.8581e-01, 5.0254e-01,\n",
       "                       2.9947e-01, 9.6334e-01, 5.7726e-01, 5.8369e-01, 2.4061e-01, 1.1641e+00,\n",
       "                       6.7284e-01, 8.6994e-01, 6.4192e-01, 1.3510e+00, 8.3713e-01, 4.1275e-01,\n",
       "                       1.9904e+00, 7.5392e-01], device='cuda:0')),\n",
       "              ('module.layer2.0.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.0.downsample.0.weight',\n",
       "               tensor([[[[ 2.3204e-02]],\n",
       "               \n",
       "                        [[ 6.1367e-02]],\n",
       "               \n",
       "                        [[ 2.1475e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.5272e-02]],\n",
       "               \n",
       "                        [[ 2.3431e-01]],\n",
       "               \n",
       "                        [[-2.2105e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.7513e-03]],\n",
       "               \n",
       "                        [[-8.1255e-02]],\n",
       "               \n",
       "                        [[-2.9198e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.7527e-02]],\n",
       "               \n",
       "                        [[-3.2539e-02]],\n",
       "               \n",
       "                        [[-1.6176e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.4503e-04]],\n",
       "               \n",
       "                        [[ 2.0356e-02]],\n",
       "               \n",
       "                        [[ 7.4875e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.7866e-02]],\n",
       "               \n",
       "                        [[ 4.8100e-02]],\n",
       "               \n",
       "                        [[-9.5283e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.7806e-02]],\n",
       "               \n",
       "                        [[-2.4988e-02]],\n",
       "               \n",
       "                        [[-2.0652e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-7.6806e-03]],\n",
       "               \n",
       "                        [[-2.6330e-02]],\n",
       "               \n",
       "                        [[ 3.1974e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.2788e-02]],\n",
       "               \n",
       "                        [[ 3.1153e-02]],\n",
       "               \n",
       "                        [[ 1.8481e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.4733e-02]],\n",
       "               \n",
       "                        [[ 4.0880e-02]],\n",
       "               \n",
       "                        [[-6.7852e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3536e-02]],\n",
       "               \n",
       "                        [[-2.3360e-02]],\n",
       "               \n",
       "                        [[ 3.6433e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.1572e-02]],\n",
       "               \n",
       "                        [[-4.0005e-02]],\n",
       "               \n",
       "                        [[ 1.4281e-02]]]], device='cuda:0')),\n",
       "              ('module.layer2.0.downsample.1.weight',\n",
       "               tensor([1.6852, 0.5647, 0.5273, 2.0906, 1.3184, 1.2857, 2.6922, 0.4301, 3.1725,\n",
       "                       0.8068, 2.3901, 0.3424, 0.7941, 0.3996, 0.4285, 0.7012, 0.6994, 1.6316,\n",
       "                       1.1065, 0.5302, 1.7626, 0.2173, 1.9913, 1.2641, 0.9845, 1.5678, 2.2657,\n",
       "                       0.8043, 0.1520, 2.7638, 0.8159, 0.2934, 0.8320, 1.5214, 0.6775, 0.5872,\n",
       "                       0.2634, 2.8856, 1.4263, 1.4509, 1.8097, 1.5144, 0.5432, 0.7235, 0.4410,\n",
       "                       0.7245, 0.4813, 0.7547, 0.7290, 0.7736, 0.6662, 1.0212, 0.4568, 1.1094,\n",
       "                       1.5065, 0.5766, 0.9032, 1.4269, 0.8702, 0.5322, 1.0569, 1.2720, 1.3542,\n",
       "                       0.3523, 1.4011, 3.4810, 0.5545, 0.7631, 0.5943, 1.8398, 1.4299, 0.5632,\n",
       "                       0.6462, 0.7879, 1.1032, 0.6694, 1.2428, 0.7890, 0.5743, 1.3856, 0.9652,\n",
       "                       2.6103, 1.4173, 2.9416, 1.2474, 0.4683, 1.1119, 1.3779, 0.5692, 2.2136,\n",
       "                       0.3148, 0.6664, 1.1648, 1.5856, 0.5669, 0.4390, 1.5597, 2.2695, 2.5108,\n",
       "                       0.6460, 0.7624, 0.3582, 1.0536, 2.3762, 0.7489, 0.3041, 1.5389, 0.3798,\n",
       "                       2.6891, 1.2562, 0.2752, 1.9186, 0.4414, 3.4842, 1.3429, 0.8883, 2.6738,\n",
       "                       1.4078, 0.2510, 1.1706, 0.7705, 0.4672, 1.6666, 1.0148, 0.9796, 1.5726,\n",
       "                       3.3253, 2.3357, 0.7107, 1.8470, 3.0714, 0.4001, 1.8387, 3.5803, 2.5256,\n",
       "                       1.2468, 1.3838, 0.7885, 0.3018, 0.7248, 0.8019, 0.4427, 2.1773, 0.2893,\n",
       "                       1.0699, 0.4713, 0.4545, 0.8710, 0.5455, 1.5257, 1.4033, 2.4575, 0.4834,\n",
       "                       0.9080, 2.1787, 0.5045, 0.8639, 0.4731, 0.5277, 1.0992, 0.7073, 1.2510,\n",
       "                       0.6885, 1.8570, 1.0938, 0.5364, 0.5670, 1.7317, 3.1028, 2.1499, 0.4132,\n",
       "                       1.4301, 1.7926, 0.4466, 0.4780, 1.1763, 0.4837, 1.0097, 1.1423, 0.5721,\n",
       "                       0.4164, 1.3899, 1.0693, 0.4573, 0.5246, 0.5397, 0.4947, 3.0069, 2.6543,\n",
       "                       0.9791, 1.2785, 1.3923, 0.6264, 2.8541, 0.6147, 0.5456, 0.6459, 0.2649,\n",
       "                       0.4249, 2.4620, 0.4734, 1.2472, 1.2340, 1.6912, 1.6206, 0.9829, 2.0814,\n",
       "                       0.4902, 0.0639, 0.3832, 0.5372, 0.4269, 0.8936, 2.5105, 1.4331, 0.5197,\n",
       "                       0.7387, 0.8381, 0.5760, 1.9396, 0.7506, 1.8867, 1.7069, 2.2191, 0.7567,\n",
       "                       1.1564, 1.6536, 0.8177, 0.5672, 0.6763, 0.4242, 2.8584, 0.5343, 2.3215,\n",
       "                       1.4620, 0.5346, 3.4040, 1.0165, 2.2694, 1.1629, 2.1583, 0.5707, 1.9321,\n",
       "                       1.5549, 0.3628, 2.2122, 1.3498, 0.5682, 0.8672, 0.5776, 0.4180, 1.3759,\n",
       "                       0.9836, 1.2828, 1.2847, 2.6830, 0.9986, 0.4360, 3.2874, 1.4312, 1.6178,\n",
       "                       0.7371, 0.9115, 1.0378, 0.5858, 0.7087, 0.4755, 1.1313, 1.5604, 1.5963,\n",
       "                       0.5990, 0.9471, 0.5714, 0.9322, 2.0609, 1.0852, 0.7630, 1.0206, 1.5881,\n",
       "                       1.6632, 0.8252, 0.1788, 1.7142, 0.9295, 0.9994, 2.3779, 0.6915, 0.8017,\n",
       "                       0.4607, 2.2762, 0.5036, 3.4503, 0.7173, 1.4032, 0.2910, 0.6618, 0.5377,\n",
       "                       0.6290, 0.5634, 0.4536, 2.2562, 2.0921, 0.9562, 0.8414, 0.9032, 1.2606,\n",
       "                       0.4399, 0.3813, 0.9572, 0.8928, 0.6418, 0.1323, 0.8714, 0.9664, 1.1002,\n",
       "                       0.6796, 0.5508, 0.7482, 2.1304, 1.0966, 0.6777, 1.1384, 1.5716, 1.2407,\n",
       "                       0.4408, 1.4585, 0.6521, 1.3302, 2.1739, 0.7805, 0.6073, 0.7261, 1.6187,\n",
       "                       1.1622, 0.7484, 1.5583, 0.8205, 1.2449, 0.3886, 0.8122, 1.4358, 2.8113,\n",
       "                       4.0460, 0.5650, 0.6494, 0.9360, 0.6090, 0.5957, 0.7449, 0.4119, 1.2147,\n",
       "                       1.7129, 0.8519, 0.3618, 1.4016, 0.4121, 0.4610, 1.0860, 1.9546, 0.2489,\n",
       "                       0.6612, 0.4259, 1.3137, 0.5867, 3.3504, 0.7026, 2.6449, 1.1869, 1.2876,\n",
       "                       0.8489, 0.5349, 0.2009, 0.3566, 0.7335, 2.2649, 0.4212, 1.6241, 0.4580,\n",
       "                       0.9723, 1.0371, 0.5960, 1.2418, 1.2496, 0.3820, 0.7101, 0.7391, 4.2215,\n",
       "                       1.3402, 0.6690, 0.3320, 1.3150, 1.8985, 1.8918, 1.3162, 0.0368, 0.3959,\n",
       "                       0.5277, 1.7988, 0.7739, 0.6564, 0.7163, 1.3995, 1.9550, 2.6961, 0.1785,\n",
       "                       0.7174, 0.3773, 0.9218, 0.9144, 0.7053, 0.6274, 0.3486, 0.3324, 0.7996,\n",
       "                       1.6800, 0.5161, 1.2202, 1.4698, 0.8545, 0.6925, 2.3586, 2.9381, 0.5249,\n",
       "                       0.6023, 0.2048, 1.0293, 1.5807, 0.6792, 0.7088, 0.8112, 0.4595, 1.2694,\n",
       "                       0.6811, 0.5461, 0.8076, 1.7269, 0.6546, 0.4996, 0.7537, 1.8174, 0.3119,\n",
       "                       2.1364, 0.6749, 2.9362, 0.4860, 1.1711, 0.5345, 2.7799, 0.7428, 1.8919,\n",
       "                       1.5543, 1.7053, 0.5614, 0.4302, 0.4977, 0.7952, 1.4730, 0.8670, 0.7869,\n",
       "                       1.6494, 2.6947, 0.6629, 1.2911, 0.7351, 0.8735, 1.8913, 1.9910, 0.6620,\n",
       "                       0.6927, 1.0267, 1.2731, 2.3135, 1.0085, 0.3406, 0.7114, 1.0453, 0.4047,\n",
       "                       0.7293, 2.6733, 0.6285, 0.5478, 0.3287, 0.4772, 0.2864, 2.0750, 0.4554,\n",
       "                       2.7839, 0.9320, 0.9151, 1.6661, 1.7129, 0.4634, 0.5923, 0.4157, 0.2683,\n",
       "                       4.1730, 0.5906, 2.4297, 1.5764, 1.0259, 0.5065, 2.0812, 2.3453, 1.3885,\n",
       "                       0.4095, 0.4863, 1.5641, 0.9299, 0.6628, 1.3333, 0.7389, 0.5975],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.0.downsample.1.bias',\n",
       "               tensor([ 1.0809e+00, -3.0315e-02,  2.8153e-01,  1.4746e+00,  4.7188e-01,\n",
       "                       -1.5038e+00, -1.0071e+00,  7.9982e-01,  2.7085e-01, -8.9895e-01,\n",
       "                       -5.1581e-01,  6.8084e-01,  3.6415e-02,  9.8837e-01, -1.4467e-01,\n",
       "                        1.5405e-02,  2.6122e-01, -1.2125e-01, -5.5974e-01,  9.3647e-02,\n",
       "                        6.3245e-01,  1.0125e+00,  6.0901e-01,  6.4187e-02,  2.6991e-01,\n",
       "                       -8.7144e-01, -2.8670e+00, -1.8525e-01,  1.1547e-01,  4.2889e-01,\n",
       "                       -7.9998e-02,  7.6441e-01, -3.9532e-01, -8.9226e-01,  2.2905e-01,\n",
       "                        3.4378e-01, -1.2855e-01, -6.5842e-01, -4.1325e-02,  7.5139e-02,\n",
       "                       -1.3431e-01,  1.1416e+00, -1.7002e-01, -2.5417e-01,  7.7385e-01,\n",
       "                       -1.3059e-01,  2.1584e-01, -4.4475e-01, -3.7663e-01,  6.8462e-01,\n",
       "                       -1.9542e-01, -3.9480e-01,  2.7223e-01, -1.2298e-01, -1.1123e+00,\n",
       "                        2.8769e-01, -7.7139e-02, -2.7886e-02,  1.6780e+00,  6.7910e-01,\n",
       "                        8.9299e-02,  1.6365e+00,  7.9914e-01, -2.0325e-02,  1.3075e+00,\n",
       "                        1.9173e-01,  9.2440e-02,  3.9322e-01, -2.8898e-01,  2.0312e-02,\n",
       "                        6.7906e-01,  5.5346e-01, -4.6170e-01,  2.4608e-01,  3.8600e-01,\n",
       "                        2.8175e-01,  5.9328e-01, -1.2813e-01,  3.7116e-01, -2.2548e-02,\n",
       "                       -2.5736e-01, -1.4799e+00,  1.1060e-01,  6.8994e-01, -1.6637e-01,\n",
       "                       -2.7342e-01,  8.9918e-01,  4.8021e-02,  1.3042e-01, -3.2328e-01,\n",
       "                        4.1550e-01,  4.6456e-01, -2.8418e-01,  6.1189e-02,  8.9195e-01,\n",
       "                       -3.0963e-01, -1.2689e+00, -8.0968e-01,  5.3008e-01, -8.9457e-01,\n",
       "                        1.5925e-01,  2.2345e-01, -1.0544e+00,  1.4189e+00,  7.2028e-01,\n",
       "                        1.2886e+00, -6.2229e-01, -2.5329e-02,  6.3757e-01,  4.0249e-01,\n",
       "                        6.3843e-01,  6.8351e-01,  4.5042e-02, -2.1809e+00,  1.5726e-01,\n",
       "                        4.9972e-02,  3.3311e-03, -9.5910e-02,  4.1535e-01,  3.1305e-01,\n",
       "                        6.4943e-01, -5.4612e-01, -2.9553e-01,  4.0277e-01,  4.2023e-02,\n",
       "                        4.4813e-01, -2.8188e-01, -4.1896e-01, -3.1057e-03,  3.9666e-01,\n",
       "                       -1.9791e+00,  7.9424e-01, -2.0726e+00,  9.3555e-02,  1.5233e+00,\n",
       "                       -1.1421e+00,  3.1087e-01, -2.9666e-01, -2.3040e-02,  2.2237e-01,\n",
       "                        1.7655e-01, -1.3976e-01,  3.9635e-01, -6.5272e-02, -1.0332e-01,\n",
       "                       -8.9918e-01,  3.1976e-01, -2.4607e-01,  1.1249e+00, -2.5654e-02,\n",
       "                        2.7472e-01,  1.4277e+00, -4.5358e-01, -3.6558e-01,  6.7207e-01,\n",
       "                        3.7530e-01, -3.4852e-01,  2.7023e-01,  2.9044e-01,  9.1824e-01,\n",
       "                        1.5136e+00,  2.9602e-01,  1.7530e-02,  5.2219e-01, -1.0413e+00,\n",
       "                        7.6232e-01,  1.9160e+00, -1.2677e-01, -2.3376e-01,  8.8821e-01,\n",
       "                        1.2054e+00, -1.3117e+00, -4.9689e-01,  2.7999e-01,  2.7991e-01,\n",
       "                       -3.7335e-01,  9.1585e-01,  5.4545e-02,  5.8474e-01, -9.3122e-02,\n",
       "                       -7.2718e-01, -2.0092e+00,  4.5062e-01, -7.8585e-02,  3.1200e-01,\n",
       "                       -3.3226e-01, -5.7938e-02,  7.0017e-01,  1.1702e-01,  7.1021e-01,\n",
       "                       -1.5695e-01,  1.0040e-01,  3.2217e-01, -8.5834e-01, -5.2042e-02,\n",
       "                        1.4155e-01, -2.6004e-01,  5.1560e-01,  2.6118e-02, -2.5246e+00,\n",
       "                        2.5692e-02,  1.2242e-01, -8.0526e-02,  1.5103e+00,  6.6825e-01,\n",
       "                       -2.2605e-02, -1.2382e-01,  3.3804e-01, -2.8252e-01,  1.1481e+00,\n",
       "                        6.9842e-01, -5.6502e-02,  7.6579e-02, -3.0323e+00, -1.1574e+00,\n",
       "                       -1.8801e-01,  4.3011e-01,  6.1014e-01,  4.2796e-01, -8.8325e-01,\n",
       "                       -8.9881e-02,  1.7947e+00,  1.1329e+00,  6.8842e-01, -1.6585e-01,\n",
       "                        5.9048e-01, -1.3127e+00,  2.9708e-01, -2.8185e-01,  1.4783e-01,\n",
       "                       -6.5718e-01, -1.6449e-01, -6.5662e-02,  5.1452e-01, -5.1768e-01,\n",
       "                       -1.8984e-01, -8.8312e-01,  5.9653e-01, -5.3214e-01,  1.1759e-01,\n",
       "                       -5.1262e-01,  6.5306e-03,  8.9281e-01,  1.4979e+00, -1.9638e-01,\n",
       "                       -2.5643e-01,  1.0957e+00,  2.7874e-01,  3.2442e-01, -1.6529e-01,\n",
       "                       -1.6891e-02,  1.4823e+00, -3.9621e-01, -3.2408e-02,  3.9397e-01,\n",
       "                       -2.4317e-01, -3.6628e-02,  2.1651e-01, -6.3848e-02,  1.4070e+00,\n",
       "                        2.4907e-01,  4.2776e-01, -2.7506e-01, -2.1483e-02,  2.3036e-01,\n",
       "                        8.0908e-03,  2.7001e-01,  7.3900e-02, -1.2147e+00, -1.0647e+00,\n",
       "                        6.4578e-01, -8.8255e-02,  2.5730e-02, -1.0125e+00, -6.6847e-01,\n",
       "                        5.6958e-01,  3.2737e-01, -3.9062e-01,  2.2613e-01,  1.8980e-01,\n",
       "                       -7.6783e-02,  7.2748e-01, -7.9067e-01, -4.9375e-01,  2.0554e+00,\n",
       "                        1.3202e+00,  3.9793e-01,  4.4682e-01, -1.6122e-01, -2.9584e-01,\n",
       "                        3.8042e-01, -1.5435e+00, -3.5087e-01,  2.3283e-01, -2.9071e-01,\n",
       "                        2.7956e-01,  2.3475e-01,  1.9140e-01,  1.3580e-01,  2.7327e-02,\n",
       "                        1.1081e-01,  1.6594e-01,  4.3294e-01,  1.9648e-01, -5.2789e-01,\n",
       "                        1.5043e-01,  8.6146e-02, -1.9945e-01, -4.1030e-01,  7.3292e-01,\n",
       "                        1.8577e-01, -3.9622e-01, -2.2586e-01,  7.5460e-01, -2.6644e-01,\n",
       "                        5.7006e-01,  5.3266e-01,  1.8059e-01, -1.5729e+00, -2.7386e-01,\n",
       "                        1.6308e+00,  4.4836e-02,  1.2409e+00,  3.3160e-01,  4.4087e-01,\n",
       "                        3.1558e-01, -2.4024e-02, -2.8401e-01,  1.8291e-01, -9.7965e-01,\n",
       "                       -4.0968e-01, -3.4322e-01, -1.0394e+00, -1.0647e-01, -2.7585e-02,\n",
       "                        5.4202e-01,  3.9868e-01, -2.2026e-01,  2.0406e-01,  5.9089e-01,\n",
       "                       -7.9010e-01, -1.0750e+00, -1.7676e-01, -1.5238e-02, -4.2603e-01,\n",
       "                        3.0441e-01,  6.7503e-01,  7.0302e-01, -1.4221e-01, -3.3557e-01,\n",
       "                       -2.2767e+00,  1.5617e+00, -7.1530e-02,  2.0548e-01,  1.6233e-01,\n",
       "                        1.1150e+00,  4.2633e-01,  7.6298e-02, -6.8362e-01, -4.0859e-01,\n",
       "                       -3.8593e-02,  1.2182e-01, -3.9051e-01,  2.5168e-01, -8.5634e-01,\n",
       "                       -1.3586e-01,  2.2884e-01,  4.0071e-03, -8.2556e-02, -3.0511e-01,\n",
       "                        1.7151e-01,  5.3805e-02, -3.6289e-01,  3.1557e-01,  1.4266e-01,\n",
       "                        4.4080e-01, -1.3566e+00,  5.4765e-01,  2.3003e-01, -1.7049e+00,\n",
       "                       -6.1743e-01, -1.4884e-01, -4.7866e-01,  7.8897e-01,  5.2511e-01,\n",
       "                        2.4760e-01, -2.7946e+00,  1.9080e-01, -4.2253e-01, -2.1424e-02,\n",
       "                       -2.6971e-02, -2.5089e-01,  8.5989e-03,  1.6489e-01, -4.0590e-01,\n",
       "                        9.4156e-01, -8.6597e-02, -2.0895e+00,  5.0151e-01,  1.7388e+00,\n",
       "                       -7.9711e-02, -2.1064e-01, -2.4428e-01, -9.0910e-01,  7.9914e-01,\n",
       "                       -5.6778e-01, -8.8710e-02,  2.2034e-01,  5.0027e-01, -2.3000e-01,\n",
       "                        6.2162e-02, -3.6402e-01,  7.6766e-02,  7.8833e-01,  9.2906e-01,\n",
       "                        1.1940e-01,  5.9794e-01, -6.2823e-01,  2.9073e-01,  4.0978e-01,\n",
       "                        3.4036e-01, -1.3960e+00,  4.4549e-01,  4.9904e-01,  1.6251e-01,\n",
       "                        3.1329e-01, -2.2192e+00, -1.3720e-01,  6.7641e-01,  6.8439e-02,\n",
       "                       -3.9092e-01, -8.4912e-01,  1.0163e-01,  2.2517e-01,  2.3772e-01,\n",
       "                        1.0244e-01,  6.9556e-01, -4.3664e-02, -4.6642e-01, -1.4499e+00,\n",
       "                       -2.8768e-01,  1.5136e-01,  7.9443e-02, -1.1511e+00,  1.5488e+00,\n",
       "                        7.7104e-01,  5.0940e-01,  1.3300e+00,  6.8715e-01,  3.5815e-01,\n",
       "                        1.0070e+00,  1.5929e+00, -3.4754e-01, -2.1671e-01,  5.9907e-01,\n",
       "                        2.0920e-01,  1.9054e+00,  1.3976e-01,  5.6816e-01,  1.9224e+00,\n",
       "                       -5.2902e-01,  1.8200e-01, -4.0280e-01, -3.3683e-01,  6.9148e-01,\n",
       "                       -9.7326e-01, -4.3399e-01, -4.9867e-01,  3.3268e-01,  1.3803e+00,\n",
       "                        6.6392e-02,  1.6347e+00, -2.1434e-01, -5.7458e-01,  1.5437e+00,\n",
       "                       -2.7289e-01,  1.6493e-01,  2.5279e-03,  6.3751e-01,  6.2154e-01,\n",
       "                       -1.6839e-01,  1.4136e+00, -1.0316e-01, -7.7531e-01, -3.2485e-01,\n",
       "                        1.6573e-01, -1.2888e+00, -1.4382e-01,  7.6234e-02,  5.2578e-01,\n",
       "                        3.0421e-01,  9.9666e-01,  3.0267e-01,  3.4918e-01,  1.1211e+00,\n",
       "                       -3.1662e+00, -1.5814e-01, -7.1677e-01, -1.3891e+00, -4.4473e-01,\n",
       "                       -1.1762e-01, -2.0214e+00,  3.3152e-01,  1.0108e-01, -2.1978e-01,\n",
       "                        1.2607e-01, -2.8173e-01,  3.0459e-01,  9.0234e-01,  9.2093e-01,\n",
       "                        4.0415e-01, -8.0689e-02], device='cuda:0')),\n",
       "              ('module.layer2.0.downsample.1.running_mean',\n",
       "               tensor([ 3.0207e-01, -2.7950e-01, -1.3076e+00, -1.6318e-01, -1.2850e+00,\n",
       "                        4.4403e-01, -8.2032e-01, -3.1844e-01,  5.7909e-01, -4.8805e-01,\n",
       "                       -1.6993e+00, -1.6114e+00,  1.3475e-01,  1.4221e+00,  3.0608e-01,\n",
       "                        6.7931e-01, -4.4374e-01,  5.2989e-01, -6.8533e-01, -7.7610e-01,\n",
       "                        1.4626e+00, -1.6655e+00,  6.1407e-01, -7.2423e-01, -3.5576e-01,\n",
       "                        9.5182e-01,  7.7735e-02, -1.5506e+00,  8.8403e-01, -1.4913e-01,\n",
       "                       -1.8118e-02, -4.0283e-02,  5.8562e-03, -5.8699e-01, -1.1435e+00,\n",
       "                        2.2759e+00, -1.3403e+00, -3.0188e+00, -1.0524e+00, -1.2411e+00,\n",
       "                        2.3796e-01, -5.6236e+00,  2.7499e-01, -6.7292e-01, -1.0077e+00,\n",
       "                        1.5706e-02, -5.1164e-01, -1.3759e+00, -8.1150e-01,  6.0252e-01,\n",
       "                        5.7808e-01, -8.6299e-01, -2.1309e-01, -2.0846e+00,  9.1131e-01,\n",
       "                       -1.7853e+00, -5.2030e-01, -1.0386e+00, -4.8478e-01, -5.4297e-01,\n",
       "                       -1.0979e+00, -1.5454e+00, -1.3134e+00, -1.7375e+00, -1.3338e+00,\n",
       "                       -2.0208e+00, -2.1284e-01, -1.7242e+00, -3.5170e-01, -6.9070e-01,\n",
       "                       -1.9148e+00,  2.6597e-03,  3.8907e-01, -6.5946e-01, -8.1597e-01,\n",
       "                        8.8087e-02,  9.2904e-01, -8.9892e-01, -1.6357e+00, -4.7733e-01,\n",
       "                       -2.0878e-01,  1.0104e+00,  1.6802e-01, -5.4313e-02, -2.9122e-01,\n",
       "                        1.9979e-01, -1.2637e+00, -4.0015e-01, -1.0291e+00,  7.7585e-01,\n",
       "                       -4.4689e-01,  1.0593e-02, -2.0262e+00, -2.5754e+00, -1.3632e-01,\n",
       "                       -1.5857e-02, -1.7928e+00, -4.8271e-01,  3.5797e-01,  1.8963e-01,\n",
       "                       -1.1401e+00, -5.6555e-02,  7.8437e-02,  5.1307e+00, -2.2064e-01,\n",
       "                        2.1815e+00, -1.2778e+00,  3.3300e-01,  3.5518e+00, -3.3535e-02,\n",
       "                        4.8270e-01, -7.1489e-01, -1.3359e+00, -1.2741e+00, -5.4497e-01,\n",
       "                       -9.2055e-01, -6.8736e-01, -1.4244e+00, -1.5672e+00, -7.6637e-01,\n",
       "                        1.0283e+00, -4.3562e-01, -7.6123e-01, -2.8347e-01, -5.4313e-01,\n",
       "                       -2.5580e+00, -2.3941e-01, -8.1749e-01, -1.0860e+00, -2.0156e-03,\n",
       "                       -9.9715e-01, -3.6532e-01, -2.9676e+00, -3.0216e+00, -6.8725e-01,\n",
       "                       -4.4366e-01,  3.6830e-01,  1.9786e+00, -5.5127e-01, -5.7357e-01,\n",
       "                       -1.8263e-01, -7.7704e-01,  1.4638e+00,  4.1702e-01,  6.1835e-03,\n",
       "                       -3.5479e-01, -8.0513e-01, -4.4592e-01, -6.9868e-01, -9.4799e-01,\n",
       "                        5.4110e-01, -2.2448e+00,  3.8649e-01, -7.8684e-01,  1.1504e+00,\n",
       "                        1.0618e+00, -1.0464e+00, -1.7155e-01, -1.9714e-01,  4.5846e-01,\n",
       "                       -1.3525e+00,  2.3452e+00, -9.9289e-01,  4.0591e+00, -4.5037e-01,\n",
       "                       -1.4424e+00,  9.0155e-01, -1.1733e+00, -1.7831e+00, -4.0120e+00,\n",
       "                        1.0819e+00, -1.1675e+00,  3.1018e-01, -3.6954e-02,  4.4287e-01,\n",
       "                       -4.0560e-01, -6.6580e-01,  9.9271e-01, -8.9242e-01,  3.1466e-01,\n",
       "                       -8.6752e-01,  2.5947e-01, -1.1318e+00,  1.3639e-02, -9.0268e-02,\n",
       "                        8.9529e-01, -9.1104e-01, -4.1627e+00,  1.8735e-01,  4.8522e-01,\n",
       "                       -1.0333e-01, -2.2011e+00, -7.4427e-02, -3.0376e+00,  2.1684e-01,\n",
       "                       -1.1733e+00, -7.8166e-02, -1.3501e+00, -5.1654e-01, -2.1300e+00,\n",
       "                        4.0791e-01, -2.1758e-01,  2.8792e-02, -2.7313e+00,  2.4786e+00,\n",
       "                        7.8134e-01, -5.4954e-01, -1.3435e+00, -3.5394e-01, -7.1094e-01,\n",
       "                        1.4529e+00, -1.1208e+00,  1.4744e+00, -1.9796e-01, -1.0142e+00,\n",
       "                        6.5790e-01, -9.6638e-01, -6.5950e-02,  7.2843e-01, -2.3238e-01,\n",
       "                        6.3858e-02,  3.4404e-01, -3.4033e+00, -4.1762e+00,  2.6385e-01,\n",
       "                        1.9239e+00, -1.5333e+00, -3.3572e-01, -4.2456e-01,  1.8912e-01,\n",
       "                       -5.8731e-01, -1.5802e+00, -4.4518e-01,  2.8036e+00, -7.2999e-01,\n",
       "                       -1.1185e-01,  2.3575e+00, -1.4817e+00, -5.7861e-01,  1.3032e-01,\n",
       "                        8.0144e-01,  1.3325e+00,  6.6883e-01,  2.3430e-01, -1.1603e+00,\n",
       "                       -1.0681e+00,  6.6410e-01, -8.0368e-01, -5.7423e-01, -5.6857e-01,\n",
       "                       -2.1648e-01,  3.1793e+00, -1.0504e+00, -3.9398e-01, -2.8829e+00,\n",
       "                       -9.0374e-01, -7.8687e-01, -3.8475e-01, -3.5135e+00,  4.9796e-01,\n",
       "                        5.5317e-01,  2.2417e+00, -4.8757e-01,  2.0579e-01, -1.2434e+00,\n",
       "                        1.1957e+00, -5.4141e-01, -1.0094e+00,  1.0770e+00,  3.3353e-01,\n",
       "                        1.7648e-01, -1.7903e+00, -7.3189e-01,  5.8636e-02, -1.4321e+00,\n",
       "                       -3.6571e+00, -8.0391e-01, -2.0005e+00, -2.3369e+00, -1.7818e+00,\n",
       "                       -4.5904e-01, -5.7899e-02, -5.6414e-01, -8.1230e-01,  7.3909e-02,\n",
       "                       -2.8930e+00,  1.6788e-01, -1.4352e+00, -2.0117e-02, -3.4987e-01,\n",
       "                        8.8811e-01, -5.3108e-01,  4.2066e-01, -5.9691e-01, -2.6516e-01,\n",
       "                        6.4671e-01, -7.8281e-02,  7.4516e-01,  1.0315e-01,  2.6435e-01,\n",
       "                       -9.6301e-01,  4.4104e-01, -1.7875e+00, -1.0717e+00, -4.8005e-01,\n",
       "                       -7.6583e-01, -3.8997e-01, -2.7092e-01, -1.1567e+00,  1.1126e+00,\n",
       "                        1.1524e+00, -2.9097e-01, -8.0471e-01, -1.0962e+00, -5.0455e-01,\n",
       "                       -5.5839e-01, -6.5295e-01, -2.6032e-01, -2.7835e+00,  8.5258e-01,\n",
       "                       -1.8731e+00, -5.6612e-01,  2.0184e+00,  2.9921e+00, -7.5741e-01,\n",
       "                       -1.7690e+00, -5.4263e-01,  1.1523e+00, -2.0886e+00, -2.3016e+00,\n",
       "                       -1.0996e+00, -7.9100e-01, -1.8163e-01, -1.7324e-01, -6.8899e-01,\n",
       "                       -9.2175e-01,  5.4487e-01, -7.6372e-01, -1.2599e+00,  2.6538e-01,\n",
       "                        1.4281e+00, -3.9050e+00, -1.5846e+00,  1.1357e+00, -1.4769e+00,\n",
       "                       -2.1541e+00,  2.9314e-01,  2.1258e-01, -1.4130e+00, -5.4902e-01,\n",
       "                       -6.0781e-01, -2.3217e+00, -2.1025e+00,  1.5991e+00, -1.1039e+00,\n",
       "                       -1.1799e+00, -4.4211e-02, -2.2404e+00, -6.6109e-01, -2.1091e-01,\n",
       "                       -5.9339e-01, -2.8056e-02, -7.4944e-02, -1.8389e+00, -1.0799e+00,\n",
       "                       -7.4430e-01, -1.4742e-01,  3.9202e-01,  7.1736e-02, -7.0214e-01,\n",
       "                       -1.7888e+00,  9.8856e-01, -2.5779e-01, -8.7454e-01,  4.4236e+00,\n",
       "                       -2.1468e-01, -8.1071e-01,  5.5573e-01, -2.0421e-01, -4.2882e-01,\n",
       "                       -2.1232e+00, -6.1819e-01, -1.2459e+00, -3.7444e+00, -3.1526e-01,\n",
       "                       -5.8876e-01,  1.9958e+00, -2.3744e-01,  7.1032e-01, -6.5058e-02,\n",
       "                        2.1462e-01,  2.9314e+00, -3.7732e-01, -8.3801e-02, -1.0738e-06,\n",
       "                       -1.4565e-01,  6.4004e-01, -1.6564e+00, -1.3676e-01, -5.8380e-01,\n",
       "                       -6.6451e-02, -1.7649e+00, -3.1160e+00, -3.9348e-01, -5.0050e-01,\n",
       "                       -4.8540e-01, -4.9301e-01, -1.9786e+00,  9.9967e-01, -3.0597e-01,\n",
       "                        6.9024e-01, -5.1191e-01,  7.0856e-01,  3.8809e-01, -3.1515e+00,\n",
       "                       -3.2543e-01, -2.5915e-01, -2.1927e+00, -5.5456e-03, -4.5049e-01,\n",
       "                        5.0309e-01, -1.4760e+00,  4.7572e-01, -5.5828e-03, -1.1067e-01,\n",
       "                        3.7454e-01,  3.1409e-01,  6.1307e-01, -1.4362e+00, -2.0085e-01,\n",
       "                       -9.2582e-02, -2.4882e+00, -1.2070e+00, -1.3222e+00,  2.5094e-01,\n",
       "                        4.0761e-01, -7.1717e-01,  4.1748e-01, -5.3687e-01, -6.1949e-01,\n",
       "                       -1.9347e-02, -1.5189e+00, -2.1929e+00, -7.3339e-01, -1.2412e+00,\n",
       "                       -1.9198e+00,  3.9409e-01, -7.0675e-01,  1.4046e-01, -4.9511e-01,\n",
       "                        5.0016e-01, -5.0766e+00, -1.4618e-01, -9.6566e-01, -1.6799e+00,\n",
       "                        1.5293e+00, -2.1933e+00,  7.0929e-02, -1.7054e+00,  3.2840e+00,\n",
       "                       -1.7758e+00, -7.8788e-01, -9.3429e-01,  2.3746e+00,  1.8872e+00,\n",
       "                       -2.4613e+00, -3.1448e+00, -4.3347e-01,  4.1604e-01, -3.9090e+00,\n",
       "                       -1.5431e+00,  3.1117e+00,  1.4915e+00,  8.8194e-01,  3.8079e+00,\n",
       "                       -1.3886e+00,  2.2177e-01,  5.0946e-02,  2.4878e-02,  2.0104e-01,\n",
       "                        2.3843e-01,  7.3339e-02, -1.7188e-01,  8.8009e-02,  6.1278e-01,\n",
       "                       -5.7155e-01,  1.4084e+00,  1.7196e-01, -4.7244e-01, -3.8147e-01,\n",
       "                        1.5781e+00, -3.4083e-01,  2.1255e-01, -6.8315e-01, -7.3725e-02,\n",
       "                       -2.2450e+00, -9.4922e-01,  4.6017e-01, -2.9847e-01, -1.1528e+00,\n",
       "                       -4.7751e-01, -2.9779e+00, -2.5150e-01,  9.1555e-02,  5.2272e-01,\n",
       "                       -1.1396e+00,  7.6085e-02, -2.4049e+00,  2.4588e+00, -3.5900e+00,\n",
       "                       -9.5520e-03, -9.7630e-01], device='cuda:0')),\n",
       "              ('module.layer2.0.downsample.1.running_var',\n",
       "               tensor([2.5806e+00, 9.2713e-01, 9.5489e-01, 4.5858e+00, 2.7390e+00, 5.0148e-01,\n",
       "                       2.1054e+00, 1.0645e+00, 6.5562e+00, 4.8992e-01, 1.4181e+00, 6.0732e-01,\n",
       "                       1.1871e+00, 1.4791e+00, 3.8860e-01, 5.4224e-01, 6.8124e-01, 1.4590e+00,\n",
       "                       8.8614e-01, 1.1872e+00, 2.1706e+00, 6.3155e-01, 2.2219e+00, 3.7339e+00,\n",
       "                       1.1048e+00, 7.3373e-01, 5.4166e-01, 6.5217e-01, 2.1573e-01, 4.2535e+00,\n",
       "                       5.6186e-01, 4.3682e-01, 4.9175e-01, 6.6990e-01, 7.6836e-01, 2.6120e+00,\n",
       "                       1.8691e-01, 3.3628e+00, 1.8924e+00, 2.5093e+00, 1.2854e+00, 1.3457e+01,\n",
       "                       6.6812e-01, 6.6515e-01, 7.0289e-01, 4.1958e-01, 1.0185e+00, 4.9101e-01,\n",
       "                       4.3264e-01, 1.7459e+00, 6.0029e-01, 1.0592e+00, 5.2597e-01, 1.1786e+00,\n",
       "                       6.6558e-01, 1.4263e+00, 1.1087e+00, 2.1759e+00, 3.5159e+00, 1.0242e+00,\n",
       "                       1.8086e+00, 2.9506e+00, 1.7248e+00, 3.3842e-01, 2.9989e+00, 4.4477e+00,\n",
       "                       4.3827e-01, 1.7924e+00, 4.8609e-01, 2.3496e+00, 8.6062e-01, 6.7523e-01,\n",
       "                       3.3466e-01, 6.4348e-01, 1.6903e+00, 5.7480e-01, 2.5640e+00, 9.6260e-01,\n",
       "                       7.5793e-01, 1.2787e+00, 1.3178e+00, 4.6116e-01, 1.6923e+00, 7.3978e+00,\n",
       "                       1.0336e+00, 2.6003e-01, 2.1856e+00, 1.1220e+00, 8.2271e-01, 2.6524e+00,\n",
       "                       6.0584e-01, 6.2940e-01, 1.5022e+00, 1.4851e+00, 1.7512e+00, 4.3909e-01,\n",
       "                       6.9453e-01, 7.3656e-01, 2.3480e+00, 3.0894e-01, 9.7516e-01, 2.8038e-01,\n",
       "                       6.5560e-01, 2.4530e+00, 1.2349e+00, 1.4976e+00, 9.1276e-01, 3.3655e-01,\n",
       "                       3.0307e+00, 1.4983e+00, 4.4781e-01, 2.5147e+00, 3.0728e-01, 1.2410e+00,\n",
       "                       2.2774e+00, 7.6172e-01, 2.3373e+00, 3.4172e+00, 4.4983e-01, 1.1834e+00,\n",
       "                       6.4726e-01, 2.4840e-01, 1.3110e+00, 1.1334e+00, 1.5024e+00, 2.1658e+00,\n",
       "                       3.1246e+00, 1.7720e+00, 9.0592e-01, 2.1746e+00, 1.5555e+00, 5.3453e-01,\n",
       "                       5.8402e-01, 3.3401e+00, 5.7914e+00, 1.0035e+00, 2.8178e+00, 5.0730e-01,\n",
       "                       3.1416e-01, 4.4748e-01, 7.8400e-01, 3.9290e-01, 2.6763e+00, 2.5519e-01,\n",
       "                       8.2095e-01, 9.9478e-02, 1.0890e+00, 4.7694e-01, 1.4174e+00, 2.0988e+00,\n",
       "                       2.0831e+00, 8.2519e+00, 2.6934e-01, 9.5513e-01, 3.8469e+00, 9.8586e-01,\n",
       "                       4.4305e-01, 8.6661e-01, 6.1927e-01, 3.6933e+00, 1.8202e+00, 1.6855e+00,\n",
       "                       4.6260e-01, 3.3685e+00, 2.1647e-01, 9.8537e-01, 1.1724e+00, 2.1597e+00,\n",
       "                       3.0592e+00, 2.3578e+00, 1.7993e+00, 4.2997e-01, 2.2911e+00, 5.4781e-01,\n",
       "                       4.7265e-01, 8.8441e-01, 1.0264e+00, 1.1351e+00, 1.8156e+00, 4.4786e-01,\n",
       "                       1.5497e-01, 6.5012e-01, 1.5475e+00, 3.6210e-01, 6.1433e-01, 3.1078e-01,\n",
       "                       4.0622e-01, 2.0459e+00, 2.0174e+00, 1.8230e+00, 6.6995e-01, 2.7147e+00,\n",
       "                       5.6749e-01, 1.2607e+00, 4.3588e-01, 9.4955e-01, 3.9818e-01, 6.1878e-01,\n",
       "                       5.1456e-01, 5.1867e-01, 3.0301e-01, 2.7509e+00, 2.1987e+00, 5.8063e+00,\n",
       "                       5.3953e+00, 1.4919e+00, 3.0244e+00, 4.8769e-01, 4.5780e-02, 5.8720e-01,\n",
       "                       5.6686e-01, 2.9420e-01, 1.7440e+00, 7.4211e-01, 6.5486e-01, 3.7725e-01,\n",
       "                       9.6481e-01, 1.4417e+00, 2.1863e+00, 9.6015e-01, 6.6911e-01, 4.7838e+00,\n",
       "                       3.5557e+00, 5.5695e+00, 6.4098e-01, 1.3960e+00, 9.6351e-01, 1.1256e+00,\n",
       "                       3.3417e-01, 5.3902e-01, 2.0028e-01, 3.8965e+00, 4.4291e-01, 3.0936e+00,\n",
       "                       1.1290e+00, 4.0152e-01, 2.5345e+00, 2.8049e+00, 2.1502e+00, 2.7709e+00,\n",
       "                       1.6217e+00, 6.6249e-01, 5.7983e+00, 6.7041e+00, 4.8008e-01, 1.4124e+00,\n",
       "                       9.0600e+00, 7.6444e-01, 1.2518e+00, 4.6131e-01, 5.1874e-01, 4.2919e+00,\n",
       "                       8.1990e-01, 2.4352e+00, 3.6653e+00, 4.1132e+00, 1.3058e+00, 4.6699e-01,\n",
       "                       5.5988e+00, 1.7099e+00, 2.3967e+00, 5.8272e-01, 6.9594e-01, 1.4608e+00,\n",
       "                       8.9649e-01, 6.4156e-01, 4.1432e-01, 1.1832e+00, 8.1703e-01, 8.4814e-01,\n",
       "                       9.5507e-01, 1.0661e+00, 4.9407e-01, 2.2154e-01, 8.9426e-01, 1.6416e+00,\n",
       "                       1.0829e+00, 4.5320e-01, 2.4112e+00, 3.4760e+00, 6.8305e-01, 2.0680e-01,\n",
       "                       5.9271e-01, 8.9458e-01, 3.1036e+00, 6.1134e+00, 5.7350e-01, 1.2356e+00,\n",
       "                       4.5360e-01, 2.4509e+00, 5.8550e-01, 4.2032e+00, 4.3287e-01, 2.5132e+00,\n",
       "                       2.0256e-01, 8.9603e-01, 4.9327e-01, 5.9626e-01, 3.8603e-01, 4.7172e-01,\n",
       "                       1.2620e+00, 1.9694e+00, 1.6870e+00, 1.1284e+00, 6.0488e-01, 1.5591e+00,\n",
       "                       3.2610e-01, 3.9113e-01, 2.0948e+00, 1.5874e+00, 1.7224e+00, 6.1657e-02,\n",
       "                       5.1115e-01, 1.7071e+00, 8.0671e-01, 1.3451e+00, 1.1789e+00, 7.8665e-01,\n",
       "                       1.6171e+00, 1.3548e+00, 1.8571e+00, 8.1681e-01, 4.6760e+00, 3.7019e+00,\n",
       "                       5.8030e-01, 1.7695e+00, 3.9039e-01, 1.1048e+00, 1.9919e+00, 3.8955e-01,\n",
       "                       2.7292e-01, 6.3714e-01, 5.3830e-01, 7.2566e-01, 5.4374e-01, 1.9818e+00,\n",
       "                       9.5445e-01, 1.3292e+00, 4.6447e-01, 1.0166e+00, 6.2073e-01, 1.0148e+00,\n",
       "                       3.7912e+00, 4.3288e-01, 4.5626e-01, 8.8728e-01, 5.8178e-01, 1.1064e+00,\n",
       "                       5.1483e-01, 1.8528e-01, 2.4979e-01, 2.5004e+00, 6.5666e-01, 4.8471e-01,\n",
       "                       1.6851e+00, 1.0177e+00, 4.3455e-01, 1.2520e+00, 8.8872e-01, 1.2434e-01,\n",
       "                       1.1607e+00, 3.7763e-01, 1.3683e+00, 1.0236e+00, 1.9896e+00, 7.8817e-01,\n",
       "                       2.3325e+00, 3.1461e+00, 7.6317e-01, 5.0057e-01, 7.5755e-01, 2.7561e-01,\n",
       "                       2.1311e-01, 1.3920e+00, 5.9782e+00, 5.6167e-01, 1.2879e+00, 5.5259e-01,\n",
       "                       1.0550e+00, 2.1590e-01, 5.7610e-01, 1.8202e+00, 8.3095e-01, 5.6310e-01,\n",
       "                       1.6888e+00, 7.5375e-01, 4.0015e+00, 4.0169e+00, 6.9738e-01, 3.0012e-01,\n",
       "                       2.0552e+00, 7.7201e-01, 1.9692e+00, 2.8876e+00, 8.2106e-13, 5.8704e-01,\n",
       "                       3.6400e-01, 8.3754e-01, 8.4797e-01, 1.6717e+00, 5.3542e-01, 1.4670e+00,\n",
       "                       4.2890e+00, 1.6058e+00, 3.1321e-01, 7.4103e-01, 4.0997e-01, 2.2178e+00,\n",
       "                       1.5814e+00, 1.0017e+00, 7.6946e-01, 4.2087e-01, 2.0193e-01, 1.2275e+00,\n",
       "                       1.9852e+00, 6.5614e-01, 1.4012e+00, 1.8958e+00, 2.2267e+00, 1.1971e+00,\n",
       "                       1.6871e+00, 1.3902e+00, 8.2486e-01, 7.6914e-01, 1.8552e-01, 1.4297e+00,\n",
       "                       5.1902e-01, 4.3299e-01, 9.6416e-01, 7.7818e-01, 3.0031e-01, 1.1297e+00,\n",
       "                       9.2311e-01, 8.6240e-01, 5.1775e-01, 2.8483e+00, 8.6036e-01, 3.7089e-01,\n",
       "                       5.4272e-01, 7.9582e-01, 2.3525e-01, 9.3809e-01, 5.5918e-01, 1.5793e+00,\n",
       "                       1.1752e+00, 1.9117e+00, 6.6613e-01, 7.7322e+00, 1.3257e+00, 2.8459e+00,\n",
       "                       1.9796e+00, 3.5336e+00, 4.2478e-01, 1.9327e-01, 3.7840e-01, 7.1021e-01,\n",
       "                       4.0745e+00, 1.0031e+00, 2.3310e+00, 5.5995e+00, 1.6610e+00, 1.0030e+00,\n",
       "                       1.4497e+00, 3.7395e-01, 2.0211e+00, 1.0807e+00, 2.1879e+00, 3.9846e-01,\n",
       "                       1.4907e+00, 2.6064e+00, 2.4675e+00, 8.8413e+00, 4.6784e-01, 2.6056e-01,\n",
       "                       4.4814e+00, 1.1889e+00, 3.6573e-01, 6.9956e-01, 5.0467e+00, 1.3172e+00,\n",
       "                       2.8517e-01, 4.9018e-01, 3.4346e-01, 1.0818e-01, 3.4797e+00, 3.6165e-01,\n",
       "                       1.8964e+00, 6.4048e-01, 1.0724e+00, 1.7413e+00, 3.6252e+00, 6.4881e-01,\n",
       "                       7.5107e-01, 5.1953e-01, 3.4617e-01, 1.6842e+00, 6.5356e-01, 1.4632e+00,\n",
       "                       4.9047e-01, 9.4677e-01, 5.0993e-01, 7.5088e-01, 1.5566e+00, 2.1232e+00,\n",
       "                       4.7334e-01, 3.7925e-01, 1.6541e+00, 1.6634e+00, 8.8590e-01, 4.8735e+00,\n",
       "                       1.6301e+00, 3.1743e-01], device='cuda:0')),\n",
       "              ('module.layer2.0.downsample.1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.1.conv1.weight',\n",
       "               tensor([[[[ 0.0043]],\n",
       "               \n",
       "                        [[ 0.0026]],\n",
       "               \n",
       "                        [[-0.0192]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0106]],\n",
       "               \n",
       "                        [[-0.0006]],\n",
       "               \n",
       "                        [[ 0.0152]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0956]],\n",
       "               \n",
       "                        [[ 0.0121]],\n",
       "               \n",
       "                        [[ 0.0539]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0269]],\n",
       "               \n",
       "                        [[-0.0440]],\n",
       "               \n",
       "                        [[-0.0252]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0020]],\n",
       "               \n",
       "                        [[-0.0093]],\n",
       "               \n",
       "                        [[-0.0569]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0272]],\n",
       "               \n",
       "                        [[-0.0355]],\n",
       "               \n",
       "                        [[-0.0265]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0595]],\n",
       "               \n",
       "                        [[ 0.0116]],\n",
       "               \n",
       "                        [[ 0.0338]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0014]],\n",
       "               \n",
       "                        [[ 0.0219]],\n",
       "               \n",
       "                        [[-0.0068]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0384]],\n",
       "               \n",
       "                        [[ 0.0214]],\n",
       "               \n",
       "                        [[-0.0364]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0050]],\n",
       "               \n",
       "                        [[-0.0598]],\n",
       "               \n",
       "                        [[ 0.0658]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0105]],\n",
       "               \n",
       "                        [[-0.0046]],\n",
       "               \n",
       "                        [[ 0.0119]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0054]],\n",
       "               \n",
       "                        [[ 0.0266]],\n",
       "               \n",
       "                        [[-0.0129]]]], device='cuda:0')),\n",
       "              ('module.layer2.1.bn1.weight',\n",
       "               tensor([1.3542, 1.8655, 1.4173, 1.0346, 1.8323, 1.2777, 1.6341, 1.0023, 1.1979,\n",
       "                       0.9039, 0.9825, 1.0061, 1.8484, 0.9256, 1.8745, 3.2990, 1.9157, 1.0460,\n",
       "                       1.8077, 1.5195, 0.7281, 1.0171, 1.4809, 1.6139, 1.4515, 1.6782, 1.0814,\n",
       "                       1.0522, 2.5529, 1.4388, 1.5055, 0.8984, 2.2240, 1.4185, 3.7134, 0.9758,\n",
       "                       1.6853, 1.3777, 1.0367, 1.1206, 1.6978, 2.5502, 1.1535, 1.0664, 1.2887,\n",
       "                       1.6264, 0.9403, 1.8706, 1.2228, 1.1265, 1.2627, 1.6463, 1.0704, 2.0905,\n",
       "                       1.1225, 1.6658, 0.8791, 2.2046, 0.9321, 0.8443, 1.6122, 1.4529, 1.4169,\n",
       "                       1.0110, 1.6690, 1.1264, 1.0301, 1.3858, 1.0622, 2.0490, 1.0912, 1.5423,\n",
       "                       1.0140, 2.3029, 2.2143, 1.7677, 1.0952, 0.9893, 1.1330, 1.3115, 0.9028,\n",
       "                       1.4142, 1.0019, 1.4361, 0.9297, 1.3982, 1.6426, 2.6555, 1.6847, 0.8312,\n",
       "                       1.4593, 1.0962, 1.5742, 1.9811, 1.3750, 3.0139, 1.0079, 1.4377, 0.9225,\n",
       "                       1.5009, 1.0950, 3.1992, 1.6249, 3.2277, 1.1821, 1.2977, 1.1166, 3.1526,\n",
       "                       1.1519, 2.2591, 2.4420, 1.2803, 1.0695, 4.0771, 1.2416, 2.3419, 1.1632,\n",
       "                       1.4569, 1.2216, 1.1899, 1.0996, 1.3152, 1.4657, 1.5306, 0.9757, 2.0642,\n",
       "                       0.9893, 1.7705], device='cuda:0')),\n",
       "              ('module.layer2.1.bn1.bias',\n",
       "               tensor([-4.8865e-01, -1.4466e+00, -3.2475e-01, -7.2770e-02, -1.1321e+00,\n",
       "                        5.6160e-01, -6.1003e-01,  7.0243e-01,  7.4014e-01,  1.1292e+00,\n",
       "                        9.1865e-01,  3.6596e-01, -1.0951e+00,  9.9121e-01, -8.8374e-01,\n",
       "                       -5.5842e+00, -1.7770e+00, -2.6394e-01, -2.1683e+00, -1.6605e-01,\n",
       "                        1.1354e+00,  1.3118e+00, -1.7158e+00, -1.4794e+00, -6.6234e-01,\n",
       "                       -1.2988e+00,  9.6397e-01,  7.7745e-01, -3.7628e+00, -5.2604e-01,\n",
       "                       -8.0322e-01,  1.3845e+00, -2.5298e+00, -6.3528e-01, -5.5732e+00,\n",
       "                        1.5069e+00, -1.3597e+00, -1.0974e-01,  2.6413e-01,  2.7613e+00,\n",
       "                       -1.4801e+00, -2.9364e+00,  6.3202e-01,  1.3534e+00,  8.8078e-02,\n",
       "                       -7.4239e-01,  2.1945e+00, -1.7255e+00, -7.5181e-04,  3.2472e-01,\n",
       "                        5.7545e-01, -1.4938e+00, -6.3430e-02, -2.5600e+00,  1.2814e-01,\n",
       "                       -1.4951e+00,  7.7595e-01, -1.9285e+00,  2.0040e-01,  1.2062e+00,\n",
       "                       -1.1820e+00, -8.3303e-01, -4.9020e-01,  2.5671e+00, -1.3611e+00,\n",
       "                        2.5037e+00,  1.2987e+00, -3.6486e-01,  6.0168e-01, -2.1996e+00,\n",
       "                        2.9994e-01, -8.0499e-01,  1.1028e-01, -1.2205e+00, -2.5884e+00,\n",
       "                       -1.5075e+00,  6.8453e-01,  8.5841e-01,  2.4948e+00, -5.1813e-01,\n",
       "                        1.0788e+00, -5.7048e-01,  1.7073e-01, -7.5095e-01,  1.6609e+00,\n",
       "                        9.6235e-02, -6.5874e-01, -4.2379e+00, -1.0263e+00,  1.1574e+00,\n",
       "                       -3.5561e-01,  2.4204e+00, -6.1548e-01, -1.8028e+00, -4.6680e-01,\n",
       "                       -1.3645e+00,  1.1730e-01, -6.0291e-01,  1.9411e+00, -1.0152e+00,\n",
       "                        1.1824e+00, -5.4683e+00, -1.1825e+00, -3.0679e+00,  5.8255e-01,\n",
       "                       -1.7817e-01,  6.5770e-01, -1.7589e+00,  4.7326e-01, -2.2145e+00,\n",
       "                       -2.4657e+00, -1.6285e-01,  1.5540e-01, -5.8927e+00,  2.2007e-01,\n",
       "                       -2.9333e+00, -1.4194e-01, -4.6497e-01, -4.7636e-01, -3.2244e-01,\n",
       "                        7.3739e-01, -4.1123e-01, -6.1992e-01, -1.8951e-01,  4.7294e-01,\n",
       "                       -1.2110e+00,  1.7556e+00, -2.0222e+00], device='cuda:0')),\n",
       "              ('module.layer2.1.bn1.running_mean',\n",
       "               tensor([-1.2095e+00, -8.1386e-01, -1.0733e+00, -2.5715e+00, -2.3546e+00,\n",
       "                        1.1267e+00, -1.3861e+00, -1.1226e+00, -2.6887e+00,  4.5480e+00,\n",
       "                        3.5751e+00,  2.9962e+00, -2.3904e+00, -7.3648e-01, -2.3915e+00,\n",
       "                       -3.8279e+00, -1.6774e+00, -1.1291e+00, -1.6140e+00, -2.6454e+00,\n",
       "                        9.7022e-01,  2.5784e+00, -7.3945e-01, -2.5270e+00, -1.8060e+00,\n",
       "                       -1.9857e+00,  1.5075e+00,  3.9430e-01, -1.6536e+00, -8.9415e-01,\n",
       "                       -1.0934e+00,  2.4980e-01, -1.5956e+00, -9.6752e-01, -1.9239e+00,\n",
       "                        6.2359e+00,  4.3080e+00,  4.2706e+00,  4.8149e-02,  2.1452e+00,\n",
       "                       -1.6054e-01, -3.6793e+00, -6.6288e-01, -3.6169e+00, -1.9063e+00,\n",
       "                       -2.7486e+00, -3.0300e-01,  5.2222e-01, -8.2196e-01, -3.0196e-01,\n",
       "                       -1.3482e+00, -1.5198e+00,  2.4918e+00,  3.3501e+00, -6.4895e-01,\n",
       "                        1.9801e+00, -2.4368e+00, -1.6392e+00, -2.0922e+00, -1.1461e+00,\n",
       "                       -2.0106e+00, -5.7456e-01, -1.3809e+00,  2.6942e-01, -1.8100e+00,\n",
       "                       -4.2297e+00, -1.1417e+00, -5.0132e-01,  3.3306e-01,  4.1274e-01,\n",
       "                        3.2655e+00, -1.9730e+00,  3.1967e+00, -6.2359e-01,  5.4105e+00,\n",
       "                       -1.8972e+00, -6.3589e+00, -1.5218e+00,  1.6617e+00, -3.3970e+00,\n",
       "                       -8.2952e-01,  1.2786e+00, -1.0055e+00,  6.6682e-01, -7.2306e-01,\n",
       "                       -2.3472e+00, -2.0750e+00, -1.5982e+00,  3.3655e-01, -1.0918e+00,\n",
       "                       -1.3041e+00, -1.0644e+00, -3.0630e-01,  4.2646e-01,  4.2813e-01,\n",
       "                       -1.7856e+00, -2.0719e+00,  9.2735e-01, -5.1024e+00, -7.7375e-01,\n",
       "                        4.9857e-01, -2.3945e+00,  7.6861e-01,  1.1201e-01,  1.8394e+00,\n",
       "                       -3.2608e+00, -3.0682e+00, -4.3545e+00,  4.3130e+00, -1.7799e+00,\n",
       "                        1.6884e+00,  2.0038e+00,  2.8871e-03, -2.0200e+00, -5.1549e+00,\n",
       "                        4.5288e-01, -1.8274e+00, -1.3758e+00, -9.7996e-01, -1.2540e+00,\n",
       "                        7.9267e-01, -1.2648e+00, -1.3137e+00, -1.4344e+00,  1.1060e+00,\n",
       "                       -3.3238e+00, -2.5486e+00, -1.1772e+00], device='cuda:0')),\n",
       "              ('module.layer2.1.bn1.running_var',\n",
       "               tensor([ 8.1070,  4.5004,  5.2836,  4.5965,  4.6482, 23.3922, 12.2685,  7.6337,\n",
       "                        7.8458,  3.0092,  6.7826,  5.3283,  3.8885,  6.1492,  5.4963,  3.6241,\n",
       "                        4.0151,  2.0366,  2.3536,  6.8962,  8.3201,  5.9626,  1.8421,  4.0257,\n",
       "                        7.5377,  4.0562,  7.3806, 16.5769,  2.1843,  2.9052,  4.6397, 10.2626,\n",
       "                        2.9447,  4.2821,  9.1423,  9.1048,  4.5291,  4.6049,  3.2469, 20.2712,\n",
       "                        4.8142,  5.0441,  6.4686, 10.6130, 16.1480, 19.1458, 16.3523,  3.7852,\n",
       "                        3.8713,  4.3368,  8.7375,  4.7087,  3.7305,  2.9003,  4.5475,  4.1009,\n",
       "                        5.5120,  3.2814,  3.1070,  7.1837,  4.5259,  3.8910,  4.1450, 29.8162,\n",
       "                        2.5955, 16.1943,  8.3223,  5.1426, 17.3847,  4.1062,  4.7125,  3.5284,\n",
       "                        4.7045,  4.7388,  3.1559,  3.8488,  4.0914, 14.5114, 24.4538,  6.3776,\n",
       "                       14.7669,  3.9350,  5.2349,  3.4663, 14.1728,  7.3995,  5.9413,  2.3567,\n",
       "                        6.7447,  9.8073,  4.6021, 12.6858,  5.0948,  3.0110,  6.1653,  3.8508,\n",
       "                        5.3445,  4.9235, 18.1089,  4.4923,  9.7726,  2.8914,  4.2150,  4.1511,\n",
       "                       23.6790,  5.4694,  6.9468,  5.9511,  6.0421,  6.2361,  3.3993,  3.6586,\n",
       "                        3.8650,  5.7842, 14.2717,  3.0499,  5.0376,  4.6509,  2.7806,  3.0358,\n",
       "                       21.7662,  4.6050,  3.1544, 20.5097,  4.6080,  2.7758, 10.7565,  2.4451],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.1.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.1.conv2.weight',\n",
       "               tensor([[[[-4.3512e-03, -9.7463e-02, -6.3383e-02],\n",
       "                         [ 2.0350e-02,  3.6471e-02, -7.4622e-03],\n",
       "                         [ 7.9196e-02,  9.7222e-02,  1.5066e-02]],\n",
       "               \n",
       "                        [[ 5.9471e-02, -4.9427e-03,  2.5000e-02],\n",
       "                         [ 6.5303e-04,  5.4233e-02, -3.0603e-03],\n",
       "                         [-1.3194e-02,  1.1202e-02, -4.3501e-02]],\n",
       "               \n",
       "                        [[-1.1062e-01, -5.1280e-02,  6.3711e-02],\n",
       "                         [ 5.6738e-03,  6.7974e-02, -1.7387e-02],\n",
       "                         [-4.0342e-03,  1.8230e-01, -1.2779e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.1314e-02,  6.3646e-02, -1.5298e-02],\n",
       "                         [ 2.8935e-03,  1.2828e-02, -4.3540e-03],\n",
       "                         [-5.0718e-02, -5.6682e-02,  4.7987e-02]],\n",
       "               \n",
       "                        [[-3.4310e-04,  8.5425e-02,  1.0532e-03],\n",
       "                         [-1.3945e-02, -1.2660e-02, -9.3818e-03],\n",
       "                         [-2.1898e-02, -8.8383e-02, -3.2872e-02]],\n",
       "               \n",
       "                        [[-3.4163e-02, -1.3781e-01, -1.8670e-02],\n",
       "                         [ 9.5607e-03, -1.1756e-03, -1.1844e-02],\n",
       "                         [ 3.0770e-02,  1.3600e-01,  8.7593e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3085e-03,  1.1538e-03,  9.5045e-03],\n",
       "                         [ 5.6346e-02,  6.3632e-02,  7.8846e-03],\n",
       "                         [-1.7981e-02,  9.4777e-03,  2.5976e-02]],\n",
       "               \n",
       "                        [[-5.0636e-02, -5.5553e-02,  2.3894e-02],\n",
       "                         [ 2.3465e-02,  3.7656e-02, -6.2338e-03],\n",
       "                         [ 3.5323e-02,  5.1885e-02,  4.6736e-02]],\n",
       "               \n",
       "                        [[-1.2530e-01,  1.5527e-02,  2.1507e-02],\n",
       "                         [ 6.7166e-02,  1.1106e-01, -2.1884e-02],\n",
       "                         [ 7.4694e-02,  4.4726e-02,  6.0871e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.0039e-02, -6.8916e-02, -1.4223e-02],\n",
       "                         [-1.0742e-02, -4.4980e-02, -9.3546e-03],\n",
       "                         [-7.2572e-03, -2.9153e-02,  2.1803e-02]],\n",
       "               \n",
       "                        [[ 1.9924e-01,  1.3192e-01, -9.0775e-03],\n",
       "                         [ 3.6546e-02, -2.9926e-02, -4.9565e-02],\n",
       "                         [ 3.7703e-02, -5.8799e-02, -1.0504e-01]],\n",
       "               \n",
       "                        [[-1.6986e-01, -1.1278e-01, -8.1585e-04],\n",
       "                         [-1.1774e-02,  4.7656e-02, -2.6614e-03],\n",
       "                         [-1.1678e-02,  9.0217e-02,  1.1122e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.7917e-02,  1.3508e-02, -4.4013e-03],\n",
       "                         [ 2.7492e-02, -7.3581e-02, -5.3146e-02],\n",
       "                         [-4.2043e-02, -4.8367e-02, -2.7784e-02]],\n",
       "               \n",
       "                        [[ 2.7122e-02, -1.4238e-02, -1.4304e-02],\n",
       "                         [ 2.8248e-02, -2.4267e-02, -1.9697e-02],\n",
       "                         [ 5.9038e-03,  1.7521e-02,  2.6387e-02]],\n",
       "               \n",
       "                        [[ 2.0642e-02,  1.0007e-02, -1.6224e-02],\n",
       "                         [ 4.9252e-02, -2.7034e-02, -3.9282e-02],\n",
       "                         [-4.0259e-02,  6.0734e-02,  3.2233e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.1448e-02, -4.3415e-02, -1.5608e-02],\n",
       "                         [ 4.4881e-02, -5.1836e-02, -5.1856e-02],\n",
       "                         [-4.2704e-03, -6.8827e-02, -1.1829e-02]],\n",
       "               \n",
       "                        [[ 3.8171e-02,  1.1951e-04, -2.1796e-02],\n",
       "                         [ 2.7216e-03, -9.5722e-04, -9.4981e-04],\n",
       "                         [ 3.1884e-02, -4.6273e-03, -1.6697e-02]],\n",
       "               \n",
       "                        [[-6.7691e-03, -4.6443e-03, -2.6772e-04],\n",
       "                         [ 1.4896e-02, -2.8501e-02, -9.2519e-03],\n",
       "                         [-7.7731e-03,  4.2538e-03,  2.2888e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-4.2394e-02,  2.8896e-02, -1.1698e-01],\n",
       "                         [ 9.9143e-02, -3.1077e-02, -1.2846e-01],\n",
       "                         [ 7.8782e-02,  5.4760e-03,  5.9480e-03]],\n",
       "               \n",
       "                        [[ 3.0209e-02, -2.1239e-03,  4.7978e-03],\n",
       "                         [ 7.2260e-03, -6.0073e-02,  2.4728e-02],\n",
       "                         [ 2.2383e-02, -2.0141e-02,  1.9277e-02]],\n",
       "               \n",
       "                        [[ 1.7110e-02, -2.0805e-03, -2.0392e-02],\n",
       "                         [ 6.1429e-02, -6.3892e-02,  3.8951e-02],\n",
       "                         [-1.7060e-02, -2.1929e-02,  3.9972e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.4542e-03, -3.1770e-02, -9.5240e-03],\n",
       "                         [ 4.2858e-03, -5.6998e-02, -5.0074e-02],\n",
       "                         [ 2.7575e-02, -8.4461e-03, -7.2253e-02]],\n",
       "               \n",
       "                        [[ 8.6076e-02, -3.8277e-02, -7.9793e-02],\n",
       "                         [ 2.2012e-01, -2.6575e-02, -2.0656e-01],\n",
       "                         [ 8.0584e-02, -1.2502e-02, -5.9022e-02]],\n",
       "               \n",
       "                        [[ 4.8098e-02,  2.9856e-02, -2.7219e-02],\n",
       "                         [-3.7794e-03,  2.4546e-02,  7.6674e-03],\n",
       "                         [ 2.2505e-02, -5.7663e-03, -2.6589e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.3451e-02, -1.0928e-01, -5.5022e-02],\n",
       "                         [ 2.2784e-01, -5.6795e-02, -3.9399e-02],\n",
       "                         [ 6.8986e-02, -5.4595e-02, -5.3248e-03]],\n",
       "               \n",
       "                        [[-4.3764e-02, -4.6129e-02, -2.1288e-02],\n",
       "                         [-1.6970e-02, -8.0105e-02, -1.5524e-02],\n",
       "                         [-4.4514e-02, -6.0874e-02, -4.8053e-03]],\n",
       "               \n",
       "                        [[-8.5714e-02,  4.3238e-02, -7.4123e-02],\n",
       "                         [-8.2692e-03, -6.3665e-02, -5.4684e-02],\n",
       "                         [-4.8488e-02, -5.7417e-03, -3.8420e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.7870e-02, -7.4011e-02,  1.0069e-02],\n",
       "                         [-4.7336e-02, -5.8547e-02, -7.0644e-02],\n",
       "                         [ 3.6944e-03, -6.6610e-02, -1.6965e-02]],\n",
       "               \n",
       "                        [[ 4.1263e-02, -7.2713e-02, -5.7201e-02],\n",
       "                         [ 9.3661e-02,  4.7666e-02,  1.9105e-02],\n",
       "                         [ 1.0349e-02, -5.7492e-02, -2.3362e-02]],\n",
       "               \n",
       "                        [[-5.1412e-02, -4.7409e-02, -2.7653e-02],\n",
       "                         [-2.9749e-02, -2.3428e-02, -1.9583e-02],\n",
       "                         [-1.6811e-02, -3.4051e-02,  1.2005e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.3499e-02, -1.1009e-02, -3.8272e-02],\n",
       "                         [-2.4022e-02, -1.2133e-01, -2.9200e-02],\n",
       "                         [-4.9164e-02, -3.2136e-02, -3.4291e-02]],\n",
       "               \n",
       "                        [[ 7.7150e-04, -2.5924e-02,  5.0627e-03],\n",
       "                         [-2.0950e-02,  4.8780e-03,  1.5819e-02],\n",
       "                         [-2.0701e-02, -1.3496e-02, -2.0882e-02]],\n",
       "               \n",
       "                        [[-3.3981e-03, -5.2352e-02, -2.3079e-02],\n",
       "                         [ 5.2368e-03,  5.8803e-04, -6.3670e-03],\n",
       "                         [-4.6446e-03, -3.0573e-02,  6.5189e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 8.3200e-03,  1.5505e-02,  3.8881e-02],\n",
       "                         [-5.0604e-03,  3.6521e-02, -9.2539e-03],\n",
       "                         [-1.3330e-02,  1.7228e-02, -5.5042e-02]],\n",
       "               \n",
       "                        [[-1.7869e-02, -4.7083e-03,  3.4098e-02],\n",
       "                         [-3.0260e-02, -8.0424e-02, -2.7158e-02],\n",
       "                         [ 2.3754e-02, -1.5535e-02, -3.2319e-02]],\n",
       "               \n",
       "                        [[ 5.0396e-02, -3.6485e-03,  4.2740e-03],\n",
       "                         [ 7.2871e-02, -9.7697e-02,  2.7690e-02],\n",
       "                         [ 4.3805e-02, -4.1336e-02,  2.3890e-02]]]], device='cuda:0')),\n",
       "              ('module.layer2.1.bn2.weight',\n",
       "               tensor([1.4982, 2.4577, 2.3398, 1.7663, 1.3555, 1.1280, 3.7166, 2.0438, 1.9795,\n",
       "                       1.7625, 1.0862, 1.5700, 1.2139, 1.5213, 1.8769, 1.9654, 1.5285, 1.1290,\n",
       "                       1.7205, 2.0294, 1.0770, 1.9440, 1.8202, 2.6571, 2.3593, 3.2962, 1.4496,\n",
       "                       1.9423, 2.1855, 1.2256, 1.6020, 2.7344, 1.4449, 1.9402, 2.3878, 0.9788,\n",
       "                       2.0071, 1.6449, 4.0007, 2.2328, 1.9589, 2.4797, 1.7240, 2.2002, 2.3226,\n",
       "                       1.6352, 2.2835, 2.1282, 0.9967, 2.2664, 1.8578, 2.0943, 1.5322, 1.7184,\n",
       "                       2.0762, 1.8931, 2.2819, 1.6657, 1.9720, 1.9570, 2.3810, 1.6305, 1.1918,\n",
       "                       1.4548, 1.9858, 1.4869, 1.7029, 2.1920, 2.2053, 1.1539, 2.1279, 2.3224,\n",
       "                       2.0755, 1.8982, 2.0195, 2.1653, 2.1041, 1.5618, 2.0877, 2.2369, 1.6419,\n",
       "                       1.2970, 1.4674, 1.5805, 1.6827, 1.2646, 1.8197, 1.5750, 2.1431, 1.8187,\n",
       "                       1.5745, 1.6497, 1.8463, 1.7791, 2.2141, 2.0439, 1.8711, 2.0106, 1.7976,\n",
       "                       2.1142, 1.7563, 1.9426, 1.7690, 1.7669, 2.1020, 1.5667, 1.9261, 2.0903,\n",
       "                       1.2797, 1.5349, 2.8446, 2.1488, 1.6757, 2.0395, 2.1755, 2.4583, 2.1521,\n",
       "                       1.3489, 2.3813, 2.8186, 1.2973, 1.9025, 1.5520, 2.0087, 1.2529, 1.7316,\n",
       "                       2.2331, 2.0853], device='cuda:0')),\n",
       "              ('module.layer2.1.bn2.bias',\n",
       "               tensor([ 1.0347e+00, -1.5924e+00, -1.4148e+00, -5.5610e-01,  1.8715e+00,\n",
       "                        2.5224e+00, -8.2571e+00, -1.3583e+00,  5.3334e-01, -2.7903e-02,\n",
       "                        6.6445e-01,  9.4516e-01,  2.4792e+00, -6.9346e-01, -6.2416e-01,\n",
       "                        7.6213e-03,  7.8893e-01,  4.6748e-01,  7.9808e-01, -4.7053e-02,\n",
       "                        2.3325e+00,  1.4016e-01, -1.5402e+00, -3.4808e+00, -2.1270e+00,\n",
       "                       -3.0901e+00,  1.1182e+00,  2.5372e-01, -1.2062e+00,  9.6628e-01,\n",
       "                        1.0441e+00, -2.1614e+00,  7.9857e-01,  5.0762e-01, -1.6008e+00,\n",
       "                        2.2699e+00, -5.8147e-01,  7.5558e-01, -5.6558e+00, -1.1622e+00,\n",
       "                       -1.1888e+00, -1.9802e+00,  4.6772e-02, -9.2943e-01, -1.9521e+00,\n",
       "                        6.8740e-01, -1.3791e+00, -3.2777e+00,  2.0253e+00,  1.5104e+00,\n",
       "                       -1.4733e-01, -1.1236e+00,  3.4113e-01, -6.9398e-01, -7.0268e-01,\n",
       "                       -1.1538e+00, -1.8999e+00,  3.2384e-01,  8.2752e-02, -1.7656e+00,\n",
       "                       -2.0228e+00,  9.9723e-01,  7.2996e-01,  1.2938e+00, -1.7306e+00,\n",
       "                        1.9920e-01,  9.9161e-01, -7.2542e-01, -9.7788e-01,  6.5933e-01,\n",
       "                       -6.1071e-02, -1.6992e+00,  4.3163e-02,  2.1132e-01, -7.8261e-01,\n",
       "                       -1.1229e+00, -9.4050e-01, -6.6953e-01, -1.2203e+00, -4.3907e-01,\n",
       "                       -8.0118e-03,  1.2972e+00,  3.2692e-01,  9.3775e-02, -1.1771e+00,\n",
       "                        1.3354e+00,  8.8882e-02, -4.5762e-01, -1.0725e+00, -1.2099e-01,\n",
       "                       -4.0443e-01,  5.6564e-03, -1.2615e+00,  6.0608e-02, -1.4210e+00,\n",
       "                       -8.6808e-01,  4.1980e-01, -1.7541e+00,  2.1345e-01, -1.0707e+00,\n",
       "                       -1.7277e-01, -1.1444e+00,  2.9459e-01, -3.9325e-01, -2.0062e+00,\n",
       "                        1.5379e+00,  5.4991e-01, -1.4428e+00,  1.2368e+00, -1.1467e+00,\n",
       "                       -1.8760e+00, -1.5764e+00,  7.2423e-01, -1.3987e+00, -1.9439e+00,\n",
       "                       -2.0124e+00, -2.3970e+00,  3.6919e+00, -1.6511e+00, -2.5108e+00,\n",
       "                        6.2211e-01, -1.1337e+00, -6.6174e-01, -7.6973e-01,  1.1124e+00,\n",
       "                       -8.9734e-02, -1.2158e+00, -2.3983e+00], device='cuda:0')),\n",
       "              ('module.layer2.1.bn2.running_mean',\n",
       "               tensor([ 0.9670,  1.9710,  0.3349, -1.0420,  2.6829, -0.3403,  1.7748, -0.3606,\n",
       "                        3.7865, -0.3722, -0.4372,  3.6212, -0.2788, -1.0420,  1.1263,  2.9410,\n",
       "                        1.3095,  0.2748,  4.4275,  3.4731, -2.8203,  2.3986, -0.3260, -0.0751,\n",
       "                        0.1115, -2.8611,  1.6292,  1.9787,  0.9790,  3.0046,  2.2180, -1.7350,\n",
       "                       -2.4822,  1.1936,  0.2199,  0.9945, -0.9472,  3.0937, -4.0138, -2.2566,\n",
       "                       -0.1877, -0.8782,  0.9075,  7.9896, -1.2967,  2.7536, -1.6924, -1.1092,\n",
       "                        2.8133,  1.9566,  0.4474, -2.0241,  1.6823,  0.5761,  0.3846, -0.8309,\n",
       "                        2.7138,  0.9717,  2.1729,  0.4542, -2.7649,  3.5420, -0.0867,  4.2891,\n",
       "                        0.2670,  0.6146,  2.6937, -3.9557,  1.1379, -1.8544,  3.2247, -1.2723,\n",
       "                        2.4187,  2.2432,  1.4348, -3.1965, -1.4922, -0.8660,  0.4050,  1.9519,\n",
       "                        2.4772,  2.2124,  0.9040,  1.9113,  0.4994,  2.1338,  1.4774,  0.0755,\n",
       "                        1.0140, -0.6091, -1.6413, -4.1732, -0.0803, -0.4354,  2.6595,  0.3557,\n",
       "                        2.3078,  0.9724,  2.1927,  1.1836,  1.6305,  0.3450,  0.4598,  1.1250,\n",
       "                       -1.1636,  2.4282,  1.2594,  0.7966,  1.5724, -1.7057, -3.3063, -0.3194,\n",
       "                        1.0848,  0.3290, -1.6842,  2.3052, -3.0137, -6.6522,  0.3137, -3.5537,\n",
       "                        0.3248,  0.2047, -0.7081,  1.9682,  1.5078,  1.5463,  0.3168, -3.7345],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.1.bn2.running_var',\n",
       "               tensor([ 8.5230,  6.0597,  1.9405,  5.7975,  5.1531,  5.4056,  3.9894,  2.6404,\n",
       "                       11.7825,  3.8106,  3.2505,  5.7039,  3.3409,  3.3410,  3.0937,  8.9797,\n",
       "                        5.7843,  4.2193,  8.6699,  8.5296,  2.3019,  9.2967,  2.3405,  1.8123,\n",
       "                        2.0593, 11.2463,  6.2961,  7.4613,  3.3616,  5.7913,  5.7305,  2.9357,\n",
       "                        2.4027,  7.7365,  2.7018,  3.7187,  3.0811,  4.9565,  6.5463,  2.8162,\n",
       "                        3.5758,  2.3780,  3.8963,  5.0802,  2.6968,  6.5078,  5.2397,  1.6372,\n",
       "                        2.0510, 15.4714,  9.0176,  2.9287,  3.5773,  2.3427,  2.7639,  2.7334,\n",
       "                        3.3946,  5.0474,  6.3327,  2.5118,  3.5286,  7.9068,  3.2206,  5.7900,\n",
       "                        2.4928,  5.8714,  4.9626,  3.9854,  8.0183,  3.7047,  9.5297,  2.7813,\n",
       "                        7.1705,  7.0552,  5.4738,  2.9355,  5.8390,  3.6321,  4.7269,  4.8557,\n",
       "                        3.2796,  5.8403,  4.1595,  5.0029,  3.1518,  4.5513,  7.3159,  3.4248,\n",
       "                        3.3163,  4.1312,  2.3014,  6.3340,  2.0658,  4.6892,  4.3878,  3.0794,\n",
       "                        6.6051,  2.9958,  6.3215,  5.0114,  5.3898,  3.0254,  4.2649,  2.8815,\n",
       "                        2.7510,  5.3233, 10.9605,  2.0141,  4.8057,  2.3555,  7.9212,  3.0559,\n",
       "                        6.0338,  2.3589,  2.6767,  5.8956,  2.7194,  5.0369,  3.2708,  4.8765,\n",
       "                        3.3355,  2.6772,  2.3587,  4.8719,  5.2141,  4.0075,  4.3285,  3.6034],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.1.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.1.conv3.weight',\n",
       "               tensor([[[[-0.0202]],\n",
       "               \n",
       "                        [[-0.0210]],\n",
       "               \n",
       "                        [[ 0.0185]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0097]],\n",
       "               \n",
       "                        [[-0.0031]],\n",
       "               \n",
       "                        [[-0.0100]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0054]],\n",
       "               \n",
       "                        [[ 0.0284]],\n",
       "               \n",
       "                        [[ 0.0175]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0085]],\n",
       "               \n",
       "                        [[ 0.0181]],\n",
       "               \n",
       "                        [[-0.0486]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0167]],\n",
       "               \n",
       "                        [[-0.0380]],\n",
       "               \n",
       "                        [[ 0.0075]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0443]],\n",
       "               \n",
       "                        [[ 0.0942]],\n",
       "               \n",
       "                        [[-0.0096]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0504]],\n",
       "               \n",
       "                        [[-0.0007]],\n",
       "               \n",
       "                        [[-0.0376]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0126]],\n",
       "               \n",
       "                        [[ 0.0079]],\n",
       "               \n",
       "                        [[ 0.0290]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0329]],\n",
       "               \n",
       "                        [[-0.0164]],\n",
       "               \n",
       "                        [[ 0.0065]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0019]],\n",
       "               \n",
       "                        [[-0.0088]],\n",
       "               \n",
       "                        [[-0.0001]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0072]],\n",
       "               \n",
       "                        [[ 0.0543]],\n",
       "               \n",
       "                        [[ 0.0712]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0358]],\n",
       "               \n",
       "                        [[ 0.0036]],\n",
       "               \n",
       "                        [[ 0.0666]]]], device='cuda:0')),\n",
       "              ('module.layer2.1.bn3.weight',\n",
       "               tensor([ 1.1222e+00,  1.5702e+00,  2.4387e+00,  5.2612e-01,  4.9926e-01,\n",
       "                        1.4819e+00,  1.2898e+00,  1.4473e+00,  7.1971e-01,  5.3582e-01,\n",
       "                        8.7329e-01,  1.8342e-01,  2.3895e-01,  2.4793e-01,  2.0582e-01,\n",
       "                        5.2938e-01,  3.2632e-01,  7.6328e-01,  4.1893e-01,  1.4311e-03,\n",
       "                        4.6429e-01, -1.7096e-02,  1.7624e+00,  3.0064e-01,  7.9900e-01,\n",
       "                        1.9011e+00,  1.8043e+00,  6.2660e-01,  3.4570e-01,  5.7233e-01,\n",
       "                        1.0518e+00,  2.2257e+00,  7.1439e-01,  1.0197e+00,  5.6782e-01,\n",
       "                        8.6938e-01,  4.4399e-01,  1.4882e+00,  6.4892e-01,  1.0939e+00,\n",
       "                        4.0225e-01, -2.0286e-01,  1.0440e+00,  5.3650e-01,  1.0216e+00,\n",
       "                        8.5820e-01,  5.2322e-03,  9.4798e-01,  2.3447e+00,  9.1503e-01,\n",
       "                        2.2432e+00,  5.1926e-01,  3.0679e-01,  8.5505e-01,  1.3545e+00,\n",
       "                       -5.4925e-02,  1.8361e+00,  3.6056e-01,  2.8554e-01,  5.5979e-01,\n",
       "                        8.8575e-01,  1.5520e-01,  1.4337e+00,  1.4403e+00,  1.3785e+00,\n",
       "                        1.0377e+00,  1.0788e+00,  8.9180e-01,  4.6428e-01,  6.6114e-01,\n",
       "                        1.9141e+00,  8.8313e-01,  1.7597e+00,  2.3273e-01,  5.4744e-01,\n",
       "                        4.6858e-01,  6.8924e-01,  3.6796e-01,  7.1121e-01,  6.2797e-01,\n",
       "                        4.7255e-01,  1.4628e+00,  9.3976e-01,  5.7254e-01,  5.5928e-01,\n",
       "                        1.7671e+00,  1.3104e+00,  1.0868e+00,  3.2256e-01,  4.8599e-01,\n",
       "                        1.2883e+00,  1.5568e+00,  5.8869e-01,  6.5730e-01,  1.6092e+00,\n",
       "                        7.0588e-02,  8.3464e-01,  3.0544e+00,  8.3968e-01,  7.1428e-01,\n",
       "                        1.3064e+00,  8.6185e-01,  1.3465e+00,  5.5436e-01,  9.9208e-01,\n",
       "                        2.6810e-01,  1.1659e+00,  7.8972e-01,  1.4434e+00,  7.4976e-01,\n",
       "                        6.7656e-01,  9.1814e-01,  1.1447e+00,  1.3136e+00,  6.8052e-01,\n",
       "                        5.5446e-01,  7.4667e-01,  2.8665e-01, -2.0379e-01,  9.7575e-01,\n",
       "                        1.1466e+00,  1.1331e+00,  7.7830e-01,  1.1389e+00,  2.1654e-01,\n",
       "                        1.2113e+00,  6.4509e-01,  1.3659e+00,  7.5836e-01,  1.8553e+00,\n",
       "                        1.0408e+00,  7.9415e-01,  1.7232e+00,  1.3614e+00,  1.2548e+00,\n",
       "                        4.3475e-01,  6.1963e-01,  1.1850e+00,  4.4590e-01,  1.9910e+00,\n",
       "                        7.9004e-01,  9.6962e-01,  9.7464e-01,  1.1449e+00,  1.4430e+00,\n",
       "                        1.1643e+00,  1.8650e-01,  1.0340e+00,  1.5214e+00,  9.0048e-01,\n",
       "                        6.2004e-01,  1.9158e+00,  6.4060e-01,  9.8677e-01,  4.7082e-01,\n",
       "                        2.1933e-01,  1.4117e+00,  9.3109e-01,  4.3912e-01,  2.5605e-01,\n",
       "                        3.0172e-01,  1.2717e+00,  9.2464e-01,  1.6391e+00,  3.7438e+00,\n",
       "                        5.0350e-01,  3.9617e-01,  8.7087e-01,  7.7661e-01,  1.3124e+00,\n",
       "                        3.4552e-01,  4.8753e-01,  6.0306e-01,  1.9644e+00,  1.0748e+00,\n",
       "                        8.8373e-01,  9.1720e-01,  6.8203e-01,  1.0604e+00,  6.8507e-01,\n",
       "                        8.9737e-01,  9.0212e-01,  2.9262e-01,  1.6531e+00,  1.1034e+00,\n",
       "                        6.8798e-01,  2.1599e+00,  2.0043e+00,  1.1796e+00,  7.6865e-01,\n",
       "                        3.1755e+00,  6.4345e-01,  4.5324e-01,  9.2720e-01,  8.1109e-01,\n",
       "                        2.1811e+00,  2.5814e+00,  1.5298e-01,  2.2309e+00,  2.0136e+00,\n",
       "                        5.9792e-01,  6.7923e-01,  7.9292e-01,  3.3250e-01,  7.7137e-01,\n",
       "                        5.0011e-01,  7.6097e-01,  7.2559e-01,  5.5581e-01,  2.0169e+00,\n",
       "                        7.9639e-01,  2.2829e+00,  3.6157e-01,  2.0234e+00,  2.7504e+00,\n",
       "                        1.5069e+00,  2.5120e+00,  1.0913e+00,  2.5144e-01,  1.0096e+00,\n",
       "                        1.1279e+00,  9.5931e-01,  5.2095e-01,  1.8982e+00,  2.2037e+00,\n",
       "                        1.0030e+00,  2.0882e+00,  1.2403e+00,  2.1592e+00,  8.4097e-01,\n",
       "                        1.4832e+00,  3.7291e-01,  2.4681e+00,  1.0360e+00,  9.2271e-01,\n",
       "                        2.6458e+00,  1.4191e+00,  3.7572e-01,  6.6896e-01,  5.1712e-01,\n",
       "                        1.4967e+00,  9.2562e-01,  7.7781e-01,  2.1540e-01,  4.6809e-01,\n",
       "                        5.9071e+00, -1.9506e-02,  6.3167e-01,  7.9278e-01,  1.2743e+00,\n",
       "                        2.4128e-01,  3.0596e-01,  5.9791e-01,  2.7671e-01,  5.7842e-01,\n",
       "                        6.3458e-01,  4.5086e-01,  3.8932e-01,  3.2072e+00,  9.4253e-01,\n",
       "                        7.3792e-01,  6.2852e-01,  5.8827e-01,  1.7358e+00,  4.8277e-01,\n",
       "                        9.7017e-01,  1.0186e+00,  7.4407e-01,  1.0824e+00,  9.2749e-01,\n",
       "                        5.1839e-01,  5.8142e-01,  1.5914e+00,  2.2363e+00,  1.5860e+00,\n",
       "                        7.4937e-01,  4.8963e-01,  1.3048e+00,  8.2795e-01,  4.1432e-01,\n",
       "                        7.2046e-01,  2.5678e-01,  1.1121e+00,  4.7585e-01,  1.1802e+00,\n",
       "                        5.5272e-01,  6.4547e-01,  5.3115e-01,  9.6832e-01,  5.8590e-01,\n",
       "                        7.7563e-01,  8.0864e-01,  8.5278e-01,  8.0811e-01,  1.6436e+00,\n",
       "                        9.0544e-01,  8.9781e-01,  6.3717e-01,  9.4053e-01,  1.7175e+00,\n",
       "                        1.4649e+00,  1.8961e+00,  3.0268e-01,  3.5499e-01,  5.4430e-01,\n",
       "                        6.7134e-01,  2.0324e+00,  3.9917e-01,  5.3258e-01,  1.1633e+00,\n",
       "                        4.1971e-01,  1.2513e+00,  3.2640e+00,  7.8023e-01,  8.4816e-01,\n",
       "                        1.0456e+00,  1.9841e-01,  4.6352e-01,  1.7136e+00,  5.8619e-01,\n",
       "                        7.1198e-01,  1.8116e+00,  3.7958e-01,  6.7969e-01,  5.9114e-01,\n",
       "                        5.9960e-01,  1.1815e+00,  1.7006e+00,  1.1734e+00,  4.4408e-01,\n",
       "                        8.2404e-01,  5.0228e-01,  3.7865e+00,  3.7213e+00,  8.9540e-01,\n",
       "                        1.7540e+00,  9.3141e-01,  5.4068e-01,  2.4772e+00,  1.3835e+00,\n",
       "                        1.0645e+00,  1.1898e+00,  1.1149e+00,  1.7500e+00,  4.9596e-01,\n",
       "                        6.4464e-01,  3.4817e+00,  5.1873e-01,  2.1910e+00,  2.5479e+00,\n",
       "                        7.8309e-01,  8.4753e-01,  5.8775e-01,  4.3560e-01,  1.2428e+00,\n",
       "                        1.0797e+00,  1.1163e+00,  3.5398e-01,  7.7734e-01,  6.5471e-01,\n",
       "                        1.9211e+00,  1.0942e+00,  1.0095e+00,  2.2688e+00,  1.0249e+00,\n",
       "                        1.0833e+00,  1.1294e+00,  5.5057e-01,  6.9950e-01,  1.4356e+00,\n",
       "                        5.3268e-01,  3.5859e-01,  2.0167e+00,  4.9294e-01,  9.1393e-01,\n",
       "                        3.1596e-01,  4.1280e-01,  9.3232e-01,  5.1124e-01,  2.6471e+00,\n",
       "                        1.2975e-01,  1.2044e+00,  8.8332e-01,  3.7594e-01,  4.6031e-01,\n",
       "                        1.0832e+00,  1.0704e+00,  3.8442e-01,  2.4971e-01,  1.4273e+00,\n",
       "                        4.0451e-01,  1.3584e+00,  1.1372e+00,  3.1932e-01,  3.0529e-01,\n",
       "                        1.8629e+00,  2.5943e+00,  1.8747e+00,  6.7697e-01,  8.9330e-01,\n",
       "                        9.8305e-01,  1.4264e+00,  6.3770e-01,  5.5469e-01,  2.7600e+00,\n",
       "                        6.9579e-01,  2.9366e-01,  6.7755e-01,  1.2782e+00,  7.2049e-01,\n",
       "                        4.0879e-01,  4.3450e-01,  4.4839e-01,  1.8782e+00,  9.8142e-01,\n",
       "                        2.0877e+00,  1.4564e+00,  3.4932e-01,  4.3890e-01,  3.0914e-01,\n",
       "                        7.4820e-01,  2.0735e+00,  2.6527e-01,  8.6790e-01,  5.6620e-01,\n",
       "                        1.4734e+00,  2.7188e+00,  3.7334e-01,  4.5688e-01,  1.1367e+00,\n",
       "                        1.0643e+00,  1.2959e+00,  5.1474e-01,  3.3080e-01,  6.8401e-01,\n",
       "                        6.9509e-01,  1.9630e+00,  1.1093e+00,  5.8096e-01,  1.5957e+00,\n",
       "                        8.6549e-01,  7.2444e-01,  2.2378e+00,  8.1847e-01,  8.0230e-01,\n",
       "                        1.2724e+00,  2.5186e+00,  2.3570e+00,  5.1063e-01,  7.7930e-01,\n",
       "                        7.5047e-01,  7.7310e-01,  1.7267e+00,  2.6835e+00,  1.2664e+00,\n",
       "                        1.1329e+00,  1.7697e+00,  1.5871e+00,  3.0244e-01,  8.3291e-01,\n",
       "                        4.1979e+00,  3.9465e-01,  6.5923e-01,  7.5398e-01,  2.7795e-01,\n",
       "                        1.5291e+00,  1.8028e+00,  4.5934e-01,  1.1307e+00,  1.7611e+00,\n",
       "                        4.4686e-01,  4.1942e-01,  2.1105e+00,  1.2537e+00,  6.2021e-02,\n",
       "                        8.6570e-01,  6.1170e-01,  6.6015e-01,  7.2461e-01,  1.1445e+00,\n",
       "                        1.4820e+00,  2.1091e+00,  5.3169e-01,  1.3975e+00,  1.1275e+00,\n",
       "                        1.9054e+00,  1.9588e+00,  1.0324e+00,  4.4628e-01,  5.2471e-01,\n",
       "                        6.3993e-01,  8.0474e-01,  2.8046e+00,  3.9610e-01,  2.2908e+00,\n",
       "                        1.2948e+00,  1.1999e+00,  1.1477e+00,  3.5402e+00,  5.9785e-01,\n",
       "                        1.2246e+00,  2.8164e+00,  6.2465e-01,  4.7744e-01,  9.0075e-01,\n",
       "                        8.6465e-01,  1.2522e+00,  5.1975e-01,  1.9688e+00,  1.2659e+00,\n",
       "                        5.8739e-01,  1.0292e+00], device='cuda:0')),\n",
       "              ('module.layer2.1.bn3.bias',\n",
       "               tensor([-1.2966e+00,  1.4384e+00, -9.8091e-01, -2.7638e+00, -5.1074e-01,\n",
       "                        3.3261e-02, -1.9373e+00, -1.9919e-01, -1.4384e+00, -4.5231e-02,\n",
       "                       -6.1106e-01, -1.8051e-01, -1.2210e-01, -2.7026e-01,  1.2227e+00,\n",
       "                       -3.7320e-01, -4.2022e-02, -7.4835e-01, -3.2571e-01,  6.4382e-03,\n",
       "                       -6.7750e-01,  1.0231e-01, -1.8462e+00, -1.1518e-01, -7.7397e-01,\n",
       "                       -9.3223e-01, -3.3757e+00, -6.2141e-01,  8.6218e-01, -2.1118e+00,\n",
       "                       -1.2746e+00,  6.9969e-01, -8.5930e-01, -5.1202e-02, -4.8389e-01,\n",
       "                        1.5837e+00, -5.4552e-01, -1.8546e+00, -7.3439e-01,  9.3234e-01,\n",
       "                       -2.7195e-01,  2.2328e-01,  1.0743e+00, -5.1578e-01, -4.2135e-01,\n",
       "                       -7.0211e-01,  2.6811e-01, -1.0580e+00,  1.7889e+00,  2.1356e-02,\n",
       "                       -6.3257e-01,  2.0257e-01,  1.9364e-01, -1.0286e+00, -2.5360e+00,\n",
       "                        4.9347e-03, -9.8022e-01, -5.0463e-01, -1.4340e+00,  6.1702e-01,\n",
       "                       -5.5763e-01,  2.6620e-01, -3.4259e+00,  2.5975e+00, -2.1167e+00,\n",
       "                       -1.7979e+00, -7.1120e-01,  1.5051e+00, -4.5034e-01, -5.9631e-01,\n",
       "                       -1.9690e+00, -9.7490e-01,  1.1842e+00,  2.1939e-01, -7.6527e-01,\n",
       "                       -4.4777e-01, -6.0183e-01, -7.1507e-02, -2.1681e-01, -4.1876e-01,\n",
       "                       -2.0022e-01, -9.8764e-01,  6.2085e-02, -1.8651e+00, -2.6908e-01,\n",
       "                        1.3551e+00, -1.2042e+00, -2.0391e+00, -2.7257e-01, -2.8373e-01,\n",
       "                        7.2721e-02, -2.9020e-01, -7.2395e-01, -6.8501e-01,  2.4035e-02,\n",
       "                        4.2866e-01, -5.9537e-01, -2.1002e+00, -1.3198e+00, -4.9963e-01,\n",
       "                       -1.6784e+00, -1.0521e+00, -1.7971e+00, -3.3396e+00, -9.2046e-01,\n",
       "                       -3.5217e-01, -1.3556e+00, -8.5013e-01, -2.6298e+00, -1.2039e+00,\n",
       "                       -8.6872e-01, -1.6381e+00, -8.7232e-01, -1.2307e+00, -5.1936e-01,\n",
       "                       -6.2535e-01, -1.0655e+00, -1.3353e-01,  2.7536e-01, -1.1111e+00,\n",
       "                       -1.4691e+00, -5.5976e-01, -6.3823e-01, -4.3329e-01, -1.4476e-01,\n",
       "                       -1.6826e+00, -1.4422e+00, -1.1823e+00, -7.5051e-01, -1.8684e+00,\n",
       "                       -1.4655e+00, -4.6226e-01, -1.2518e+00, -2.9863e+00, -3.8828e+00,\n",
       "                       -6.1651e-01, -3.0961e-01,  9.4058e-01,  7.5154e-02, -1.3304e+00,\n",
       "                       -9.5485e-02, -1.6138e+00, -2.9347e+00, -3.4817e-01, -1.3565e+00,\n",
       "                        1.4370e+00, -1.0346e-01,  4.3538e-01,  2.0124e+00,  2.9345e-01,\n",
       "                       -1.6726e+00, -2.5631e+00, -5.3541e-01,  5.3428e-01, -1.2953e+00,\n",
       "                       -8.9282e-02, -1.4237e+00,  2.7574e+00, -1.9289e-01, -9.9451e-01,\n",
       "                       -1.0947e-01, -1.6582e+00, -9.7560e-01, -1.3640e+00, -2.1633e+00,\n",
       "                       -1.2103e-01, -5.9293e-02, -1.2161e+00, -1.3062e+00, -1.4670e+00,\n",
       "                       -1.0987e+00, -6.6301e-02,  5.6726e-01,  1.2269e+00, -1.7323e+00,\n",
       "                       -9.3198e-01,  7.0597e-01, -7.6086e-01, -2.1397e+00, -1.1977e+00,\n",
       "                        4.6373e-01,  1.4992e+00, -2.6477e-01,  6.1800e-02, -1.0355e+00,\n",
       "                        2.0831e-01, -4.7102e-02, -2.3560e+00, -1.2652e+00, -5.9866e-01,\n",
       "                       -2.4941e+00, -2.8337e-01, -2.6020e-01, -1.4674e+00, -8.3954e-01,\n",
       "                       -6.1910e-01, -7.4655e-01,  1.8739e-01, -2.0630e-01, -2.5462e-01,\n",
       "                       -1.5170e-01, -3.0432e-01, -7.8775e-02, -2.2085e+00, -8.9837e-01,\n",
       "                       -7.1448e-01, -7.0415e-01, -7.1304e-01, -8.0570e-03, -8.0329e-02,\n",
       "                       -5.3182e-01, -5.5969e-01,  7.2957e-01, -3.0412e+00, -3.2673e+00,\n",
       "                        8.3091e-01, -1.0067e+00, -1.0153e+00, -2.7021e-01, -9.4022e-01,\n",
       "                       -9.6217e-01, -3.0665e+00, -1.0402e+00, -1.5809e+00, -2.8179e-01,\n",
       "                       -1.6465e+00, -3.8279e+00, -1.3849e+00,  6.1133e-01, -9.2070e-01,\n",
       "                        1.0962e+00, -7.1952e-01, -1.0160e+00, -1.1854e+00, -1.3044e+00,\n",
       "                       -5.8221e-01, -1.8071e+00, -6.7693e-01, -6.3520e-01, -1.8058e-01,\n",
       "                        1.5478e-01,  3.8926e-01, -1.4137e+00, -2.1276e+00, -3.1044e-01,\n",
       "                       -5.0703e+00, -9.1581e-01, -1.1545e+00, -8.7078e-01, -3.5572e-01,\n",
       "                       -1.1425e-01, -2.1319e+00, -5.8957e-01, -2.2061e-01, -2.5942e-01,\n",
       "                       -1.3011e+00, -4.2140e-01, -2.6125e-01, -1.1942e+00, -2.2301e+00,\n",
       "                        1.8657e-02, -4.1175e-01, -4.7843e-01, -6.1162e-01, -2.8175e-01,\n",
       "                        1.8351e+00, -7.9540e-01, -5.6062e-01, -1.6194e-01, -2.4162e+00,\n",
       "                       -1.3749e-01, -3.2846e-01, -1.3207e+00, -1.9046e+00, -2.8342e+00,\n",
       "                       -5.7906e-01, -4.9865e-01, -2.0670e+00, -7.7822e-01, -8.1008e-01,\n",
       "                       -7.9104e-01, -2.9309e-01, -9.3867e-01, -5.5044e-01,  6.9396e-02,\n",
       "                       -3.1307e+00, -7.8657e-01, -7.2241e-01, -1.3928e+00, -7.2495e-01,\n",
       "                       -1.2420e+00,  6.4742e-01, -1.5295e+00, -3.5126e-02,  1.2490e+00,\n",
       "                       -3.5584e-01, -7.4786e-01, -8.4705e-01, -1.1455e+00, -1.1944e-01,\n",
       "                       -1.7188e+00, -2.0306e+00, -2.2930e-01, -2.4998e-01, -2.6978e-01,\n",
       "                       -6.0912e-01, -2.4364e-01, -1.6856e-01, -1.0891e-01, -1.2751e+00,\n",
       "                        6.3787e-02,  1.2762e+00, -2.5779e+00, -1.1162e+00, -8.7933e-01,\n",
       "                        5.4649e-01, -1.2202e-01, -1.5571e-01, -2.4518e+00, -4.8787e-01,\n",
       "                       -3.2380e-01, -1.3299e+00, -1.6056e+00, -1.2164e+00, -8.4448e-02,\n",
       "                       -1.3199e+00, -7.9141e-01, -1.3512e+00, -1.2711e+00, -1.2894e-01,\n",
       "                       -8.4510e-01, -4.0226e-01, -4.7097e+00, -2.3382e+00, -5.8815e-01,\n",
       "                       -6.1904e-01, -8.1320e-01, -6.8379e-01, -1.3055e+00, -2.4179e+00,\n",
       "                       -9.4891e-01, -2.4829e+00, -2.6934e+00, -7.6741e-01, -3.0744e-01,\n",
       "                       -2.8188e-01,  1.2623e+00, -6.3519e-01,  3.1467e-01,  3.5922e-02,\n",
       "                       -8.3079e-01, -2.4710e+00, -4.6617e-01,  7.8823e-01, -1.1250e+00,\n",
       "                        2.4164e+00, -1.7462e+00, -4.1750e-01, -7.3087e-01, -8.4707e-01,\n",
       "                       -2.1286e-01, -1.7188e+00, -4.1204e-01, -8.2700e-01, -1.4492e+00,\n",
       "                       -3.4233e-01, -1.4963e+00,  1.2582e+00, -2.6449e-01, -1.3113e+00,\n",
       "                       -1.5431e-01,  1.3099e+00,  9.2939e-01,  2.2003e-01, -1.2481e+00,\n",
       "                       -2.2072e-01, -5.1225e-01, -2.3941e+00, -2.7476e-01, -1.5120e-01,\n",
       "                        2.3143e-01, -1.1449e-01, -6.5747e-01, -3.4031e-01, -5.4331e-01,\n",
       "                       -9.7435e-01, -3.2513e+00, -1.8219e-01,  1.3958e-01,  1.1229e+00,\n",
       "                       -1.6739e-01, -2.2648e+00, -1.1986e+00, -1.5007e-01, -1.3521e-01,\n",
       "                        2.3800e-01, -7.1802e-01, -2.3283e+00, -5.6830e-01,  7.1114e-01,\n",
       "                       -1.4247e+00, -6.0504e-01,  6.1561e-01, -9.7393e-01,  1.2401e+00,\n",
       "                        6.9150e-01, -1.1810e-01, -1.0771e+00, -1.1307e+00, -3.3960e-02,\n",
       "                       -4.2632e-01,  1.6118e+00, -4.4478e-01,  3.6998e-01, -1.5688e+00,\n",
       "                        1.3592e+00, -2.0480e+00,  1.4371e-01, -4.4746e-01, -5.4027e-01,\n",
       "                       -9.1370e-01, -1.9553e+00, -2.1358e-01, -1.9227e+00, -4.1518e-01,\n",
       "                       -1.2710e+00, -1.8069e+00, -3.1571e-02, -1.1747e-01, -1.5840e+00,\n",
       "                        9.0860e-01, -8.0132e-01, -5.6654e-01, -2.1982e-01, -8.8672e-01,\n",
       "                       -2.6150e-01, -9.7699e-01, -1.0556e+00, -7.8025e-01,  3.2345e-01,\n",
       "                       -7.1507e-01, -9.5389e-01, -1.3094e+00, -1.1161e+00,  1.5169e-01,\n",
       "                       -1.1699e+00,  4.3432e-02, -3.3197e+00, -4.9447e-01, -7.8339e-01,\n",
       "                        2.0102e-01, -3.5578e+00,  1.2762e+00, -4.6919e-01, -9.4707e-01,\n",
       "                       -1.2650e+00, -1.3102e+00, -1.6632e-01, -1.2265e-01, -3.6805e+00,\n",
       "                       -4.0685e+00, -3.4287e-01, -1.7083e+00, -3.4692e-01, -2.7351e-01,\n",
       "                       -5.0280e-01, -1.8651e+00, -3.7456e-01,  1.0211e+00, -9.3624e-01,\n",
       "                       -1.6600e-01, -2.8630e+00, -2.4795e+00,  8.2455e-01, -5.4988e-02,\n",
       "                       -1.5898e+00, -6.7678e-01, -5.5802e-01, -9.2247e-01,  1.7927e-01,\n",
       "                       -6.9915e-01,  7.1062e-01, -3.5912e-01,  1.3737e+00, -4.4465e-01,\n",
       "                       -1.3216e+00, -3.1801e+00,  1.5031e-01,  1.4609e-01, -1.6220e+00,\n",
       "                       -1.0576e+00, -1.2135e+00, -1.3411e+00, -8.9023e-02, -2.7491e-01,\n",
       "                       -1.5926e+00,  1.7367e-01, -5.2010e-01, -3.5728e+00, -4.2150e-01,\n",
       "                        3.3696e-01, -1.8250e+00, -5.7593e-01, -5.9007e-01,  1.1730e+00,\n",
       "                       -9.4890e-01, -1.2424e+00, -4.9550e-01,  1.9779e-01, -1.0552e-01,\n",
       "                       -4.9971e-01, -1.0754e+00], device='cuda:0')),\n",
       "              ('module.layer2.1.bn3.running_mean',\n",
       "               tensor([ 7.3419e-01,  2.2026e-01, -6.8985e-01, -7.8314e-01, -3.0911e-01,\n",
       "                       -5.4387e-01,  6.6490e-01, -2.2862e-01, -7.7405e-01, -6.7829e-01,\n",
       "                        3.7315e-01, -1.4015e-01, -1.8334e-02, -3.0859e-01,  7.5520e-01,\n",
       "                       -9.5193e-01,  8.6635e-02, -7.8826e-01, -2.3465e-01,  9.2667e-03,\n",
       "                       -1.3230e-01, -2.0992e-02, -3.0583e-01, -9.6530e-02,  1.2002e-01,\n",
       "                       -1.4601e+00, -1.0704e+00,  1.4539e-01,  7.7124e-01, -1.1255e+00,\n",
       "                       -1.4580e-01, -4.6045e-02, -6.1572e-01, -1.4911e-01,  7.7362e-01,\n",
       "                        1.6824e+00, -3.2770e-01, -1.0244e+00, -3.5860e-01, -2.0156e-01,\n",
       "                       -1.9953e-01, -5.6693e-01,  4.0427e-01,  4.2877e-01,  4.6263e-01,\n",
       "                       -1.5858e-01, -3.2384e-02, -5.7014e-01,  2.4897e-01, -2.5206e-01,\n",
       "                       -7.8204e-01,  6.9669e-01, -1.1355e-01, -5.6074e-01,  7.9725e-01,\n",
       "                        4.8286e-02, -4.9461e-01,  1.4156e-01, -1.8833e-01,  1.7016e-01,\n",
       "                       -5.2610e-02,  9.8330e-01, -1.5032e-01,  4.6678e-01, -3.9821e-01,\n",
       "                       -9.6699e-01,  1.7375e-01,  5.9913e-01, -4.4374e-01,  1.3559e-01,\n",
       "                        1.4827e-01, -1.7856e-01,  1.3065e-01, -2.1466e-01, -7.1931e-01,\n",
       "                       -1.4082e-01,  9.2408e-01, -7.7132e-02, -2.6756e-01, -2.7775e-01,\n",
       "                       -2.2115e-01,  1.6833e-01,  1.9020e-01, -9.9876e-01,  1.7763e-01,\n",
       "                       -1.7709e-02, -7.5377e-02, -8.8106e-02, -8.7257e-02,  2.1918e-02,\n",
       "                        3.1537e-01, -1.6714e-01, -8.7392e-02,  3.3786e-01, -4.2458e-03,\n",
       "                       -1.0040e-02,  3.8448e-01, -5.8908e-02, -7.9354e-01,  1.6630e-01,\n",
       "                        5.8161e-03, -5.9329e-01,  7.9871e-02,  4.4103e-01, -1.9984e-01,\n",
       "                        7.0854e-01, -2.5207e-01,  1.3335e-01, -1.6587e+00, -6.4792e-02,\n",
       "                        1.3538e-01,  6.4389e-02,  1.9486e-01, -3.9269e-01,  1.0751e-01,\n",
       "                       -1.1471e-01,  1.9306e-01,  2.5099e-01, -1.8760e-01, -1.0692e-01,\n",
       "                       -4.7150e-01,  8.9538e-02,  7.4101e-02, -7.8967e-01, -6.1922e-01,\n",
       "                       -5.2640e-02, -4.2472e-01,  5.0926e-01, -3.7621e-01, -6.9542e-01,\n",
       "                        1.6069e-02,  2.6581e-01, -5.4960e-01, -5.0063e-01, -7.0174e-01,\n",
       "                       -2.9356e-01,  8.1844e-01, -4.7245e-01,  1.4670e-01, -1.0593e+00,\n",
       "                       -7.0077e-01, -1.2833e-01, -1.4134e+00, -1.8306e-01, -6.2606e-01,\n",
       "                       -6.4253e-01,  5.0371e-02, -5.2756e-01,  2.2926e+00, -1.3564e-01,\n",
       "                       -3.9591e-01, -1.2803e+00,  3.1669e-01,  3.0949e-01,  1.6301e+00,\n",
       "                        2.3440e-01,  4.7837e-01,  8.9220e-01,  1.2599e-01,  3.2487e-01,\n",
       "                        3.7996e-01, -4.8116e-01, -8.4024e-02, -1.0981e+00,  1.4734e-01,\n",
       "                        4.3786e-01,  3.7187e-01, -6.5612e-01, -2.0381e-01,  4.4049e-01,\n",
       "                       -3.9250e-02,  1.4601e-01, -9.6988e-01, -3.1513e-01, -1.4815e-01,\n",
       "                       -1.8317e-01,  2.7059e-01, -5.8883e-01,  1.7887e-02, -2.6916e-02,\n",
       "                        9.3513e-01, -8.6259e-01,  2.1279e-02, -2.4709e-01,  4.0570e-01,\n",
       "                       -1.8885e-01,  1.4808e-01,  1.5979e-01, -3.7815e-01,  5.7961e-01,\n",
       "                       -1.8730e+00, -1.5510e-02, -3.4935e-01,  2.5560e-01,  5.1933e-02,\n",
       "                        7.9187e-01,  6.3803e-01,  1.1307e-01,  2.1862e-02, -7.2370e-03,\n",
       "                        2.7821e-01,  5.8231e-01,  5.4495e-01, -6.4083e-01, -1.2227e+00,\n",
       "                       -1.0006e-01, -2.6844e-01,  4.0589e-01, -3.8713e-01, -2.4879e-01,\n",
       "                        4.4653e-01,  2.7802e-01,  9.4970e-02, -3.2695e-01, -1.5844e+00,\n",
       "                        5.8974e-02,  4.8954e-01, -3.4357e-01, -6.9689e-01, -3.9669e-01,\n",
       "                       -1.0430e-01, -1.0161e+00, -8.5697e-02, -7.0490e-01,  1.9041e-01,\n",
       "                       -2.7069e-01,  6.6421e-01, -3.2193e-01, -4.3367e-01,  3.0654e-01,\n",
       "                        1.1023e-01, -1.8690e-01, -3.7708e-01,  7.3252e-02,  2.3443e-01,\n",
       "                       -1.5888e-01, -1.0743e-01,  6.0792e-01,  2.4320e-01, -4.9395e-02,\n",
       "                       -8.0940e-01, -4.2448e-01, -1.4825e+00,  6.5985e-01, -2.8131e-01,\n",
       "                       -1.3408e+00,  6.7940e-03,  7.5149e-03,  5.9764e-01,  2.4227e-01,\n",
       "                        5.0533e-01, -4.1211e-01, -2.5015e-01, -6.1232e-01,  1.0720e+00,\n",
       "                        4.1978e-01,  7.2753e-01, -1.4192e-01, -4.3680e-01, -7.7697e-02,\n",
       "                        1.6766e-01,  6.2883e-03, -2.0850e-02, -5.2521e-01, -4.4865e-01,\n",
       "                        1.6377e+00,  7.2611e-01, -3.9132e-02, -2.2827e-01, -1.3037e-01,\n",
       "                        1.5345e-01,  3.3956e-01,  3.4409e-01, -1.2358e+00, -1.8312e-01,\n",
       "                        6.6680e-01, -9.8267e-02,  1.0243e-01, -6.7021e-01,  6.2604e-01,\n",
       "                        1.6309e-01, -2.9785e-01, -5.2161e-01, -3.1067e-01, -1.4393e-01,\n",
       "                       -9.0993e-01,  1.4454e-01,  6.0977e-01,  6.0580e-02,  5.3370e-01,\n",
       "                       -6.5140e-01, -1.1004e-01, -3.0303e-01, -4.6093e-01, -1.3638e-01,\n",
       "                        2.5176e-01, -4.0304e-01, -2.9928e-01, -2.6802e-01, -2.3293e-01,\n",
       "                        4.2152e-02,  6.7267e-01, -9.3387e-01, -7.1224e-03,  1.0792e+00,\n",
       "                       -4.4816e-01, -3.2963e-01,  3.5426e-01, -3.2216e-01,  7.1463e-01,\n",
       "                       -8.5092e-01, -1.4571e+00, -4.1707e-01,  3.5132e-02, -4.1606e-01,\n",
       "                        1.6364e-02, -3.4073e-01, -3.6670e-01,  4.3607e-01, -1.9581e-01,\n",
       "                        2.0999e-01,  1.4648e-01,  4.9408e-01, -9.1313e-01, -7.9326e-01,\n",
       "                       -8.3956e-01, -7.8414e-01, -1.1191e+00,  5.6186e-01, -1.9464e-01,\n",
       "                       -2.0555e-01,  2.0756e-01, -8.9562e-01, -1.8974e-01, -3.2686e-01,\n",
       "                       -1.0205e-01, -1.2517e+00,  3.1415e-01, -3.3223e-01,  9.9111e-02,\n",
       "                       -3.1598e-01, -3.9506e-01, -9.9932e-01, -3.4374e-02,  6.7688e-02,\n",
       "                       -2.6001e-03,  3.0275e-01, -2.0420e-01, -6.2533e-01,  5.8140e-01,\n",
       "                        7.0509e-02,  8.6410e-02,  3.6197e-01,  9.6158e-01, -1.0892e-01,\n",
       "                       -1.0166e-01, -5.9228e-01,  9.5626e-01, -3.6922e-01, -2.8459e-01,\n",
       "                        4.8726e-01, -1.7881e-01,  4.1285e-01, -2.3085e-01, -4.5455e-02,\n",
       "                        3.9632e-02,  1.9580e-03, -6.2085e-01, -2.9351e-01,  3.0520e-01,\n",
       "                        7.2057e-01,  7.8132e-01, -2.8849e-01,  8.7566e-02,  1.5886e-01,\n",
       "                       -1.9452e-01,  8.2820e-03,  1.2720e-01, -1.9434e-01,  1.5223e-01,\n",
       "                       -3.9990e-02, -9.6191e-02, -2.9991e-01,  8.3904e-02,  1.3003e+00,\n",
       "                       -5.3552e-01,  7.9952e-01,  1.3860e-01,  3.7057e-01, -5.3878e-01,\n",
       "                        2.5947e-01, -6.2320e-01,  5.2380e-01,  1.8425e-01, -7.2195e-01,\n",
       "                       -1.2364e-01, -1.0351e+00, -1.2056e+00, -3.2491e-01, -2.7291e-01,\n",
       "                        9.5133e-02,  1.9353e-01,  3.9768e-01, -1.2647e-01, -6.5513e-01,\n",
       "                        4.8189e-01,  2.0651e-01, -8.5306e-01, -8.5171e-01,  1.7451e-01,\n",
       "                       -6.6563e-02, -1.0252e-01,  6.8764e-02, -6.4108e-01,  9.9040e-02,\n",
       "                        5.2276e-02,  4.1784e-01,  4.2820e-01,  3.7396e-01,  4.1784e-01,\n",
       "                        1.0440e-01,  4.4107e-01, -2.6344e-01,  8.4041e-02, -1.0241e-01,\n",
       "                       -2.1005e-01, -8.3559e-02, -5.6332e-01,  1.0005e-03, -4.6538e-01,\n",
       "                       -2.3603e-01, -3.5202e-01,  2.2305e-01, -1.1987e-02,  3.7924e-01,\n",
       "                       -2.8373e-01, -2.0377e-01, -1.7512e-01, -4.6040e-01,  3.9298e-01,\n",
       "                       -1.5390e-01, -1.1721e-01,  3.1918e-01,  3.8198e-01,  2.2698e-01,\n",
       "                       -7.7336e-01,  2.7629e-01, -1.1556e+00, -8.0701e-01, -5.9325e-01,\n",
       "                       -2.1738e-01, -3.4209e-01, -8.2503e-03,  2.7218e-01, -8.5723e-02,\n",
       "                        7.3904e-02, -7.6151e-01, -1.9794e-01, -1.1699e-01, -8.5084e-01,\n",
       "                       -1.6815e+00, -7.1200e-02, -1.1557e-01, -5.6431e-01,  7.2325e-01,\n",
       "                       -1.8726e-01,  1.7589e-01, -4.6130e-02, -2.2645e-01,  2.6118e-01,\n",
       "                        1.5196e-01, -1.0663e+00,  7.4564e-01, -1.1405e+00,  6.4445e-02,\n",
       "                       -1.7432e-01,  3.3886e-01,  5.8587e-01,  5.4895e-01,  1.5827e-01,\n",
       "                        2.4838e-01, -9.8002e-01, -1.2262e-02,  1.7672e-02,  7.3356e-01,\n",
       "                       -5.3873e-01, -1.4793e+00,  4.3042e-01,  2.5518e-01,  4.0852e-01,\n",
       "                        3.1978e-01,  4.6280e-01, -1.5134e-01,  1.5402e-01,  5.3690e-01,\n",
       "                        7.3078e-01, -3.0273e-01,  1.2341e-01,  5.2713e-01, -3.4900e-01,\n",
       "                        1.3464e+00, -3.4490e-01,  1.5070e-01,  2.3111e-01, -4.7783e-01,\n",
       "                       -1.8251e-01,  2.8969e-01, -2.9609e-01, -8.1765e-01, -5.7926e-01,\n",
       "                       -9.7807e-02,  2.1368e-01], device='cuda:0')),\n",
       "              ('module.layer2.1.bn3.running_var',\n",
       "               tensor([0.6335, 1.3088, 1.3887, 0.4480, 0.1495, 0.9202, 0.2477, 1.1907, 0.5513,\n",
       "                       0.6766, 0.3186, 0.1790, 0.1627, 0.2573, 0.1969, 0.1976, 0.1472, 0.2262,\n",
       "                       0.1194, 0.0117, 0.6758, 0.0254, 0.6759, 0.3006, 0.2206, 0.5219, 0.1890,\n",
       "                       0.1331, 0.1968, 0.2445, 0.3626, 1.9617, 0.1806, 0.2131, 0.2634, 1.5914,\n",
       "                       0.2660, 0.4422, 0.1386, 0.8499, 0.0967, 1.0109, 1.6621, 0.1423, 0.5556,\n",
       "                       0.2559, 0.0219, 0.2683, 2.0346, 1.1554, 0.9681, 0.2861, 0.1153, 0.3357,\n",
       "                       0.2179, 0.0617, 1.0641, 0.1507, 0.2291, 0.2880, 0.4534, 0.4814, 0.3456,\n",
       "                       1.0666, 1.0607, 0.3892, 0.3341, 0.6167, 0.1674, 0.4090, 1.1032, 0.3344,\n",
       "                       1.1785, 0.0611, 0.1995, 0.3239, 0.5328, 0.1453, 0.3031, 0.1971, 0.1109,\n",
       "                       0.2776, 0.2196, 0.5843, 0.1363, 0.7200, 0.7150, 0.3475, 0.1628, 0.2044,\n",
       "                       1.1542, 0.5669, 0.3049, 0.6611, 1.3690, 0.0528, 0.3705, 0.7976, 0.4069,\n",
       "                       0.1361, 0.5039, 0.2268, 0.2304, 0.2447, 0.6343, 0.3985, 0.2472, 0.2742,\n",
       "                       0.4050, 0.4446, 0.5067, 0.1296, 0.5270, 0.2276, 0.2962, 0.1723, 0.2363,\n",
       "                       0.2980, 0.1057, 0.4639, 0.8066, 0.2080, 0.2147, 0.2977, 0.2199, 0.5228,\n",
       "                       0.1579, 0.4667, 0.3113, 1.0102, 0.1761, 0.2923, 0.3246, 0.3201, 0.3694,\n",
       "                       0.1009, 0.6041, 0.4557, 0.2073, 0.8771, 0.2531, 0.3351, 0.1597, 0.4949,\n",
       "                       0.4225, 1.7370, 0.1952, 0.5117, 1.7987, 0.7211, 0.2910, 0.8774, 0.1335,\n",
       "                       0.4787, 0.3883, 0.1701, 0.2570, 0.7927, 0.1463, 0.2670, 0.3615, 0.5068,\n",
       "                       0.2979, 1.1216, 1.0657, 0.2389, 0.3856, 0.2348, 0.2645, 0.6351, 0.3612,\n",
       "                       0.0974, 0.5884, 1.3911, 0.4115, 0.3189, 0.9101, 0.2744, 0.3382, 0.2283,\n",
       "                       0.5045, 0.7373, 0.1555, 0.8323, 0.4974, 0.2429, 1.2250, 1.0798, 0.7440,\n",
       "                       0.4248, 1.4380, 0.6747, 0.1780, 0.2213, 0.1708, 1.1742, 1.5341, 0.1382,\n",
       "                       1.3639, 0.4241, 0.2533, 0.5678, 0.5634, 0.6816, 0.5580, 0.1620, 0.5048,\n",
       "                       0.4341, 0.3764, 1.5427, 0.3081, 1.1062, 0.2510, 0.1345, 0.4978, 0.6686,\n",
       "                       1.4948, 0.5857, 0.2144, 0.1819, 0.3875, 0.7624, 0.2408, 0.9026, 1.3996,\n",
       "                       0.3687, 0.2796, 0.4008, 1.1849, 0.2113, 0.5355, 0.2208, 1.1769, 0.7862,\n",
       "                       0.2491, 1.3303, 0.4978, 0.2679, 0.3359, 0.4479, 0.8277, 0.5791, 0.7758,\n",
       "                       0.2350, 0.1933, 2.8628, 0.0393, 0.2929, 0.6037, 0.4076, 0.1524, 0.5349,\n",
       "                       0.2025, 0.3034, 0.6890, 0.2457, 0.1934, 0.2748, 4.5751, 0.9463, 0.4854,\n",
       "                       0.2260, 0.1702, 1.1207, 0.8988, 0.5694, 0.3498, 0.3110, 0.2302, 0.1274,\n",
       "                       0.3150, 0.2702, 0.5595, 0.9774, 0.3305, 0.5157, 0.1807, 0.1729, 0.3846,\n",
       "                       0.1732, 0.2163, 0.1719, 0.2569, 0.1792, 0.6255, 0.6110, 0.5286, 0.2458,\n",
       "                       0.3687, 0.2137, 0.3711, 0.7854, 0.2102, 0.7850, 0.7903, 0.4462, 0.2942,\n",
       "                       0.2855, 0.3084, 0.8520, 1.0340, 0.6656, 0.1488, 0.1250, 0.1769, 0.2926,\n",
       "                       0.8690, 0.1729, 0.2877, 0.6409, 0.6446, 1.2272, 0.7726, 0.4123, 0.2398,\n",
       "                       0.6068, 0.2088, 0.1294, 0.2134, 0.3061, 0.4416, 0.4416, 0.2751, 0.4779,\n",
       "                       0.2731, 0.2398, 0.3203, 0.4447, 0.6024, 0.1644, 0.1806, 0.1420, 0.6197,\n",
       "                       1.0274, 0.2606, 1.0745, 0.3662, 0.1294, 1.3393, 0.4726, 0.2255, 0.3141,\n",
       "                       0.2129, 0.7118, 0.1244, 0.2206, 5.0038, 0.3982, 1.2799, 1.5056, 0.2177,\n",
       "                       0.4343, 0.1749, 0.1942, 0.4689, 0.9625, 0.4294, 0.1748, 0.1426, 0.1558,\n",
       "                       1.2751, 0.3920, 0.3458, 1.3159, 0.3023, 0.5813, 0.7039, 0.5523, 0.1551,\n",
       "                       0.4461, 0.6010, 0.2907, 0.8202, 0.2089, 0.5349, 0.2183, 0.1294, 0.3640,\n",
       "                       0.2413, 1.7448, 0.1353, 1.0759, 0.3282, 0.3293, 0.3975, 0.3713, 0.1086,\n",
       "                       0.4696, 0.1035, 0.8660, 0.2995, 0.6458, 0.4455, 0.3116, 0.2134, 1.0038,\n",
       "                       1.1067, 0.5223, 0.2412, 0.6688, 0.3835, 0.7058, 0.3795, 0.1323, 2.9615,\n",
       "                       0.2787, 0.1156, 0.3030, 0.8712, 0.5824, 0.2026, 0.4757, 0.1038, 1.0427,\n",
       "                       0.6553, 1.7811, 0.6642, 0.0955, 0.2847, 0.1925, 0.4605, 0.4566, 0.1427,\n",
       "                       0.3187, 0.2666, 1.0403, 1.2337, 0.1177, 0.1931, 0.3450, 0.8513, 0.2772,\n",
       "                       0.1716, 0.2348, 0.4933, 0.4185, 1.3848, 0.3495, 0.1563, 0.7439, 0.3356,\n",
       "                       0.3893, 0.6639, 0.1825, 0.5382, 0.7051, 1.5992, 0.9981, 0.4968, 0.4543,\n",
       "                       0.5894, 0.5510, 0.9383, 1.3118, 0.4235, 0.4231, 1.0261, 0.6495, 0.2420,\n",
       "                       0.6892, 0.6105, 0.3301, 0.1502, 0.2166, 0.1764, 0.9392, 0.5402, 0.1081,\n",
       "                       1.0250, 1.1048, 0.3310, 0.5236, 0.3533, 0.4360, 0.2071, 0.4534, 0.2480,\n",
       "                       0.2772, 0.5729, 0.8109, 0.6773, 1.6486, 0.1043, 1.3203, 1.0345, 0.6088,\n",
       "                       0.5838, 0.3078, 0.1637, 0.1444, 0.5456, 0.4053, 1.3389, 0.1582, 1.9506,\n",
       "                       0.3383, 1.1936, 0.4698, 0.8959, 0.1565, 0.5981, 1.2060, 0.3237, 0.1885,\n",
       "                       0.7053, 0.2714, 0.6238, 0.1894, 0.9468, 1.7390, 0.9412, 0.2449],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.1.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.2.conv1.weight',\n",
       "               tensor([[[[-0.0285]],\n",
       "               \n",
       "                        [[-0.0308]],\n",
       "               \n",
       "                        [[-0.0303]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0753]],\n",
       "               \n",
       "                        [[-0.0779]],\n",
       "               \n",
       "                        [[-0.0105]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0228]],\n",
       "               \n",
       "                        [[-0.0303]],\n",
       "               \n",
       "                        [[ 0.0537]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0499]],\n",
       "               \n",
       "                        [[ 0.0541]],\n",
       "               \n",
       "                        [[-0.0066]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0216]],\n",
       "               \n",
       "                        [[-0.1073]],\n",
       "               \n",
       "                        [[ 0.0527]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0017]],\n",
       "               \n",
       "                        [[ 0.0395]],\n",
       "               \n",
       "                        [[-0.0113]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0048]],\n",
       "               \n",
       "                        [[ 0.0294]],\n",
       "               \n",
       "                        [[ 0.0240]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0078]],\n",
       "               \n",
       "                        [[ 0.0165]],\n",
       "               \n",
       "                        [[-0.0599]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0215]],\n",
       "               \n",
       "                        [[ 0.0101]],\n",
       "               \n",
       "                        [[-0.0138]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0345]],\n",
       "               \n",
       "                        [[ 0.0028]],\n",
       "               \n",
       "                        [[-0.0167]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0621]],\n",
       "               \n",
       "                        [[-0.0855]],\n",
       "               \n",
       "                        [[-0.0006]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0139]],\n",
       "               \n",
       "                        [[ 0.0139]],\n",
       "               \n",
       "                        [[-0.0172]]]], device='cuda:0')),\n",
       "              ('module.layer2.2.bn1.weight',\n",
       "               tensor([2.5999, 1.7446, 1.6535, 1.9365, 2.6361, 1.8930, 1.3938, 1.2396, 0.9840,\n",
       "                       2.0268, 1.7362, 1.7280, 1.8672, 1.9511, 1.0864, 1.5190, 1.7590, 1.0308,\n",
       "                       2.4699, 1.3327, 1.4522, 2.0432, 2.4958, 1.7165, 1.6767, 1.2479, 1.3540,\n",
       "                       1.7936, 1.4885, 1.3698, 1.9056, 1.6078, 1.3561, 1.7042, 1.8193, 1.9810,\n",
       "                       1.5345, 1.4276, 1.6369, 2.5734, 1.6715, 1.3905, 2.0264, 1.6282, 1.6386,\n",
       "                       1.7891, 1.7667, 1.3040, 1.4041, 1.5749, 2.3783, 1.5855, 1.4232, 1.3639,\n",
       "                       1.9345, 1.7591, 2.9303, 1.6070, 2.0458, 1.5875, 0.9683, 1.7362, 1.6338,\n",
       "                       1.7018, 1.8189, 1.0887, 1.0953, 1.4557, 1.4848, 2.1534, 1.6790, 1.2223,\n",
       "                       4.5141, 1.8426, 1.8136, 1.4039, 2.1584, 1.9566, 2.1970, 2.2642, 1.6508,\n",
       "                       1.8795, 1.8075, 1.4863, 1.9942, 2.2271, 1.0911, 2.7511, 1.1961, 2.2069,\n",
       "                       1.8838, 1.3244, 1.6618, 2.5122, 1.4543, 1.3936, 1.0592, 1.4890, 1.8897,\n",
       "                       1.6732, 1.8508, 3.2885, 1.7366, 2.0444, 2.1006, 1.8983, 1.6974, 1.5787,\n",
       "                       1.9525, 1.8318, 1.9194, 1.9515, 2.6343, 2.4785, 2.2414, 1.6893, 1.1460,\n",
       "                       1.7531, 1.3518, 1.2701, 1.6049, 1.7463, 1.5147, 2.3649, 1.6182, 1.3331,\n",
       "                       2.3922, 1.6883], device='cuda:0')),\n",
       "              ('module.layer2.2.bn1.bias',\n",
       "               tensor([-1.8458e+00, -9.6625e-01, -4.1535e-01, -6.5144e-01, -2.5014e+00,\n",
       "                       -6.4142e-01,  3.5713e-01, -4.0282e-01,  1.6030e+00, -1.8792e+00,\n",
       "                       -4.7517e-01, -5.1672e-01, -1.1866e+00, -1.1371e+00,  6.7364e-01,\n",
       "                        1.7370e-01, -4.4003e-01,  7.8364e-01, -1.0874e+00,  5.8772e-01,\n",
       "                       -3.8803e-01, -1.7085e-02, -2.0974e+00, -7.5904e-01, -6.5050e-01,\n",
       "                        1.0408e+00, -1.6754e-01, -4.8701e-01, -7.4448e-04,  5.9901e-01,\n",
       "                       -1.4299e+00, -4.9299e-01,  1.7461e-01, -2.9134e-01, -7.6477e-01,\n",
       "                       -1.6488e+00,  1.5409e-01,  2.7821e-01, -9.9665e-02, -2.4372e+00,\n",
       "                       -1.1185e-01,  2.0932e-01, -1.4715e+00, -4.4957e-01, -2.6942e-01,\n",
       "                       -4.4068e-01, -3.2297e-01,  2.7054e-01, -1.0257e-01, -6.3356e-01,\n",
       "                       -3.2752e+00,  3.1776e-01, -5.7452e-02,  5.7109e-01, -7.5532e-01,\n",
       "                       -1.3759e+00, -1.6276e+00, -2.9105e-01, -1.9038e+00, -1.0710e-01,\n",
       "                        1.6677e+00, -1.3753e+00, -1.0455e+00, -3.6727e-01, -1.2884e+00,\n",
       "                        7.2604e-01,  5.1514e-01,  5.1218e-01, -7.4989e-01, -2.1646e+00,\n",
       "                        6.2455e-02,  8.1121e-01, -5.7265e+00, -4.6199e-01, -1.1257e+00,\n",
       "                       -6.9739e-01, -1.6465e+00, -1.1460e+00, -1.5588e+00, -2.4940e+00,\n",
       "                       -1.2442e-02, -1.2370e+00, -9.4844e-01, -4.9191e-01, -7.2915e-01,\n",
       "                       -3.0869e+00,  1.7754e+00, -4.0500e+00,  8.2639e-02, -1.4217e+00,\n",
       "                       -8.2917e-01,  4.6929e-01, -2.0957e-01, -1.9349e+00,  3.8344e-02,\n",
       "                        2.9355e-01,  6.5779e-01,  3.6051e-01, -9.6376e-01, -1.3187e+00,\n",
       "                       -1.6187e+00, -3.0700e+00, -1.6148e-02, -1.0992e+00, -1.1090e+00,\n",
       "                       -1.5095e+00, -1.9539e-01, -1.3410e-02, -1.3507e+00, -1.0573e+00,\n",
       "                       -1.1616e+00, -6.9668e-01, -3.4984e+00, -9.5306e-01, -2.2121e+00,\n",
       "                       -3.7118e-01,  3.5624e-01, -8.4575e-01,  4.4729e-01,  6.0250e-01,\n",
       "                       -5.4711e-01, -9.9458e-01,  1.8753e-01, -2.6604e+00, -1.1463e-01,\n",
       "                        2.1203e-01, -2.0344e+00, -1.8797e-01], device='cuda:0')),\n",
       "              ('module.layer2.2.bn1.running_mean',\n",
       "               tensor([-0.5100, -2.0494, -0.0081,  0.6574, -1.8509,  0.3444,  1.5644, -1.2669,\n",
       "                       -1.2640, -1.4077,  0.0596, -0.7239, -0.2725,  0.3056,  1.7439,  1.6383,\n",
       "                        0.3834,  1.5695, -1.9126,  2.8708,  0.8699, -0.2610, -1.1693, -0.5990,\n",
       "                       -0.4838,  1.4884, -0.2428, -0.6100,  0.4384,  0.9819, -0.5125, -0.3994,\n",
       "                        1.4494,  1.2192, -0.0518, -1.4049, -0.1444, -3.3508, -0.2096,  1.0765,\n",
       "                       -0.4874,  1.8068,  0.9417,  0.1766,  0.0571,  0.4019,  0.9456,  2.7252,\n",
       "                        0.2829,  0.5852, -1.4215,  0.4444,  0.8417,  2.1700,  2.0251, -1.1154,\n",
       "                        0.0540,  0.6899, -2.5709,  1.6800, -1.1858,  0.9799, -0.3198, -1.5434,\n",
       "                       -0.5567,  0.3767,  1.2536,  0.9918, -0.4560, -2.0924,  0.2186, -3.9166,\n",
       "                        0.3645, -0.0683, -1.3480,  2.2038,  0.2787, -1.6235, -4.8293, -1.5690,\n",
       "                        2.5712, -1.1109, -0.9653, -0.4939,  0.3076, -1.4364, -1.2357,  0.1660,\n",
       "                       -0.3906, -0.4574,  0.6192,  2.1833, -0.5406, -0.7532,  1.2551, -0.8030,\n",
       "                       -0.1156,  0.7262,  0.4629,  0.5512, -0.9486, -1.7966,  0.5263,  0.1103,\n",
       "                       -0.3370, -0.0750,  0.8882,  0.6373, -0.6695, -0.6912, -1.0386,  0.0698,\n",
       "                       -2.3882,  1.4284, -2.8029,  1.3935,  0.4237, -0.8080,  1.3765,  2.3091,\n",
       "                       -0.0777, -0.8006,  2.1302,  0.3399,  1.2477,  0.4948, -0.8569,  0.3097],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.2.bn1.running_var',\n",
       "               tensor([ 3.6566,  4.8707,  4.3458,  6.7116,  2.7012,  5.0312,  4.4231,  2.4034,\n",
       "                        5.3189,  2.4134,  5.3505,  5.9095,  4.2001,  5.4659,  3.3699,  6.2214,\n",
       "                        6.3338,  2.7716, 11.3562,  5.4820,  3.1660, 12.2750,  5.9804,  3.8876,\n",
       "                        4.8721,  4.8741,  3.6803,  7.0014,  4.1863,  6.6632,  3.4320,  3.9602,\n",
       "                        5.5659,  5.9268,  6.9766,  2.8784,  7.2376,  4.2517,  5.6234,  4.1470,\n",
       "                        5.9187,  5.7199,  4.0245,  5.8762,  4.4562,  6.1635,  7.2224,  5.7754,\n",
       "                        4.6057,  2.9794,  2.0819,  8.1964,  4.1416,  6.0851,  5.4894,  3.5199,\n",
       "                       11.6859,  3.9861,  2.7509,  5.7084,  4.6890,  2.3769,  2.3714,  5.6257,\n",
       "                        3.1964,  4.5786,  3.5207,  6.4316,  3.7143,  2.0079,  5.4750,  5.9379,\n",
       "                        3.6214,  5.8140,  3.5377,  4.8268,  3.7705,  3.7498,  4.8895,  2.6959,\n",
       "                        6.8730,  3.5548,  4.1307,  5.0621,  5.5016,  2.0808,  7.5599,  3.2782,\n",
       "                        2.6507,  2.8225,  6.0573,  5.8091,  4.9250,  5.7367,  3.8333,  4.8150,\n",
       "                        2.7249,  5.8409,  5.4416,  3.0811,  2.5614,  7.1180,  4.7484,  5.2507,\n",
       "                        7.1710,  2.4962,  5.9457,  7.3708,  3.0959,  3.6229,  3.7088,  5.0736,\n",
       "                        3.7686,  8.2353,  5.2656,  7.2933,  3.4693,  5.2992,  4.0745,  5.0869,\n",
       "                        4.5052,  2.5095,  8.4222,  3.3641,  6.3228,  4.6639,  3.7782,  4.5195],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.2.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.2.conv2.weight',\n",
       "               tensor([[[[-8.4935e-04, -2.7044e-02, -7.5682e-03],\n",
       "                         [-3.6726e-02,  4.6155e-03, -2.0548e-02],\n",
       "                         [-2.2750e-02, -1.8362e-02, -2.7111e-02]],\n",
       "               \n",
       "                        [[-2.1136e-02, -2.4055e-02, -7.4939e-03],\n",
       "                         [-6.3162e-03, -4.1937e-02,  3.8528e-02],\n",
       "                         [-4.7098e-02, -4.1283e-02, -1.0891e-02]],\n",
       "               \n",
       "                        [[-6.3690e-02, -2.8639e-02, -5.8129e-03],\n",
       "                         [-3.0655e-02, -5.0182e-02, -2.3423e-02],\n",
       "                         [ 1.5473e-02, -2.5876e-03, -4.6728e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.9543e-02, -1.6631e-02, -2.9482e-02],\n",
       "                         [-1.5104e-02, -1.9036e-02, -4.0501e-02],\n",
       "                         [ 5.2556e-02,  2.7441e-02,  5.4710e-02]],\n",
       "               \n",
       "                        [[-2.1263e-02, -3.7841e-03, -4.3744e-02],\n",
       "                         [-3.7128e-02,  1.2313e-01, -3.0301e-02],\n",
       "                         [ 1.6175e-02,  4.3453e-02,  8.5615e-03]],\n",
       "               \n",
       "                        [[ 3.8085e-03,  6.8257e-03, -3.2657e-03],\n",
       "                         [-2.7584e-02, -1.0573e-02, -2.1582e-02],\n",
       "                         [-2.7723e-03, -1.8176e-02,  3.0063e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.5405e-03, -7.9259e-03, -6.6817e-03],\n",
       "                         [ 1.4302e-02, -7.1965e-03, -1.5337e-02],\n",
       "                         [-1.4091e-02,  1.5748e-02, -2.7108e-02]],\n",
       "               \n",
       "                        [[ 7.8728e-02, -3.0478e-02,  1.1040e-03],\n",
       "                         [ 2.1035e-02, -1.6027e-01,  5.2617e-02],\n",
       "                         [-2.5919e-02, -1.1621e-02,  9.3510e-02]],\n",
       "               \n",
       "                        [[-3.5173e-02,  8.4368e-03,  3.4722e-02],\n",
       "                         [-1.0583e-01, -9.8897e-02,  9.6794e-02],\n",
       "                         [ 2.4298e-03, -1.2881e-02,  4.1728e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.4135e-02,  2.9003e-03, -2.5899e-03],\n",
       "                         [-2.3692e-02,  7.6867e-03, -1.2065e-02],\n",
       "                         [-2.9571e-02, -5.5567e-03, -4.7955e-02]],\n",
       "               \n",
       "                        [[-1.0505e-02, -6.1683e-03, -8.1230e-03],\n",
       "                         [-8.9447e-03, -3.8498e-02, -2.0319e-02],\n",
       "                         [ 2.7771e-02, -3.1881e-02,  3.7382e-02]],\n",
       "               \n",
       "                        [[ 9.4103e-04,  3.1049e-03, -2.3949e-03],\n",
       "                         [ 2.3754e-02, -2.4929e-02, -9.1532e-03],\n",
       "                         [-9.6543e-03,  3.0186e-02, -1.6853e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1917e-02, -1.4346e-02,  7.9458e-04],\n",
       "                         [ 1.3738e-02, -3.2068e-02,  4.3314e-02],\n",
       "                         [-1.3084e-02, -3.5343e-03, -3.2044e-03]],\n",
       "               \n",
       "                        [[-6.5138e-03,  3.8106e-02, -5.0424e-02],\n",
       "                         [-2.1374e-02,  5.5018e-02,  1.2916e-02],\n",
       "                         [ 5.4871e-02, -6.5331e-02,  1.2948e-01]],\n",
       "               \n",
       "                        [[ 6.3085e-02, -5.3642e-02,  9.4755e-03],\n",
       "                         [ 1.7048e-02, -1.2301e-02,  3.2484e-02],\n",
       "                         [ 3.1879e-02,  2.4288e-02, -1.6817e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.3702e-02, -6.8546e-02,  9.5699e-03],\n",
       "                         [-1.6519e-01,  1.1281e-01,  6.3281e-02],\n",
       "                         [-1.0643e-01,  5.7066e-02,  8.4459e-02]],\n",
       "               \n",
       "                        [[ 1.1565e-03,  5.6952e-02,  1.2085e-02],\n",
       "                         [-2.4251e-02, -9.7389e-03,  4.5447e-02],\n",
       "                         [ 1.9889e-02,  7.7196e-03, -1.0005e-02]],\n",
       "               \n",
       "                        [[ 4.2776e-03,  2.3196e-02, -1.4123e-02],\n",
       "                         [ 3.2772e-02, -2.8958e-02,  3.6294e-02],\n",
       "                         [ 3.7406e-03,  2.8900e-02, -2.6167e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.3106e-02, -1.6032e-02, -1.6720e-02],\n",
       "                         [ 2.4334e-02,  3.0358e-02, -7.7841e-03],\n",
       "                         [ 1.0011e-02,  1.7955e-02, -2.0996e-02]],\n",
       "               \n",
       "                        [[ 2.4949e-02, -2.4401e-02, -3.6224e-02],\n",
       "                         [-6.3200e-03, -5.0050e-02, -3.5571e-02],\n",
       "                         [-2.1407e-02, -1.3336e-02,  2.2418e-02]],\n",
       "               \n",
       "                        [[ 1.0415e-02, -3.1983e-02,  1.9223e-03],\n",
       "                         [-1.1465e-03, -3.7220e-02, -1.4054e-02],\n",
       "                         [-3.0356e-03, -3.1959e-02,  9.2825e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.9629e-03,  9.3114e-03, -6.8279e-03],\n",
       "                         [-2.8632e-02, -8.1462e-03, -5.0688e-02],\n",
       "                         [-2.8388e-02, -1.1158e-02, -3.9239e-02]],\n",
       "               \n",
       "                        [[ 3.6848e-02,  6.1085e-02, -2.8338e-02],\n",
       "                         [ 1.2767e-01,  3.8119e-01,  8.6727e-02],\n",
       "                         [ 5.9047e-02,  2.0167e-01,  8.1322e-02]],\n",
       "               \n",
       "                        [[ 8.3759e-03, -8.1537e-03,  9.7534e-03],\n",
       "                         [ 4.7103e-03, -3.1862e-02, -1.0342e-02],\n",
       "                         [-1.7290e-02,  1.2957e-02,  1.8888e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.1521e-01, -8.9876e-02, -1.0304e-01],\n",
       "                         [-7.1879e-02,  7.5024e-02, -6.5922e-02],\n",
       "                         [-1.0030e-01, -1.2924e-01, -1.0833e-01]],\n",
       "               \n",
       "                        [[ 5.0659e-04, -3.2996e-03, -1.4577e-02],\n",
       "                         [-1.8599e-02, -2.4403e-02, -2.4523e-02],\n",
       "                         [-1.7586e-02, -2.9464e-03, -3.5853e-02]],\n",
       "               \n",
       "                        [[-1.4441e-02, -2.8660e-03, -3.4269e-02],\n",
       "                         [-2.9944e-02, -7.5896e-03,  3.0654e-02],\n",
       "                         [-3.5125e-02, -5.7496e-02, -3.4668e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.1552e-03, -2.6141e-02,  3.0956e-02],\n",
       "                         [ 2.5107e-02, -5.1552e-02,  3.2406e-02],\n",
       "                         [-2.5217e-03, -1.1373e-03,  1.3081e-02]],\n",
       "               \n",
       "                        [[ 2.5275e-02, -5.7214e-03,  2.4210e-02],\n",
       "                         [-7.5476e-02,  7.3034e-02, -1.8038e-02],\n",
       "                         [-1.0351e-02,  1.1630e-02, -1.8155e-02]],\n",
       "               \n",
       "                        [[-3.3582e-04, -2.6599e-02,  3.3593e-03],\n",
       "                         [-1.1187e-02, -5.5102e-02, -2.3657e-02],\n",
       "                         [-1.7086e-02, -3.0228e-02, -3.4358e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.7330e-03, -3.6615e-02,  1.6029e-02],\n",
       "                         [ 1.7919e-03,  3.0246e-03,  6.0643e-03],\n",
       "                         [ 1.5692e-02, -4.0143e-02, -1.4244e-02]],\n",
       "               \n",
       "                        [[-5.5351e-02, -5.9429e-02,  8.7105e-03],\n",
       "                         [-2.4672e-03, -2.5635e-02,  3.9872e-02],\n",
       "                         [ 5.4026e-03, -4.6597e-02,  2.6516e-02]],\n",
       "               \n",
       "                        [[-5.1431e-02, -1.7588e-02, -1.7607e-02],\n",
       "                         [-1.3855e-02, -2.1972e-03,  1.8771e-03],\n",
       "                         [-6.9472e-03, -4.8369e-02, -2.4579e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.1581e-02, -9.5596e-03, -7.5793e-02],\n",
       "                         [-2.8934e-03,  1.0314e-01, -3.7049e-02],\n",
       "                         [-2.7238e-02,  1.0119e-01, -1.4524e-02]],\n",
       "               \n",
       "                        [[ 1.7347e-02,  1.8593e-02,  1.2828e-02],\n",
       "                         [-3.2787e-02, -5.7192e-02, -3.1792e-02],\n",
       "                         [ 1.4432e-03,  8.7675e-03, -1.1439e-02]],\n",
       "               \n",
       "                        [[ 1.0937e-02, -7.2429e-03,  4.3752e-03],\n",
       "                         [ 5.2880e-03, -6.7866e-03,  2.8733e-02],\n",
       "                         [-1.9874e-03, -2.1441e-02,  3.7778e-02]]]], device='cuda:0')),\n",
       "              ('module.layer2.2.bn2.weight',\n",
       "               tensor([2.0228, 2.2621, 1.9954, 2.1734, 2.2409, 2.2911, 2.0316, 1.9835, 2.3018,\n",
       "                       2.5218, 2.2897, 1.2426, 4.2039, 2.3780, 2.4703, 1.5895, 2.1859, 1.1342,\n",
       "                       2.2643, 2.3253, 1.5185, 1.3269, 2.2430, 2.0022, 2.5174, 1.9984, 1.2647,\n",
       "                       1.5304, 1.1320, 1.7912, 1.9885, 2.0310, 1.6634, 1.6298, 2.2009, 2.5762,\n",
       "                       1.2528, 2.3011, 1.8040, 1.8069, 3.3369, 1.0628, 2.2171, 2.2063, 2.3520,\n",
       "                       2.3295, 1.2336, 2.0635, 2.4115, 2.3877, 2.8640, 1.9299, 2.3805, 2.0568,\n",
       "                       1.7119, 1.8602, 1.4184, 2.0462, 3.2469, 2.2296, 2.0986, 2.7562, 2.1667,\n",
       "                       1.8495, 2.0557, 2.1570, 3.4300, 2.0913, 1.1905, 2.5277, 2.1439, 1.1775,\n",
       "                       2.2079, 1.1584, 1.6854, 1.8144, 2.2460, 2.1603, 1.2757, 1.2083, 1.7132,\n",
       "                       1.3769, 2.2280, 2.4323, 2.4020, 2.3086, 2.6495, 1.9104, 2.0489, 1.5361,\n",
       "                       1.9616, 2.0705, 2.4044, 1.6000, 1.1041, 2.1508, 1.0945, 2.2084, 1.9011,\n",
       "                       2.0231, 1.5983, 2.1394, 3.0184, 1.9039, 2.1860, 2.2308, 2.0296, 2.2993,\n",
       "                       3.3175, 1.8301, 2.1869, 3.1313, 2.1316, 2.5189, 1.2136, 2.2471, 2.2480,\n",
       "                       2.3410, 1.9092, 2.1690, 2.6926, 3.3070, 2.0815, 1.6541, 2.0995, 3.9142,\n",
       "                       2.9129, 1.9614], device='cuda:0')),\n",
       "              ('module.layer2.2.bn2.bias',\n",
       "               tensor([-0.5088, -1.1711, -0.9488, -0.9289, -1.2516, -1.2740, -1.4306, -0.6482,\n",
       "                       -1.3166, -1.5918, -1.4405,  2.0393, -0.8914, -1.5621, -2.2075,  1.2626,\n",
       "                       -0.9238,  2.6968, -0.8937, -1.2040,  0.4530,  3.3935, -1.3025, -1.3126,\n",
       "                       -2.5785, -0.8522,  1.8383,  2.6309,  2.8646, -0.2914, -0.6779,  0.0987,\n",
       "                       -0.1498, -0.0323, -1.0959, -1.7897,  2.9348, -0.7923, -0.2198, -0.1452,\n",
       "                       -2.6262,  2.1098, -1.1948, -1.3032, -1.4660, -2.1622,  3.3184, -1.4809,\n",
       "                       -1.6373, -0.1728, -1.6059, -0.4394, -1.9065, -0.9809, -0.0988, -0.4818,\n",
       "                       -1.3722, -1.3776, -1.6278, -1.2102, -0.4431, -2.0296, -1.4819, -0.6856,\n",
       "                       -0.9908, -1.1300, -3.1324, -1.2131,  3.2411, -2.1794, -0.9032,  1.1251,\n",
       "                       -2.1111,  1.8585,  0.1871, -0.1949, -2.1102, -1.5119,  3.4920,  3.1823,\n",
       "                       -0.0354,  1.3264, -0.7076, -1.2972, -1.7029, -1.3729, -2.0971, -1.1365,\n",
       "                       -0.6867,  0.3858, -0.9439, -1.1863, -1.2261,  0.4344,  2.1566, -1.0220,\n",
       "                        1.9257, -0.6517, -0.4189, -0.5153,  0.5678, -0.6120, -3.4489, -0.2623,\n",
       "                       -0.6257, -1.9579, -0.7397, -1.3704, -2.5663, -0.1147, -1.5837, -2.4919,\n",
       "                       -1.2755, -1.1270,  3.4441, -1.1185, -2.3350, -1.7217,  0.2832, -1.1002,\n",
       "                       -1.8675, -1.7850, -1.0997,  0.0098, -1.0520, -3.7067, -1.7628, -0.9476],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.2.bn2.running_mean',\n",
       "               tensor([-2.4245e+00, -1.9677e+00,  3.5526e-01, -1.6330e+00,  1.8149e-01,\n",
       "                       -3.7835e-01, -6.4196e-01, -9.0736e-02, -7.2333e-01, -4.0228e+00,\n",
       "                       -1.0733e+00,  4.3143e-01, -3.1706e+00, -1.2146e+00, -3.7132e+00,\n",
       "                       -2.8121e+00, -5.3205e-01,  2.2731e+00,  3.2011e-01, -3.1898e-01,\n",
       "                        1.8030e-01, -2.8183e+00, -1.9963e+00, -2.5738e-01,  3.4908e-01,\n",
       "                       -1.3610e+00,  1.7107e+00,  1.4870e+00, -1.0822e+00, -8.2733e-01,\n",
       "                       -1.8076e+00, -1.3774e+00, -1.0172e+00,  7.3811e-01, -1.4754e+00,\n",
       "                       -4.7381e-01, -3.0737e+00, -1.3559e+00, -6.3114e-01, -8.5875e-01,\n",
       "                       -1.6558e+00,  1.5512e+00, -4.7082e-02, -4.3466e-01, -3.1157e+00,\n",
       "                       -5.8031e-01, -1.4037e+00, -4.0970e-01,  1.0233e-01, -1.8007e-01,\n",
       "                       -1.0502e+00, -2.1497e+00, -8.8574e-01, -6.3713e-01, -1.0167e+00,\n",
       "                        6.1855e-01, -2.6579e-01, -1.1047e+00,  2.4067e-01, -2.0822e+00,\n",
       "                       -2.6261e+00, -1.0002e+00, -3.5582e-01,  1.0193e+00,  2.4793e-01,\n",
       "                        9.5591e-01, -4.2193e+00, -4.7490e-01, -2.3583e+00, -1.0682e+00,\n",
       "                       -1.0621e+00, -1.2662e+00, -8.5053e-01,  6.0948e-01,  6.5271e-01,\n",
       "                       -2.2616e+00, -8.2742e-01, -9.0207e-01, -1.7471e+00,  2.0290e+00,\n",
       "                       -5.5347e-01,  2.0189e+00, -9.6219e-01,  1.1993e-01, -1.9655e+00,\n",
       "                       -1.5841e+00, -9.1209e-01,  4.6163e-03, -3.7174e-01, -1.6575e+00,\n",
       "                       -7.0752e-02, -4.5809e-01, -6.4823e-01, -2.7473e-01,  9.0969e-01,\n",
       "                       -5.4138e-01, -6.7532e-01, -1.2898e+00, -1.7665e+00, -6.9745e-01,\n",
       "                        9.8361e-01, -2.0596e+00, -2.1466e+00, -2.3497e-01, -2.3927e+00,\n",
       "                       -1.0251e+00, -1.9517e+00, -1.8777e+00, -2.4131e+00, -1.0165e+00,\n",
       "                        3.3378e-02, -3.4067e-01, -1.1537e+00, -1.4458e+00,  4.7067e+00,\n",
       "                       -4.8461e-01, -8.6307e-01, -1.3887e+00, -1.0637e+00, -1.9237e+00,\n",
       "                       -2.1530e-01,  1.2262e+00,  6.3742e-01, -1.9291e-01,  3.5572e-01,\n",
       "                       -4.5750e+00, -8.5181e-01, -7.8307e-01], device='cuda:0')),\n",
       "              ('module.layer2.2.bn2.running_var',\n",
       "               tensor([ 8.1231,  2.6146,  2.2802,  3.0003,  6.3175,  4.5963,  4.6488,  8.1220,\n",
       "                        3.3228, 12.5858,  2.5149,  3.4292, 16.8707,  3.1848,  1.9142,  8.0391,\n",
       "                        7.1367,  3.2675,  2.3834,  6.7411,  4.4007,  6.0075, 10.4469,  4.7420,\n",
       "                        2.0059,  6.2200,  3.2489,  3.5756,  2.9625,  3.5065,  4.6837,  7.1327,\n",
       "                        3.9259,  2.9673,  3.0515,  4.6720,  2.5554,  5.7246,  3.8977,  4.3335,\n",
       "                        3.2537,  2.9603,  2.6191,  6.4592,  9.8342,  5.8527,  3.7569,  3.8476,\n",
       "                        4.5240,  8.7209,  3.4379,  3.1623,  3.0932,  3.2017,  4.0286,  2.9625,\n",
       "                        1.1762,  5.2371,  5.6240, 10.7052, 10.7259,  4.9015,  5.1297,  2.4649,\n",
       "                        2.2950,  2.1894,  2.6009,  2.4813,  3.5731,  3.2503,  4.7110,  3.5247,\n",
       "                        4.9002,  3.5633,  3.0251,  4.8614,  4.9619,  5.1035,  3.6744,  3.4149,\n",
       "                        2.8371,  3.8452,  4.2523,  2.0580,  2.9557,  9.7471,  2.2140,  4.3422,\n",
       "                        2.6758,  5.4612,  2.3370,  2.0351,  2.1857,  3.3239,  5.0297,  5.1024,\n",
       "                        2.8349, 12.3712,  3.0443,  7.8994,  2.9498, 11.2716,  2.3307,  5.1608,\n",
       "                        3.8325,  5.1878,  4.7655, 10.2450,  4.1494,  3.1693,  5.4504,  3.5970,\n",
       "                        1.8037,  3.0584,  3.1195,  4.8803,  2.5378,  1.9009,  6.8236,  9.2263,\n",
       "                        4.9964,  5.6903,  2.6190,  2.8374,  2.5409,  5.5778,  3.5580,  2.3444],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.2.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.2.conv3.weight',\n",
       "               tensor([[[[ 0.0312]],\n",
       "               \n",
       "                        [[-0.0037]],\n",
       "               \n",
       "                        [[-0.0008]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0138]],\n",
       "               \n",
       "                        [[-0.0527]],\n",
       "               \n",
       "                        [[-0.0031]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0085]],\n",
       "               \n",
       "                        [[-0.0043]],\n",
       "               \n",
       "                        [[ 0.0069]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0655]],\n",
       "               \n",
       "                        [[ 0.0103]],\n",
       "               \n",
       "                        [[-0.0066]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0104]],\n",
       "               \n",
       "                        [[ 0.0074]],\n",
       "               \n",
       "                        [[ 0.0449]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0008]],\n",
       "               \n",
       "                        [[-0.0191]],\n",
       "               \n",
       "                        [[-0.0192]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0026]],\n",
       "               \n",
       "                        [[ 0.0195]],\n",
       "               \n",
       "                        [[-0.0375]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0561]],\n",
       "               \n",
       "                        [[-0.0767]],\n",
       "               \n",
       "                        [[-0.0058]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0272]],\n",
       "               \n",
       "                        [[-0.0010]],\n",
       "               \n",
       "                        [[ 0.0326]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0164]],\n",
       "               \n",
       "                        [[-0.1621]],\n",
       "               \n",
       "                        [[ 0.0114]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0809]],\n",
       "               \n",
       "                        [[-0.0966]],\n",
       "               \n",
       "                        [[ 0.0029]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0023]],\n",
       "               \n",
       "                        [[ 0.0061]],\n",
       "               \n",
       "                        [[-0.1199]]]], device='cuda:0')),\n",
       "              ('module.layer2.2.bn3.weight',\n",
       "               tensor([ 0.4468,  1.3217,  0.2873,  0.6182,  1.1504,  0.7089,  0.6324,  1.4478,\n",
       "                        0.6751,  1.5516,  0.5540,  0.1660,  0.1873,  1.7265,  1.8012,  1.2444,\n",
       "                        0.4351,  0.3992,  0.9488,  0.0733,  0.2073,  0.1643,  1.0240,  0.1709,\n",
       "                        1.9756,  1.3094,  1.4642,  1.0872,  1.5949,  0.6221,  1.4765,  1.5377,\n",
       "                        1.6676,  2.6110,  0.8348,  0.2867,  1.3859,  0.2329,  0.9424,  0.7629,\n",
       "                        0.5909, -0.0085,  0.6362,  1.1456,  1.3947,  1.7507,  0.0061,  1.3965,\n",
       "                        1.3884,  0.4041,  0.3654,  0.4132,  1.1075,  0.8378,  1.0291,  0.1419,\n",
       "                        0.3276,  0.2899,  0.7834,  0.6962,  0.5161,  0.0681,  1.2435,  0.3657,\n",
       "                        0.4229,  1.1491,  0.8542,  0.6129,  0.5813,  0.5223,  1.3331,  1.4332,\n",
       "                        2.1657,  0.7571,  1.9120,  0.4191,  0.3235,  0.6083,  1.3849,  0.3931,\n",
       "                        0.7496,  0.9415,  0.9433,  0.4242,  0.6139,  1.7072,  1.0372,  2.5681,\n",
       "                        0.4900,  0.4558,  0.7883,  1.6394,  0.4666,  0.2711,  1.4338,  1.0517,\n",
       "                        1.0409,  2.5426,  0.4189,  1.4556,  1.4866,  1.7154,  1.6552,  0.4999,\n",
       "                        1.2367,  0.2528,  0.9676,  1.2682,  0.8546,  0.2797,  0.3659,  0.7161,\n",
       "                        0.5005,  1.4547,  0.4755, -0.0922,  0.8977,  0.3325,  0.5151,  0.6379,\n",
       "                        0.3520,  1.5981,  0.7925,  1.1844,  0.1522,  0.4675,  0.6736,  2.0589,\n",
       "                        1.6086,  1.1709,  1.0172,  1.0290,  2.9766,  2.0304,  1.3806,  0.3627,\n",
       "                        0.1723,  1.8164,  0.6985,  1.4533,  0.9589,  1.3217,  0.8518,  1.8238,\n",
       "                        1.9034,  0.6854,  0.1859,  1.0143,  1.1682,  0.7309,  1.2914,  1.7423,\n",
       "                        1.1692,  1.3031,  0.2752,  0.2957,  1.0224,  1.2177,  0.8258,  0.4099,\n",
       "                        0.7440,  0.6079,  1.6527,  0.7155,  0.8832,  1.1982,  0.9870,  1.0263,\n",
       "                        0.9056,  0.6977,  0.6206,  2.0261,  0.3261,  1.1080,  1.5154,  0.7499,\n",
       "                        1.2056,  0.6234,  2.1432,  1.4957,  0.8952,  0.3638,  0.4081,  0.9919,\n",
       "                        1.7226,  1.2493,  0.4536,  0.8008,  0.7189,  0.2325,  3.3674,  0.2183,\n",
       "                        0.9526,  0.6734,  1.2144,  0.1009,  0.6528,  0.2186,  1.1298,  1.5433,\n",
       "                        0.6620,  0.1866,  0.2102,  0.2111,  0.7198,  0.8125,  0.4298,  0.4498,\n",
       "                        1.2195,  1.2750,  0.9405,  0.2592,  0.6042,  0.6009,  1.7215,  2.1821,\n",
       "                        0.9544,  1.0268,  0.2002,  0.5220,  1.1194,  0.4182,  0.4563,  1.4886,\n",
       "                        0.2979,  0.5735,  3.9911,  1.3182,  0.5350,  1.6057,  0.7506,  0.5745,\n",
       "                        0.4050,  0.3795,  0.8339,  0.3962,  1.2407,  0.4586,  0.6284,  0.1747,\n",
       "                        0.5393,  1.5301,  0.6323,  0.0297,  0.7660,  2.6692,  0.0920,  1.4131,\n",
       "                        0.2747,  1.3129,  0.2540,  0.0619,  0.5843,  0.2774,  0.3354,  0.2502,\n",
       "                        0.6031,  0.3288,  3.0228,  1.0599,  0.7392,  1.4283,  0.5586,  0.3698,\n",
       "                        0.2144,  0.5998,  0.9079,  0.7733,  1.8450,  2.0455,  0.6314,  0.2920,\n",
       "                        1.7672,  1.6463,  1.3034,  0.2611,  2.0761,  3.3625,  0.3440,  0.6071,\n",
       "                        1.0180,  0.1721,  1.2782,  0.3614,  1.1076,  0.4573,  0.2588,  0.6746,\n",
       "                        1.1275,  0.7456,  0.2595,  0.1928,  1.6300,  0.4826,  1.2049,  0.6500,\n",
       "                        0.6328,  0.7150,  1.9957,  1.1838,  0.5005,  1.0429,  0.7111,  0.7852,\n",
       "                        0.1183,  0.5062,  1.3477,  0.7156,  0.5438,  1.3712,  0.0512,  0.8654,\n",
       "                        3.2766,  1.4804,  1.3704,  1.0498,  0.1986,  0.8538,  1.1672,  0.5948,\n",
       "                        1.2183,  1.4722,  0.5470,  0.2366,  1.1214,  0.5168,  1.2413,  1.0958,\n",
       "                        0.5669,  0.4109,  1.4435,  0.8814,  1.9889,  1.5551,  0.9004,  0.8784,\n",
       "                        0.4716,  1.5922,  0.3493,  2.4165,  0.7633,  0.7427,  2.9268,  1.5100,\n",
       "                        0.3779,  1.6165,  0.7339,  0.2513,  0.5667,  0.8960,  1.2535,  0.8551,\n",
       "                        1.9212,  0.8723,  0.4409,  0.2104,  1.0580,  0.4701,  0.8812,  1.5318,\n",
       "                        0.2402,  1.5119,  0.8856,  0.1312,  0.4895,  1.0990,  0.6226,  0.4465,\n",
       "                        1.6415,  1.6452,  0.2805,  1.0828,  2.1168,  0.7905,  0.6448,  0.2251,\n",
       "                        0.5204,  1.3881,  0.3537,  0.2928,  0.1183,  0.2261,  1.0399,  0.2405,\n",
       "                        0.7585,  1.0236,  1.5725,  0.2627,  0.3716,  0.5554,  0.4248,  1.7192,\n",
       "                        0.4410,  0.0700,  0.4115,  1.1906,  0.4618,  1.7976,  1.1050,  0.8007,\n",
       "                        0.7264,  0.2454,  0.5545,  0.9899,  0.8239,  1.2646,  0.5861,  0.4304,\n",
       "                        0.5946,  0.5105,  0.6286,  1.4206,  0.8061,  1.3299,  0.6410,  1.4794,\n",
       "                        0.5060,  0.2373,  0.4453,  0.3152,  0.4394,  4.1816,  0.2573,  1.2995,\n",
       "                        1.6212,  1.6898,  1.5051,  0.8049,  1.9574,  1.7628,  1.3995,  0.8562,\n",
       "                        1.1483,  0.1187,  0.1950,  0.5247,  1.8052,  1.2015,  1.8730,  0.9058,\n",
       "                        1.5712,  0.5998,  1.3047,  0.7294,  0.8749,  0.8151,  0.8853,  1.5920,\n",
       "                        0.1756,  0.4144,  0.8879,  0.0107,  1.3831,  0.5617,  1.5243,  1.7679,\n",
       "                        1.6462,  1.6459,  0.3601,  0.1778,  3.1832,  0.2561,  2.0144,  0.9754,\n",
       "                        0.4787,  1.3772,  1.6721,  1.0528,  0.8984,  1.7975,  0.2708,  0.6460,\n",
       "                        1.1454,  1.7831,  0.2067,  1.2520,  1.1988,  0.7209,  1.3578,  0.7535,\n",
       "                        1.6808,  1.4612,  0.9565,  1.3426,  0.8722,  1.1961,  1.9484,  1.3203,\n",
       "                        0.7226,  0.2590,  0.5840,  0.9311,  0.2239,  0.7730,  1.5257,  2.0328,\n",
       "                        1.2354,  0.8865,  1.8396,  0.5739,  1.6995,  2.0746,  0.5058,  0.2660,\n",
       "                        0.7641,  1.5840,  0.1631,  0.5979,  0.7038,  0.7164,  0.5183,  1.6520],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.2.bn3.bias',\n",
       "               tensor([-7.1272e-01, -2.5324e+00,  7.3042e-02, -4.6156e-01, -1.2579e+00,\n",
       "                        2.6750e-01, -9.1614e-01, -2.2256e+00, -5.0532e-01,  6.3875e-01,\n",
       "                       -4.7199e-01,  7.1496e-02, -1.2132e-01, -4.6565e-01,  3.4811e-01,\n",
       "                       -9.1915e-01, -4.3494e-01, -3.1817e-01, -1.2520e+00,  5.2782e-03,\n",
       "                        2.8432e-01,  1.0017e-02, -2.0300e+00, -1.0431e-01, -1.7517e+00,\n",
       "                       -1.5882e+00,  2.8735e-01, -7.2291e-01, -2.9970e-01, -8.3510e-01,\n",
       "                       -2.0974e+00, -3.8933e+00,  5.9866e-01, -2.2161e+00, -3.3204e-01,\n",
       "                       -2.0321e-01,  2.3797e+00,  3.8349e-01, -1.1976e+00, -1.9156e+00,\n",
       "                       -5.4695e-01, -1.6704e-02,  8.5419e-01, -9.4432e-01, -1.6206e+00,\n",
       "                        1.0185e+00, -8.8383e-02,  3.3014e-01, -3.6991e+00, -2.3062e-01,\n",
       "                       -1.6182e-01,  3.2166e-01, -5.8364e-01, -4.7052e-01, -8.4652e-01,\n",
       "                       -2.3189e-02, -2.7733e-03, -1.9761e-01, -1.6152e+00, -1.4847e+00,\n",
       "                        1.9943e-01,  6.7780e-03,  1.2429e+00, -4.4960e-01, -3.7974e-01,\n",
       "                       -2.0953e+00, -6.1474e-01,  2.0317e-01, -9.2185e-01, -1.6105e-01,\n",
       "                       -1.1671e+00, -1.8852e+00, -1.8642e+00, -9.2129e-01, -2.1169e+00,\n",
       "                       -3.7857e-01, -2.3156e-01, -4.6939e-01, -5.3281e-01, -1.1864e-01,\n",
       "                       -3.2832e-01, -1.3095e+00, -1.9571e+00, -3.4268e-01, -8.6424e-01,\n",
       "                       -3.0712e+00, -1.4611e+00, -3.9328e-01, -2.1631e-01, -5.1146e-01,\n",
       "                        2.2603e-01, -1.9143e+00, -3.9308e-01,  5.3724e-01, -2.9371e+00,\n",
       "                        2.7606e-01,  3.9292e-01, -3.1070e+00, -7.6462e-01, -1.8079e+00,\n",
       "                       -8.5088e-01, -2.5718e+00, -6.6168e-01, -3.9357e-01, -1.7419e+00,\n",
       "                       -3.5167e-01, -1.3847e+00, -1.1433e+00, -1.1104e+00, -2.6499e-01,\n",
       "                       -4.4426e-02, -2.4239e+00, -3.5151e-01, -2.1390e+00, -4.2104e-01,\n",
       "                        7.6061e-02, -7.1985e-01, -3.1763e-01, -1.1788e-01, -4.2595e-01,\n",
       "                       -1.3954e-01, -1.4274e+00, -7.1257e-01, -1.8687e+00, -7.0454e-02,\n",
       "                       -3.2215e-01, -1.1838e+00,  2.6535e-02, -9.0800e-01, -1.3276e+00,\n",
       "                        6.5947e-02, -1.3890e+00, -4.5488e+00, -2.9783e+00, -2.1553e+00,\n",
       "                       -2.4480e-01,  1.7710e-01, -4.3366e-01, -6.5053e-01, -1.8327e+00,\n",
       "                       -1.8562e+00,  8.7512e-01,  9.4508e-01,  1.2866e+00, -1.5155e+00,\n",
       "                        4.1044e-01, -1.5588e-01, -1.6958e+00,  9.6236e-01, -8.6447e-01,\n",
       "                       -1.7899e-01, -3.8044e+00, -8.7272e-01, -8.6184e-01, -1.4546e-01,\n",
       "                        3.0017e-04, -1.2191e-01,  2.1567e+00, -8.9501e-01, -2.4859e-01,\n",
       "                       -2.9390e+00, -6.9902e-01, -2.3021e+00, -4.7686e-01, -2.8722e+00,\n",
       "                       -2.1011e+00, -3.6605e+00, -1.2708e+00, -7.0387e-01, -5.5827e-01,\n",
       "                       -7.5375e-01, -1.4877e+00,  6.9137e-01, -2.7315e+00,  5.0972e-01,\n",
       "                       -1.6483e+00, -3.1692e-01, -5.2028e-01,  1.3648e+00, -1.9303e-01,\n",
       "                        2.0651e-01,  8.7924e-01,  7.1535e-02, -8.1967e-02,  1.9387e-01,\n",
       "                       -6.2536e-01, -6.3430e-01, -1.0735e+00, -4.9465e-01,  1.0197e-01,\n",
       "                       -1.6432e+00, -1.6633e-01, -7.5473e-01, -3.0325e-01, -1.3870e+00,\n",
       "                        2.3470e-02,  5.1136e-02,  1.8242e-01, -7.2523e-01, -1.1482e+00,\n",
       "                       -2.1369e-01,  1.9896e-01, -4.7297e-02, -1.2012e-01, -4.0847e-01,\n",
       "                       -4.1665e-01, -4.1949e-01, -3.5040e-01,  1.3199e+00, -2.8273e+00,\n",
       "                       -1.4801e+00,  1.0321e-01,  5.2168e-01,  9.0446e-01, -3.9527e-01,\n",
       "                       -2.5624e+00, -1.6776e+00, -1.8296e+00, -1.6860e-01, -6.3800e-02,\n",
       "                       -1.0248e+00, -3.9887e-01, -1.5573e+00, -2.7027e+00, -4.7015e-02,\n",
       "                       -4.2474e-01, -9.3326e-01, -2.2503e-01, -1.3339e+00, -2.4914e+00,\n",
       "                       -3.1134e+00, -4.3416e-02, -1.0566e-02, -2.9999e-01, -1.9798e-01,\n",
       "                       -1.1902e-01, -7.4933e-02, -2.1774e-01, -5.2700e-01,  8.4459e-03,\n",
       "                       -6.6565e-01, -1.1198e+00, -7.2390e-01,  7.1640e-02,  1.8012e-02,\n",
       "                       -3.9990e+00,  2.3485e-01, -2.4427e-01, -1.0677e-01, -7.2239e-01,\n",
       "                       -2.4971e-01,  4.6074e-02, -1.2246e-01, -2.0878e-01, -2.4668e-01,\n",
       "                        3.6488e-01, -2.3276e-01, -3.5194e-01, -4.2419e+00, -4.1180e-01,\n",
       "                       -1.2026e+00, -2.0314e+00, -9.6421e-01, -1.3143e-01, -1.8875e-01,\n",
       "                       -2.3835e-01,  9.0926e-02, -5.4457e-01, -1.2835e+00, -1.7396e+00,\n",
       "                       -5.9278e-01, -1.8997e-01, -7.8098e-01, -3.8688e-01, -1.0771e+00,\n",
       "                       -1.3194e-01, -2.0644e+00, -6.0196e-01, -4.8041e-01, -8.4978e-01,\n",
       "                       -8.9036e-01, -1.2610e-01, -1.3087e+00,  1.5370e-01, -1.8324e+00,\n",
       "                       -3.7366e-01, -2.5635e-01, -1.3323e-01,  3.5128e-02, -3.9942e-01,\n",
       "                        7.2101e-01, -1.9360e-01, -1.1908e+00, -9.6906e-01, -2.0227e+00,\n",
       "                        2.3403e-02, -1.7356e-01,  3.8720e-02, -1.6158e+00, -3.4514e-01,\n",
       "                       -5.2976e-01, -1.3542e+00, -8.7598e-01, -4.9667e-02,  4.8675e-01,\n",
       "                        3.0741e-02, -9.9927e-01, -4.1350e-01, -5.6270e-01,  1.8863e+00,\n",
       "                       -3.3894e-01,  1.0064e-01, -2.7086e+00, -8.0996e-01, -1.0306e+00,\n",
       "                       -2.3610e+00,  3.1547e-01, -1.0175e+00, -1.8508e+00, -3.5756e-01,\n",
       "                       -3.5517e+00, -1.3507e+00, -4.0698e-01, -2.8823e-01, -1.1930e+00,\n",
       "                       -6.2860e-01, -2.0653e+00, -1.4851e+00, -5.0374e-01, -2.4813e-01,\n",
       "                        5.2878e-04, -6.3078e-01, -3.0607e+00, -3.2105e+00, -8.3551e-01,\n",
       "                       -2.1474e+00, -3.7480e-01, -2.6085e+00,  5.1916e-01, -1.7299e+00,\n",
       "                       -1.5940e+00, -6.3491e-01, -5.0467e+00, -3.1715e-01, -2.8210e-01,\n",
       "                       -3.4227e+00, -2.8983e+00, -8.1787e-02, -1.3049e+00, -1.6357e+00,\n",
       "                        4.2121e-01, -6.7689e-01, -1.8530e+00,  8.4571e-02, -1.8347e-01,\n",
       "                        1.0767e+00,  5.1252e-01, -5.4402e-02, -7.3325e-01,  1.4559e+00,\n",
       "                        3.2778e-02, -2.7624e-02, -7.9013e-01,  5.9812e-02, -4.3844e-01,\n",
       "                        9.5111e-01, -5.1281e-01,  2.8746e-01, -1.1186e+00, -5.6117e-01,\n",
       "                        9.7626e-01,  1.3096e+00, -3.4287e+00, -7.7558e-01,  8.1669e-01,\n",
       "                       -2.2263e-02, -1.0721e-01,  3.2920e+00, -2.0339e-01, -3.9044e-02,\n",
       "                        7.2449e-01, -1.3997e-01, -7.0439e-01, -2.8514e-01, -4.0401e-01,\n",
       "                       -7.9735e-01,  2.8124e-01, -1.9218e-01, -1.9908e-02, -1.0310e-01,\n",
       "                       -2.2168e-01,  2.6411e-01, -7.0828e-01,  1.2072e-01,  2.8990e-01,\n",
       "                       -3.3683e+00, -1.2846e-01, -3.3580e+00, -1.2506e+00, -4.1254e+00,\n",
       "                        7.2024e-02, -9.7597e-02, -6.0509e-02, -1.5397e+00, -8.2983e-01,\n",
       "                        3.1221e-01, -9.5654e-02,  2.0362e+00, -4.6377e-01, -2.6332e-01,\n",
       "                       -2.3077e-01,  3.3586e-01, -6.1706e-01, -2.8573e+00, -5.9088e-01,\n",
       "                       -3.3837e+00,  1.6699e+00, -2.8915e-01, -2.6294e-02, -3.6830e-01,\n",
       "                       -4.2318e-01, -4.7949e+00, -1.3863e-01,  3.5866e-01,  1.3584e+00,\n",
       "                       -8.1176e-01, -2.7887e-01, -3.6421e-01, -2.5514e-01, -1.1374e+00,\n",
       "                       -1.2324e+00, -7.6799e-01, -9.5188e-01,  1.0746e-01, -1.2850e-01,\n",
       "                       -7.7249e-01, -1.1422e+00, -1.9085e+00, -8.6144e-01, -4.6152e-01,\n",
       "                        1.0976e+00, -6.2644e-01, -2.0840e+00, -1.2365e+00, -3.3727e+00,\n",
       "                       -5.0193e-01, -2.2910e+00, -2.1665e+00, -1.3764e-02, -3.2765e-01,\n",
       "                       -1.7314e+00,  3.9759e-01, -2.7223e+00, -9.5696e-01, -1.8848e+00,\n",
       "                       -1.5316e+00, -3.2899e+00, -1.4051e+00, -9.9320e-02,  1.9940e-01,\n",
       "                       -4.2602e+00, -1.9587e-01, -1.4451e+00, -1.3995e+00, -2.1251e-01,\n",
       "                       -1.3747e+00, -1.3068e+00, -1.0158e-01, -4.1651e-01, -1.9535e+00,\n",
       "                       -2.1052e-01, -3.3654e-01, -2.6572e+00, -1.1543e+00, -3.4764e-02,\n",
       "                        5.8787e-01,  1.8652e-01, -4.8536e-01, -9.9204e-01, -2.1350e+00,\n",
       "                       -2.3350e+00, -1.8727e+00, -9.6218e-01, -4.5859e-02, -5.1159e-01,\n",
       "                       -5.2813e-01, -3.8639e+00, -2.0707e+00, -1.0008e+00,  3.6691e-02,\n",
       "                       -6.0791e-01, -7.9988e-01, -7.2195e-02, -7.6961e-01, -3.7003e+00,\n",
       "                       -2.5037e+00, -6.1958e-01, -5.4770e-01, -2.5802e+00, -8.3709e-01,\n",
       "                        5.1185e-01, -4.6971e+00, -6.5049e-01, -9.7114e-02,  7.5178e-02,\n",
       "                       -2.1757e+00,  6.3460e-01, -5.8820e-01, -2.1640e+00, -5.0399e-01,\n",
       "                       -4.4157e-01, -1.1044e+00], device='cuda:0')),\n",
       "              ('module.layer2.2.bn3.running_mean',\n",
       "               tensor([ 1.5742e-01, -4.8701e-01, -3.1716e-01,  8.1418e-01, -1.0842e+00,\n",
       "                        8.8062e-02,  3.8418e-01,  6.2046e-01,  1.0229e-01,  4.3919e-01,\n",
       "                        3.2635e-02,  1.6178e-01, -3.7307e-01, -5.9531e-01,  5.6518e-01,\n",
       "                       -1.0974e+00, -1.6886e+00,  3.7230e-01, -8.8274e-02, -7.9842e-02,\n",
       "                       -3.1509e-01,  1.5807e-01, -1.4186e-01,  3.3008e-01, -1.3264e+00,\n",
       "                       -3.5751e-01, -5.3412e-01,  5.4358e-01, -1.0804e+00,  2.1583e-01,\n",
       "                       -1.2881e+00, -2.4631e-01, -1.2353e-01,  4.6917e-01, -4.2844e-01,\n",
       "                        1.0879e+00,  4.8703e-01,  1.6238e-01,  6.7081e-01, -4.3451e-02,\n",
       "                        1.7954e-02,  6.6627e-02, -5.8149e-01,  6.9746e-01,  5.5437e-01,\n",
       "                       -8.5272e-02, -3.4138e-03,  2.1646e+00,  4.2450e-01, -7.9456e-02,\n",
       "                       -7.4138e-01, -4.9695e-01, -8.0387e-01, -9.8332e-02, -5.0128e-01,\n",
       "                       -3.0292e-01,  4.6954e-01, -1.3410e-01, -1.0456e+00, -4.6550e-01,\n",
       "                        2.8774e-01, -2.2215e-01,  4.0869e-01,  1.5767e-01,  1.5070e-01,\n",
       "                        1.5338e-01, -3.3223e-01,  9.5016e-01, -4.3141e-01, -3.7428e-01,\n",
       "                        1.4617e-01, -8.6581e-01,  9.0704e-01,  8.5876e-01, -1.8967e-01,\n",
       "                       -1.7616e-01,  3.6055e-01,  5.9892e-01,  3.2534e-01,  5.0961e-01,\n",
       "                       -6.1943e-01,  6.3047e-01, -3.8964e-01,  1.5664e-01, -2.8719e-01,\n",
       "                       -1.5999e+00, -1.6613e-02,  1.4607e+00, -2.7374e-01, -6.3934e-01,\n",
       "                       -3.5070e-01,  6.9996e-01, -7.4188e-02,  7.9307e-01, -2.6198e-01,\n",
       "                        6.3399e-01,  9.4448e-01, -3.1204e-01, -1.7743e-01,  5.2556e-02,\n",
       "                       -2.0605e-03, -2.7365e-01, -7.4178e-01,  5.3556e-01, -2.3447e-02,\n",
       "                        1.3023e+00,  9.9226e-01,  9.3410e-01, -6.4407e-01,  1.2993e-01,\n",
       "                       -1.3432e-01, -7.6579e-02,  6.6393e-02, -5.3305e-02, -4.3196e-01,\n",
       "                       -5.0772e-03,  8.8939e-01,  6.0806e-01, -4.3396e-01,  2.4933e-01,\n",
       "                       -2.6809e-01, -3.7858e-01,  8.0925e-01, -3.8172e-01, -3.2659e-01,\n",
       "                       -7.2289e-02,  6.1654e-01,  6.9185e-01, -9.4001e-01, -7.4915e-01,\n",
       "                        6.2822e-01, -1.0280e-01, -1.6235e+00, -4.9758e-01, -6.6775e-01,\n",
       "                        1.6482e-01, -5.4349e-01,  7.6102e-01,  2.3804e-01,  9.7235e-01,\n",
       "                        2.4177e+00,  6.5824e-01, -2.8564e-01,  4.0205e-01,  1.0862e+00,\n",
       "                       -9.9411e-02,  3.4891e-01,  1.9121e-02, -1.5919e+00, -6.6548e-01,\n",
       "                       -4.3588e-03,  2.4496e-01,  2.3553e-01,  1.0549e+00, -9.5766e-02,\n",
       "                       -2.5915e-01,  1.2087e+00, -6.7383e-01, -1.6292e-01, -6.8323e-01,\n",
       "                       -3.6011e-02,  1.5954e-01, -1.7281e+00,  3.5333e-01, -1.5025e-01,\n",
       "                       -4.2118e-02, -9.9576e-02,  1.0079e-01, -3.1632e-01,  2.1680e-01,\n",
       "                       -6.3762e-01,  7.2580e-01, -9.3069e-01,  5.4531e-02,  8.2998e-01,\n",
       "                        8.5780e-01, -6.3301e-01, -5.1721e-01,  5.2565e-01, -6.0350e-01,\n",
       "                       -5.1616e-01, -3.0357e-01, -4.7258e-01,  2.3134e-01,  2.5244e+00,\n",
       "                        2.7135e+00,  5.5204e-01,  1.2979e-01, -4.8508e-01,  6.6697e-01,\n",
       "                        4.9801e-01, -1.9388e-01,  1.2589e-01,  2.2043e-01,  8.2451e-01,\n",
       "                        6.2881e-01,  6.9107e-01, -9.1506e-02,  8.9171e-01,  2.3899e-01,\n",
       "                       -3.3564e-01, -3.1507e-01, -4.4656e-02,  9.5708e-02, -5.6712e-01,\n",
       "                       -1.0138e-01, -4.7847e-01, -7.1659e-01, -2.5669e+00,  5.9849e-01,\n",
       "                       -1.1962e+00, -2.8244e-01, -3.9646e-01,  4.2221e-01, -9.8063e-01,\n",
       "                       -1.0738e-02, -1.2060e-01,  9.7006e-01, -3.1987e-01,  5.5535e-01,\n",
       "                        1.6156e-01,  9.1901e-01, -2.7472e-01,  3.9225e-01,  1.1726e-01,\n",
       "                       -2.0904e-01, -7.1609e-01,  5.0099e-01,  4.0161e-01, -1.8810e+00,\n",
       "                       -1.3549e-01,  4.5072e-01,  2.9010e-01,  1.8341e-01,  3.1231e-02,\n",
       "                        3.4209e-01,  7.8913e-02,  3.0111e-01,  2.6940e-01,  6.8616e-02,\n",
       "                        6.6512e-01, -1.0720e+00, -4.5165e-01,  8.5649e-02, -5.2470e-01,\n",
       "                       -2.8887e-01,  4.5664e-02,  1.6197e-01, -3.5676e-02,  1.3009e+00,\n",
       "                        5.8845e-01,  1.0018e-01, -4.1968e-01,  3.5271e-01,  8.6442e-02,\n",
       "                       -3.1798e-01, -4.8497e-02, -5.2438e-01, -7.4413e-02,  1.2919e-01,\n",
       "                       -1.9592e-01, -1.5633e+00, -9.5183e-02,  3.9705e-01,  4.2581e-01,\n",
       "                       -2.6799e-01, -8.6414e-02,  1.5293e-01, -6.0897e-01,  1.2733e+00,\n",
       "                        6.0234e-01,  1.7824e-01,  2.2708e+00,  1.5573e+00, -4.6717e-01,\n",
       "                       -1.5627e-01,  6.3571e-01, -7.1808e-01,  6.4317e-02,  9.2510e-01,\n",
       "                       -7.5015e-01,  1.1044e+00, -5.0317e-01,  9.3114e-02, -2.9387e-01,\n",
       "                       -1.6323e-01, -4.7122e-01,  1.7400e-01,  4.6139e-01,  1.3608e-01,\n",
       "                       -2.9906e-01,  1.7604e-01, -4.4563e-01,  6.6913e-01, -5.6484e-02,\n",
       "                       -1.2310e+00, -7.7873e-01, -1.0493e-01, -1.3265e+00, -6.1440e-02,\n",
       "                        6.3165e-02,  1.3141e+00, -1.0763e+00,  6.3255e-01, -5.1725e-01,\n",
       "                        4.6124e-01,  1.1968e+00, -9.7258e-02, -7.4677e-01,  3.1262e-01,\n",
       "                       -2.4553e-01, -1.9446e-01,  3.6683e-02,  1.6231e+00, -2.0630e+00,\n",
       "                       -5.9719e-01, -7.5327e-01,  1.3302e-02, -6.5168e-01, -1.9542e-01,\n",
       "                        3.8517e-02, -1.1145e+00, -3.6816e-01,  2.2096e-01, -2.1241e+00,\n",
       "                        9.3986e-01, -4.2553e-01, -3.2076e-01,  4.9835e-01,  5.7021e-01,\n",
       "                        6.4953e-01, -1.5778e-01,  3.5951e-01,  3.2323e-01, -8.4971e-01,\n",
       "                        1.5804e-01,  4.2088e-02, -1.3264e-02,  9.1916e-02, -4.5243e-01,\n",
       "                       -1.0804e-01,  9.0043e-02, -5.8512e-01,  1.0241e+00, -1.2183e-01,\n",
       "                       -1.2323e-01, -7.0884e-01, -5.6774e-01,  1.8060e-01,  4.3854e-01,\n",
       "                        7.9077e-01,  2.3314e-01, -5.9556e-01, -2.2456e+00, -1.0928e-01,\n",
       "                        7.0987e-02, -7.0796e-01,  6.4552e-01,  8.2478e-01,  1.5381e+00,\n",
       "                        6.4801e-01, -3.6610e-01,  8.1701e-01,  4.6845e-01,  2.4551e-02,\n",
       "                        9.6110e-01,  3.9904e-01, -5.9304e-01,  7.1606e-01,  1.2632e+00,\n",
       "                        3.6130e-01,  1.6803e-01,  3.7421e-01, -2.2870e-01,  4.4580e-01,\n",
       "                       -3.2299e-01,  5.8083e-01,  1.0277e+00, -4.6627e-01, -6.0082e-01,\n",
       "                       -2.6065e-01,  3.2886e-01, -1.1210e+00, -3.0039e-01,  3.2867e-01,\n",
       "                        1.1757e+00,  6.2999e-02,  3.9546e-01, -3.0096e-02,  4.8676e-01,\n",
       "                        2.7617e-01,  2.6690e-01,  3.0493e-01,  1.9029e-01, -8.5785e-01,\n",
       "                       -2.8711e-01,  8.1325e-02, -3.4349e-01,  3.2037e-02, -1.9892e-01,\n",
       "                       -1.5711e-03, -3.5342e-01,  1.9774e-01, -1.9597e-01,  2.7359e-01,\n",
       "                        8.3459e-01,  1.7803e-01, -1.3908e+00, -4.9018e-01, -8.8673e-01,\n",
       "                       -1.3486e+00,  1.0960e+00, -3.0248e-01,  4.0071e-01, -9.5759e-01,\n",
       "                        7.0902e-01,  2.0207e-01,  7.2639e-01, -1.0887e-01,  9.4811e-01,\n",
       "                        5.3007e-01, -1.0325e+00,  8.9911e-02,  2.7075e-02, -1.0724e+00,\n",
       "                       -1.1809e+00, -1.5419e-01,  1.1659e+00, -6.6045e-01, -6.8091e-01,\n",
       "                        9.7159e-01,  8.6392e-02, -5.7253e-01,  2.1332e-02, -1.8056e-01,\n",
       "                        3.1241e-02,  7.5223e-02, -1.0650e+00,  4.8480e-01, -1.1528e+00,\n",
       "                        2.6832e-01, -1.1488e-01,  7.7954e-02, -5.6845e-02,  4.0486e-02,\n",
       "                        1.3837e-01, -2.0051e-01,  1.1804e-01, -6.1454e-01, -2.3173e-01,\n",
       "                        7.9063e-01, -4.7663e-02, -3.3297e-01,  7.4250e-01, -1.3778e-01,\n",
       "                       -2.6182e-01,  3.5047e-01, -1.0542e+00, -1.4441e-01, -1.6773e-01,\n",
       "                       -5.8190e-01,  2.5418e-01,  1.0338e+00,  2.3970e-01, -4.8108e-01,\n",
       "                        8.2839e-01,  7.8512e-01, -7.1914e-01, -4.6192e-01,  3.0119e-01,\n",
       "                        5.0452e-04, -7.8020e-02, -2.4934e-01,  5.3873e-02, -2.9602e-01,\n",
       "                        6.9857e-01,  7.7214e-02, -4.1060e-01,  5.7820e-01,  1.6414e-01,\n",
       "                       -1.8119e-01, -3.8033e-01, -7.3886e-01,  3.4832e-01, -3.9055e-01,\n",
       "                       -9.5412e-01, -9.2023e-01, -3.0561e-01, -4.6519e-01,  6.5760e-01,\n",
       "                       -1.7701e-01, -5.8391e-01, -2.3489e-01, -1.6948e-01, -2.6517e-01,\n",
       "                       -6.1221e-01,  7.9825e-01, -1.1472e-01,  7.3484e-02, -3.2917e-01,\n",
       "                        1.1133e+00, -9.9153e-01,  1.9103e-01,  3.8332e-01,  6.9459e-01,\n",
       "                       -1.1913e+00,  8.4250e-02,  4.0069e-02, -6.2467e-01, -6.9822e-01,\n",
       "                       -3.0385e-01,  5.5788e-02], device='cuda:0')),\n",
       "              ('module.layer2.2.bn3.running_var',\n",
       "               tensor([0.2111, 0.5591, 0.1372, 0.4562, 0.5044, 0.3962, 0.1347, 0.6523, 0.2731,\n",
       "                       2.8660, 0.1302, 0.1553, 0.0906, 1.5518, 1.4196, 0.4189, 0.2127, 0.1024,\n",
       "                       0.2036, 0.0437, 0.2717, 0.3367, 0.2427, 0.2000, 0.4239, 0.1854, 0.5895,\n",
       "                       0.3322, 1.1577, 0.4657, 0.2907, 0.5638, 0.8996, 0.5750, 0.4680, 0.5914,\n",
       "                       0.9414, 0.1245, 0.2640, 0.3423, 0.1390, 0.0275, 0.4484, 0.3968, 0.6057,\n",
       "                       0.8142, 0.0194, 0.5743, 0.3870, 0.3549, 0.1335, 0.3396, 0.6247, 0.3383,\n",
       "                       0.3248, 0.1143, 0.1587, 0.1626, 0.7099, 0.3712, 0.2858, 0.2204, 0.3923,\n",
       "                       0.3009, 0.3849, 0.4460, 0.2695, 0.5689, 0.1653, 0.2574, 0.6771, 0.4763,\n",
       "                       0.7732, 0.2757, 0.3875, 0.4526, 0.2331, 0.3145, 0.4427, 0.1332, 0.2799,\n",
       "                       0.2250, 0.1643, 0.2834, 0.2228, 0.2618, 0.3457, 1.4452, 0.2633, 0.1450,\n",
       "                       0.5483, 0.3660, 0.2763, 0.2360, 0.5777, 0.6255, 0.4437, 0.3131, 0.1972,\n",
       "                       0.2862, 0.5354, 0.2870, 0.4217, 0.6750, 0.5080, 0.5580, 0.2006, 0.4299,\n",
       "                       0.2950, 0.1209, 0.2008, 0.0735, 0.2045, 0.3979, 0.1691, 0.0210, 0.2803,\n",
       "                       0.1926, 0.3200, 0.3068, 0.1619, 0.4095, 0.2601, 0.1851, 0.1031, 0.1376,\n",
       "                       0.1990, 2.2539, 0.8428, 0.4073, 0.4423, 0.4639, 0.9731, 0.4646, 0.6514,\n",
       "                       0.1468, 0.1017, 0.6062, 0.2891, 0.3279, 0.2647, 0.9620, 0.4090, 1.1353,\n",
       "                       0.4629, 0.6471, 0.2076, 0.3618, 1.7278, 0.3652, 0.5778, 0.5634, 0.2666,\n",
       "                       0.3734, 0.1645, 0.3570, 0.2964, 1.3309, 0.3027, 0.2910, 0.3397, 0.1856,\n",
       "                       0.3328, 0.2454, 0.0592, 0.3704, 0.4332, 0.3105, 0.4714, 0.8699, 0.8895,\n",
       "                       0.4994, 0.3508, 0.3415, 0.6448, 0.1696, 0.7872, 0.2026, 3.4328, 0.6969,\n",
       "                       0.3883, 0.4034, 0.2273, 0.3416, 0.7004, 0.4099, 0.1512, 0.5726, 0.2907,\n",
       "                       0.1191, 0.8258, 0.1445, 0.5779, 0.2212, 0.2890, 0.0453, 0.3242, 0.1904,\n",
       "                       0.5039, 0.3128, 0.2511, 0.2247, 0.1408, 0.2352, 0.5966, 0.4375, 0.1147,\n",
       "                       0.3443, 1.0245, 0.4608, 0.2712, 0.1070, 0.4244, 0.2152, 0.8797, 0.4441,\n",
       "                       0.2505, 0.3492, 0.2136, 0.1690, 0.3306, 0.2517, 0.2597, 0.5672, 0.1310,\n",
       "                       0.2231, 1.9819, 0.4666, 0.2346, 0.3805, 0.0962, 0.3060, 0.1370, 0.3778,\n",
       "                       0.3302, 0.1419, 1.4971, 0.3738, 0.2134, 0.1692, 0.1848, 0.5510, 0.5643,\n",
       "                       0.0410, 0.3007, 1.2883, 0.5056, 0.6708, 0.1473, 0.3826, 0.1295, 0.1575,\n",
       "                       0.1647, 0.1796, 0.7662, 0.4003, 0.2581, 0.2933, 0.7576, 0.9881, 0.3391,\n",
       "                       0.5261, 0.1360, 0.1680, 0.1710, 0.3809, 0.3171, 0.2523, 0.5630, 0.3386,\n",
       "                       0.2449, 0.1011, 0.6027, 0.5353, 0.2587, 0.2070, 0.5941, 1.9445, 0.1252,\n",
       "                       0.3336, 0.2988, 0.1015, 0.2086, 0.1484, 0.4761, 0.4418, 0.1280, 0.3508,\n",
       "                       0.9681, 0.4269, 0.1687, 0.1813, 0.6125, 0.2143, 0.3387, 0.2702, 0.2166,\n",
       "                       0.3782, 0.4898, 0.4109, 0.2553, 0.2373, 0.4051, 0.3298, 0.0788, 0.2428,\n",
       "                       0.3952, 0.3327, 0.4323, 1.2758, 0.0489, 0.5699, 0.9913, 0.5527, 0.3517,\n",
       "                       0.4997, 0.1479, 0.3277, 0.2168, 0.2614, 0.2611, 0.3265, 0.3503, 0.1285,\n",
       "                       0.5754, 0.2201, 0.2628, 0.3889, 0.1957, 0.1338, 0.4265, 0.2191, 0.2066,\n",
       "                       0.1070, 0.3213, 0.2473, 0.1943, 0.3601, 0.2720, 0.4597, 0.1102, 0.2500,\n",
       "                       0.8658, 0.4708, 0.1670, 0.1307, 0.3609, 0.2814, 0.2161, 0.3271, 0.6545,\n",
       "                       0.5983, 0.2879, 0.5487, 0.1795, 0.1965, 0.5546, 0.2051, 0.2242, 1.1592,\n",
       "                       0.1422, 0.6509, 0.3121, 0.0653, 0.1760, 0.5723, 0.2664, 0.4784, 0.3770,\n",
       "                       0.3709, 0.2071, 0.6874, 0.5180, 0.2798, 0.8353, 0.1254, 0.1348, 1.2275,\n",
       "                       0.1261, 0.2272, 0.1574, 0.1170, 0.2353, 0.1693, 0.6769, 0.4253, 1.5038,\n",
       "                       0.2547, 0.1678, 0.5385, 0.1729, 1.3618, 0.1230, 0.0709, 0.6638, 0.3503,\n",
       "                       0.1654, 0.4327, 0.3365, 0.4434, 0.2045, 0.0939, 0.8189, 0.1835, 0.4629,\n",
       "                       0.4737, 0.2772, 0.4248, 0.3578, 0.4270, 0.3874, 1.0987, 0.1796, 0.4141,\n",
       "                       0.3756, 0.4243, 0.3105, 0.0920, 0.2707, 0.2643, 0.5080, 1.2831, 0.1281,\n",
       "                       0.5212, 0.8556, 0.8568, 0.4610, 0.3227, 1.5453, 0.5173, 0.8360, 0.1704,\n",
       "                       0.3714, 0.0813, 0.1273, 0.2067, 0.6893, 0.2486, 0.5463, 0.2923, 0.6759,\n",
       "                       0.1765, 0.2609, 0.2725, 0.5816, 0.3699, 0.2250, 0.5214, 0.0978, 0.1339,\n",
       "                       0.5724, 0.0177, 0.3593, 0.1606, 0.3204, 0.4241, 0.9282, 0.4198, 0.2364,\n",
       "                       0.4663, 1.3345, 0.1504, 0.5674, 0.3466, 0.4015, 0.4132, 0.4229, 0.3691,\n",
       "                       0.5909, 1.2529, 0.1366, 0.5936, 0.1908, 0.5728, 0.7497, 0.7037, 0.6930,\n",
       "                       0.2598, 0.6710, 0.4093, 0.3504, 0.6731, 0.3047, 0.8008, 0.4343, 0.3700,\n",
       "                       0.4715, 0.2087, 0.2172, 0.1135, 0.3278, 0.5246, 0.1162, 0.2815, 0.5398,\n",
       "                       0.5751, 0.7228, 0.2425, 0.3756, 0.1578, 0.9553, 0.3127, 0.5101, 0.0836,\n",
       "                       0.5929, 0.3545, 0.3593, 0.2329, 0.3236, 0.5126, 0.5992, 0.3540],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.2.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.3.conv1.weight',\n",
       "               tensor([[[[ 0.0345]],\n",
       "               \n",
       "                        [[-0.0191]],\n",
       "               \n",
       "                        [[-0.0151]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0550]],\n",
       "               \n",
       "                        [[ 0.1162]],\n",
       "               \n",
       "                        [[ 0.0035]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0028]],\n",
       "               \n",
       "                        [[ 0.0767]],\n",
       "               \n",
       "                        [[-0.0034]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0552]],\n",
       "               \n",
       "                        [[ 0.0189]],\n",
       "               \n",
       "                        [[-0.0080]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0869]],\n",
       "               \n",
       "                        [[ 0.0245]],\n",
       "               \n",
       "                        [[-0.0170]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0021]],\n",
       "               \n",
       "                        [[-0.0851]],\n",
       "               \n",
       "                        [[-0.0099]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0359]],\n",
       "               \n",
       "                        [[ 0.0146]],\n",
       "               \n",
       "                        [[-0.0151]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0172]],\n",
       "               \n",
       "                        [[ 0.0155]],\n",
       "               \n",
       "                        [[-0.0193]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0026]],\n",
       "               \n",
       "                        [[-0.0965]],\n",
       "               \n",
       "                        [[-0.0559]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0455]],\n",
       "               \n",
       "                        [[ 0.0399]],\n",
       "               \n",
       "                        [[ 0.0330]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0056]],\n",
       "               \n",
       "                        [[-0.0074]],\n",
       "               \n",
       "                        [[ 0.0524]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0574]],\n",
       "               \n",
       "                        [[-0.0276]],\n",
       "               \n",
       "                        [[ 0.0098]]]], device='cuda:0')),\n",
       "              ('module.layer2.3.bn1.weight',\n",
       "               tensor([1.2502, 2.0285, 1.5629, 1.6770, 1.2831, 1.0744, 1.4260, 2.0385, 1.8546,\n",
       "                       1.9808, 1.5137, 1.7291, 0.9660, 1.7924, 1.9891, 1.4599, 1.3494, 2.0011,\n",
       "                       1.3521, 2.3360, 1.8829, 2.4801, 1.1257, 1.7505, 1.1386, 1.9175, 1.6863,\n",
       "                       1.6112, 1.8551, 1.6793, 1.7381, 1.0357, 2.9406, 1.7731, 1.9923, 0.9117,\n",
       "                       1.5472, 1.9534, 1.7087, 1.7323, 1.8177, 2.2400, 2.1442, 2.0736, 1.7320,\n",
       "                       1.8568, 1.5107, 1.8620, 1.1404, 1.8692, 1.8902, 1.1967, 1.6972, 1.8605,\n",
       "                       1.3849, 2.2414, 1.4213, 1.3612, 1.4431, 1.2532, 2.4949, 1.9312, 1.4481,\n",
       "                       2.3998, 1.4636, 1.2996, 1.1686, 1.1267, 1.3050, 1.8412, 1.8452, 2.2741,\n",
       "                       2.0522, 1.4242, 1.5328, 1.7748, 1.8657, 2.4919, 0.9296, 2.9569, 1.8876,\n",
       "                       1.9175, 2.5281, 2.1879, 1.9418, 2.7817, 1.5869, 1.7026, 2.1954, 1.7054,\n",
       "                       1.6994, 1.2529, 1.8558, 1.9387, 1.9689, 1.9473, 1.9001, 1.8772, 1.6229,\n",
       "                       2.6807, 2.0922, 1.4542, 1.0538, 2.0130, 1.7309, 1.3082, 2.1591, 1.2560,\n",
       "                       2.2483, 1.3920, 1.7694, 2.0218, 2.0979, 1.7615, 2.0484, 1.7886, 1.7066,\n",
       "                       1.6502, 2.3041, 1.8107, 1.9431, 1.8059, 1.7167, 2.2500, 1.7968, 1.7908,\n",
       "                       1.7417, 1.9899], device='cuda:0')),\n",
       "              ('module.layer2.3.bn1.bias',\n",
       "               tensor([ 0.0720, -1.3964, -0.3521, -0.3472,  1.3267,  1.4671, -0.2311, -2.0064,\n",
       "                       -1.2785, -1.2484, -0.5741, -0.7847,  1.2956, -0.9337, -1.1841,  0.2482,\n",
       "                        0.4576, -2.1092, -0.0541, -1.0112, -1.0982, -1.6902,  1.6934, -0.7029,\n",
       "                        0.8146, -0.8976, -0.0781,  0.2062, -0.7905,  0.0112, -0.6085,  1.2221,\n",
       "                       -2.0490, -1.0427, -1.2202,  1.5873, -0.7571, -0.8144,  0.3784, -0.5888,\n",
       "                       -1.1859, -1.9806, -1.4015, -1.6725, -1.0224, -0.4434,  0.0579, -1.2041,\n",
       "                        0.7831, -0.9813, -0.5674,  1.1701, -0.9585, -0.9405,  0.6064, -2.2334,\n",
       "                       -0.3261,  0.2511,  1.3913, -0.0400, -1.8410, -1.4723, -0.1036, -2.6584,\n",
       "                        0.1013,  0.3503,  0.9565,  0.8288,  0.2845, -1.1661, -0.9146, -2.5427,\n",
       "                       -1.4219, -0.1016,  0.3022, -0.8028, -0.9724, -1.6245,  1.3016, -4.9879,\n",
       "                       -1.2964, -1.2385, -1.0167, -2.2016, -1.7977, -2.6681, -0.3089, -0.5421,\n",
       "                       -2.1151, -0.4147, -0.0141,  1.3135, -1.0850, -1.3863, -1.6862, -1.5945,\n",
       "                       -0.3883, -0.7924,  0.2804, -2.6080, -1.7109, -0.4234,  0.6127, -1.5109,\n",
       "                       -0.7014,  0.2694, -2.0651,  0.2213, -2.2633,  0.4858, -0.9193, -1.3224,\n",
       "                       -1.9473, -0.2248, -0.9994, -0.4587,  0.1544, -0.0276, -1.1944, -0.6765,\n",
       "                       -0.5920, -0.8565, -0.1461, -3.1082, -0.8640, -0.6586,  0.3790, -1.5647],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.3.bn1.running_mean',\n",
       "               tensor([-1.4687,  0.2456,  1.6771, -0.5097,  0.4168, -2.0970, -1.7134, -0.3576,\n",
       "                       -2.1288, -1.8006, -1.0799, -1.2775, -0.6128,  0.9360, -0.1714,  0.8414,\n",
       "                        2.7726, -1.4711, -0.2880,  1.1593,  1.0771, -0.2942,  0.9506, -1.6763,\n",
       "                        0.4802, -1.0652, -0.4196, -0.2170, -1.6481, -0.6423, -0.6067, -1.1493,\n",
       "                       -0.1446, -0.6918, -2.1836,  0.1729, -0.5692, -0.5224,  0.6413, -0.1380,\n",
       "                       -2.0218, -1.8994,  0.4370, -1.7292, -0.0456,  0.7870, -0.9262,  1.8398,\n",
       "                        0.3718, -1.4899,  0.0090,  0.3461, -0.2063,  0.0699,  1.7103, -1.6303,\n",
       "                        0.5835,  0.4824,  5.3867,  0.9362, -3.4983, -1.6897,  0.2282, -3.4443,\n",
       "                        0.8981, -0.6134,  2.1036, -0.6172,  0.8200, -0.2080, -1.7096, -1.8264,\n",
       "                       -1.1212, -0.1244, -0.1211, -1.7428,  0.2941, -3.2220,  2.9550, -1.3406,\n",
       "                       -2.3954, -1.6090, -0.7579, -1.7724,  0.3388, -1.4019,  0.5438,  2.7939,\n",
       "                       -0.4813, -0.5663, -0.8128,  2.3894,  1.4368, -0.9651, -1.1260, -1.0449,\n",
       "                        0.4112, -1.0214, -0.2109, -1.9579, -2.0047,  0.6986,  1.7554, -0.5576,\n",
       "                       -3.2406,  1.2783, -1.9589, -0.1059, -0.7550, -0.1716, -0.6312, -1.0772,\n",
       "                       -0.4205, -0.1638, -1.7753, -1.0136,  1.0517, -0.8070, -1.8264, -1.3192,\n",
       "                        0.2468,  1.1600, -1.1048,  0.7626, -0.2387,  1.1417,  0.6982, -1.2796],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.3.bn1.running_var',\n",
       "               tensor([ 2.1849,  3.9136,  5.5874,  6.0034,  7.8801,  4.6289,  4.0002,  3.7412,\n",
       "                        4.2086,  5.3690,  3.2873,  4.8538,  3.4355,  5.7018,  5.1484,  5.9890,\n",
       "                        6.0298,  3.2236,  3.9165,  4.2291,  4.7112,  5.3001,  6.3829,  5.2511,\n",
       "                        4.6831,  4.8440,  6.7567,  7.4945,  4.4547,  7.0560,  5.5741,  4.4907,\n",
       "                        7.3051,  3.8920,  4.4695,  3.6400,  5.1163,  4.2741,  9.3588,  6.5106,\n",
       "                        4.9756,  4.0222,  6.0614,  4.2580,  3.8922,  5.7461,  5.7582,  2.8656,\n",
       "                        4.4693,  5.0380,  5.7077,  4.1157,  8.1013,  5.0467,  5.5160,  4.4960,\n",
       "                        3.8301,  5.0354, 10.2729,  6.0649, 14.9101,  4.0285,  4.9496,  3.0848,\n",
       "                        5.2884,  4.4613,  4.1155,  5.5297,  3.7673,  3.7510,  6.8360,  2.5320,\n",
       "                        5.2038,  3.8365,  8.5568,  4.6713,  4.9234,  4.6860,  3.4742,  2.4915,\n",
       "                        5.2124,  4.4975, 10.2164,  3.2967,  2.6567,  4.7848,  4.1465,  5.5145,\n",
       "                        3.3039,  7.0586,  6.7076,  7.7128,  4.1939,  5.3360,  3.7321,  4.0181,\n",
       "                        7.2441,  4.4370,  6.8300,  4.2466,  5.5526,  3.1248,  4.1777,  3.1999,\n",
       "                        4.8197,  4.5070,  3.0779,  4.3584,  2.9516,  6.1944,  4.7083,  4.3339,\n",
       "                        3.1943,  5.7936,  4.8088,  5.4160,  8.5610,  7.3216,  4.2493,  5.0659,\n",
       "                        5.6638,  5.0285,  6.5853,  2.4885,  5.1018,  6.6961,  9.7415,  3.7309],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.3.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.3.conv2.weight',\n",
       "               tensor([[[[-2.4675e-02, -4.6269e-02, -2.9714e-02],\n",
       "                         [ 1.0433e-02,  1.9609e-02,  1.4707e-02],\n",
       "                         [ 1.1039e-02,  4.6750e-02,  1.3237e-02]],\n",
       "               \n",
       "                        [[ 4.3310e-02,  2.5689e-02, -8.9794e-03],\n",
       "                         [ 1.2085e-01, -7.5555e-02, -1.4842e-01],\n",
       "                         [-2.3657e-02, -1.6641e-02, -2.4451e-02]],\n",
       "               \n",
       "                        [[ 7.4579e-02,  5.3985e-02,  4.8826e-02],\n",
       "                         [-9.9472e-02, -4.7374e-02, -1.5333e-01],\n",
       "                         [ 9.1230e-03,  6.9254e-02, -1.1752e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.6210e-02,  1.9008e-02,  1.0361e-02],\n",
       "                         [ 3.9578e-02,  6.4555e-04,  1.5854e-02],\n",
       "                         [ 5.4420e-03, -2.3810e-02, -2.8343e-02]],\n",
       "               \n",
       "                        [[-5.2603e-03,  7.7975e-03, -1.6838e-02],\n",
       "                         [ 5.3945e-02,  8.9536e-02,  4.2815e-02],\n",
       "                         [-1.0489e-02,  1.0812e-02, -3.1334e-03]],\n",
       "               \n",
       "                        [[-7.3164e-03,  1.2415e-02, -6.3188e-03],\n",
       "                         [ 3.9681e-05, -2.2272e-02,  6.5911e-03],\n",
       "                         [ 1.3710e-02,  1.6347e-02,  7.3069e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.0946e-02, -7.3398e-02, -1.7135e-02],\n",
       "                         [-8.0022e-02,  9.6398e-02, -1.0320e-01],\n",
       "                         [-7.1809e-02, -1.1336e-01, -5.5267e-02]],\n",
       "               \n",
       "                        [[ 5.4745e-02,  6.9545e-02, -1.5994e-02],\n",
       "                         [ 1.3245e-01, -4.8640e-02, -3.9357e-02],\n",
       "                         [ 1.7317e-02, -8.6066e-02,  6.4489e-02]],\n",
       "               \n",
       "                        [[ 5.5794e-02, -4.9508e-02,  5.8879e-02],\n",
       "                         [-2.0677e-02, -3.5996e-01,  5.7805e-03],\n",
       "                         [ 3.4668e-02, -5.8045e-02,  3.8463e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.3350e-02,  4.0228e-02, -3.7382e-02],\n",
       "                         [-2.3329e-02, -1.6260e-02, -7.8986e-02],\n",
       "                         [ 2.6491e-03, -1.6790e-02, -4.1278e-02]],\n",
       "               \n",
       "                        [[ 9.7551e-03,  6.5613e-02,  5.9960e-02],\n",
       "                         [ 7.7135e-02,  7.9769e-03, -1.2844e-01],\n",
       "                         [ 3.8423e-03,  4.4843e-02, -2.7892e-02]],\n",
       "               \n",
       "                        [[ 3.3767e-02, -4.6237e-02, -1.5345e-02],\n",
       "                         [ 1.7151e-02, -5.4672e-02, -1.3158e-02],\n",
       "                         [ 1.1058e-02, -4.5592e-02, -5.2785e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.7175e-03, -8.2540e-03, -1.6253e-02],\n",
       "                         [-1.0687e-02, -1.3383e-02, -2.4001e-02],\n",
       "                         [-9.5307e-03,  2.7917e-02,  9.1313e-03]],\n",
       "               \n",
       "                        [[-6.8209e-03,  2.0474e-02, -3.7328e-02],\n",
       "                         [-5.7486e-02,  5.3059e-03, -5.9011e-02],\n",
       "                         [-5.3485e-03,  1.1397e-02, -7.7205e-03]],\n",
       "               \n",
       "                        [[ 2.1859e-03, -6.1824e-03, -1.9292e-02],\n",
       "                         [ 4.9695e-02,  2.7505e-02, -3.4311e-02],\n",
       "                         [-6.6444e-03, -1.3708e-02, -2.4095e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.4187e-02,  2.0398e-02,  2.8819e-02],\n",
       "                         [ 2.3119e-02, -3.8728e-03,  1.1611e-02],\n",
       "                         [-3.6601e-02, -4.3287e-02, -3.0027e-02]],\n",
       "               \n",
       "                        [[-1.5180e-02,  3.1369e-02, -2.8670e-02],\n",
       "                         [-5.3393e-02,  1.5609e-02,  3.7226e-02],\n",
       "                         [-2.0524e-02, -9.7906e-03,  1.4670e-02]],\n",
       "               \n",
       "                        [[-1.2530e-02, -3.1727e-02, -7.2193e-03],\n",
       "                         [-5.1185e-03, -3.0409e-02, -1.0289e-02],\n",
       "                         [ 2.7820e-03, -1.1731e-02, -5.2910e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.9873e-02,  3.6239e-03, -3.1597e-03],\n",
       "                         [-1.4703e-02, -4.1458e-02,  1.2898e-02],\n",
       "                         [ 1.0662e-02,  4.2499e-02,  3.9934e-02]],\n",
       "               \n",
       "                        [[-1.9013e-02, -3.9334e-02,  4.4795e-02],\n",
       "                         [-6.2360e-02, -7.9181e-02,  2.6708e-02],\n",
       "                         [-6.9447e-03, -2.8600e-03, -7.1959e-02]],\n",
       "               \n",
       "                        [[ 2.4044e-02,  6.5966e-02,  1.0420e-02],\n",
       "                         [ 1.6643e-02,  1.7883e-01, -4.7740e-02],\n",
       "                         [ 8.3462e-03, -1.8690e-02, -1.3326e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.8280e-02,  2.9074e-02,  1.5113e-02],\n",
       "                         [ 3.2642e-02,  4.3982e-04,  3.9471e-02],\n",
       "                         [-2.8829e-02, -5.1389e-02,  2.9936e-03]],\n",
       "               \n",
       "                        [[ 3.2786e-02,  1.5272e-02,  3.7973e-02],\n",
       "                         [-1.6023e-02, -4.6051e-02, -8.0332e-03],\n",
       "                         [-3.2205e-02, -4.8992e-02, -5.9254e-02]],\n",
       "               \n",
       "                        [[-2.7255e-02, -2.9414e-02,  7.5081e-03],\n",
       "                         [-2.1270e-02, -2.3022e-03,  1.8900e-02],\n",
       "                         [-2.0890e-02,  1.4145e-02,  2.6877e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1714e-03, -1.8586e-03, -9.3735e-04],\n",
       "                         [ 1.3446e-03,  2.5616e-02, -4.9119e-03],\n",
       "                         [-1.2371e-02, -2.2031e-03, -7.9655e-03]],\n",
       "               \n",
       "                        [[ 1.6876e-02, -3.4283e-02, -4.5709e-03],\n",
       "                         [-3.5424e-02, -5.3673e-03, -3.3915e-03],\n",
       "                         [-3.4781e-02, -1.3344e-02,  3.0963e-03]],\n",
       "               \n",
       "                        [[ 4.5861e-02,  1.8098e-02, -2.8862e-02],\n",
       "                         [-7.8264e-03,  4.2924e-02,  1.2471e-03],\n",
       "                         [-3.5315e-02, -7.4727e-03,  5.3057e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.8763e-02, -1.7400e-02, -2.3219e-02],\n",
       "                         [ 1.4989e-02,  2.2388e-02, -1.2933e-02],\n",
       "                         [-3.5151e-02, -6.4097e-03,  3.0223e-03]],\n",
       "               \n",
       "                        [[ 1.4374e-02, -5.6170e-03, -1.8645e-02],\n",
       "                         [-2.8539e-03,  3.4980e-02,  2.4608e-02],\n",
       "                         [ 7.8425e-03,  3.3372e-03,  4.1519e-02]],\n",
       "               \n",
       "                        [[-1.2970e-02, -1.0211e-02,  4.1865e-02],\n",
       "                         [ 2.9186e-03, -4.6000e-03,  1.8670e-02],\n",
       "                         [ 4.5739e-02, -6.0423e-03, -1.3256e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.0201e-02, -4.7423e-02, -7.0627e-03],\n",
       "                         [-3.9413e-02, -8.0002e-03, -8.5656e-03],\n",
       "                         [ 3.8032e-02,  7.8458e-02, -9.8536e-04]],\n",
       "               \n",
       "                        [[ 8.0949e-03,  4.3855e-02, -3.2405e-02],\n",
       "                         [ 3.4690e-02, -2.3541e-02, -5.5464e-02],\n",
       "                         [ 4.9693e-02, -4.8318e-02, -2.3397e-02]],\n",
       "               \n",
       "                        [[ 3.2814e-02, -4.2135e-03,  1.7563e-02],\n",
       "                         [ 4.2346e-03,  1.3894e-02, -4.1864e-02],\n",
       "                         [ 1.9572e-02, -2.1052e-02, -6.5263e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.1203e-03,  5.8425e-02,  1.7297e-02],\n",
       "                         [-2.7798e-02, -3.6647e-02,  8.2769e-04],\n",
       "                         [ 5.4227e-03,  3.1123e-03,  3.0777e-02]],\n",
       "               \n",
       "                        [[ 1.5130e-02,  5.9324e-03,  2.9988e-03],\n",
       "                         [ 2.7206e-02, -5.4156e-02,  2.6439e-03],\n",
       "                         [ 7.9864e-03, -3.2393e-03,  5.9121e-03]],\n",
       "               \n",
       "                        [[ 1.9344e-03,  9.9033e-03,  2.6851e-02],\n",
       "                         [ 4.5429e-04,  1.5189e-02,  1.3087e-02],\n",
       "                         [ 1.4408e-02,  1.2865e-02, -2.2910e-02]]]], device='cuda:0')),\n",
       "              ('module.layer2.3.bn2.weight',\n",
       "               tensor([1.5539, 1.1090, 2.3942, 2.0292, 2.6586, 0.9531, 0.9517, 2.0952, 1.8529,\n",
       "                       1.5156, 2.2183, 1.3048, 1.0505, 2.0093, 1.6346, 2.0859, 0.9289, 1.7597,\n",
       "                       2.0757, 2.4012, 1.0468, 1.0858, 1.9075, 1.6537, 1.9610, 1.7478, 2.5714,\n",
       "                       2.2799, 2.3231, 2.9715, 1.0249, 1.5693, 1.9598, 1.5275, 1.3731, 2.0968,\n",
       "                       1.9014, 2.2809, 0.9869, 1.7532, 0.9942, 1.4026, 2.0321, 1.0002, 1.9471,\n",
       "                       1.2159, 2.0592, 1.6377, 1.4937, 1.7154, 1.4199, 1.9035, 3.2575, 2.3816,\n",
       "                       1.8099, 1.6048, 3.0908, 3.6085, 1.9518, 1.8596, 3.1621, 1.7124, 1.1753,\n",
       "                       1.7786, 1.1803, 1.8652, 2.1725, 1.3008, 1.8991, 2.0552, 1.8345, 1.2945,\n",
       "                       1.0562, 1.5743, 1.1897, 2.1216, 4.1480, 1.6760, 1.6167, 1.5246, 1.2490,\n",
       "                       1.1195, 1.9597, 1.0579, 1.7444, 2.0794, 2.1455, 2.0459, 1.9504, 1.7394,\n",
       "                       1.3538, 2.3191, 2.1288, 1.6305, 1.9688, 1.5222, 4.2187, 1.7990, 1.8511,\n",
       "                       1.1123, 1.7282, 1.8478, 2.1385, 1.8371, 2.1648, 1.9459, 1.2385, 1.8398,\n",
       "                       1.9783, 2.1756, 1.8624, 1.4167, 1.7578, 1.8177, 1.2689, 1.7443, 2.5122,\n",
       "                       1.4860, 1.7722, 2.1417, 1.5789, 1.6922, 1.9562, 1.0189, 2.0114, 1.9301,\n",
       "                       1.7476, 0.9201], device='cuda:0')),\n",
       "              ('module.layer2.3.bn2.bias',\n",
       "               tensor([-0.0077,  2.7611, -2.6949, -3.3333, -2.1233,  2.3565,  2.1209, -1.6363,\n",
       "                       -0.6826,  0.4772, -1.9920,  0.5857,  0.9159, -1.1177, -0.0852, -2.9901,\n",
       "                        2.1524, -1.3802, -1.2711, -1.3219,  1.9899,  2.9307, -0.1745, -0.8714,\n",
       "                       -1.7087, -0.4352, -2.5452, -2.1402, -1.2686, -1.5457,  2.7935, -0.2553,\n",
       "                       -0.6019, -0.6028, -0.1460, -1.4281, -1.2325, -1.4053,  1.9186, -0.8545,\n",
       "                        2.3776,  0.7308, -1.3869,  2.0893, -1.3156,  0.8671, -1.2101, -0.8617,\n",
       "                       -0.1123, -0.8319,  0.1042, -0.5057, -3.7139, -2.3431, -0.9575, -0.1345,\n",
       "                       -2.8614, -2.7801, -1.0526, -1.3212, -2.8292, -1.1031,  3.0852, -0.7302,\n",
       "                        1.5684, -1.2689, -0.8183,  0.9975, -0.7377, -0.6134, -1.0423,  0.5582,\n",
       "                        2.4911, -0.0255,  4.5252, -0.8067, -2.9620, -0.5063, -0.2905,  0.0745,\n",
       "                        0.2413,  0.8532, -0.6000,  0.3961, -1.1554, -0.9963, -1.8313, -1.2162,\n",
       "                       -0.7297, -0.4342,  4.1272, -1.3327, -1.3734, -0.3861, -1.6038, -0.4458,\n",
       "                       -3.3566, -0.8836, -1.4473,  2.9948, -0.9938, -0.7895, -1.5667, -1.3008,\n",
       "                       -1.0086, -0.6731,  0.6097, -1.0460, -1.9253, -1.9967, -0.5463,  0.0839,\n",
       "                       -1.0263, -0.9284,  0.2067,  0.0178, -2.2585, -0.3572, -0.7172, -2.0150,\n",
       "                       -0.2334, -0.5438, -1.1792,  1.8990, -0.6110, -0.9545, -0.4163,  1.5431],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.3.bn2.running_mean',\n",
       "               tensor([ 0.2769, -3.9305, -1.0091,  0.6743, -2.9521, -0.1533,  0.2871, -0.8771,\n",
       "                       -0.9703,  4.8300, -3.1585, -0.7906,  1.3136,  0.1786, -0.9786,  0.7935,\n",
       "                       -0.7962,  0.4104, -0.1539, -0.8831,  2.0896, -0.8380, -1.3001, -0.6551,\n",
       "                       -0.8240, -0.0541, -0.8738, -0.7026, -1.9392, -4.1081, -1.0732, -0.0980,\n",
       "                       -0.8214, -1.8553,  0.7330,  0.0879, -1.5789, -1.2840,  0.8527,  0.0855,\n",
       "                        2.4252, -0.2274, -1.6970, -0.8737, -1.2073, -0.7727, -0.0418, -1.0709,\n",
       "                        0.5199, -1.4367,  0.4950,  2.3037, -2.3429, -2.3178, -1.0494, -0.5862,\n",
       "                       -3.1410, -2.4093, -0.8705, -0.5413, -2.9898,  4.5092,  1.2512, -0.5348,\n",
       "                       -1.1483,  2.0236, -0.9309,  0.4868,  4.3641, -1.0602, -0.4302,  0.1141,\n",
       "                       -2.3749, -0.9163, -1.1214, -0.8621, -3.3086, -0.5913, -1.0602, -0.9921,\n",
       "                       -1.2969,  0.2272, -2.2679, -0.5795, -0.5482, -0.6672, -0.3671, -0.0056,\n",
       "                       -0.8931, -0.3175, -1.2571, -1.3969, -0.6969, -0.4520, -1.3447, -0.7881,\n",
       "                       -4.1790, -1.3946, -0.4985, -0.6303, -1.6134, -1.0958, -1.1262, -1.4075,\n",
       "                       -0.4129,  0.7640,  0.4474, -1.8490, -3.2828, -0.5482, -1.8814, -0.8395,\n",
       "                       -0.8066,  0.2623,  0.2336,  0.8533, -2.8997, -1.2156, -1.3735, -1.1620,\n",
       "                        0.1102, -1.3010, -0.1281, -2.1123, -1.1238, -0.8293, -0.5273, -0.0151],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.3.bn2.running_var',\n",
       "               tensor([4.6859, 4.0635, 1.4797, 3.2442, 3.2423, 2.7775, 2.6643, 1.6477, 2.7338,\n",
       "                       9.2415, 1.8674, 2.7827, 2.5844, 5.5345, 3.6825, 3.4346, 2.0648, 1.8707,\n",
       "                       2.9433, 2.9160, 3.9869, 3.4326, 5.3662, 2.6868, 1.9592, 2.9084, 3.8374,\n",
       "                       1.9145, 3.6955, 5.4662, 2.0293, 3.8621, 3.3601, 2.3203, 2.8577, 2.7717,\n",
       "                       3.9014, 2.2242, 2.3627, 2.3272, 3.2800, 4.2875, 3.7793, 1.9960, 1.9289,\n",
       "                       3.3410, 3.2534, 2.4785, 4.4761, 4.0495, 2.3566, 3.7635, 1.2508, 3.5559,\n",
       "                       3.7950, 2.8373, 3.2934, 3.3562, 2.2073, 2.1741, 3.7477, 4.6234, 5.0681,\n",
       "                       2.8403, 3.4416, 4.0394, 2.1811, 5.2921, 4.7064, 2.1388, 3.7590, 4.3406,\n",
       "                       3.6359, 3.6953, 4.8352, 3.7880, 4.5631, 2.5970, 2.5131, 2.9725, 2.6418,\n",
       "                       2.7149, 5.1616, 2.8582, 1.6885, 2.8796, 1.9613, 3.1709, 3.7675, 4.7077,\n",
       "                       7.0480, 2.7784, 2.9308, 2.5151, 1.8034, 2.7101, 3.3329, 4.9699, 2.4348,\n",
       "                       3.2860, 1.8063, 6.1697, 2.5743, 2.4514, 3.1460, 3.0334, 2.8620, 2.7408,\n",
       "                       1.8637, 1.7381, 5.0707, 2.1901, 1.4159, 2.2902, 2.1158, 3.3835, 2.4121,\n",
       "                       4.1425, 5.9095, 1.8626, 3.7158, 2.5051, 2.0614, 3.1074, 3.3011, 2.5929,\n",
       "                       4.8100, 3.6312], device='cuda:0')),\n",
       "              ('module.layer2.3.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer2.3.conv3.weight',\n",
       "               tensor([[[[-5.3836e-02]],\n",
       "               \n",
       "                        [[ 9.9577e-02]],\n",
       "               \n",
       "                        [[ 6.6332e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.0289e-02]],\n",
       "               \n",
       "                        [[-6.9363e-02]],\n",
       "               \n",
       "                        [[-8.4461e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.0862e-04]],\n",
       "               \n",
       "                        [[ 6.1024e-05]],\n",
       "               \n",
       "                        [[ 4.7063e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.5959e-03]],\n",
       "               \n",
       "                        [[ 1.1430e-03]],\n",
       "               \n",
       "                        [[ 3.1413e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.3395e-02]],\n",
       "               \n",
       "                        [[ 5.4466e-02]],\n",
       "               \n",
       "                        [[-8.6130e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4304e-02]],\n",
       "               \n",
       "                        [[-2.0205e-02]],\n",
       "               \n",
       "                        [[ 3.5925e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 8.0601e-02]],\n",
       "               \n",
       "                        [[ 1.4915e-01]],\n",
       "               \n",
       "                        [[-1.7814e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.6847e-03]],\n",
       "               \n",
       "                        [[ 9.1465e-03]],\n",
       "               \n",
       "                        [[ 2.3590e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0650e-02]],\n",
       "               \n",
       "                        [[ 1.0176e-01]],\n",
       "               \n",
       "                        [[-1.1704e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.9878e-02]],\n",
       "               \n",
       "                        [[-2.2580e-02]],\n",
       "               \n",
       "                        [[-4.5019e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.1557e-01]],\n",
       "               \n",
       "                        [[-4.6118e-02]],\n",
       "               \n",
       "                        [[ 7.8851e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.2307e-02]],\n",
       "               \n",
       "                        [[-8.6934e-02]],\n",
       "               \n",
       "                        [[ 8.7645e-03]]]], device='cuda:0')),\n",
       "              ('module.layer2.3.bn3.weight',\n",
       "               tensor([ 7.0519e-01, -2.1891e-03,  1.2181e+00,  3.6143e-03,  1.1795e+00,\n",
       "                        7.0656e-01,  5.3712e-01,  2.0645e-01, -4.5760e-03,  2.3575e+00,\n",
       "                        2.6224e-01,  4.7139e-01,  3.2518e-01,  3.7449e-01,  5.0854e-01,\n",
       "                        2.0141e+00,  1.3990e+00,  7.5437e-01,  1.3704e+00,  3.5510e-01,\n",
       "                        2.9502e-02,  2.4425e-01,  5.6333e-01,  8.7079e-01,  2.0095e+00,\n",
       "                        2.4964e+00,  6.1365e-01,  1.0583e+00,  3.9731e-01,  1.8514e-01,\n",
       "                        1.7505e+00,  2.2055e-01,  9.5020e-01,  3.0635e+00,  1.1227e+00,\n",
       "                        4.6136e-01,  2.7041e-01,  4.4220e-01,  8.4780e-01,  6.9228e-01,\n",
       "                        4.9815e-01,  6.0563e-02,  1.1644e+00,  1.1951e+00,  1.0838e+00,\n",
       "                        1.6032e+00,  3.6790e-01,  1.7879e+00,  3.6067e-01,  5.0095e-01,\n",
       "                        1.2402e+00,  5.0739e-01,  1.4047e+00,  1.0777e+00,  9.2014e-01,\n",
       "                        4.7610e-01,  2.2524e+00,  3.6811e-01,  4.1079e-01,  7.8544e-01,\n",
       "                        1.4547e+00,  1.9792e-01,  5.7490e-01,  5.9589e-01,  4.0280e-01,\n",
       "                        2.0228e-01,  1.6821e+00,  5.3806e-01,  1.8667e+00,  5.8562e-01,\n",
       "                        5.1558e-01,  9.0514e-01,  6.7364e-01,  1.9564e+00,  2.1482e+00,\n",
       "                        2.4239e-01,  2.1022e-01,  6.4278e-01,  2.2851e+00,  1.6297e+00,\n",
       "                        1.1611e+00,  7.5164e-01,  2.2164e+00, -2.9552e-02,  1.9504e+00,\n",
       "                        2.4128e+00,  1.0004e+00,  1.8221e-01,  6.8114e-01,  9.8290e-01,\n",
       "                        8.1324e-01,  1.3435e+00,  3.9911e-01,  8.4507e-01,  1.6421e-01,\n",
       "                        4.5683e-01,  1.1879e+00,  3.6672e+00, -5.3340e-03,  1.6430e+00,\n",
       "                        1.3789e+00,  1.9903e+00,  1.3150e+00,  8.8875e-03,  1.1507e+00,\n",
       "                        1.0280e-02,  1.8143e+00,  1.0958e+00,  2.1812e-01,  3.5756e-01,\n",
       "                        3.8844e-01,  1.1850e+00,  6.1079e-01,  5.9628e-01,  1.6450e+00,\n",
       "                        8.0539e-01,  1.5163e+00,  7.7021e-01,  7.9911e-01,  8.5812e-01,\n",
       "                        4.4412e-01,  2.4645e+00,  1.4115e+00,  2.3351e+00,  3.1234e-01,\n",
       "                        3.1904e-01, -4.8567e-04,  1.4346e+00,  2.1868e+00,  7.4496e-01,\n",
       "                        4.1473e-01,  8.0012e-01,  1.0758e+00,  3.5294e-01, -2.0779e-01,\n",
       "                        1.3864e-01,  1.1553e+00,  2.2571e+00,  1.1830e+00,  2.0081e+00,\n",
       "                        2.4861e+00,  1.1442e+00,  1.4197e+00,  1.2616e+00,  1.8683e+00,\n",
       "                        1.5111e+00,  4.1431e-01,  2.0614e+00,  1.0444e+00,  5.8615e-01,\n",
       "                        1.6249e+00,  1.7142e-01,  1.6289e+00,  1.8159e+00,  2.8125e-01,\n",
       "                        2.1654e-01,  1.6619e+00,  1.2048e-02,  1.5117e+00,  7.7520e-01,\n",
       "                        8.1163e-01,  1.0307e+00,  2.1657e+00,  9.9343e-01,  3.5150e+00,\n",
       "                        1.5635e+00,  9.1602e-01,  1.0352e+00,  1.5858e-01,  1.2986e-01,\n",
       "                        5.5260e-01,  2.0389e+00,  6.9110e-01,  4.9998e-01,  2.1024e-01,\n",
       "                        1.8714e+00,  1.1484e+00,  1.9646e+00,  1.4191e+00,  1.5879e+00,\n",
       "                        1.8216e+00,  1.1570e+00,  1.2307e+00,  1.0873e+00,  1.7265e+00,\n",
       "                        2.3762e+00,  2.9189e-01,  2.4664e-01,  2.4342e-01,  1.1764e+00,\n",
       "                        1.8537e+00, -5.1342e-03,  1.0899e+00,  5.5090e-01,  2.2415e+00,\n",
       "                        1.1115e+00,  1.1793e+00,  4.2785e-01,  1.2657e+00,  2.2911e+00,\n",
       "                        1.4581e+00,  1.2039e+00,  8.1099e-01,  2.8726e-01,  8.7604e-01,\n",
       "                        1.3103e+00,  1.3290e+00,  4.2309e-01,  4.1325e-01,  1.1818e+00,\n",
       "                        1.6885e+00,  9.7534e-01,  8.3936e-01,  5.7447e-01,  1.3944e+00,\n",
       "                        9.2009e-01,  5.0464e-01,  1.1067e+00, -3.0403e-04,  1.0268e+00,\n",
       "                        1.7691e+00,  1.3167e-01,  6.1837e-01,  2.7578e-01,  7.8367e-01,\n",
       "                        8.4515e-01,  4.0020e+00,  1.4426e+00,  2.7751e-01,  1.7537e+00,\n",
       "                        1.6760e+00,  3.4173e-01,  1.3285e+00,  2.2379e-01,  7.9129e-01,\n",
       "                        5.3744e-01,  6.2047e-01,  4.4590e-01,  4.0699e-01,  1.1897e+00,\n",
       "                        4.1935e-01,  2.1561e+00,  4.6310e-03,  3.3139e-01,  8.6814e-01,\n",
       "                        2.2714e+00, -2.5155e-04,  6.3663e-01,  5.3765e-01,  1.3447e+00,\n",
       "                        2.8173e-01,  7.0137e-04,  2.1908e+00,  3.3017e-01, -4.0703e-03,\n",
       "                        3.7848e-01,  6.5488e-01,  1.9485e-01,  2.1830e+00,  2.9759e-01,\n",
       "                        8.2521e-01,  8.1080e-01,  1.1447e+00,  1.1387e+00,  2.9206e-01,\n",
       "                        2.4161e-01,  1.3278e+00,  1.5474e+00,  1.6612e+00,  1.5415e+00,\n",
       "                        1.6533e+00,  3.6486e-01,  1.2419e+00,  2.2519e+00,  1.0055e+00,\n",
       "                        6.3302e-01,  1.3565e+00,  3.5684e+00,  3.5175e-01,  5.9832e-01,\n",
       "                        1.3609e+00,  5.0777e-01,  6.3787e-01,  1.2587e+00,  8.3280e-01,\n",
       "                        9.4190e-03,  2.4242e-01,  1.6828e+00,  1.1413e+00,  2.1013e-01,\n",
       "                        1.9703e+00,  6.3944e-01,  1.5589e+00,  4.5724e-01,  6.7240e-01,\n",
       "                        1.2150e+00,  1.4355e+00,  1.2744e+00,  1.7448e+00,  6.7023e-01,\n",
       "                        3.0071e-01,  2.2022e+00,  6.6408e-01,  1.7323e+00,  3.2104e-01,\n",
       "                        1.4312e+00,  1.1476e+00,  1.2396e+00,  7.4654e-01, -7.1363e-03,\n",
       "                        4.7062e-01,  1.1255e+00,  3.4770e+00,  9.7071e-01,  1.9826e+00,\n",
       "                        1.0839e+00,  4.7661e-01,  6.0458e-01,  1.6138e+00,  6.0511e-01,\n",
       "                        1.3855e+00,  2.0764e+00,  3.7274e-01,  7.6345e-01,  1.6669e+00,\n",
       "                        8.0331e-01,  2.1019e+00,  2.2731e+00, -2.4558e-02,  6.5292e-01,\n",
       "                        1.3798e+00,  1.2424e+00,  2.3520e+00,  2.5694e+00,  1.2786e+00,\n",
       "                        5.0169e-01,  1.0431e+00,  4.9748e-01,  2.9038e-01,  1.0413e+00,\n",
       "                        1.6296e+00,  4.4266e-01,  5.4825e-01,  1.4672e+00,  6.6433e-01,\n",
       "                        2.8087e+00,  1.8054e+00,  3.9260e-01,  2.1635e-01,  2.7793e-01,\n",
       "                        1.7241e+00,  2.2758e-01,  8.7416e-01,  1.5720e+00,  1.0377e+00,\n",
       "                        1.1138e+00,  1.4846e+00,  8.0432e-01,  1.6132e+00,  5.6591e-01,\n",
       "                        1.3980e+00,  1.6146e+00,  2.2062e+00,  8.3627e-01,  1.8780e-01,\n",
       "                        1.3944e+00,  2.5283e-01,  2.4568e-01,  1.6555e+00,  1.4732e+00,\n",
       "                        8.9947e-01,  4.8000e-01,  9.7497e-01,  2.0122e+00,  1.0440e-01,\n",
       "                        5.4001e-01,  5.7629e-01,  6.4812e-01,  7.4230e-01,  4.4665e-01,\n",
       "                        4.7582e-01,  1.0910e+00,  1.4387e+00,  1.1616e-03,  7.0302e-01,\n",
       "                        1.6344e+00,  7.7304e-01,  7.7755e-01,  1.2439e+00,  4.5414e-02,\n",
       "                        9.1752e-01,  1.2107e+00,  9.2574e-01,  1.0594e+00,  1.1948e+00,\n",
       "                        8.9707e-01,  5.7098e-01,  8.7026e-01,  1.8401e+00,  1.2612e+00,\n",
       "                        1.4946e+00,  1.4759e+00, -6.6279e-03,  2.4715e-01,  1.0147e+00,\n",
       "                        1.4356e+00,  1.0367e+00,  9.6403e-01,  3.7803e-01,  7.4270e-01,\n",
       "                        6.1629e-01,  1.2414e+00,  1.9563e+00,  1.0180e+00,  3.4699e-01,\n",
       "                        2.6066e-01,  1.3743e+00,  3.8385e-01,  6.7743e-01,  3.3715e-01,\n",
       "                        2.2280e-01,  8.7724e-01,  1.7767e+00,  1.2364e+00,  3.5235e-01,\n",
       "                        1.1979e-01,  3.3990e-01,  2.2479e+00,  1.0572e-02,  1.8386e+00,\n",
       "                        1.5708e-01,  1.7684e+00,  8.5125e-01,  3.4477e-01,  1.7196e-01,\n",
       "                        4.6661e-01,  8.8993e-01,  1.4152e+00,  1.1713e+00,  1.2287e+00,\n",
       "                        2.2648e-01,  2.2026e-01,  3.0421e+00,  5.1085e-01,  1.3101e+00,\n",
       "                        5.2591e-01,  1.0534e+00,  2.9989e-01,  5.9339e-01,  7.9389e-01,\n",
       "                        3.8595e-03,  1.4376e-01,  1.4319e+00,  1.7480e-01,  1.7663e+00,\n",
       "                        1.9706e+00,  5.0451e-03,  2.2242e+00,  7.5423e-01, -1.7947e-03,\n",
       "                        2.8164e+00,  5.1738e-01,  8.1276e-01,  2.0148e+00,  9.7473e-01,\n",
       "                        8.8120e-01,  1.5220e+00,  1.7504e+00,  1.3351e+00,  1.7354e-03,\n",
       "                        7.5079e-01,  6.4685e-03,  2.2390e+00,  1.2291e+00,  1.0126e-03,\n",
       "                        9.9829e-01,  1.0470e+00,  5.1628e-01,  7.6047e-01,  1.2410e+00,\n",
       "                        2.5532e+00,  1.5680e+00,  1.6221e+00,  1.1401e+00,  1.0770e+00,\n",
       "                        1.7231e+00,  6.5076e-01,  3.3513e+00,  1.6595e+00,  3.7081e-01,\n",
       "                        9.2396e-01,  1.1170e+00,  8.3277e-01,  1.2896e+00,  3.1933e-01,\n",
       "                        4.7041e-01,  1.2259e-02,  5.4531e-01,  1.1389e+00,  5.0700e-01,\n",
       "                        1.3874e+00,  1.0807e+00,  1.9199e-01,  6.5389e-01,  9.6519e-01,\n",
       "                        1.7260e+00,  1.5743e-01,  5.6957e-01,  5.1656e-01,  2.5184e-01,\n",
       "                        3.1072e-01,  1.2434e+00], device='cuda:0')),\n",
       "              ('module.layer2.3.bn3.bias',\n",
       "               tensor([-9.9170e-01,  2.4685e-03, -1.5964e+00, -2.3668e-03,  1.8210e+00,\n",
       "                        1.0209e+00, -5.9848e-01, -1.4972e-01,  3.4495e-03,  1.0371e+00,\n",
       "                       -3.4614e-01, -6.6047e-01, -4.5247e-01, -7.4376e-01, -1.0194e+00,\n",
       "                       -1.7321e+00, -2.3904e+00, -1.2329e+00, -1.5674e+00, -4.2868e-01,\n",
       "                        1.2174e-03,  6.3044e-01, -7.4989e-01, -1.3342e+00, -2.2289e+00,\n",
       "                       -6.7706e-01, -1.3740e-02, -1.6307e-01, -4.2683e-01, -2.0183e-01,\n",
       "                       -1.7510e+00, -1.4302e-01, -1.4011e+00, -2.8727e+00, -1.5718e+00,\n",
       "                        2.6135e-02,  5.1033e-01, -4.0941e-01, -1.7529e+00, -8.0846e-01,\n",
       "                       -9.3141e-01, -3.1877e-02,  2.2152e-01, -5.8804e-01, -1.9281e+00,\n",
       "                       -3.0099e+00,  8.2678e-01, -1.9996e+00, -3.2242e-01, -3.1215e-01,\n",
       "                       -1.1052e+00, -4.4371e-01, -1.8244e+00, -1.3000e+00, -1.2135e+00,\n",
       "                       -5.4486e-01, -2.2370e+00, -2.8049e-01, -7.3061e-01, -1.4999e+00,\n",
       "                       -1.5986e+00, -3.0374e-02, -8.2228e-01, -7.3597e-01, -7.0175e-01,\n",
       "                        8.4942e-02, -1.2588e+00, -7.9600e-01,  2.0313e+00, -9.2460e-01,\n",
       "                       -8.8366e-01,  6.3063e-01, -1.4797e+00, -2.3876e+00, -2.8637e+00,\n",
       "                       -3.7016e-01, -2.4544e-01, -1.0055e+00, -2.3444e+00, -1.3947e+00,\n",
       "                       -2.0172e+00, -1.5894e-01, -7.2268e-01,  5.0419e-02, -3.7359e-01,\n",
       "                       -3.0953e+00, -1.4001e+00,  2.2036e-01, -9.4571e-01, -1.2262e+00,\n",
       "                        1.4688e+00, -1.8767e+00, -4.3261e-01,  1.1483e-01, -1.3149e-01,\n",
       "                       -1.8578e-01, -4.5474e-01, -4.8283e+00,  1.6879e-01, -1.0412e+00,\n",
       "                       -1.9373e+00, -1.0837e+00, -9.0282e-01,  7.9609e-04, -1.8429e+00,\n",
       "                       -3.0745e-02, -1.1817e+00,  1.3956e+00, -2.6409e-01,  6.6663e-01,\n",
       "                       -5.6031e-01,  2.0425e+00, -7.5500e-01, -4.4506e-02, -1.7328e+00,\n",
       "                       -7.4002e-01, -4.9656e-01, -9.9246e-01, -9.5687e-01, -7.4410e-01,\n",
       "                        7.3010e-02, -3.6303e+00, -9.7593e-01, -2.2630e+00, -3.7045e-01,\n",
       "                       -5.9019e-01,  2.8849e-01, -1.0209e+00, -2.3515e+00, -7.3369e-01,\n",
       "                       -3.6820e-01, -2.5476e-01, -2.2462e+00, -6.1017e-01, -2.7359e-01,\n",
       "                        5.0402e-01, -1.8429e+00, -3.6290e+00, -1.8757e+00, -3.1065e+00,\n",
       "                       -2.7215e+00, -8.9216e-01, -6.3631e-01, -2.7259e+00, -2.8207e+00,\n",
       "                        7.5887e-01, -4.4206e-01, -1.1464e+00, -1.1420e-01, -8.3783e-01,\n",
       "                       -2.2733e+00, -1.4607e-01, -1.4094e+00, -2.8201e+00, -1.7417e-01,\n",
       "                        2.2241e-01, -1.3791e+00,  1.4782e-01, -2.0399e+00, -1.1949e+00,\n",
       "                       -8.7249e-01, -1.4031e+00, -2.4475e+00, -1.8067e+00, -3.0830e+00,\n",
       "                       -2.0627e+00, -9.6556e-01, -1.7996e+00,  1.0459e-01, -1.6100e-01,\n",
       "                        5.6865e-01, -2.0732e+00,  7.2643e-01,  8.7861e-01,  1.9403e-01,\n",
       "                       -2.3603e-01, -3.2388e+00, -2.5617e+00, -4.7435e-01, -1.8250e+00,\n",
       "                       -1.1540e+00,  8.2056e-01, -1.4391e+00, -1.3970e+00, -3.0249e+00,\n",
       "                       -3.0624e+00, -3.4605e-01, -2.8757e-01, -4.4890e-01, -1.8329e+00,\n",
       "                       -2.0261e+00,  7.4140e-04, -1.3719e+00, -6.6653e-01, -1.2429e+00,\n",
       "                       -1.1720e+00, -1.3269e+00, -9.2615e-01, -1.7364e+00, -2.7680e+00,\n",
       "                       -1.7622e+00, -1.7159e+00, -8.3532e-01, -5.2989e-01, -8.0603e-01,\n",
       "                       -2.0843e+00, -1.2800e+00, -5.8762e-01, -1.8076e-01, -1.9815e+00,\n",
       "                       -4.2362e-01, -1.4837e+00, -7.1474e-01,  1.1981e-01, -1.6921e-01,\n",
       "                       -1.2728e+00,  1.0112e+00, -1.5372e+00,  3.8334e-03, -5.7348e-01,\n",
       "                       -1.8711e+00, -1.7887e-01, -6.8618e-01, -3.2655e-01, -6.6039e-01,\n",
       "                       -1.4145e+00, -2.2761e+00, -1.8194e+00, -2.5674e-01, -1.0331e+00,\n",
       "                       -3.4705e-01, -6.9478e-01, -1.7899e+00, -3.5017e-01, -1.1992e+00,\n",
       "                       -8.5927e-01, -6.2995e-01, -5.1757e-01, -6.1840e-01, -1.5057e+00,\n",
       "                        1.1997e+00, -1.6686e+00, -5.5935e-04, -3.1925e-01, -1.8215e+00,\n",
       "                       -2.3618e+00,  2.7479e-03,  3.8467e-01, -8.2977e-01, -2.0879e+00,\n",
       "                       -4.7061e-01,  6.4386e-03, -2.0605e+00, -4.7255e-01,  4.7903e-03,\n",
       "                        1.0484e-01, -9.1753e-01, -1.9366e-01,  2.0062e+00, -8.3052e-02,\n",
       "                       -1.1123e+00,  3.5897e-02, -1.3249e+00, -1.3423e+00, -4.3709e-01,\n",
       "                       -3.6615e-01, -2.6490e+00, -1.2811e+00, -1.4001e+00, -7.0491e-01,\n",
       "                       -2.5896e+00, -3.8808e-01, -1.3801e+00, -1.5376e+00, -2.3414e+00,\n",
       "                       -6.9446e-01, -1.7728e+00, -2.4849e+00, -4.2499e-01, -1.7057e-01,\n",
       "                       -2.1098e+00, -4.9605e-01, -1.0893e+00, -1.3818e+00, -3.6181e+00,\n",
       "                        4.3055e-03, -3.7628e-01, -1.7887e-01,  1.9186e+00, -2.6573e-01,\n",
       "                        1.0128e+00,  1.1104e-01,  3.6733e-01, -5.1216e-01, -3.5117e-01,\n",
       "                       -1.7696e+00, -1.9366e+00, -1.4976e+00, -2.9082e+00, -9.8485e-01,\n",
       "                       -5.7345e-01,  1.1927e+00, -1.1171e+00, -2.3311e+00,  4.8857e-02,\n",
       "                       -1.3085e+00, -1.8552e+00, -1.9613e+00, -1.1217e+00,  6.2450e-03,\n",
       "                        1.0338e+00, -1.3682e+00, -3.1128e+00, -1.4621e+00, -2.0885e+00,\n",
       "                       -1.8070e+00, -2.4227e-01, -1.2074e+00, -7.8356e-01, -9.2026e-01,\n",
       "                       -2.0866e+00, -1.6462e+00,  8.7556e-01,  1.8585e+00, -1.6414e+00,\n",
       "                       -1.4242e+00,  2.6443e-01,  4.1068e-03,  1.5803e-02, -1.0600e+00,\n",
       "                       -1.5776e+00, -2.2807e+00, -1.9605e-01, -1.4328e+00, -1.7897e+00,\n",
       "                       -6.7459e-01, -1.3750e+00,  4.3847e-01,  6.0780e-01, -1.1686e+00,\n",
       "                        5.7197e-01,  3.0078e-01, -1.1537e+00, -2.5934e+00, -7.8669e-01,\n",
       "                       -1.4370e+00, -1.5656e+00, -4.6966e-01,  4.3736e-01,  6.2671e-01,\n",
       "                       -9.1934e-01,  3.3188e-01, -9.7905e-01,  2.9194e-01, -1.2073e+00,\n",
       "                        1.0890e+00, -1.6951e+00, -1.0055e+00, -1.5051e+00, -3.4635e-01,\n",
       "                       -1.6840e+00, -1.8126e+00, -2.5025e+00, -1.0511e+00, -2.0896e-01,\n",
       "                       -2.6339e+00, -4.7794e-01,  1.0417e-01, -2.0227e+00, -7.5100e-01,\n",
       "                        8.1690e-01,  4.1766e-01, -1.6256e+00, -3.0052e+00,  2.5636e-02,\n",
       "                       -5.5115e-01, -1.0980e+00, -1.2926e-01, -1.6600e+00, -5.1433e-01,\n",
       "                        5.4792e-01, -1.4605e+00, -2.2501e+00,  6.2197e-03, -7.7148e-01,\n",
       "                       -1.8701e+00, -4.9063e-01, -1.3123e+00, -1.3012e+00,  3.1848e-01,\n",
       "                       -1.2025e+00, -1.2828e+00, -4.9429e-01, -1.6205e+00,  1.5260e+00,\n",
       "                       -1.5882e+00, -1.0015e+00,  7.2095e-01, -3.1014e+00, -2.4899e+00,\n",
       "                       -2.3517e+00, -1.2558e+00,  4.0814e-03, -1.4215e-01, -3.0393e+00,\n",
       "                       -3.1187e+00, -2.0197e+00,  1.7481e+00, -4.1769e-01, -5.9939e-01,\n",
       "                       -9.1169e-01, -1.2722e+00, -2.5736e+00, -2.0153e+00, -4.7565e-01,\n",
       "                       -2.3998e-01,  1.4314e+00, -6.7488e-01, -8.7891e-01, -2.5195e-01,\n",
       "                       -3.0669e-01, -1.4695e+00,  1.3133e-01, -1.8623e+00, -8.4317e-01,\n",
       "                       -9.0369e-02,  6.8078e-02, -1.6454e+00,  9.1959e-03, -1.0958e+00,\n",
       "                        3.7895e-01, -5.1923e-01, -1.3595e+00, -2.4212e-01, -2.0068e-01,\n",
       "                       -5.2786e-01, -1.6531e+00,  1.2507e+00, -1.5663e+00, -1.5522e+00,\n",
       "                        3.1582e-01, -3.6451e-01, -1.7328e+00, -5.9417e-01, -2.3549e+00,\n",
       "                       -8.2173e-01, -1.6818e+00, -4.5553e-01, -1.0116e+00, -2.1513e+00,\n",
       "                        2.3713e-02,  1.3734e-01, -1.7611e+00,  3.5118e-01, -2.0384e+00,\n",
       "                       -1.6757e+00,  3.4322e-03, -1.9055e+00, -9.9636e-01,  7.8137e-03,\n",
       "                       -3.4532e+00, -6.6157e-01, -6.9233e-01,  3.1117e-01, -1.5980e+00,\n",
       "                       -1.0609e+00,  6.8490e-02, -1.6982e+00, -2.1489e+00,  7.0115e-03,\n",
       "                       -7.2515e-01,  3.1635e-03, -9.4068e-01, -6.0704e-01, -1.8635e-03,\n",
       "                       -8.1145e-01, -1.3264e+00, -6.2991e-01,  1.4988e-01,  9.2341e-01,\n",
       "                       -1.7684e+00, -3.1360e+00, -1.5454e+00, -1.9100e+00, -1.4106e+00,\n",
       "                       -1.8088e+00,  5.6719e-01, -3.6064e+00, -1.5602e+00, -6.0850e-01,\n",
       "                       -1.1801e+00, -1.3971e+00, -6.2653e-01, -1.9106e+00, -3.2266e-01,\n",
       "                       -1.0552e+00,  1.1601e-02, -1.1209e+00,  1.5519e+00, -1.0397e+00,\n",
       "                       -2.6872e+00, -3.8622e-01, -2.6902e-01, -4.8224e-01, -9.7687e-01,\n",
       "                       -2.0171e+00,  4.6171e-01, -1.2006e+00,  1.4857e+00, -3.2189e-01,\n",
       "                       -3.6074e-01, -1.9250e-01], device='cuda:0')),\n",
       "              ('module.layer2.3.bn3.running_mean',\n",
       "               tensor([-2.5367e+00,  1.8929e-02,  9.0275e-01, -4.0690e-02, -4.2177e-01,\n",
       "                       -7.9820e-01,  7.5581e-02,  6.2425e-02,  1.0749e-02, -1.7825e-01,\n",
       "                       -3.7517e-01, -7.1823e-01,  4.1682e-01,  4.3196e-01,  1.1998e-01,\n",
       "                       -1.0090e+00, -4.1167e-01,  5.0104e-01, -8.2185e-01,  5.3624e-01,\n",
       "                        1.7083e-01,  4.8186e-01, -3.5211e-01, -1.5127e-01, -7.8002e-01,\n",
       "                       -2.4483e-01,  8.1081e-02, -1.0666e+00, -2.2155e-01,  1.3972e-01,\n",
       "                       -2.8546e-01,  1.7677e-02, -3.9575e-01, -3.2477e-01, -5.1844e-01,\n",
       "                       -2.3415e-01,  5.8740e-01,  8.0412e-01, -1.6638e-01,  3.8266e-02,\n",
       "                       -4.3798e-01,  1.6713e-01,  6.3960e-01, -3.3058e-01, -2.5295e-01,\n",
       "                        4.6965e-02,  1.5515e-01,  1.2635e+00, -2.2607e-01, -3.8686e-01,\n",
       "                        6.4683e-02,  1.2289e+00, -1.7130e+00, -5.9699e-02,  1.0543e+00,\n",
       "                        3.7369e-01, -4.2271e-01, -3.9017e-01, -2.6446e-01, -5.4607e-01,\n",
       "                       -5.3463e-01, -8.5405e-01,  6.6615e-01,  7.4960e-01,  4.1633e-01,\n",
       "                       -1.1855e-01, -1.1420e+00, -9.9552e-01,  7.1323e-01, -2.4956e-01,\n",
       "                       -7.8283e-01, -2.9104e-01,  4.5577e-01, -2.3938e-01, -5.9270e-01,\n",
       "                        3.9364e-01,  9.7999e-01, -2.1990e-01, -1.2087e+00, -1.2602e+00,\n",
       "                       -5.0782e-01, -7.5334e-01,  3.8211e-01, -2.1911e-02,  2.8473e+00,\n",
       "                       -6.7913e-01, -8.6943e-02,  2.1028e-01,  2.8397e-01, -8.7700e-01,\n",
       "                       -1.0037e-02,  1.8653e-01,  5.0151e-01,  9.7243e-01,  2.5463e-01,\n",
       "                        4.1485e-02,  3.2563e-01,  1.0938e-02,  1.2102e-02, -5.3605e-01,\n",
       "                        8.7338e-01, -3.8414e-01,  4.0463e-01,  3.7165e-03, -4.5105e-01,\n",
       "                        8.7175e-02, -5.3130e-01,  6.2788e-01, -1.1153e-01,  5.0622e-02,\n",
       "                        6.9046e-02, -1.1717e+00, -6.3692e-03, -5.4023e-02,  6.4288e-01,\n",
       "                        1.0985e+00, -8.7390e-01, -5.7440e-01, -5.4342e-01, -4.0832e-01,\n",
       "                        3.4172e-02, -1.0973e+00, -8.9809e-01, -2.0792e-01,  7.5548e-02,\n",
       "                       -2.2157e-01,  1.2816e-02, -2.3889e-01, -1.9192e+00,  2.7046e-01,\n",
       "                       -1.6124e-01, -2.6569e-02,  1.2581e+00, -2.6769e-02, -3.9035e-01,\n",
       "                        5.0238e-02, -3.3476e-01, -3.4280e-01, -1.1396e+00,  4.3970e-01,\n",
       "                       -1.4126e+00, -4.3960e-01,  3.8103e-01, -1.1295e+00, -9.8936e-02,\n",
       "                        2.5103e-01, -7.9121e-01,  1.9843e+00, -1.3285e+00, -5.6993e-03,\n",
       "                       -9.2926e-02, -1.0442e-01, -1.4253e+00,  8.3983e-02, -1.9107e-01,\n",
       "                        8.2863e-02, -1.6696e+00, -7.2415e-02, -4.1039e-01,  1.7039e-01,\n",
       "                       -9.0288e-01, -9.2296e-01, -3.9640e-01,  1.1874e+00, -4.0816e-01,\n",
       "                       -2.6113e-01, -5.8392e-01,  2.5693e-01, -4.5441e-01,  7.1161e-01,\n",
       "                        2.4896e-01,  2.3366e-01,  3.1475e-01,  3.2883e-01, -2.1785e-01,\n",
       "                       -2.3519e-01, -2.2525e+00,  2.3596e-01,  4.6556e-01, -7.3563e-01,\n",
       "                        1.1445e+00, -1.7737e+00, -5.9759e-01,  1.0309e+00, -2.9317e-01,\n",
       "                        1.9183e-01,  5.5149e-02, -6.1848e-01,  6.3948e-01, -4.7307e-01,\n",
       "                        1.0232e-01,  3.9037e-02, -1.2135e-01,  6.2806e-01,  1.7965e-01,\n",
       "                       -1.8571e-02, -3.8428e-01, -3.2037e-03, -6.3486e-01, -5.4357e-01,\n",
       "                        4.3457e-01, -7.4740e-01, -5.6688e-01,  7.3977e-01,  1.6844e+00,\n",
       "                        1.2180e-01, -1.1795e+00, -1.2071e+00,  2.8758e-01,  4.9234e-01,\n",
       "                       -5.6355e-01,  2.3310e-01,  6.1306e-02, -1.5422e-01, -7.1736e-01,\n",
       "                       -1.5996e-01, -3.6453e-01,  3.7085e-01,  1.3935e-02,  5.8051e-01,\n",
       "                        5.8849e-01, -1.7957e-01,  6.9263e-02, -8.9690e-02, -5.5277e-01,\n",
       "                       -1.6182e+00, -1.5284e+00, -6.6070e-01, -2.6879e-01, -5.4395e-01,\n",
       "                        7.4560e-01,  1.1289e+00,  8.6314e-02,  8.1792e-01,  1.4148e+00,\n",
       "                       -8.1856e-03,  1.0933e+00, -2.8247e-01, -1.3870e+00,  3.4000e-01,\n",
       "                       -6.5969e-01, -5.7868e-01, -4.4417e-02,  4.2788e-01, -2.9639e-01,\n",
       "                       -4.5904e-01,  5.1191e-02, -6.8057e-01,  9.5947e-01,  5.9790e-02,\n",
       "                        1.6880e-01, -6.4969e-03, -1.1854e+00, -3.7816e-02, -5.6516e-02,\n",
       "                        2.1004e+00, -1.3354e+00, -2.8698e-01,  1.3388e+00,  3.9758e-01,\n",
       "                       -3.7931e-01, -8.6140e-01, -2.9961e-01,  5.1503e-01, -3.2536e-01,\n",
       "                        1.1918e-01, -9.6826e-01, -6.6938e-01,  9.7446e-02, -3.6491e-01,\n",
       "                       -6.0890e-01,  2.3966e-01, -8.2053e-01, -1.0152e-01,  4.7811e-01,\n",
       "                        7.0827e-01, -2.0146e-01, -1.0340e+00,  3.9224e-01,  6.6481e-01,\n",
       "                       -5.8324e-01, -7.9123e-01, -6.9804e-01,  4.7063e-02, -1.4821e-01,\n",
       "                       -7.7230e-02,  2.9583e-01, -6.3858e-01, -3.7569e-01, -3.4757e-01,\n",
       "                        1.2113e+00,  9.2856e-01, -5.0167e-02, -3.6691e-02, -5.5842e-01,\n",
       "                       -6.0247e-01, -1.7033e-01, -2.1440e-01, -8.2543e-01, -8.1615e-02,\n",
       "                       -4.2496e-01,  2.2527e-01, -1.9629e-01,  6.0218e-01,  6.0860e-01,\n",
       "                       -3.7293e-01,  2.0725e-01, -9.7203e-01, -3.2294e-01, -3.6583e-02,\n",
       "                       -3.5787e-01,  2.9999e-01, -6.7528e-01, -1.1791e-02, -9.0166e-01,\n",
       "                       -9.5584e-01,  1.5386e+00, -4.3217e-01, -1.2316e-01, -4.2973e-01,\n",
       "                       -2.9757e-01, -9.5612e-01, -1.7283e-01, -5.9858e-01, -1.4632e+00,\n",
       "                        1.1154e-01, -2.9737e+00,  6.8929e-01,  9.0196e-02,  4.1602e-01,\n",
       "                        2.5528e-01, -4.7363e-01, -2.4154e-01,  1.4387e+00, -5.8143e-01,\n",
       "                       -2.0886e-01,  1.8906e-01, -1.1971e+00,  3.5024e-02, -7.0165e-01,\n",
       "                        1.5236e-01, -9.9752e-01, -4.0735e-01, -5.3821e-01, -8.2685e-01,\n",
       "                        2.5913e+00,  8.2247e-01, -1.6639e-01, -4.0843e-01, -3.3689e-01,\n",
       "                       -3.2555e-01, -1.8685e-01,  6.0672e-02, -5.6281e-01,  5.5418e-01,\n",
       "                        2.5485e+00,  2.2112e-02,  1.7102e+00, -1.2842e+00, -6.7940e-01,\n",
       "                       -6.0649e-01, -1.4739e+00, -1.0164e-01,  6.6968e-01,  8.3129e-01,\n",
       "                       -2.3881e-01, -4.7034e-01,  6.4485e-01, -1.4805e-01, -7.1204e-01,\n",
       "                       -2.6878e-01, -2.2688e-01, -6.5753e-01, -2.2726e+00,  4.2073e-01,\n",
       "                        1.1576e+00, -2.7725e-01,  4.5661e-01, -4.8602e-01, -1.4654e-02,\n",
       "                        5.9143e-01, -1.6161e-01, -1.1275e+00,  6.7804e-02,  8.1819e-01,\n",
       "                        1.2869e-01,  2.6403e-01, -2.3501e-01,  2.2006e-01,  1.0032e-01,\n",
       "                        2.6054e-01, -1.5007e-01,  1.1126e-01, -2.2384e-01, -9.7652e-02,\n",
       "                       -5.7877e-01, -2.4979e-01,  3.3883e-01, -3.8933e-01,  2.2679e-02,\n",
       "                       -1.6546e+00, -2.2635e-01,  4.2415e-03,  6.5447e-02, -9.7046e-02,\n",
       "                       -1.0684e-02, -5.1175e-01,  1.7979e-02, -2.1663e-02, -1.6785e+00,\n",
       "                       -2.4219e-01, -5.9701e-01,  9.2130e-02,  3.8183e-01,  4.7387e-01,\n",
       "                       -1.5550e-01,  1.7436e+00,  7.9244e-02, -1.1210e-01, -1.2706e-01,\n",
       "                        3.0685e-01,  6.0907e-01, -2.5266e+00,  9.5841e-01,  1.9199e-01,\n",
       "                        4.2090e-01, -6.2611e-01,  2.6161e+00,  7.6806e-03,  5.6011e-03,\n",
       "                       -4.7428e-01,  5.6490e-01, -6.7123e-01,  1.0502e-01,  8.4865e-02,\n",
       "                       -7.1244e-01,  7.0330e-01,  7.0421e-01, -8.2595e-01, -2.0069e-01,\n",
       "                       -2.1726e-01,  2.3825e-01, -1.5359e+00,  5.4344e-01, -6.0753e-01,\n",
       "                        4.5580e-01, -3.1216e-01, -2.8189e-01, -7.0858e-01, -3.0499e-01,\n",
       "                        4.0561e-02, -8.1052e-03,  2.7288e-01, -7.7582e-01, -4.7655e-01,\n",
       "                       -8.4073e-02, -2.2242e-02, -7.6211e-02, -7.0112e-01,  3.5645e-04,\n",
       "                       -3.0020e-01, -8.5396e-01, -8.9063e-01, -1.7659e+00, -9.2022e-01,\n",
       "                       -5.7243e-01, -2.0976e-01, -1.4865e+00,  1.2232e+00, -4.6609e-02,\n",
       "                        1.1636e-01, -6.6391e-02,  1.1700e+00,  8.6281e-01, -7.4132e-02,\n",
       "                       -2.3079e-01,  9.2672e-01,  6.6543e-01, -2.8112e+00, -9.7660e-01,\n",
       "                       -3.5207e-01, -5.3955e-01, -2.2217e+00, -1.0798e-02, -2.3948e-01,\n",
       "                       -1.5513e-01, -7.0554e-01, -4.7974e-01, -1.1083e+00, -1.8891e-01,\n",
       "                        3.7981e-01,  1.1726e-01,  2.7111e-01, -3.3310e-01, -1.2591e-01,\n",
       "                       -3.0760e-01, -1.4909e-02,  4.9837e-01, -1.0043e+00, -5.1832e-01,\n",
       "                       -1.3820e+00,  1.7504e+00,  5.3589e-01, -7.6728e-01,  1.1310e-01,\n",
       "                       -6.2075e-01, -4.0129e-02, -4.1139e-01, -6.4863e-01,  7.8601e-01,\n",
       "                       -2.2698e-02, -1.4329e+00], device='cuda:0')),\n",
       "              ('module.layer2.3.bn3.running_var',\n",
       "               tensor([0.3173, 0.0036, 0.2396, 0.0089, 0.4773, 0.3221, 0.0950, 0.0597, 0.0046,\n",
       "                       2.3818, 0.0741, 0.3919, 0.1615, 0.2377, 0.2791, 0.4277, 0.3913, 0.1597,\n",
       "                       0.2575, 0.2283, 0.0386, 0.1914, 0.0932, 0.3657, 0.2854, 0.5333, 0.1542,\n",
       "                       0.3169, 0.1735, 0.0672, 0.2666, 0.0688, 0.2723, 0.6964, 0.3029, 0.6766,\n",
       "                       0.1442, 0.1503, 0.1467, 0.2106, 0.1060, 0.1110, 0.6004, 0.3560, 0.1792,\n",
       "                       0.3095, 0.4975, 0.6084, 0.1023, 0.4310, 0.2705, 0.2243, 0.5180, 0.2620,\n",
       "                       0.2172, 0.3215, 0.3625, 0.1251, 0.2108, 0.2244, 0.4396, 0.2448, 0.2055,\n",
       "                       0.1779, 0.2747, 0.1158, 0.3515, 0.2842, 1.6393, 0.1685, 0.1689, 0.3410,\n",
       "                       0.1249, 0.4211, 0.2402, 0.1172, 0.1243, 0.2455, 0.6512, 0.5194, 0.2928,\n",
       "                       0.3062, 0.4089, 0.0344, 0.8511, 0.3049, 0.1958, 0.0838, 0.2120, 0.2527,\n",
       "                       0.4149, 0.2185, 0.1951, 0.4988, 0.0433, 0.1978, 0.3421, 0.8402, 0.0080,\n",
       "                       0.3002, 0.1876, 0.3695, 0.2379, 0.0056, 0.2274, 0.0209, 0.3889, 0.4330,\n",
       "                       0.0631, 0.2946, 0.1660, 0.5644, 0.2025, 0.2724, 0.4576, 0.2631, 0.5489,\n",
       "                       0.3724, 0.5811, 0.3282, 0.3047, 0.3369, 0.3732, 0.4429, 0.1624, 0.0778,\n",
       "                       0.0028, 0.4989, 0.4546, 0.1664, 0.1190, 0.2895, 0.1354, 0.0630, 0.0547,\n",
       "                       0.0746, 0.4723, 0.3385, 0.3248, 0.2667, 0.6028, 0.4548, 0.5134, 0.3486,\n",
       "                       0.1996, 1.0566, 0.3405, 0.4368, 0.7724, 0.1983, 0.3166, 0.0376, 0.3489,\n",
       "                       0.2800, 0.2254, 0.1382, 0.4525, 0.0169, 0.3022, 0.3621, 0.4025, 0.3238,\n",
       "                       0.3813, 0.2415, 0.5625, 0.2608, 0.2955, 0.1654, 0.0943, 0.0633, 0.5934,\n",
       "                       0.4706, 0.3799, 0.1651, 0.1604, 0.7170, 0.3245, 0.3790, 0.5481, 0.3857,\n",
       "                       0.6807, 0.6750, 0.4603, 0.1909, 0.3302, 0.6196, 0.0655, 0.0969, 0.1038,\n",
       "                       0.3253, 0.2455, 0.0042, 0.3480, 0.1397, 0.4291, 0.2649, 0.2417, 0.3837,\n",
       "                       0.2300, 0.4910, 0.4035, 0.4024, 0.3264, 0.1983, 0.7321, 0.3621, 0.3696,\n",
       "                       0.2172, 0.2042, 0.1912, 0.4694, 0.1664, 0.3114, 0.2605, 0.3841, 0.1421,\n",
       "                       0.1537, 0.2689, 0.0066, 0.2670, 0.3598, 0.0671, 0.2372, 0.0714, 0.1798,\n",
       "                       0.2705, 0.6611, 0.2835, 0.0702, 0.3577, 0.5877, 0.1446, 0.1767, 0.1247,\n",
       "                       0.1573, 0.0887, 0.2172, 0.2898, 0.1376, 0.4094, 0.1938, 0.5352, 0.0071,\n",
       "                       0.2963, 0.2015, 0.4229, 0.0114, 0.3575, 0.2717, 0.2215, 0.1263, 0.0129,\n",
       "                       0.4536, 0.1514, 0.0102, 0.2775, 0.2110, 0.1089, 1.7366, 0.1784, 0.2409,\n",
       "                       0.2867, 0.2328, 0.2832, 0.1722, 0.0998, 0.2082, 0.4242, 0.2729, 0.5199,\n",
       "                       0.4444, 0.1274, 0.2567, 0.5185, 0.1087, 0.3138, 0.2595, 0.5339, 0.1244,\n",
       "                       0.2494, 0.2696, 0.3291, 0.0771, 0.2774, 0.2267, 0.0064, 0.1183, 0.8403,\n",
       "                       0.6257, 0.0462, 1.2756, 0.2988, 0.6309, 0.1390, 0.1304, 0.3299, 0.2994,\n",
       "                       0.3996, 0.2274, 0.1126, 0.0990, 0.8969, 0.2100, 0.4767, 0.1164, 0.4958,\n",
       "                       0.1556, 0.2511, 0.2119, 0.0070, 0.3482, 0.3595, 0.4619, 0.2669, 0.2815,\n",
       "                       0.2251, 0.3614, 0.1455, 0.5814, 0.2108, 0.1642, 0.3440, 0.2920, 0.6680,\n",
       "                       0.5046, 0.2318, 0.7230, 0.8946, 0.0071, 0.1567, 0.3642, 0.2326, 0.9251,\n",
       "                       0.5203, 0.2607, 0.1166, 0.3029, 0.2327, 0.1005, 0.1243, 0.5943, 0.2277,\n",
       "                       0.0808, 0.1975, 0.2344, 0.5625, 0.4070, 0.2328, 0.0804, 0.1010, 0.4847,\n",
       "                       0.2086, 0.1302, 0.8764, 0.2510, 0.8442, 0.3822, 0.2574, 0.3017, 0.2334,\n",
       "                       0.3674, 0.4411, 0.4198, 0.1819, 0.0462, 0.3328, 0.0989, 0.1683, 0.2388,\n",
       "                       0.3408, 0.4792, 0.2505, 0.1735, 0.4398, 0.0796, 0.3186, 0.1130, 0.4027,\n",
       "                       0.1687, 0.1239, 0.2756, 0.2536, 0.2454, 0.0058, 0.3904, 0.3694, 0.2651,\n",
       "                       0.3176, 0.4556, 0.0222, 0.3026, 0.4883, 0.3938, 0.3678, 1.6858, 0.1677,\n",
       "                       0.0776, 0.5473, 0.2563, 0.2820, 0.2256, 0.3529, 0.0079, 0.0770, 0.2777,\n",
       "                       0.2155, 0.2309, 0.6101, 0.1501, 0.3800, 0.1779, 0.6449, 0.4091, 0.2054,\n",
       "                       0.1455, 0.0649, 0.7963, 0.1030, 0.3271, 0.2033, 0.0959, 0.1191, 1.1443,\n",
       "                       0.2309, 0.1757, 0.0399, 0.1026, 0.8181, 0.0077, 0.4320, 0.0867, 0.5419,\n",
       "                       0.1730, 0.1574, 0.0633, 0.1871, 0.2066, 0.5970, 0.2909, 0.2615, 0.1563,\n",
       "                       0.0693, 0.6858, 0.1245, 0.2924, 0.2165, 0.1626, 0.0831, 0.3878, 0.1820,\n",
       "                       0.0067, 0.1525, 0.2263, 0.0639, 0.3017, 0.3160, 0.0041, 0.3073, 0.4572,\n",
       "                       0.0084, 0.3299, 0.2097, 0.1486, 1.2188, 0.4281, 0.1273, 0.6959, 0.4274,\n",
       "                       0.4360, 0.0054, 0.3356, 0.0098, 0.5071, 0.3279, 0.0118, 0.3322, 0.2910,\n",
       "                       0.1458, 0.5250, 0.7058, 0.3814, 0.3727, 0.3954, 0.3086, 0.3924, 0.2555,\n",
       "                       0.6280, 0.4244, 0.3986, 0.1242, 0.2971, 0.3003, 0.2131, 0.2660, 0.0809,\n",
       "                       0.0577, 0.0068, 0.1306, 1.2566, 0.1031, 0.3812, 0.3280, 0.0833, 0.2502,\n",
       "                       0.4031, 0.2399, 0.0773, 0.1514, 0.2215, 0.1406, 0.2013, 0.2997],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer2.3.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.0.conv1.weight',\n",
       "               tensor([[[[-0.1128]],\n",
       "               \n",
       "                        [[ 0.0155]],\n",
       "               \n",
       "                        [[-0.0434]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0431]],\n",
       "               \n",
       "                        [[-0.1861]],\n",
       "               \n",
       "                        [[ 0.0343]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0342]],\n",
       "               \n",
       "                        [[-0.0226]],\n",
       "               \n",
       "                        [[ 0.0226]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0367]],\n",
       "               \n",
       "                        [[-0.0075]],\n",
       "               \n",
       "                        [[-0.0570]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0897]],\n",
       "               \n",
       "                        [[-0.0085]],\n",
       "               \n",
       "                        [[ 0.0052]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0884]],\n",
       "               \n",
       "                        [[-0.0381]],\n",
       "               \n",
       "                        [[ 0.0324]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0677]],\n",
       "               \n",
       "                        [[ 0.0728]],\n",
       "               \n",
       "                        [[-0.0273]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0177]],\n",
       "               \n",
       "                        [[ 0.0292]],\n",
       "               \n",
       "                        [[-0.0238]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0110]],\n",
       "               \n",
       "                        [[-0.0079]],\n",
       "               \n",
       "                        [[-0.0051]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0013]],\n",
       "               \n",
       "                        [[-0.0485]],\n",
       "               \n",
       "                        [[-0.0424]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0210]],\n",
       "               \n",
       "                        [[ 0.0005]],\n",
       "               \n",
       "                        [[ 0.0487]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0160]],\n",
       "               \n",
       "                        [[-0.0050]],\n",
       "               \n",
       "                        [[-0.0314]]]], device='cuda:0')),\n",
       "              ('module.layer3.0.bn1.weight',\n",
       "               tensor([3.0097, 1.9125, 1.9648, 3.3716, 1.7822, 2.4782, 2.2555, 2.3898, 2.2448,\n",
       "                       2.3091, 2.0284, 1.8474, 2.7269, 2.1511, 1.9296, 3.0844, 2.0094, 1.7454,\n",
       "                       2.9269, 2.1298, 2.3176, 2.4323, 1.7161, 2.8584, 2.7758, 2.3514, 2.1182,\n",
       "                       2.5898, 2.6553, 2.5964, 1.8223, 2.0868, 2.1362, 2.3736, 2.0865, 2.8372,\n",
       "                       2.8996, 3.9002, 3.0291, 2.3744, 2.1857, 2.4390, 2.5430, 1.8624, 2.1769,\n",
       "                       1.4039, 3.6103, 1.3616, 1.8103, 2.0460, 2.8421, 2.7080, 2.0715, 1.9474,\n",
       "                       1.9641, 2.4043, 2.8411, 2.3171, 2.2383, 2.2122, 2.8808, 2.0441, 2.6134,\n",
       "                       1.9410, 2.6212, 2.1740, 2.1010, 1.9687, 2.4954, 2.2587, 1.9157, 3.2698,\n",
       "                       2.7545, 1.7606, 2.5647, 2.9234, 2.4141, 2.1065, 2.2916, 2.4969, 2.9530,\n",
       "                       1.9537, 2.9130, 2.8106, 1.4624, 2.3843, 3.1165, 2.9004, 1.8075, 2.5820,\n",
       "                       3.0468, 3.3770, 2.7478, 2.6173, 2.2949, 2.6801, 1.5565, 2.2855, 2.8910,\n",
       "                       2.7522, 1.9255, 1.9457, 2.4233, 2.0461, 2.5733, 1.9962, 1.7718, 2.4920,\n",
       "                       2.6124, 2.7183, 3.0905, 3.0168, 2.7066, 2.5900, 2.7100, 2.3687, 2.4898,\n",
       "                       2.1437, 2.3113, 3.1305, 1.8627, 2.5077, 2.4316, 2.6725, 2.7654, 1.8248,\n",
       "                       1.8059, 2.4502, 2.9989, 2.7679, 2.1866, 1.5628, 1.1478, 2.4453, 1.7514,\n",
       "                       2.9196, 1.8323, 2.6139, 2.1557, 2.3662, 2.7881, 1.9856, 1.5531, 2.6751,\n",
       "                       1.9774, 2.1042, 2.1319, 2.1747, 2.1085, 1.8646, 1.9382, 2.1006, 3.3074,\n",
       "                       2.1214, 2.3664, 3.0309, 3.0958, 1.9273, 2.7095, 1.5886, 2.3486, 1.6985,\n",
       "                       2.3386, 2.3126, 2.8408, 2.8287, 1.7683, 2.1601, 1.7230, 2.3048, 3.2616,\n",
       "                       2.9467, 2.8509, 1.7612, 2.1908, 1.8209, 2.2056, 2.0323, 2.9513, 2.7155,\n",
       "                       2.6879, 2.2910, 2.4455, 1.6547, 2.2074, 2.6641, 2.1553, 2.1579, 3.2690,\n",
       "                       3.2094, 3.1617, 2.4471, 2.3758, 2.9049, 2.5379, 3.1410, 2.0478, 2.0954,\n",
       "                       2.8374, 2.3982, 2.7775, 2.2501, 3.2114, 2.4425, 2.3854, 2.6171, 2.6002,\n",
       "                       2.6410, 2.7616, 2.2229, 1.8842, 1.9058, 2.3803, 2.1758, 3.2568, 1.9904,\n",
       "                       2.1289, 2.2832, 2.4634, 2.3119, 2.8949, 2.4587, 3.2761, 2.2682, 2.4434,\n",
       "                       3.0141, 2.4204, 4.3901, 2.4102, 2.1868, 2.6974, 2.9134, 2.3400, 2.3164,\n",
       "                       1.9507, 2.8904, 2.2564, 2.5753, 2.2805, 2.6940, 2.2327, 2.1035, 2.5302,\n",
       "                       2.4168, 2.3405, 1.9438, 2.5413, 2.5845, 2.3521, 2.4904, 2.5673, 2.7279,\n",
       "                       3.2444, 2.8776, 3.1213, 2.9269], device='cuda:0')),\n",
       "              ('module.layer3.0.bn1.bias',\n",
       "               tensor([-3.5371, -0.5451, -1.2238, -4.9029, -0.7372, -2.5193, -1.2626, -1.1683,\n",
       "                       -1.1293, -1.5923, -0.9049, -0.5056, -1.9606, -1.2113, -0.8816, -3.5723,\n",
       "                       -1.0918, -0.5654, -3.1791, -1.3377, -1.3181, -1.3960,  0.1642, -3.8699,\n",
       "                       -3.0880, -1.6717, -1.2514, -1.5397, -2.6673, -2.6945, -0.6921, -1.1893,\n",
       "                       -0.9331, -2.1169, -0.8577, -2.4864, -2.6577, -3.7183, -2.9385, -2.4223,\n",
       "                       -1.3797, -1.7177, -1.6478, -0.2528, -1.0989,  0.1401, -4.2534,  0.8056,\n",
       "                       -0.7289, -0.8197, -2.8532, -2.1708, -0.8773, -0.9422, -0.8834, -1.0503,\n",
       "                       -3.3556, -1.4702, -1.6238, -1.2707, -2.3321, -0.9433, -2.5731, -0.9789,\n",
       "                       -2.1110, -1.1215, -0.7864, -1.3376, -2.0591, -1.1954, -0.7587, -4.0892,\n",
       "                       -2.2827, -0.4764, -2.0421, -4.9123, -2.2635, -1.2937, -1.3941, -1.3290,\n",
       "                       -3.7815, -0.7640, -2.8777, -3.7267, -0.1585, -1.2833, -2.5827, -4.6060,\n",
       "                       -0.0964, -2.4012, -3.6652, -4.3586, -1.6345, -2.4216, -1.5312, -1.6980,\n",
       "                       -0.4170, -1.3296, -2.4442, -3.0233, -0.6760, -0.8555, -2.0599, -0.7607,\n",
       "                       -2.0124, -1.1563, -0.8874, -1.9691, -2.1520, -2.7102, -2.7233, -2.8050,\n",
       "                       -2.7529, -1.4910, -1.7075, -1.2989, -1.9551, -1.2975, -1.6179, -3.6144,\n",
       "                       -0.8188, -1.4568, -1.7822, -2.0226, -2.2603, -0.9618, -0.1856, -2.2073,\n",
       "                       -3.2433, -2.8794, -0.8492, -0.1908,  0.9153, -0.5723, -0.1125, -3.9340,\n",
       "                       -0.4352, -2.4626, -1.5592, -2.1541, -2.9023, -0.4947,  0.3440, -1.8175,\n",
       "                       -0.6570, -1.1562, -0.8167, -1.3492, -1.2860, -0.5960, -0.7900, -1.1792,\n",
       "                       -5.2479, -0.8257, -2.0650, -2.2830, -2.7565, -1.2136, -2.9002,  0.1853,\n",
       "                       -1.7738,  0.1065, -1.2767, -2.0287, -1.9185, -2.1930, -0.6545, -1.4353,\n",
       "                       -0.5982, -1.0220, -4.8101, -3.4819, -2.2445, -0.6755, -1.8292, -0.5685,\n",
       "                       -1.5792, -1.1066, -2.5200, -2.0156, -2.3186, -1.6133, -1.4568, -0.1915,\n",
       "                       -1.6154, -1.6308, -1.2187, -1.5142, -2.7273, -3.6906, -2.3582, -1.5247,\n",
       "                       -1.7956, -2.8517, -1.7406, -2.7905, -1.3420, -1.4932, -3.1408, -1.4070,\n",
       "                       -2.5062, -1.2370, -4.5578, -1.8685, -2.5966, -2.3553, -2.9738, -2.7428,\n",
       "                       -1.6959, -0.9359, -0.7870, -0.8711, -1.8128, -1.7468, -4.3719, -0.5887,\n",
       "                       -1.7918, -1.1525, -1.3365, -1.4637, -2.7465, -2.7851, -4.4619, -1.4082,\n",
       "                       -1.4385, -4.2581, -1.8659, -6.7261, -2.5804, -1.0928, -2.4209, -2.6732,\n",
       "                       -1.1227, -1.0136, -0.8939, -3.0482, -1.4915, -2.2405, -1.7989, -2.8650,\n",
       "                       -2.0783, -1.1382, -2.2769, -1.9566, -1.8541, -1.0656, -2.1266, -1.5228,\n",
       "                       -1.4728, -2.1314, -2.1570, -0.3565, -4.0018, -2.0861, -3.3826, -3.5869],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.0.bn1.running_mean',\n",
       "               tensor([-1.8462, -0.8654, -0.3263, -1.2478, -1.4708, -0.8115, -2.1805,  1.8869,\n",
       "                        0.3002, -0.5542,  1.6336, -0.7474, -2.2259, -1.4841, -1.1182, -0.9895,\n",
       "                       -0.2338, -1.5437, -2.3883, -1.0232,  0.2776, -0.5842, -0.2320, -1.2917,\n",
       "                       -0.0589,  0.3808, -1.2292, -0.8847, -0.5251, -0.4383, -0.0136,  0.1487,\n",
       "                        2.7738, -1.2594, -0.4836, -0.9152, -0.3169, -0.5053, -0.1717, -1.4110,\n",
       "                       -0.0439, -0.9368, -0.9535,  0.2129,  0.1783, -2.8699, -3.0813,  2.0627,\n",
       "                       -0.9147,  0.6247, -1.0185, -1.7177, -0.3966, -0.4606, -1.1087, -0.1350,\n",
       "                       -2.3605, -1.5976, -1.1294, -1.4601, -1.6512, -1.3358, -1.4567,  0.3743,\n",
       "                       -3.0978, -0.7024,  0.2114, -1.3337, -1.2191,  0.2071, -1.2122, -1.1709,\n",
       "                       -1.7104, -1.0013, -3.3275, -2.6927, -2.2245,  1.5477,  0.7224, -3.2820,\n",
       "                        0.1968,  0.0786,  1.2525, -0.9740, -0.6382,  1.6833, -1.6303, -0.7878,\n",
       "                        0.3624,  1.8056, -2.3754, -3.8564, -1.3709, -1.3652, -0.9432,  0.4129,\n",
       "                       -0.9978, -0.1947,  2.0237, -3.0407,  0.9924, -0.2815, -0.9300,  0.6377,\n",
       "                       -1.4315, -0.5044, -0.6969, -0.2214, -2.6775,  1.0002,  2.2456, -1.7200,\n",
       "                       -1.5670,  2.2039,  0.6614, -1.1016, -0.6647, -0.7552,  0.6716, -2.0221,\n",
       "                       -0.4684,  0.3294, -1.7695,  1.6565, -2.9201, -1.4465, -0.3145,  1.2745,\n",
       "                       -0.2724, -1.7349,  0.4280, -0.4516, -0.7745, -1.4779, -1.3009, -0.6173,\n",
       "                        0.3607,  0.8002, -1.5111, -3.1586, -0.1060, -0.4813,  0.4386,  0.6186,\n",
       "                        0.3664, -1.3761, -1.5197,  1.7418, -1.2629, -0.8839,  2.4211, -1.2675,\n",
       "                       -3.0827, -2.5874, -2.0591, -0.5838,  1.6553, -0.2992, -2.9157,  1.7491,\n",
       "                       -3.1405, -1.5446, -1.5496, -1.6293, -0.0147, -1.4396,  0.1765, -2.3398,\n",
       "                       -0.2199,  0.2314,  0.1036, -0.1091, -1.6810,  0.3371, -1.0472, -0.6127,\n",
       "                       -2.1874, -3.2356,  1.4962, -0.3212, -1.3658, -4.5329,  0.4961,  1.4009,\n",
       "                       -1.2250, -1.9346, -0.4301, -0.8532,  1.3363, -1.7151, -1.4617, -1.8513,\n",
       "                       -2.4130,  0.1061, -3.0979, -0.1574, -1.6762, -1.1796, -1.1887,  0.9034,\n",
       "                       -0.7100, -1.9330, -1.8257, -0.6147, -2.4027, -2.3197, -0.8676, -0.6982,\n",
       "                       -0.5809,  1.7292, -2.1269, -0.7033, -0.6179, -1.0488, -1.1966,  0.2699,\n",
       "                        0.6316,  0.5598, -0.6681, -0.1416, -3.3893, -1.0373,  0.7688, -0.5990,\n",
       "                       -0.3241,  0.2806, -5.9386, -2.4262, -1.7201,  0.3734, -2.1535,  0.8559,\n",
       "                        0.7598, -2.7130, -0.2679, -1.2767, -2.3356, -0.6542,  0.0422,  1.4588,\n",
       "                       -2.5790,  0.4072, -1.8675, -0.3610,  0.3667,  0.2617, -1.5467,  0.1007,\n",
       "                        0.1453, -1.6794, -0.0605, -2.6696, -2.9368, -0.8138,  0.1827, -3.7625],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.0.bn1.running_var',\n",
       "               tensor([ 5.9350,  8.5447,  4.1550,  3.6810,  6.4252,  4.6259,  6.4082,  6.9399,\n",
       "                        5.5413,  5.3767,  5.8344,  5.8941,  6.9015,  6.3177,  4.7040,  4.2807,\n",
       "                        5.0365,  5.5675,  5.0421,  4.6428,  9.1747,  9.2381,  9.6835,  3.6619,\n",
       "                        3.4839,  7.9591,  5.4139,  8.5439,  4.0957,  4.3565,  4.7728,  4.5856,\n",
       "                       10.0961,  5.3787,  5.5006,  4.7008,  5.6573,  7.9099,  6.1449,  4.3156,\n",
       "                        7.1590,  7.7876,  8.0658, 13.0685,  5.1965,  9.0897,  5.0661, 11.5225,\n",
       "                        5.5764,  7.2089,  4.8935,  5.6377,  5.3412,  6.8839,  6.5280,  9.6282,\n",
       "                        4.5527,  5.9085,  5.0867,  8.0337,  7.6035,  7.9421,  4.4869,  4.4541,\n",
       "                        4.9025,  7.6694,  7.6119,  4.4034,  6.3857,  6.6951,  4.9783,  3.4193,\n",
       "                        7.6160,  6.5549,  6.7916,  1.6232,  4.1332,  5.4121,  5.8248,  9.9349,\n",
       "                        4.0797,  6.0784,  6.4439,  3.8622,  4.7803,  6.6617,  6.1316,  2.7413,\n",
       "                       11.4529,  4.7784,  4.1509,  4.5505, 10.2908,  5.2504,  6.3526,  7.6342,\n",
       "                        4.9302,  5.8055,  8.0429,  3.5739,  7.2835,  9.1819,  6.7846,  8.1295,\n",
       "                        5.5375,  4.6316,  4.3884,  7.6205,  6.4500,  5.7531,  3.4684,  7.0068,\n",
       "                        5.5967, 10.4491,  9.3468,  7.2082,  3.8600,  5.7264,  4.2496,  5.8346,\n",
       "                        5.6547,  6.5514,  6.8624,  4.7636,  6.9755,  3.9744,  7.4990,  3.8306,\n",
       "                        5.1767,  5.5178,  7.6306,  5.6771,  7.9750, 10.4576,  8.6496,  4.1224,\n",
       "                        7.7709,  4.8351,  6.1431,  5.4257,  4.9675,  9.2189, 11.2717,  8.8402,\n",
       "                        7.6147,  6.0731,  7.4998,  6.1789,  4.8635,  5.3592,  7.2682,  5.6407,\n",
       "                        3.7144,  5.4556,  4.4785,  7.1907,  4.7604,  4.8678,  4.4836,  7.3952,\n",
       "                        3.9716,  9.1468,  5.9661,  3.6519,  8.9795,  5.8385,  4.4937,  5.0371,\n",
       "                        5.1015,  8.7698,  5.4285,  4.2841,  9.2458,  4.9262,  4.5746,  6.0152,\n",
       "                        6.2376,  6.5201,  6.5881,  5.8571,  4.5931,  5.5858, 10.6855,  7.5351,\n",
       "                        5.3726,  8.6485,  6.3135,  4.1539,  4.0704,  3.3318,  8.4648,  6.0909,\n",
       "                        7.0001,  5.9378,  4.7192,  5.6720,  4.3970,  4.0148,  4.6383,  9.4083,\n",
       "                        5.4263,  8.0183,  5.1463,  4.5308,  3.7592,  5.1192,  3.6852,  5.6741,\n",
       "                        6.6768,  6.2183,  5.7195,  5.2984,  4.5127,  3.5943,  3.6778,  6.4123,\n",
       "                        4.9241,  7.7756,  6.3844,  8.5491,  4.9119,  3.8449,  4.3323,  5.4049,\n",
       "                       10.5136,  3.5740,  5.9081,  5.1715,  3.1922,  6.2137,  5.4248,  5.1526,\n",
       "                       10.0599,  7.9968,  9.2869,  5.5854,  8.1902,  5.6179,  4.6687,  4.4891,\n",
       "                        4.4044,  5.4102,  7.7697,  4.2257,  4.7676,  5.6135,  6.9706,  6.8704,\n",
       "                        6.7852,  5.4572,  4.1003, 10.3639,  4.1562,  6.9342,  4.0538,  4.5886],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.0.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.0.conv2.weight',\n",
       "               tensor([[[[-1.6337e-03,  9.0420e-03,  1.4544e-02],\n",
       "                         [-2.0114e-03,  2.3392e-02,  4.2464e-02],\n",
       "                         [ 2.2584e-03,  1.0718e-02,  1.9346e-02]],\n",
       "               \n",
       "                        [[-2.5650e-03,  4.4116e-03, -3.4750e-03],\n",
       "                         [-1.1825e-02,  2.4209e-02, -2.1420e-02],\n",
       "                         [ 2.2859e-03,  2.7064e-02, -9.5070e-03]],\n",
       "               \n",
       "                        [[-1.5426e-02, -1.5393e-02,  7.5739e-04],\n",
       "                         [-4.7206e-02, -1.5269e-02, -1.0946e-02],\n",
       "                         [-4.4324e-02, -1.2751e-02,  4.6072e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.5051e-02,  1.9658e-02,  4.4144e-02],\n",
       "                         [-7.4764e-03,  2.4829e-02,  3.7492e-02],\n",
       "                         [ 6.6158e-03,  2.7217e-02,  1.8602e-02]],\n",
       "               \n",
       "                        [[-3.3927e-02, -1.3758e-02,  9.6459e-03],\n",
       "                         [-4.3904e-02,  1.4892e-02,  4.0915e-03],\n",
       "                         [-3.5679e-02, -2.2550e-02,  1.6365e-02]],\n",
       "               \n",
       "                        [[ 1.1275e-02,  1.4047e-02,  2.6402e-03],\n",
       "                         [ 6.4317e-03,  3.3243e-02,  2.8905e-02],\n",
       "                         [ 9.8165e-03,  2.7132e-02,  4.9315e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.4251e-03, -6.3651e-03, -9.0500e-03],\n",
       "                         [-1.4338e-02, -3.9565e-02, -1.0727e-02],\n",
       "                         [-5.4589e-03, -7.5572e-03, -1.6179e-02]],\n",
       "               \n",
       "                        [[ 7.9622e-03,  1.8636e-02, -3.4626e-05],\n",
       "                         [ 2.8470e-03,  3.8338e-02,  5.9012e-03],\n",
       "                         [ 7.2340e-04,  1.6334e-02,  1.2980e-02]],\n",
       "               \n",
       "                        [[ 4.4957e-02,  8.5947e-02,  4.9010e-02],\n",
       "                         [ 5.4275e-02,  4.9217e-02,  7.8662e-02],\n",
       "                         [ 1.2799e-02,  4.4714e-02,  4.2316e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.0849e-02,  8.7351e-02,  8.0384e-02],\n",
       "                         [ 8.2350e-02,  3.5491e-02,  8.7693e-02],\n",
       "                         [ 7.6098e-02,  7.6800e-02,  5.5072e-02]],\n",
       "               \n",
       "                        [[-1.3220e-03, -4.0917e-03,  1.4521e-02],\n",
       "                         [ 1.0374e-02, -1.0522e-02, -2.9467e-03],\n",
       "                         [ 1.5733e-02, -7.7738e-03,  8.9324e-03]],\n",
       "               \n",
       "                        [[ 6.9134e-03,  1.9657e-02,  3.1198e-03],\n",
       "                         [-9.5418e-03,  8.4506e-03, -1.2586e-02],\n",
       "                         [ 8.0167e-03,  1.0837e-02, -8.1912e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9615e-02, -1.8038e-02, -7.3696e-03],\n",
       "                         [ 8.0703e-03, -2.5469e-02, -1.9245e-02],\n",
       "                         [-1.9163e-02, -1.8192e-02, -2.9743e-02]],\n",
       "               \n",
       "                        [[ 1.1667e-02,  1.5026e-02,  4.6415e-03],\n",
       "                         [ 6.7434e-03,  1.7611e-02,  2.0950e-02],\n",
       "                         [ 1.5250e-02, -8.0507e-03,  7.2742e-03]],\n",
       "               \n",
       "                        [[ 1.3400e-02,  2.3932e-02,  2.5196e-02],\n",
       "                         [ 4.0695e-03,  3.4134e-02,  1.9730e-02],\n",
       "                         [-1.2194e-03,  1.2934e-02,  1.4679e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.7317e-02, -8.9300e-02, -5.5119e-02],\n",
       "                         [-6.7154e-02, -9.3462e-02, -1.0231e-01],\n",
       "                         [-6.6895e-02, -8.5594e-02, -7.3249e-02]],\n",
       "               \n",
       "                        [[ 4.4441e-03, -6.3806e-03, -1.3947e-02],\n",
       "                         [-4.1227e-03, -2.3065e-03, -2.9079e-03],\n",
       "                         [-5.3181e-03, -1.4861e-02, -5.0907e-03]],\n",
       "               \n",
       "                        [[ 2.1452e-02,  4.2202e-02,  3.7335e-02],\n",
       "                         [ 2.6091e-02,  3.1537e-02,  4.2918e-02],\n",
       "                         [ 1.8557e-02,  3.4341e-02,  2.4041e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3330e-03,  6.1800e-03,  2.1080e-02],\n",
       "                         [ 6.2168e-03,  9.5019e-03,  1.4486e-02],\n",
       "                         [ 8.6064e-05, -3.8390e-03, -3.5906e-03]],\n",
       "               \n",
       "                        [[-5.4941e-03, -1.0956e-02,  1.2799e-02],\n",
       "                         [-1.7524e-02, -1.9057e-02, -1.3775e-02],\n",
       "                         [-8.3304e-03, -2.5731e-02, -1.2552e-02]],\n",
       "               \n",
       "                        [[ 2.8535e-02,  2.6833e-02,  1.6334e-03],\n",
       "                         [ 2.2865e-02,  7.4522e-03,  1.9274e-02],\n",
       "                         [ 3.0699e-02,  2.0364e-02,  2.0710e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.1393e-03,  2.8798e-02,  3.4042e-03],\n",
       "                         [ 1.3039e-02,  2.5987e-02,  1.6383e-02],\n",
       "                         [ 3.8854e-03,  9.2924e-03,  1.6893e-02]],\n",
       "               \n",
       "                        [[-5.1534e-02, -7.1323e-02, -4.7767e-02],\n",
       "                         [-7.1484e-02, -9.7633e-02, -6.8058e-02],\n",
       "                         [-4.7017e-02, -9.0661e-02, -6.2352e-02]],\n",
       "               \n",
       "                        [[-1.3983e-02, -1.9730e-02, -2.5988e-02],\n",
       "                         [-3.2380e-02, -5.2905e-03, -1.3595e-02],\n",
       "                         [-3.5008e-02, -1.7954e-02, -2.4909e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.9645e-03, -5.2815e-03,  8.0401e-03],\n",
       "                         [ 1.0449e-02,  5.9837e-03, -9.3889e-03],\n",
       "                         [ 5.9805e-03,  3.4731e-03, -1.6008e-02]],\n",
       "               \n",
       "                        [[-1.1039e-02,  6.9966e-03, -1.5717e-02],\n",
       "                         [-2.3580e-02,  7.5317e-03, -9.7406e-03],\n",
       "                         [-5.5452e-03,  3.2710e-04, -2.4853e-02]],\n",
       "               \n",
       "                        [[-4.4383e-02, -5.3120e-02, -3.6784e-02],\n",
       "                         [-4.7918e-02, -3.8666e-02, -5.0159e-02],\n",
       "                         [-3.2364e-02, -5.4653e-02, -4.2575e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.1449e-02,  2.7947e-02,  2.8152e-02],\n",
       "                         [ 2.2851e-02,  1.9962e-02, -1.2484e-03],\n",
       "                         [ 7.4922e-03,  9.6560e-03,  8.0012e-03]],\n",
       "               \n",
       "                        [[ 1.7670e-02,  4.2725e-03,  3.6378e-03],\n",
       "                         [ 4.9600e-03, -7.9544e-03,  7.8654e-03],\n",
       "                         [-6.9470e-04, -2.5603e-02, -4.3034e-04]],\n",
       "               \n",
       "                        [[-2.6104e-02, -3.4046e-02, -2.8104e-02],\n",
       "                         [-2.3765e-02, -3.6479e-03, -2.1222e-02],\n",
       "                         [-7.8767e-03, -3.2542e-02, -3.2077e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6801e-05,  2.6326e-02,  1.7018e-02],\n",
       "                         [ 3.7879e-02,  1.6255e-02,  5.2209e-03],\n",
       "                         [ 1.2458e-02,  5.2750e-03,  1.0498e-02]],\n",
       "               \n",
       "                        [[-1.2363e-02, -1.7665e-02, -3.1717e-03],\n",
       "                         [-5.2501e-03,  7.9664e-03,  3.2156e-02],\n",
       "                         [ 3.0983e-02, -7.7243e-03,  1.2913e-02]],\n",
       "               \n",
       "                        [[ 4.4225e-03, -2.4741e-02, -2.6280e-02],\n",
       "                         [ 3.7514e-04, -1.9141e-02, -4.3894e-02],\n",
       "                         [ 2.5875e-02, -4.9809e-02, -6.9049e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3148e-02,  2.2896e-02,  1.0370e-02],\n",
       "                         [-1.6200e-02,  8.9131e-03, -1.5870e-02],\n",
       "                         [-4.1116e-03, -1.5151e-02, -1.0269e-02]],\n",
       "               \n",
       "                        [[-1.4270e-02, -2.8741e-02, -9.7451e-03],\n",
       "                         [ 1.0290e-02, -1.0892e-02, -3.1067e-02],\n",
       "                         [-1.7646e-03, -1.0738e-02, -2.7311e-02]],\n",
       "               \n",
       "                        [[-4.6469e-03, -2.0069e-02, -1.1082e-03],\n",
       "                         [-1.1104e-04,  1.0249e-02,  1.3630e-02],\n",
       "                         [ 2.8903e-02,  1.6882e-02,  2.2620e-02]]]], device='cuda:0')),\n",
       "              ('module.layer3.0.bn2.weight',\n",
       "               tensor([1.5531, 1.6139, 1.2849, 1.7466, 1.1597, 1.1051, 1.1531, 1.5597, 1.3529,\n",
       "                       1.2352, 1.8631, 1.5006, 2.2619, 1.1543, 1.1072, 1.8597, 1.4624, 1.4505,\n",
       "                       1.1710, 1.1547, 1.1640, 1.5210, 1.2281, 1.8271, 1.1662, 1.4277, 1.4742,\n",
       "                       1.3420, 1.4396, 1.5023, 1.2340, 1.3806, 2.9090, 1.2009, 1.6195, 1.0656,\n",
       "                       1.4857, 1.2720, 1.3299, 1.6181, 1.0412, 2.2048, 1.1706, 1.0115, 1.1359,\n",
       "                       1.2416, 1.5061, 1.1689, 1.3430, 1.7987, 1.0320, 1.1556, 1.3670, 0.9774,\n",
       "                       1.4725, 1.1426, 1.1831, 1.1394, 1.0754, 1.0287, 1.9846, 1.1478, 1.6802,\n",
       "                       1.0498, 1.5021, 1.6598, 1.6290, 1.4051, 1.2779, 1.6486, 1.3725, 1.5239,\n",
       "                       1.2397, 1.0724, 1.6815, 1.0399, 1.0155, 1.4115, 1.6200, 1.1775, 1.2531,\n",
       "                       1.0622, 1.2131, 1.0260, 1.8407, 1.3384, 1.0623, 1.3901, 1.3756, 1.3460,\n",
       "                       1.5899, 1.0774, 1.6544, 1.3027, 1.0744, 1.9133, 1.0377, 1.0335, 1.2784,\n",
       "                       1.6370, 1.6250, 1.6476, 1.8129, 1.4682, 1.5964, 1.3446, 1.2183, 1.1033,\n",
       "                       1.0977, 1.4565, 2.1563, 1.0032, 1.0792, 1.5463, 5.2127, 1.6207, 1.3682,\n",
       "                       1.2725, 1.7496, 1.8849, 1.3793, 1.4712, 1.0310, 1.6313, 1.1382, 1.2651,\n",
       "                       1.4421, 1.8813, 1.1494, 1.8943, 1.6241, 1.1457, 1.7013, 1.1822, 1.4678,\n",
       "                       1.5177, 2.1381, 1.5002, 1.0713, 1.0862, 1.0026, 1.3660, 1.1182, 1.7615,\n",
       "                       1.1995, 1.0091, 1.2457, 2.0265, 1.4162, 1.5640, 1.0554, 1.1400, 1.8875,\n",
       "                       1.0899, 1.2526, 1.1927, 1.2911, 1.7925, 1.5386, 1.4460, 1.9407, 1.4804,\n",
       "                       1.3083, 1.4038, 1.6981, 1.5901, 1.4245, 1.0647, 1.6828, 1.2897, 1.0138,\n",
       "                       1.0306, 1.0016, 1.8638, 1.1079, 1.3342, 1.7709, 1.9263, 1.1416, 1.0182,\n",
       "                       1.8181, 1.3304, 1.2064, 1.6007, 2.7573, 1.6244, 1.0361, 1.0219, 1.1071,\n",
       "                       1.2782, 1.0491, 1.1467, 1.5239, 2.0265, 1.3061, 1.7206, 1.2043, 1.2756,\n",
       "                       1.4022, 1.0446, 1.7986, 1.4509, 1.8981, 1.6005, 1.3266, 1.4698, 1.0263,\n",
       "                       1.4518, 1.2019, 1.4125, 1.0167, 1.8938, 1.0827, 1.4310, 1.2765, 1.5764,\n",
       "                       1.0579, 1.5060, 1.5126, 1.5830, 1.4542, 1.6649, 1.6932, 1.4998, 1.0101,\n",
       "                       1.5017, 1.9138, 1.5321, 0.9877, 1.0660, 2.8447, 1.0077, 1.0859, 1.3358,\n",
       "                       1.2345, 1.0769, 1.4585, 1.4039, 1.4242, 1.4814, 1.2147, 1.3451, 1.4599,\n",
       "                       1.5167, 1.3010, 1.4821, 2.1329, 1.0666, 1.7502, 1.0658, 1.0908, 1.5815,\n",
       "                       1.2112, 2.2503, 1.3848, 1.4740], device='cuda:0')),\n",
       "              ('module.layer3.0.bn2.bias',\n",
       "               tensor([ 4.1024e-02,  4.2728e-01,  9.7388e-01,  3.0659e-01,  2.1039e+00,\n",
       "                        1.3732e+00,  7.3357e-01,  4.7066e-02,  1.3772e-01,  3.0792e-01,\n",
       "                       -7.3210e-01,  3.0546e-01, -8.0474e-01,  2.1921e+00,  2.1404e+00,\n",
       "                       -4.9389e-01,  1.4237e-01,  1.3246e+00,  1.9706e+00,  1.4917e+00,\n",
       "                        8.9227e-01, -1.3225e-01,  2.0990e+00, -1.0956e+00,  1.5054e+00,\n",
       "                        1.4251e+00, -5.3822e-01,  8.7396e-01, -4.1938e-01,  5.3601e-03,\n",
       "                        8.4989e-01,  3.0426e-01, -1.8635e+00,  2.5423e+00, -4.8876e-01,\n",
       "                        2.2692e+00,  9.9361e-01,  1.0123e+00,  1.8022e+00, -5.5260e-01,\n",
       "                        3.1954e+00, -8.3637e-01,  1.2417e+00,  2.6272e+00,  2.4407e+00,\n",
       "                        8.9046e-01,  1.2235e+00,  1.6751e+00,  6.6861e-01,  7.9862e-01,\n",
       "                        2.5929e+00,  2.0412e+00,  1.8538e-01,  2.7744e+00,  9.2922e-01,\n",
       "                        2.1586e+00,  1.1993e+00,  7.1766e-01,  2.7915e+00,  2.8405e+00,\n",
       "                       -1.0229e+00,  1.2237e+00,  3.7576e-02,  2.4190e+00,  5.5038e-01,\n",
       "                       -7.7859e-01, -6.0840e-01,  2.0411e-01,  9.9208e-01,  7.8501e-02,\n",
       "                        6.7918e-01,  5.3952e-01,  2.0072e+00,  2.4823e+00, -1.5684e-01,\n",
       "                        2.8882e+00,  2.9062e+00, -2.8472e-01, -2.4747e-01,  1.9020e+00,\n",
       "                        1.0279e+00,  2.1009e+00,  2.0422e+00,  2.7774e+00,  1.6944e-01,\n",
       "                        4.7647e-01,  2.9118e+00,  5.3911e-01,  1.9085e+00,  1.0453e+00,\n",
       "                        7.9671e-01,  3.1490e+00,  6.6194e-01,  1.2893e+00,  2.3541e+00,\n",
       "                       -3.2566e-01,  3.0997e+00,  2.3559e+00,  1.0185e+00,  8.2498e-02,\n",
       "                       -7.3328e-01, -3.0961e-01, -4.0705e-02,  1.8681e-01,  8.9059e-01,\n",
       "                        4.6733e-01,  9.7892e-01,  1.9905e+00,  2.8642e+00,  1.6957e-01,\n",
       "                       -1.0750e+00,  2.8368e+00,  1.7742e+00, -7.5597e-01, -5.4486e+00,\n",
       "                       -6.6160e-01,  3.3533e-01,  2.8624e-01, -2.7781e-01,  2.3318e-02,\n",
       "                       -4.2890e-01, -1.4270e-01,  2.1278e+00, -5.4685e-02,  5.7616e-01,\n",
       "                        9.0900e-01, -1.2219e-01, -3.5205e-01,  2.4285e+00, -3.1665e-01,\n",
       "                        3.7718e-01,  1.4170e+00, -4.5205e-01,  1.3223e+00, -1.9375e-01,\n",
       "                       -6.6887e-01, -8.9576e-01,  8.3167e-02,  2.6130e+00,  1.0976e+00,\n",
       "                        3.0613e+00,  9.6681e-01,  2.0577e+00, -2.1545e-01,  8.2122e-01,\n",
       "                        2.0625e+00,  1.1769e-01, -6.2621e-01,  1.1949e-01, -1.0161e+00,\n",
       "                        2.5881e+00,  1.5717e+00, -1.4752e-01,  3.2246e+00,  3.7997e-01,\n",
       "                        9.1813e-01,  1.0297e+00, -2.8794e-01,  6.9465e-01,  1.2728e+00,\n",
       "                       -4.0369e-01,  7.1202e-01,  2.1623e+00,  5.3666e-01,  1.3403e-01,\n",
       "                       -5.2936e-01,  1.1845e+00,  2.1726e+00, -2.3325e-01,  1.1319e+00,\n",
       "                        2.8921e+00,  2.7722e+00,  3.0344e+00, -8.2592e-01,  8.9622e-01,\n",
       "                        9.4074e-01, -5.5063e-01, -1.2955e-01,  1.9425e+00,  3.4317e+00,\n",
       "                        1.6698e-01, -3.3638e-02,  1.2840e+00,  1.6105e+00, -1.4782e+00,\n",
       "                       -2.0608e-01,  9.4848e-01,  1.8963e+00,  2.1492e+00,  1.0908e+00,\n",
       "                        2.5845e+00,  1.0973e+00,  3.7444e-01, -7.8704e-01,  9.7313e-01,\n",
       "                       -1.2495e+00,  1.0556e+00,  2.5809e-01, -8.1479e-01,  1.4546e+00,\n",
       "                       -7.6559e-01,  4.6961e-01, -4.1197e-01, -1.0518e-01,  1.8529e+00,\n",
       "                        4.4375e-01,  3.3105e+00,  1.0591e+00,  9.1727e-01,  8.4364e-01,\n",
       "                        2.7082e+00, -1.1290e+00,  1.4409e+00,  4.9950e-01, -2.8594e-01,\n",
       "                        2.6740e-01,  2.0681e+00, -6.7274e-01,  9.6906e-02, -1.3898e-02,\n",
       "                        1.1756e+00, -4.5216e-01,  5.0475e-01,  1.2165e+00,  2.2862e+00,\n",
       "                        6.8616e-02, -5.2837e-01,  4.9978e-01,  1.8715e+00,  1.6677e+00,\n",
       "                       -1.4261e+00,  3.0195e+00,  2.9108e+00,  6.9917e-01,  8.0957e-01,\n",
       "                        2.8439e+00, -1.0161e-01,  1.2461e+00,  3.1062e-01,  2.1772e-01,\n",
       "                        8.0559e-01,  1.1333e+00,  2.9039e-01,  5.9674e-01,  1.2046e+00,\n",
       "                       -4.2467e-01, -5.5171e-01,  2.6034e+00,  2.2924e-01,  3.1127e+00,\n",
       "                        2.0238e+00,  6.1480e-01,  1.3650e+00, -2.8417e-02,  4.6476e-02,\n",
       "                       -5.6924e-03], device='cuda:0')),\n",
       "              ('module.layer3.0.bn2.running_mean',\n",
       "               tensor([-2.1383e-01, -7.3386e-01,  2.8521e-01, -1.6338e+00, -1.2332e-01,\n",
       "                       -5.2597e-01, -4.6335e-01, -9.9852e-01, -6.6793e-01,  3.1304e-02,\n",
       "                       -4.1219e-02, -3.0385e-01, -1.6824e+00,  1.0111e+00,  1.2553e+00,\n",
       "                       -1.2997e+00,  9.6753e-02, -6.7349e-01,  9.2527e-01,  1.0006e+00,\n",
       "                        3.5008e-01, -8.1958e-01,  1.2852e+00, -9.2823e-01,  1.7055e-01,\n",
       "                        1.7655e+00, -2.9100e-01,  2.4131e-01, -1.8000e-01, -7.1464e-01,\n",
       "                        9.9645e-01,  2.1843e-01, -1.2701e+00,  8.7798e-01, -1.0006e-01,\n",
       "                        5.9623e-01, -1.0816e+00,  4.0129e-01,  1.0934e+00, -2.0184e-01,\n",
       "                        3.3273e-01, -1.7154e+00,  2.2322e-02,  7.6912e-01,  2.4359e-01,\n",
       "                       -7.2115e-01,  7.1133e-01, -2.8649e-03, -2.3261e-01,  1.2880e-01,\n",
       "                        9.1232e-01,  5.5794e-01, -1.2192e-01,  8.7501e-01,  4.0891e-01,\n",
       "                        1.2499e+00,  9.1536e-01, -2.4831e-01,  9.0113e-01,  1.1974e+00,\n",
       "                       -1.0909e+00,  6.7322e-01, -3.0789e-01,  2.9799e-01, -2.9142e-01,\n",
       "                       -1.5680e-01, -2.5692e-01, -9.0663e-01,  3.1587e-01, -8.0171e-01,\n",
       "                       -5.3644e-01, -1.5951e+00,  1.6638e+00,  1.3067e+00, -7.9571e-01,\n",
       "                       -5.0183e-01,  7.6453e-01, -2.1134e-01, -1.0005e+00, -1.5737e-02,\n",
       "                        5.3905e-01,  5.8000e-01,  1.9566e-01,  8.5007e-01, -1.2828e+00,\n",
       "                       -4.5307e-01,  5.2504e-01,  1.2268e-02,  3.4546e-01,  7.2937e-01,\n",
       "                       -1.2183e-01,  1.3900e+00, -1.4620e+00,  2.0886e-01,  3.6584e-01,\n",
       "                       -9.7247e-01,  4.1832e-02,  6.3105e-01,  1.9066e-01, -5.8624e-01,\n",
       "                        1.4680e-01, -2.9515e-01, -1.1191e+00, -7.9968e-01, -5.6847e-02,\n",
       "                       -4.5012e-01,  4.5789e-01,  1.7663e+00,  8.0465e-01, -4.4587e-01,\n",
       "                       -1.8483e+00, -8.6096e-01, -7.8370e-02, -5.9277e-01, -3.1028e+00,\n",
       "                        7.0585e-02, -6.3642e-01, -4.5971e-01, -3.9639e-01, -1.8862e+00,\n",
       "                       -5.7374e-03, -6.9258e-01,  1.2406e+00, -1.8244e+00,  2.0137e-01,\n",
       "                        4.2959e-01, -1.9362e-01, -1.2792e+00,  1.2563e+00, -8.4426e-01,\n",
       "                       -8.0278e-01,  1.0460e+00, -1.6700e+00,  7.4158e-01,  3.0319e-02,\n",
       "                       -8.1006e-02, -1.4886e+00, -9.6596e-01,  1.5890e+00,  1.7233e-01,\n",
       "                       -3.0886e-01, -3.4856e-01,  1.2252e+00, -7.3016e-01,  9.3309e-01,\n",
       "                        7.5358e-01,  8.8739e-01, -1.4843e+00, -4.6454e-02,  1.1329e+00,\n",
       "                       -2.1154e-01,  6.3502e-01, -1.7710e+00, -4.2353e-01,  3.3750e-01,\n",
       "                        2.7911e+00,  8.3725e-01, -2.0805e+00, -7.9161e-01,  3.4558e-01,\n",
       "                       -8.8341e-01,  4.5262e-01, -1.0214e+00, -1.2344e-01, -2.4426e-01,\n",
       "                       -5.6188e-01, -8.2335e-02,  1.2220e+00, -2.7767e-01, -1.5764e-01,\n",
       "                        2.2660e-01,  9.5964e-01,  1.9575e-01, -7.5537e-01, -1.2744e-01,\n",
       "                        4.6797e-01, -5.1320e-01, -2.8475e+00,  1.2476e+00, -1.7483e-01,\n",
       "                       -9.5856e-01, -3.9649e-01,  8.3657e-01,  2.5051e-01, -2.0708e+00,\n",
       "                        2.6459e-01, -3.8151e-01,  1.1129e+00,  2.0310e+00,  1.1632e+00,\n",
       "                        1.4295e+00,  8.9725e-01, -5.4591e-01, -1.8170e+00,  3.3968e-01,\n",
       "                       -1.9758e-01,  9.4052e-01, -3.8697e-01, -2.1153e-01,  1.0560e+00,\n",
       "                       -1.1134e+00,  1.5781e-01, -2.0375e+00, -1.5728e+00,  5.1525e-01,\n",
       "                       -8.2133e-01,  3.1780e-01,  4.4181e-02,  4.2291e-01, -4.2045e-01,\n",
       "                        1.1158e+00, -5.3296e-01,  8.9100e-01, -9.9582e-01, -9.2371e-01,\n",
       "                       -1.2327e+00,  2.3580e-01, -3.2258e-01, -7.9976e-01, -3.2642e-01,\n",
       "                        1.2094e+00, -4.1958e-01, -3.9423e-01,  4.9038e-01, -3.4314e-01,\n",
       "                       -1.2173e+00, -1.8492e+00, -7.8166e-01,  1.0460e+00,  8.6901e-01,\n",
       "                       -2.7425e+00, -1.1880e+00,  1.3043e+00, -1.6549e-01,  1.6797e-01,\n",
       "                        2.0056e+00, -4.6368e-02,  9.6855e-02, -9.8555e-03, -1.0919e+00,\n",
       "                        6.8307e-01, -4.2589e-01, -8.0819e-01, -1.0218e+00,  1.3854e-01,\n",
       "                       -3.6797e-01, -1.8600e+00,  1.7299e+00, -1.2203e+00,  2.4684e-01,\n",
       "                        6.1342e-01,  5.2529e-02,  5.5212e-01, -2.9719e+00, -9.2186e-01,\n",
       "                       -3.7243e-02], device='cuda:0')),\n",
       "              ('module.layer3.0.bn2.running_var',\n",
       "               tensor([ 4.8454,  8.1000,  5.7970, 10.2946,  5.9603,  4.9972,  2.6672,  3.9526,\n",
       "                        4.9874,  3.7675,  2.7975,  8.0072,  6.3613,  5.7059,  5.5064,  4.1449,\n",
       "                        3.2305, 10.7160,  4.3524,  5.8406,  3.8520,  4.9543,  6.7821,  3.1620,\n",
       "                        5.1590, 11.3700,  3.0587,  7.7383,  4.2143,  7.8338,  5.5689,  5.3576,\n",
       "                        4.2226,  5.3669,  5.1266,  4.6108,  9.4067,  5.9796,  6.1450,  4.4945,\n",
       "                        3.8356,  5.0496,  5.6395,  3.7090,  5.0552,  5.6098,  9.5641,  5.8912,\n",
       "                        5.1582,  8.6599,  3.8349,  5.3049,  2.7531,  3.3005,  7.0694,  4.7868,\n",
       "                        5.2348,  3.1049,  4.7090,  3.7442,  3.1839,  4.7590,  6.7305,  4.3229,\n",
       "                        6.0399,  3.0538,  2.7304,  5.8597,  7.3826,  6.7404,  6.8260,  9.8836,\n",
       "                        8.2360,  4.5238,  3.9536,  4.4481,  3.9050,  2.9273,  5.0623,  6.0134,\n",
       "                        8.5056,  4.1447, 10.5398,  4.0108,  9.4389,  6.2984,  3.9400,  6.1044,\n",
       "                        8.9667,  6.4397,  7.4716,  4.4584, 10.1300,  9.5073,  4.6768,  6.1489,\n",
       "                        4.3788,  3.8176,  8.5112,  5.5444,  3.3066,  3.3476,  6.5729,  4.0681,\n",
       "                        6.6994,  4.4977,  4.4536,  5.0108,  6.3083,  7.3489,  4.7502,  3.3779,\n",
       "                        4.7987,  5.0129, 10.2181,  3.9286,  4.9428,  4.6164,  3.9809,  8.7916,\n",
       "                        3.0879,  5.1430,  4.4637,  4.6695,  3.0959,  5.9386,  6.3394,  8.4075,\n",
       "                        6.6059,  5.8377,  7.0030,  5.4311,  5.6768,  5.6115,  4.1188,  3.1833,\n",
       "                        5.2516,  9.5919,  4.9787,  4.1333,  3.9403,  7.5359,  5.4549,  4.6383,\n",
       "                        5.7610,  3.7526,  3.6606,  6.9940,  4.7355,  4.5146,  3.7731,  5.5839,\n",
       "                        6.1055,  4.7198,  7.0093, 14.7923,  6.8763,  6.3787,  9.3712,  9.6378,\n",
       "                        5.2390,  6.2846,  7.3154,  6.7302,  8.9631,  4.6796, 15.5106,  3.8693,\n",
       "                        4.3222,  9.9263,  3.6243,  4.2219,  3.9280,  3.6809,  4.1370,  8.2755,\n",
       "                        3.9456, 11.3792,  5.7282,  3.7172,  8.6739,  3.1994,  4.3679,  7.9583,\n",
       "                        7.0857,  4.2410,  3.2485,  4.0950,  5.7594,  6.1523,  4.7668,  4.9437,\n",
       "                        8.1372,  5.4802,  6.1467,  2.4879,  7.3616,  3.9921,  2.3967,  3.5774,\n",
       "                        3.7779,  8.5759,  6.6141,  7.5077,  7.0534,  5.5782,  3.5245,  7.3524,\n",
       "                        4.0676,  7.7235,  3.9835,  3.5289,  4.7043,  5.4780,  2.9361,  6.8030,\n",
       "                        4.1262,  2.6927,  5.4043,  3.8954,  8.3248,  4.4650,  7.5691,  9.4272,\n",
       "                        3.5308,  6.1699,  6.1634,  8.4945,  3.6674,  4.3214,  7.3453,  3.8041,\n",
       "                        4.6218,  5.8348,  5.3758,  4.2955,  3.8695,  7.9341,  4.4265,  6.1243,\n",
       "                        8.3500,  6.1784,  4.9060, 11.8152,  6.4760,  4.0015,  7.7490,  4.1366,\n",
       "                        8.3052,  4.2784,  4.3735,  5.7694,  5.1733, 14.9230,  4.0332,  4.5149],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.0.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.0.conv3.weight',\n",
       "               tensor([[[[-0.0045]],\n",
       "               \n",
       "                        [[-0.0639]],\n",
       "               \n",
       "                        [[ 0.0847]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0249]],\n",
       "               \n",
       "                        [[-0.0144]],\n",
       "               \n",
       "                        [[-0.0071]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0047]],\n",
       "               \n",
       "                        [[-0.0479]],\n",
       "               \n",
       "                        [[ 0.0583]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1038]],\n",
       "               \n",
       "                        [[ 0.0309]],\n",
       "               \n",
       "                        [[ 0.0147]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0154]],\n",
       "               \n",
       "                        [[ 0.0180]],\n",
       "               \n",
       "                        [[ 0.0294]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0652]],\n",
       "               \n",
       "                        [[ 0.0530]],\n",
       "               \n",
       "                        [[ 0.0103]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0255]],\n",
       "               \n",
       "                        [[ 0.0032]],\n",
       "               \n",
       "                        [[ 0.0327]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0349]],\n",
       "               \n",
       "                        [[ 0.0256]],\n",
       "               \n",
       "                        [[-0.0232]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0186]],\n",
       "               \n",
       "                        [[-0.0229]],\n",
       "               \n",
       "                        [[ 0.0696]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0417]],\n",
       "               \n",
       "                        [[-0.0079]],\n",
       "               \n",
       "                        [[ 0.0209]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0334]],\n",
       "               \n",
       "                        [[ 0.0194]],\n",
       "               \n",
       "                        [[ 0.0029]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0569]],\n",
       "               \n",
       "                        [[ 0.0007]],\n",
       "               \n",
       "                        [[ 0.0070]]]], device='cuda:0')),\n",
       "              ('module.layer3.0.bn3.weight',\n",
       "               tensor([1.5829, 2.0787, 1.2576,  ..., 1.9163, 1.6536, 0.7768], device='cuda:0')),\n",
       "              ('module.layer3.0.bn3.bias',\n",
       "               tensor([ 0.2246, -1.0681, -0.1896,  ..., -0.7465, -0.3480, -0.2400],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.0.bn3.running_mean',\n",
       "               tensor([ 0.2604, -1.8294, -3.0708,  ..., -0.9562, -0.7685,  0.8396],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.0.bn3.running_var',\n",
       "               tensor([1.1577, 0.7125, 1.1186,  ..., 0.6160, 1.2434, 0.2787], device='cuda:0')),\n",
       "              ('module.layer3.0.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.0.downsample.0.weight',\n",
       "               tensor([[[[-0.0448]],\n",
       "               \n",
       "                        [[ 0.0188]],\n",
       "               \n",
       "                        [[ 0.0027]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0034]],\n",
       "               \n",
       "                        [[-0.0089]],\n",
       "               \n",
       "                        [[ 0.0147]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0251]],\n",
       "               \n",
       "                        [[ 0.0152]],\n",
       "               \n",
       "                        [[-0.0216]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0496]],\n",
       "               \n",
       "                        [[-0.0198]],\n",
       "               \n",
       "                        [[ 0.0082]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0609]],\n",
       "               \n",
       "                        [[ 0.0265]],\n",
       "               \n",
       "                        [[-0.0130]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0686]],\n",
       "               \n",
       "                        [[ 0.0714]],\n",
       "               \n",
       "                        [[ 0.0325]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0428]],\n",
       "               \n",
       "                        [[ 0.0265]],\n",
       "               \n",
       "                        [[ 0.0408]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0244]],\n",
       "               \n",
       "                        [[-0.0104]],\n",
       "               \n",
       "                        [[ 0.0079]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0024]],\n",
       "               \n",
       "                        [[ 0.0219]],\n",
       "               \n",
       "                        [[-0.0059]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0052]],\n",
       "               \n",
       "                        [[ 0.0166]],\n",
       "               \n",
       "                        [[ 0.0176]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0195]],\n",
       "               \n",
       "                        [[ 0.0158]],\n",
       "               \n",
       "                        [[-0.0023]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0255]],\n",
       "               \n",
       "                        [[ 0.0020]],\n",
       "               \n",
       "                        [[ 0.0807]]]], device='cuda:0')),\n",
       "              ('module.layer3.0.downsample.1.weight',\n",
       "               tensor([0.8833, 1.0183, 1.1510,  ..., 1.5345, 0.6130, 1.0372], device='cuda:0')),\n",
       "              ('module.layer3.0.downsample.1.bias',\n",
       "               tensor([ 0.2246, -1.0681, -0.1896,  ..., -0.7465, -0.3480, -0.2400],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.0.downsample.1.running_mean',\n",
       "               tensor([-1.2767, -1.1252,  1.0771,  ..., -1.5005, -1.1026,  0.2991],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.0.downsample.1.running_var',\n",
       "               tensor([1.3823, 0.7824, 1.6784,  ..., 1.0022, 0.9186, 0.8027], device='cuda:0')),\n",
       "              ('module.layer3.0.downsample.1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.1.conv1.weight',\n",
       "               tensor([[[[-2.2114e-02]],\n",
       "               \n",
       "                        [[ 5.3967e-03]],\n",
       "               \n",
       "                        [[ 1.3009e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.4553e-02]],\n",
       "               \n",
       "                        [[ 3.3032e-02]],\n",
       "               \n",
       "                        [[-4.6896e-05]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.9560e-02]],\n",
       "               \n",
       "                        [[-2.2092e-02]],\n",
       "               \n",
       "                        [[ 3.1757e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.9209e-04]],\n",
       "               \n",
       "                        [[ 6.0929e-03]],\n",
       "               \n",
       "                        [[ 6.9803e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-7.7350e-03]],\n",
       "               \n",
       "                        [[ 6.8182e-03]],\n",
       "               \n",
       "                        [[-4.0447e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.6458e-02]],\n",
       "               \n",
       "                        [[-2.4627e-02]],\n",
       "               \n",
       "                        [[ 3.5782e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 3.8036e-02]],\n",
       "               \n",
       "                        [[ 5.4665e-02]],\n",
       "               \n",
       "                        [[ 5.1252e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.4147e-02]],\n",
       "               \n",
       "                        [[ 6.7660e-02]],\n",
       "               \n",
       "                        [[ 2.9735e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.8584e-03]],\n",
       "               \n",
       "                        [[ 1.2016e-02]],\n",
       "               \n",
       "                        [[-9.1513e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.3511e-02]],\n",
       "               \n",
       "                        [[-1.4376e-02]],\n",
       "               \n",
       "                        [[-2.3247e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.0709e-02]],\n",
       "               \n",
       "                        [[-1.3009e-02]],\n",
       "               \n",
       "                        [[ 4.1575e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.1532e-02]],\n",
       "               \n",
       "                        [[-2.6687e-02]],\n",
       "               \n",
       "                        [[-1.3996e-02]]]], device='cuda:0')),\n",
       "              ('module.layer3.1.bn1.weight',\n",
       "               tensor([1.8960, 1.6971, 1.6080, 0.8372, 2.1114, 0.8745, 1.0439, 0.8264, 1.8687,\n",
       "                       1.2076, 2.4514, 1.3249, 1.6004, 1.2198, 1.0317, 1.0652, 1.1923, 1.4914,\n",
       "                       1.5426, 1.1031, 0.7620, 1.6692, 0.7718, 1.4982, 0.7285, 1.1786, 1.5793,\n",
       "                       0.8898, 1.5410, 1.2582, 1.3093, 1.3288, 1.1724, 1.5894, 1.6182, 1.5915,\n",
       "                       1.5759, 1.5037, 1.4523, 1.4154, 0.9664, 1.7938, 1.6063, 0.8873, 1.6741,\n",
       "                       1.5414, 1.1797, 2.3372, 0.9429, 0.8159, 0.9362, 1.2685, 1.3163, 1.2832,\n",
       "                       4.3541, 1.5263, 1.2803, 0.8453, 1.0826, 1.0647, 1.4375, 1.3853, 0.8810,\n",
       "                       1.0727, 0.9608, 1.5643, 1.5120, 1.3889, 1.3638, 0.9920, 1.4020, 1.8407,\n",
       "                       1.9572, 1.3722, 0.9328, 1.3686, 0.9147, 2.0042, 0.9484, 1.1943, 0.9218,\n",
       "                       1.5458, 1.1356, 1.0342, 1.4092, 2.1926, 2.3166, 3.4953, 1.8505, 1.2993,\n",
       "                       1.4613, 0.9277, 1.0240, 1.4059, 1.1028, 2.0017, 1.6342, 2.3123, 0.9628,\n",
       "                       1.0756, 2.6546, 1.1946, 1.2720, 1.4165, 0.9739, 1.0603, 1.1073, 0.9407,\n",
       "                       0.9225, 1.1645, 1.2583, 0.9851, 0.8211, 1.2632, 1.3702, 1.1551, 1.1689,\n",
       "                       1.6800, 1.1467, 1.3249, 1.0251, 1.2631, 1.3719, 1.5029, 1.3994, 1.0457,\n",
       "                       1.7006, 1.1876, 1.5073, 1.6165, 1.4173, 1.2192, 1.4458, 0.8229, 1.5186,\n",
       "                       1.5648, 1.8307, 1.3814, 1.5103, 1.8711, 1.3926, 1.4606, 2.3336, 1.4905,\n",
       "                       1.8497, 0.9244, 0.8531, 1.5704, 1.4503, 1.4082, 1.1859, 0.9857, 1.4236,\n",
       "                       1.0727, 1.5036, 0.9084, 1.0286, 0.7250, 0.7467, 1.3253, 2.4922, 1.0138,\n",
       "                       1.1449, 0.9102, 1.2840, 0.9761, 3.2921, 1.3321, 1.0848, 1.2340, 2.1080,\n",
       "                       1.0677, 1.0242, 1.1983, 1.2802, 0.7853, 0.9647, 0.8053, 1.3929, 1.8811,\n",
       "                       0.9421, 1.3694, 1.6496, 1.0382, 1.0417, 1.3621, 1.0623, 0.9968, 1.5338,\n",
       "                       1.2136, 1.0823, 1.0828, 1.1693, 1.3353, 1.3927, 1.4038, 1.5241, 1.2353,\n",
       "                       1.2407, 1.5739, 2.0728, 2.4520, 2.3124, 1.4731, 0.8879, 0.7913, 1.6930,\n",
       "                       1.2334, 2.0594, 0.9417, 1.9016, 1.2989, 2.5259, 0.7927, 1.1635, 1.3570,\n",
       "                       1.2627, 1.4646, 1.0583, 0.8771, 0.9864, 1.0742, 1.1804, 1.2283, 1.2156,\n",
       "                       1.4598, 0.9185, 1.4438, 1.8538, 1.3825, 0.8201, 1.3996, 1.1660, 1.7308,\n",
       "                       1.0052, 1.2441, 0.8814, 0.9368, 0.9288, 1.7787, 1.4168, 1.3401, 1.0183,\n",
       "                       1.1267, 1.2194, 1.6435, 1.7948, 0.7484, 0.9564, 1.0039, 1.0538, 0.8954,\n",
       "                       0.7280, 1.5261, 1.2980, 1.1474], device='cuda:0')),\n",
       "              ('module.layer3.1.bn1.bias',\n",
       "               tensor([-1.5986e+00, -1.1877e+00, -1.3593e+00,  5.1195e-01, -2.1499e+00,\n",
       "                        7.5088e-01,  1.9226e-01,  4.5556e-01, -2.0697e+00, -4.5924e-01,\n",
       "                       -2.1313e+00, -4.6026e-01, -1.0883e+00, -6.8307e-01, -1.9400e-01,\n",
       "                       -1.7527e-01, -6.5757e-01, -8.9107e-01, -1.1285e+00, -5.3015e-01,\n",
       "                        9.6168e-01, -1.8149e+00,  8.5954e-01, -1.2766e+00,  1.1098e+00,\n",
       "                       -5.3391e-01, -6.5554e-01,  5.4308e-01, -1.8717e+00, -7.7456e-01,\n",
       "                       -8.3215e-01, -6.6848e-01, -4.7735e-01, -1.7265e+00, -2.1319e+00,\n",
       "                       -7.7809e-01, -1.8545e+00, -1.3904e+00, -6.6703e-01, -1.2619e+00,\n",
       "                        7.7188e-02, -1.9732e+00, -1.9596e+00,  8.7148e-01, -2.1480e+00,\n",
       "                       -1.3914e+00, -3.1499e-01, -7.3656e-01,  4.6198e-01,  6.8730e-01,\n",
       "                        6.2001e-02, -3.2446e-01, -6.7478e-01, -6.4636e-01, -4.5372e+00,\n",
       "                       -1.5423e+00, -8.0314e-01,  4.1652e-01, -3.1176e-01, -3.1438e-01,\n",
       "                       -1.3310e+00, -1.7319e+00,  3.8184e-01, -2.1564e-01,  5.7530e-02,\n",
       "                       -1.4118e+00, -1.2027e+00, -7.5188e-01, -1.0860e+00,  4.4342e-01,\n",
       "                       -1.1040e+00, -1.8228e+00, -1.9758e+00, -8.5461e-01,  3.0131e-01,\n",
       "                       -8.4993e-01, -1.5942e-02, -1.6134e+00,  2.0328e-01, -7.0756e-02,\n",
       "                        7.5432e-02, -1.7401e+00,  5.8630e-02,  4.7438e-01, -9.1674e-01,\n",
       "                       -3.3650e+00, -2.5461e+00, -1.2794e+00, -1.9729e+00, -6.6027e-01,\n",
       "                       -1.1920e+00,  2.7087e-01, -1.5205e-01, -7.9754e-01, -6.6705e-01,\n",
       "                       -1.1684e+00, -1.7010e+00, -7.8535e-01,  2.4772e-01,  9.2572e-02,\n",
       "                       -3.9327e+00, -8.3927e-01, -5.8067e-01, -1.3045e+00,  3.1054e-01,\n",
       "                       -2.7210e-01, -3.3585e-01,  1.2879e-01,  1.0968e-01, -1.5368e-01,\n",
       "                       -5.2698e-01,  5.2465e-01,  5.1001e-01, -8.2723e-01, -1.1626e+00,\n",
       "                       -5.3016e-01, -4.0802e-01, -1.1958e+00, -4.8916e-01, -4.6161e-01,\n",
       "                       -1.5793e-01, -9.7670e-01, -6.2496e-02, -9.0770e-01, -1.1775e+00,\n",
       "                       -2.2791e-01, -1.1701e+00, -2.7247e-01, -1.2644e+00, -1.2020e+00,\n",
       "                       -8.4266e-01, -7.4447e-01, -1.0485e+00,  1.1140e+00, -1.1894e+00,\n",
       "                       -1.9711e+00, -2.1149e-01, -1.0432e+00, -1.3355e+00, -1.6918e+00,\n",
       "                       -9.5757e-01, -1.2628e+00, -2.2165e+00, -1.7660e+00, -1.7728e+00,\n",
       "                        7.1153e-01,  2.1533e-01, -1.7269e+00, -1.3134e+00, -1.1188e+00,\n",
       "                       -3.0917e-01,  1.3217e-01, -8.7414e-01, -6.7228e-02, -1.7083e+00,\n",
       "                        2.0035e-01,  3.3224e-02,  9.8999e-01,  1.5350e+00, -7.9112e-01,\n",
       "                       -3.2186e+00, -8.9442e-02, -3.8776e-01,  1.3316e-01, -9.2568e-01,\n",
       "                        6.0818e-01, -8.4937e-01, -1.0856e+00, -9.6932e-03, -5.7817e-01,\n",
       "                       -7.7909e-01, -1.4583e-01,  6.8772e-01, -6.1659e-01, -1.0390e+00,\n",
       "                        9.6903e-01,  8.2018e-02,  1.3341e+00, -9.0345e-01, -2.2071e+00,\n",
       "                        2.2308e-01,  1.3627e-02,  4.6613e-01,  3.2459e-02, -7.3714e-03,\n",
       "                       -1.2235e+00, -1.1523e-01,  3.7221e-01, -1.4886e+00, -7.0396e-01,\n",
       "                       -2.3933e-01, -3.4532e-01, -4.9553e-01, -6.3511e-01, -1.1282e+00,\n",
       "                       -5.6040e-01, -1.3454e+00,  3.4392e-02, -6.6595e-01, -1.5695e+00,\n",
       "                       -2.7628e+00, -2.3984e+00, -1.2218e+00, -1.0492e+00,  4.4570e-01,\n",
       "                        8.7347e-01, -1.1135e+00, -6.4383e-01, -6.4611e-01,  6.6674e-03,\n",
       "                       -2.5787e+00, -6.1347e-01, -1.2577e+00,  4.3668e-01, -5.9156e-01,\n",
       "                       -8.2208e-01, -8.2083e-01, -1.3251e+00,  3.0674e-02,  2.4248e-01,\n",
       "                       -1.6903e-01, -2.0069e-01, -2.8167e-01, -1.1652e-01, -6.9551e-01,\n",
       "                       -1.0522e+00,  4.6679e-01, -1.3984e+00, -2.1068e+00, -1.2069e+00,\n",
       "                        8.0243e-01, -7.0203e-01, -4.9222e-01, -1.3832e+00,  1.3521e-01,\n",
       "                       -1.0018e+00,  7.2307e-02,  3.8117e-01,  8.4119e-02, -1.7793e+00,\n",
       "                       -1.1966e+00, -8.3371e-01,  4.4323e-03,  2.8507e-01, -6.6417e-01,\n",
       "                       -2.5935e+00, -1.6392e+00,  9.3170e-01,  2.8816e-01,  8.9969e-02,\n",
       "                       -2.7054e-01,  6.0372e-01,  1.0062e+00,  1.2930e+00, -6.3272e-01,\n",
       "                       -3.4874e-01], device='cuda:0')),\n",
       "              ('module.layer3.1.bn1.running_mean',\n",
       "               tensor([-3.6950e-01, -7.0535e-01,  5.9490e-01, -1.4913e+00, -1.5905e+00,\n",
       "                       -5.0967e-01, -6.2712e-01,  2.9557e-01, -5.3927e-01,  5.8286e-01,\n",
       "                       -9.5929e-01, -6.0142e-01,  1.5742e+00,  2.4276e+00,  1.3829e+00,\n",
       "                        9.4176e-01,  2.1117e+00, -1.5944e-01,  2.8611e-01, -1.4071e+00,\n",
       "                       -1.0287e-01, -1.7194e-01, -1.5546e+00,  4.0442e-03, -9.1187e-01,\n",
       "                       -4.2119e-01, -6.0538e-01,  4.2773e+00,  2.9324e-01,  5.4967e-01,\n",
       "                       -3.3074e-01, -9.2991e-01,  1.6504e+00, -2.6485e+00, -8.3252e-01,\n",
       "                        7.8923e-01, -1.7683e+00, -4.5898e-01,  2.6687e-01, -8.6409e-01,\n",
       "                        1.2187e+00, -7.7604e-01, -1.0852e+00,  8.5307e-01, -1.1976e+00,\n",
       "                       -2.2100e-01, -7.5916e-02, -3.9794e+00, -6.0111e-01, -6.9692e-01,\n",
       "                        1.9198e+00, -1.8375e+00, -1.1934e+00,  9.2587e-01, -1.4775e+00,\n",
       "                       -3.8327e-01, -1.8842e-01, -6.1483e-01, -3.3925e+00,  2.3560e+00,\n",
       "                        5.1435e-01, -6.2453e-01, -1.1147e+00,  6.5179e-01,  2.0570e+00,\n",
       "                       -7.0999e-01,  2.7858e-02, -7.5956e-01, -2.2474e+00,  1.7008e+00,\n",
       "                       -2.5532e+00, -1.7340e+00, -1.4548e+00,  1.5365e-01, -7.1946e-01,\n",
       "                       -2.5940e+00, -1.1429e+00, -4.9189e-01, -2.6000e+00, -2.7687e+00,\n",
       "                        2.8790e+00, -3.8204e-01,  1.1513e+00,  1.9744e+00, -1.1816e+00,\n",
       "                       -1.7184e-01, -1.6175e+00, -3.3183e-01, -1.1334e+00, -1.3041e+00,\n",
       "                        1.6922e+00,  4.1544e-01,  3.2423e+00,  5.8696e-01, -1.3710e+00,\n",
       "                       -1.6651e+00, -1.8546e+00,  5.5535e-01, -1.4781e+00, -1.3632e+00,\n",
       "                       -7.0695e-01, -8.1106e-01,  2.8062e-01, -1.6140e+00,  2.1000e-01,\n",
       "                       -5.9764e-01, -4.8402e-01,  1.3733e+00, -8.6353e-01,  2.9749e+00,\n",
       "                        9.4028e-01,  7.1182e-01, -5.7038e-01,  2.7781e-01,  8.4127e-01,\n",
       "                       -1.1654e-01,  4.2676e-01, -1.9234e+00,  3.3196e-01, -2.0415e-01,\n",
       "                        4.6437e-02, -1.2268e+00, -9.1162e-02, -3.5107e-01,  4.7544e-01,\n",
       "                        1.0368e+00, -2.3603e+00, -1.0754e+00, -6.0535e-01, -6.7171e-01,\n",
       "                       -4.7221e-01,  1.2298e+00, -6.2684e-02, -4.2819e-01, -1.9456e+00,\n",
       "                       -3.3605e-01,  2.3873e+00, -1.5854e+00,  1.5104e+00,  5.9556e-02,\n",
       "                        7.9464e-02, -1.1065e+00, -2.1730e+00, -1.7709e+00,  2.1996e+00,\n",
       "                       -1.6282e+00, -1.1722e+00, -7.0890e-01, -7.3855e-02, -1.9052e+00,\n",
       "                       -1.1245e+00,  9.5805e-01, -9.1312e-01, -9.3824e-01, -1.4210e-01,\n",
       "                       -2.4207e+00, -7.9357e-01,  3.3335e+00, -7.5047e+00,  2.7092e-01,\n",
       "                       -5.9248e-01,  5.3332e-01,  3.7359e-01,  1.7430e+00,  9.1876e-01,\n",
       "                       -1.9107e-01, -1.5001e+00,  7.9723e-01, -2.0669e-01, -1.2755e+00,\n",
       "                        2.1550e-01,  8.4091e-01,  2.6949e+00,  1.8799e+00,  2.2003e+00,\n",
       "                        1.7053e+00,  1.4232e+00, -8.3197e+00,  2.3685e+00, -3.0339e+00,\n",
       "                       -1.6794e+00, -2.7230e+00, -8.3750e+00,  2.4707e-01, -1.2954e+00,\n",
       "                       -1.2025e+00,  3.2058e-01, -1.8802e+00, -3.5322e+00,  1.4061e+00,\n",
       "                        5.8342e-01,  2.9076e-01,  1.1688e+00, -1.1961e+00, -8.1306e-01,\n",
       "                       -7.2514e-01, -7.2911e-01,  3.4043e-01, -1.2871e+00,  9.2729e-01,\n",
       "                       -1.7132e+00,  6.4004e-01, -1.9913e-01,  3.0274e+00, -1.8062e+00,\n",
       "                       -7.1513e-02,  5.0658e-01,  1.3793e+00,  5.2137e-02, -2.9083e-01,\n",
       "                       -1.3283e+00,  1.4533e+00,  7.0273e-01,  8.8724e-01,  3.2131e-01,\n",
       "                        3.1598e-01,  1.5046e+00, -2.3156e-01, -1.8807e+00, -4.7433e-01,\n",
       "                        1.0506e+00, -4.8159e+00,  1.7238e-01,  3.8058e-01, -1.6353e+00,\n",
       "                        4.7670e-01,  7.1082e-02, -5.2110e-01, -6.2373e-01, -8.7542e-01,\n",
       "                       -6.0715e-01, -3.4024e-01, -6.1159e-01, -5.9348e-01, -3.9379e+00,\n",
       "                        1.3971e+00, -1.8479e+00, -1.8163e-01,  1.9672e+00, -1.3866e-01,\n",
       "                       -6.1017e-01, -1.5246e-01,  1.7373e+00, -1.5877e+00, -4.3938e-01,\n",
       "                       -1.2709e+00, -2.5593e+00, -1.0250e+00, -1.7460e-01, -1.9016e+00,\n",
       "                        1.2235e+00, -4.7949e-01,  1.4812e-01,  1.8316e+00, -1.0164e+00,\n",
       "                       -2.6188e+00], device='cuda:0')),\n",
       "              ('module.layer3.1.bn1.running_var',\n",
       "               tensor([ 5.0158,  4.4677,  2.9606,  5.8752,  2.5882,  7.2609,  6.7009,  4.4511,\n",
       "                        2.4798,  3.7043, 11.4230,  4.4075,  2.4063,  3.0604,  3.4312,  2.9628,\n",
       "                        2.9863,  3.1039,  3.1193,  3.4686,  4.8968,  2.8321,  5.3264,  2.8500,\n",
       "                        4.5156,  3.5252,  4.3530,  5.5380,  2.5997,  2.6747,  3.2617,  3.3631,\n",
       "                        2.8039,  2.6124,  2.6010,  4.6509,  2.4709,  2.3177,  4.8421,  3.3243,\n",
       "                        3.8105,  1.8982,  2.4195,  5.6628,  1.8076,  2.3924,  3.7451, 13.8486,\n",
       "                        5.4326,  6.6055,  3.7195,  4.2898,  3.7881,  3.6333,  5.5315,  2.3315,\n",
       "                        2.8641,  6.4984,  4.4408,  2.4594,  2.6214,  2.7539,  5.5398,  3.9389,\n",
       "                        3.1800,  2.9619,  2.4220,  3.7159,  1.8696,  7.0574,  3.5745,  3.0774,\n",
       "                        2.6914,  2.4315,  5.2068,  4.5121,  4.2646,  2.6971,  3.6969,  5.8139,\n",
       "                        2.7730,  2.4379,  8.8210,  6.6368,  3.2012,  2.0878,  2.9292, 18.5617,\n",
       "                        2.8054,  2.9104,  2.8906,  6.0115,  3.1042,  3.2854,  2.0640,  5.6838,\n",
       "                        2.0125, 20.7541,  6.1231,  7.9228,  2.3739,  2.9049,  2.8566,  1.9592,\n",
       "                        4.8428,  3.9599,  2.8601,  3.2161,  4.9144,  8.3800,  3.0651,  6.0081,\n",
       "                        5.6114,  2.7493,  2.6778,  3.8390,  3.8726,  4.1205,  3.2084,  3.6494,\n",
       "                        2.4017,  2.0466,  4.9289,  3.9507,  2.3357,  3.0897,  4.2420,  3.6328,\n",
       "                        2.0457,  2.8601,  4.8721,  4.7357,  4.1720,  6.9544,  2.4134,  1.7578,\n",
       "                       30.4861,  2.6200,  3.0288,  2.2910,  3.2255,  2.3635,  6.2839,  2.2441,\n",
       "                        6.4442,  9.0287,  4.1293,  2.4833,  2.9900,  2.3490,  3.5895,  5.0989,\n",
       "                        3.6859,  3.6470,  2.4894,  6.6467,  4.3352,  4.3491,  5.4424,  3.4311,\n",
       "                        2.3609,  3.5811,  3.8770,  4.5997,  2.4760,  7.7650, 21.3693,  1.7748,\n",
       "                        6.7595,  2.2639, 14.2787,  3.7011, 11.9945,  4.1127,  2.4449,  5.6885,\n",
       "                        4.1897,  6.7064,  2.8479,  3.5074,  4.5031, 10.3358, 21.8828,  2.8405,\n",
       "                        4.5960,  2.1250,  4.1187,  7.7885,  2.8475,  2.5738,  3.5217,  2.9325,\n",
       "                        2.0016,  3.3681,  3.0844,  3.9256,  2.8617,  6.5002,  2.8664,  2.3125,\n",
       "                        2.2038,  3.0092,  7.6539,  3.9777,  5.9929,  4.3791,  2.9095,  3.8509,\n",
       "                       12.0681,  4.5261,  2.4887,  2.9303, 11.5002,  3.7696,  4.4420,  3.2338,\n",
       "                        3.0511,  2.2622,  5.1169,  6.5485,  3.1582,  3.9528,  3.7232,  7.9310,\n",
       "                        3.4324,  2.7695,  6.2778,  2.3323,  2.6586,  2.0422,  4.3566,  3.1600,\n",
       "                        3.0097,  6.5269,  5.0214,  1.9964,  4.2440,  4.9862,  3.9433,  2.5852,\n",
       "                        2.4584,  2.7298,  4.2252,  8.3441,  2.3671,  2.1880,  3.3699,  3.9018,\n",
       "                        5.2148,  4.1338,  3.9156,  6.7789,  4.0486, 57.2603,  3.0196,  3.3403],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.1.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.1.conv2.weight',\n",
       "               tensor([[[[-4.8720e-02,  9.9558e-03,  3.3036e-02],\n",
       "                         [-6.1899e-02,  2.5294e-02,  2.5628e-02],\n",
       "                         [-6.2521e-02, -1.3178e-02,  1.8046e-02]],\n",
       "               \n",
       "                        [[ 2.0732e-02,  4.3768e-03,  1.2779e-02],\n",
       "                         [ 8.5591e-03, -1.0913e-02,  1.4676e-02],\n",
       "                         [-4.7175e-03,  5.3431e-04, -2.1660e-02]],\n",
       "               \n",
       "                        [[-5.6735e-03, -3.3529e-03,  1.8256e-02],\n",
       "                         [-3.3127e-02,  1.4672e-02,  2.1298e-02],\n",
       "                         [-2.2908e-02, -2.1796e-02,  2.8492e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.0206e-02, -2.0487e-02,  2.7962e-02],\n",
       "                         [-1.3282e-02,  1.8765e-02,  6.6833e-02],\n",
       "                         [-8.6879e-03, -2.0244e-02,  2.9794e-02]],\n",
       "               \n",
       "                        [[ 1.0711e-02,  4.9938e-03, -2.6295e-02],\n",
       "                         [-4.3522e-02, -7.3252e-03, -6.3380e-02],\n",
       "                         [-2.6489e-02, -7.2684e-03,  1.8827e-03]],\n",
       "               \n",
       "                        [[-1.2597e-02, -1.4083e-02,  1.9368e-03],\n",
       "                         [ 3.7908e-02, -2.0146e-02, -1.5715e-02],\n",
       "                         [ 3.4128e-02,  1.3691e-02, -2.0266e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.9601e-02,  7.7773e-05,  2.8127e-02],\n",
       "                         [-1.6118e-03, -2.2322e-02,  2.6959e-04],\n",
       "                         [-4.3806e-03, -7.7269e-04, -4.6682e-03]],\n",
       "               \n",
       "                        [[-2.7765e-03,  1.3065e-03,  3.5575e-03],\n",
       "                         [-7.3874e-03, -6.8371e-03,  3.2869e-04],\n",
       "                         [-4.7806e-03, -3.1780e-03, -1.5394e-02]],\n",
       "               \n",
       "                        [[-7.6405e-03, -1.6430e-02, -4.9711e-03],\n",
       "                         [-1.7561e-02,  1.2938e-02,  1.0787e-02],\n",
       "                         [-2.0010e-02, -1.4708e-02,  6.0444e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.8847e-02, -1.7060e-02, -1.6007e-02],\n",
       "                         [-1.8341e-02,  2.1461e-02,  4.6447e-03],\n",
       "                         [-9.4308e-03, -2.3469e-02, -2.5437e-02]],\n",
       "               \n",
       "                        [[ 1.6878e-02,  1.3119e-02, -8.2269e-03],\n",
       "                         [-4.5086e-03, -2.8377e-02, -9.9141e-03],\n",
       "                         [-3.3634e-03, -1.1854e-02,  1.5592e-02]],\n",
       "               \n",
       "                        [[ 9.7345e-03,  1.7972e-02,  6.6572e-03],\n",
       "                         [ 2.3928e-02, -1.9271e-02,  2.7118e-02],\n",
       "                         [ 1.2118e-02,  4.1660e-02,  6.0321e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.2809e-03, -9.9962e-03,  1.1558e-05],\n",
       "                         [-6.1986e-03, -3.5759e-04, -1.4354e-02],\n",
       "                         [-1.3856e-02, -3.4465e-02, -2.0079e-02]],\n",
       "               \n",
       "                        [[-1.6354e-02, -2.8367e-02, -5.6027e-03],\n",
       "                         [-5.5908e-04, -2.5199e-02,  8.5607e-03],\n",
       "                         [ 1.6939e-02,  8.6608e-03,  6.5186e-04]],\n",
       "               \n",
       "                        [[-1.5387e-02, -3.7080e-02, -3.7502e-02],\n",
       "                         [-3.6209e-02, -1.8274e-02, -4.9835e-02],\n",
       "                         [-4.3404e-02, -5.5321e-02, -5.6912e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.5335e-02,  2.1344e-02, -2.1175e-03],\n",
       "                         [ 3.8567e-03, -5.8248e-02,  8.9512e-03],\n",
       "                         [ 1.0818e-02,  5.7634e-03, -7.9559e-03]],\n",
       "               \n",
       "                        [[-6.3658e-03, -2.0469e-02, -2.1519e-02],\n",
       "                         [-1.2763e-02,  4.0606e-03,  2.2694e-02],\n",
       "                         [ 2.4527e-03, -2.4470e-02, -1.2560e-02]],\n",
       "               \n",
       "                        [[ 7.3327e-03, -1.8517e-02, -3.1600e-03],\n",
       "                         [-1.7012e-02, -4.6382e-02,  8.6061e-03],\n",
       "                         [ 1.2014e-02,  9.0382e-03, -7.5451e-05]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.2778e-03,  7.8233e-03, -1.7772e-02],\n",
       "                         [ 2.1323e-02,  1.0241e-02,  2.3810e-02],\n",
       "                         [ 2.5910e-02,  2.6861e-02,  1.9881e-02]],\n",
       "               \n",
       "                        [[ 6.8239e-03,  3.2825e-02, -2.5425e-02],\n",
       "                         [ 1.7887e-02,  2.0920e-02, -1.6461e-02],\n",
       "                         [ 2.9725e-03, -3.2438e-04,  3.3017e-03]],\n",
       "               \n",
       "                        [[-1.0165e-03, -1.2840e-02, -1.3521e-02],\n",
       "                         [-1.0022e-02, -1.5231e-02, -3.6019e-03],\n",
       "                         [-4.0456e-02, -3.6126e-02, -4.2208e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.1374e-01, -1.9287e-01, -1.3767e-01],\n",
       "                         [ 1.6848e-02,  9.5921e-02,  2.4319e-02],\n",
       "                         [ 9.2863e-02,  1.6110e-01,  7.6413e-02]],\n",
       "               \n",
       "                        [[-7.7353e-03,  1.6253e-03, -9.7402e-03],\n",
       "                         [ 3.6356e-02, -1.6450e-02, -3.5853e-02],\n",
       "                         [-1.6129e-02,  2.8026e-02, -1.0210e-02]],\n",
       "               \n",
       "                        [[-3.1901e-02, -4.1196e-02, -2.0727e-02],\n",
       "                         [-1.6590e-02, -6.4131e-03, -1.0543e-02],\n",
       "                         [ 1.0598e-02,  1.1440e-02,  1.1287e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.8750e-02, -6.3484e-02, -5.2632e-02],\n",
       "                         [-5.8424e-02, -2.1054e-02, -4.6396e-02],\n",
       "                         [-3.7137e-02, -4.3729e-02, -5.0577e-02]],\n",
       "               \n",
       "                        [[ 1.3441e-02, -1.1231e-02, -1.0432e-02],\n",
       "                         [-8.0586e-03, -2.5568e-02, -3.2994e-03],\n",
       "                         [ 9.2078e-03,  1.1340e-02,  8.6766e-03]],\n",
       "               \n",
       "                        [[-4.3797e-02, -5.7524e-02, -3.5353e-02],\n",
       "                         [-6.0077e-02, -8.2644e-02, -7.1013e-02],\n",
       "                         [-3.5330e-02, -5.2873e-02, -2.7720e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4470e-02, -2.2245e-02, -2.1863e-02],\n",
       "                         [-2.3142e-02, -4.8478e-02, -1.7673e-02],\n",
       "                         [-1.3100e-02, -2.3379e-02, -6.7122e-03]],\n",
       "               \n",
       "                        [[ 1.1588e-02,  2.2954e-03, -1.7181e-02],\n",
       "                         [-2.4356e-02, -2.7237e-02,  7.3633e-03],\n",
       "                         [ 1.0116e-02, -1.5537e-02,  1.6705e-02]],\n",
       "               \n",
       "                        [[-2.2356e-02, -5.0504e-03, -2.1871e-02],\n",
       "                         [-1.2176e-02,  4.7541e-03, -2.1766e-02],\n",
       "                         [-2.5732e-02, -2.5691e-02, -3.6297e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1214e-02, -2.6653e-02, -3.4343e-02],\n",
       "                         [-1.9153e-02,  1.7460e-02, -3.2117e-02],\n",
       "                         [-1.2968e-02, -4.9162e-03, -3.9797e-02]],\n",
       "               \n",
       "                        [[ 2.4675e-02,  2.5803e-02,  1.1124e-02],\n",
       "                         [ 1.4257e-02, -2.9354e-02, -4.4545e-03],\n",
       "                         [-4.5365e-03, -7.7529e-03,  2.3000e-03]],\n",
       "               \n",
       "                        [[-9.7300e-03, -7.1630e-03, -1.9722e-02],\n",
       "                         [-7.5146e-03,  3.9816e-03, -1.4620e-02],\n",
       "                         [-5.1479e-03, -1.9195e-02, -4.1995e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.6053e-03, -1.7816e-02, -1.3093e-02],\n",
       "                         [-7.3356e-03,  1.2152e-02, -2.0696e-02],\n",
       "                         [-6.7815e-03, -1.9597e-02, -2.9109e-02]],\n",
       "               \n",
       "                        [[-4.4799e-02, -2.7398e-02, -2.2088e-02],\n",
       "                         [-3.5341e-02,  1.6461e-02, -3.7409e-02],\n",
       "                         [-1.4415e-02, -6.3243e-02, -4.4405e-02]],\n",
       "               \n",
       "                        [[ 3.9232e-03,  3.1554e-02,  2.3745e-02],\n",
       "                         [ 3.2013e-02, -9.1932e-03,  2.5697e-02],\n",
       "                         [ 2.7168e-03,  6.5853e-03, -4.6637e-03]]]], device='cuda:0')),\n",
       "              ('module.layer3.1.bn2.weight',\n",
       "               tensor([1.0989, 1.5475, 1.2232, 1.0362, 1.6310, 1.3006, 1.5871, 1.7987, 1.7223,\n",
       "                       1.8414, 1.6543, 1.2800, 0.8549, 2.5917, 1.9756, 2.6775, 1.9168, 1.7017,\n",
       "                       1.4330, 1.7481, 1.0373, 1.5691, 2.0844, 1.5296, 1.5895, 1.2397, 0.8483,\n",
       "                       1.2415, 3.8757, 1.6178, 1.6728, 1.7948, 1.4972, 1.1632, 1.3718, 1.8179,\n",
       "                       1.2110, 1.8235, 2.1409, 1.6275, 1.5481, 2.0890, 1.4003, 1.2742, 1.4471,\n",
       "                       1.6328, 1.8733, 1.7536, 1.4041, 2.4901, 1.6832, 1.7076, 1.4344, 1.2796,\n",
       "                       1.8174, 1.5352, 1.1738, 1.8039, 1.5380, 1.2494, 1.4378, 2.2369, 3.1905,\n",
       "                       1.7043, 1.9467, 1.6334, 1.3183, 1.8562, 0.9703, 1.5777, 1.4844, 1.8899,\n",
       "                       1.1871, 1.3932, 1.4099, 1.2006, 1.6038, 1.6433, 1.2763, 0.9772, 2.1442,\n",
       "                       1.3300, 1.6178, 1.7918, 1.6351, 1.2499, 1.1235, 1.2233, 0.7856, 1.5126,\n",
       "                       1.6684, 1.0701, 1.4412, 1.4374, 1.2235, 3.1288, 3.9407, 1.4562, 1.3635,\n",
       "                       1.5894, 1.9464, 2.1333, 1.8245, 1.1108, 1.5026, 3.5731, 1.3200, 0.8177,\n",
       "                       1.7456, 2.1694, 1.5855, 1.4594, 1.1349, 1.3553, 1.3303, 0.8027, 1.0792,\n",
       "                       2.4020, 1.3365, 1.8813, 1.1869, 2.0682, 1.5779, 1.6969, 1.6797, 2.0067,\n",
       "                       1.1379, 1.1543, 1.1133, 1.3400, 1.0667, 1.2950, 1.9775, 1.7793, 1.5354,\n",
       "                       1.3182, 2.1989, 2.1903, 1.4266, 0.7663, 1.6695, 1.6422, 1.4713, 1.3926,\n",
       "                       1.5456, 2.2673, 1.5303, 1.2615, 1.3475, 1.7298, 1.2953, 1.2084, 2.0908,\n",
       "                       1.1040, 1.5876, 1.3916, 1.2519, 1.7184, 1.5511, 1.3181, 1.6494, 1.1501,\n",
       "                       1.1606, 1.2895, 1.1862, 1.2834, 1.8259, 1.5135, 1.6932, 1.4278, 1.5319,\n",
       "                       2.0561, 1.6711, 1.5056, 1.1971, 1.4885, 1.3980, 1.5265, 1.4878, 1.4304,\n",
       "                       1.6083, 2.0346, 1.0266, 2.1545, 1.6586, 1.5826, 1.6137, 1.5902, 1.8971,\n",
       "                       1.8091, 0.8697, 1.4323, 1.4918, 1.4968, 0.9339, 1.9978, 1.1605, 1.8518,\n",
       "                       5.7837, 1.6999, 1.0426, 1.4323, 0.8536, 2.1048, 1.6230, 1.4463, 1.7202,\n",
       "                       2.3082, 1.4545, 1.2077, 0.9320, 5.9526, 1.7692, 1.2313, 1.2656, 1.6448,\n",
       "                       1.6446, 1.2046, 2.1560, 0.8848, 1.6066, 1.7258, 2.1979, 1.7240, 1.7532,\n",
       "                       1.7721, 1.3589, 1.4067, 3.1686, 1.3939, 1.1534, 1.7525, 2.0569, 1.5451,\n",
       "                       2.0388, 1.2568, 1.0745, 1.6391, 1.4091, 1.4219, 1.6893, 1.8631, 1.5103,\n",
       "                       1.7810, 3.6050, 1.4304, 1.6272, 1.7544, 0.8248, 1.4991, 0.8995, 1.6869,\n",
       "                       4.4360, 1.5022, 2.3497, 1.1623], device='cuda:0')),\n",
       "              ('module.layer3.1.bn2.bias',\n",
       "               tensor([ 7.9260e-01, -1.1968e+00,  5.6295e-02,  4.1329e-01, -1.0891e+00,\n",
       "                        8.2922e-01, -1.0902e+00, -8.3398e-01, -1.1657e+00, -1.1453e+00,\n",
       "                       -9.7941e-01, -4.3624e-03,  6.9934e-01, -1.8950e+00, -1.5381e+00,\n",
       "                       -2.5803e+00, -8.0247e-01, -1.8321e+00, -8.3685e-01, -1.4128e+00,\n",
       "                        1.5904e-01, -7.8291e-01, -1.2777e+00, -8.8777e-01, -8.5079e-01,\n",
       "                       -1.2448e-01,  1.9519e+00, -4.9838e-01, -3.1264e+00, -9.4724e-01,\n",
       "                       -1.0181e+00, -1.1849e+00, -4.2973e-01,  4.6218e-01,  5.1397e-01,\n",
       "                       -1.4152e+00,  2.1146e-01, -1.4684e+00, -1.6990e+00, -1.0620e+00,\n",
       "                       -8.9419e-01, -1.0532e+00, -1.4178e-01, -5.4799e-01, -1.2148e+00,\n",
       "                       -1.1542e+00, -2.2291e+00, -1.2091e+00, -4.0658e-01, -2.1687e+00,\n",
       "                       -8.9664e-01, -1.0218e+00, -5.4058e-01, -5.6592e-02, -1.1915e+00,\n",
       "                       -9.7269e-01,  8.7708e-01, -1.1378e+00, -7.0319e-01, -4.8628e-01,\n",
       "                       -1.0583e+00, -1.9391e+00, -2.8742e+00, -1.0849e+00, -7.4524e-01,\n",
       "                       -1.4528e+00, -1.0021e-01, -1.2502e+00,  6.8680e-01, -8.5253e-01,\n",
       "                       -1.5318e+00, -1.3281e+00,  2.8061e-02, -2.4336e-01, -6.6707e-01,\n",
       "                       -1.3490e-02, -7.9856e-01, -1.0191e+00,  1.8122e-01,  6.0599e-01,\n",
       "                       -1.5572e+00, -4.4228e-01, -1.7540e+00, -1.9473e+00, -1.2681e+00,\n",
       "                       -6.3816e-01,  1.7803e-01, -2.6506e-01,  1.6406e+00, -8.1895e-01,\n",
       "                       -1.0904e+00,  2.5209e+00, -7.0278e-01, -9.5710e-01, -3.9110e-01,\n",
       "                       -2.8610e+00, -2.0214e+00, -1.2130e+00,  2.8632e-01, -8.6124e-01,\n",
       "                       -9.5800e-01, -2.0826e+00, -3.0427e+00, -3.2084e-01, -9.9750e-01,\n",
       "                       -3.2413e+00,  3.8243e-01,  9.2786e-01, -1.3524e+00, -8.3097e-01,\n",
       "                       -9.6532e-01, -1.5552e+00,  4.2119e-01, -6.0663e-01, -7.8309e-01,\n",
       "                        1.2979e+00,  6.3955e-01, -1.8624e+00, -5.2496e-01, -1.5134e+00,\n",
       "                        1.5440e-01, -1.6037e+00, -1.6944e+00, -5.4742e-01, -1.0276e+00,\n",
       "                       -2.1427e+00,  2.9483e-01, -6.8482e-02,  3.5985e-01, -5.5820e-01,\n",
       "                        5.3171e-01, -4.4113e-01, -1.7368e+00, -1.1946e+00, -7.2198e-01,\n",
       "                       -8.6333e-01, -1.5616e+00, -1.9354e+00, -1.4327e+00,  1.7626e+00,\n",
       "                       -1.0248e+00, -8.6165e-01, -8.2347e-01, -5.5780e-01, -6.5389e-01,\n",
       "                       -2.7538e+00, -7.0042e-01, -1.2718e+00, -7.2192e-01, -2.2807e+00,\n",
       "                       -3.6374e-01,  4.0113e-01, -1.1829e+00,  6.8706e-01, -1.1988e+00,\n",
       "                       -1.7192e-01,  8.9459e-02, -1.1803e+00, -5.2775e-01,  1.8892e-01,\n",
       "                       -1.0310e+00,  5.6142e-02,  8.9261e-02,  8.8457e-01,  5.7748e-01,\n",
       "                       -6.6568e-01, -2.1249e+00, -4.3871e-01, -1.5683e+00, -3.7640e-01,\n",
       "                       -7.3653e-01, -1.4695e+00, -1.0017e+00, -6.6507e-01, -1.1234e-01,\n",
       "                       -6.9751e-01, -8.3223e-01, -8.1255e-01, -5.1346e-01, -6.8762e-01,\n",
       "                       -1.1287e+00, -1.8045e+00,  4.2132e-01, -2.2432e+00, -7.5213e-01,\n",
       "                       -4.6333e-01, -9.8185e-01, -1.3862e+00, -1.2570e+00, -1.1176e+00,\n",
       "                        9.6454e-01, -6.6566e-01, -7.9872e-01, -8.6056e-01,  4.2368e-01,\n",
       "                       -1.2590e+00,  2.6251e-01, -1.4692e+00, -6.1655e+00, -1.2016e+00,\n",
       "                        6.9341e-01, -4.4206e-01,  6.5849e-01, -2.6783e+00, -1.1361e+00,\n",
       "                       -6.1909e-01, -1.1320e+00, -2.2723e+00, -8.7380e-01,  3.3195e-02,\n",
       "                        1.3602e+00, -4.9850e+00, -4.8895e-01,  5.5141e-02,  4.3373e-01,\n",
       "                       -8.8902e-01, -1.0867e+00, -1.2343e-01, -1.1366e+00,  2.2905e+00,\n",
       "                       -1.2409e+00, -6.5426e-01, -1.2969e+00, -9.3455e-01, -1.0678e+00,\n",
       "                       -1.2787e+00,  2.5954e-01, -9.6629e-01, -3.7695e+00,  3.6722e-01,\n",
       "                        2.5955e-01, -1.1468e+00, -1.6302e+00, -7.8080e-01, -2.3621e+00,\n",
       "                       -7.3959e-01,  2.7358e-01, -1.3568e+00, -8.7675e-01, -4.9011e-01,\n",
       "                       -9.9411e-01, -1.2934e+00, -1.0094e+00, -7.3786e-01, -4.4956e+00,\n",
       "                       -5.9262e-01, -7.5115e-01, -1.3936e+00,  1.8495e+00, -5.7212e-01,\n",
       "                        1.4129e+00, -1.0267e+00, -2.4453e+00, -4.0311e-01, -2.4314e+00,\n",
       "                       -1.7087e-01], device='cuda:0')),\n",
       "              ('module.layer3.1.bn2.running_mean',\n",
       "               tensor([ 1.2828e+00, -1.5039e+00, -1.1352e-01,  7.9357e-01, -1.4903e-02,\n",
       "                        4.4722e-02, -1.7971e+00,  1.4890e-01, -4.9278e-01, -1.3484e+00,\n",
       "                       -5.3335e-01, -1.2575e+00, -4.4956e-01, -2.1865e+00, -1.6778e+00,\n",
       "                       -1.5786e+00, -2.5362e-01, -4.5981e-01,  2.7028e-01, -1.2643e+00,\n",
       "                       -1.3441e+00, -5.4047e-01,  1.5487e-01, -8.7333e-01, -1.4512e-01,\n",
       "                       -4.1502e-01, -3.6887e-02, -7.6508e-01, -5.0105e-01, -2.1267e-01,\n",
       "                       -1.0121e-01, -1.4768e+00,  1.2310e+00,  1.0417e+00,  1.3301e+00,\n",
       "                       -1.4829e+00,  6.4821e-01,  5.5528e-01, -1.7155e+00,  8.5033e-02,\n",
       "                       -1.9941e-02, -9.6432e+00,  5.4538e-01, -5.2682e-01, -4.1897e-01,\n",
       "                       -4.9894e-01,  8.2308e-01,  4.5977e-01,  7.8361e-02, -1.5944e+00,\n",
       "                       -6.7922e-01,  3.3106e-01, -1.0891e+00,  1.1869e+00, -8.9947e-01,\n",
       "                       -2.4514e-01,  1.0684e+00, -6.4127e-01,  5.0978e-01, -5.5093e-01,\n",
       "                       -1.8633e-01, -2.6171e-01, -2.6229e+00,  4.7595e-01, -6.3751e-02,\n",
       "                       -4.0234e-01, -6.9889e-02, -2.1215e+00,  5.0454e-01, -1.1561e+00,\n",
       "                       -1.1101e+00, -3.9845e-01,  7.0054e-01,  5.5820e-01, -6.7006e-01,\n",
       "                       -1.7601e+00, -4.7566e-01, -7.1988e-01, -1.2241e+00,  2.6867e-01,\n",
       "                        6.8961e-01, -2.6620e-01, -5.6606e-01,  4.0181e-01,  1.0614e-01,\n",
       "                       -5.5953e-01, -2.4592e-01, -9.6710e-02, -7.8668e-01, -1.0165e+00,\n",
       "                       -2.2477e-01,  3.1904e+00, -2.9049e-01, -5.2774e-01, -1.8771e-01,\n",
       "                       -7.8738e-03, -2.6079e+00, -1.1504e+00,  1.4556e+00,  5.3407e-01,\n",
       "                       -5.6044e-01, -1.1562e-01,  9.4876e-03, -9.2666e-01, -6.2914e-01,\n",
       "                        8.8795e-01,  1.5172e+00, -8.3632e-01, -1.5759e-01, -4.7096e-01,\n",
       "                       -5.4556e-01, -7.8769e-01, -1.6328e-03,  2.3765e-01, -4.4243e-01,\n",
       "                        9.9237e-01,  1.3254e+00,  7.8072e-01, -2.3692e-01,  4.9980e-01,\n",
       "                       -6.1340e-01, -9.6527e-01,  6.6049e-01,  1.2427e+00, -2.6837e-01,\n",
       "                        1.5238e-01,  1.2302e-01, -1.5459e+00,  2.1104e+00, -2.9136e-01,\n",
       "                        6.3186e-01, -1.0803e+00,  6.4501e-02, -1.5955e+00, -1.5501e+00,\n",
       "                       -1.2606e+00, -3.8786e+00, -1.0161e+00, -4.9720e-01, -1.5221e+00,\n",
       "                        1.3823e-01, -3.0234e-01,  4.3107e-02,  1.2315e-01,  5.6784e-01,\n",
       "                       -1.4694e+00, -5.8737e-01,  3.1368e-01, -1.1031e-01,  4.5642e-01,\n",
       "                       -5.6714e-01,  6.7185e-01, -3.4884e-01,  7.9522e-01, -8.6551e-01,\n",
       "                        4.6428e-01,  5.8534e-01,  2.5074e-02,  2.4437e-01,  1.6535e+00,\n",
       "                       -1.4003e-01,  1.1165e+00,  6.3109e-01,  9.7963e-01,  1.3371e+00,\n",
       "                       -7.0091e-01, -3.4524e-01,  3.4873e+00, -2.3635e-01, -1.1191e+00,\n",
       "                       -1.0268e-01, -1.0461e+00, -1.4249e-01,  1.7668e+00, -1.4481e+00,\n",
       "                       -2.1007e-01, -4.4250e-01, -2.4868e-01, -1.6079e-01, -7.1366e-01,\n",
       "                       -5.1173e-01,  5.2836e-02, -4.4642e-01, -1.3091e+00,  1.0206e-01,\n",
       "                       -3.4861e-01,  1.4151e-02, -7.8464e-01, -2.6890e-01, -8.1696e-01,\n",
       "                       -8.2050e-01, -2.3204e-01, -9.4653e-02, -8.2485e-01,  9.7868e-01,\n",
       "                       -4.2171e-04, -1.1589e+00, -2.2204e-01, -4.1226e+00, -1.5243e+00,\n",
       "                        4.1007e+00, -1.1544e+00, -5.7864e-01, -1.0631e+00,  1.5932e+00,\n",
       "                        7.5195e-03, -7.4985e-02, -1.4659e+00, -1.2910e+00,  1.5960e-01,\n",
       "                       -1.4203e+00,  4.8904e-01, -8.9658e+00, -8.5691e-02,  1.0616e+00,\n",
       "                        6.0021e-01, -2.9697e-01, -1.5676e+00, -1.7628e-01, -1.3551e+00,\n",
       "                       -2.4360e-01, -1.2653e-02, -6.3933e-01, -1.9500e+00, -2.4480e-02,\n",
       "                       -1.1835e+00,  1.5971e+00, -1.1072e+00, -2.4714e+00,  1.8329e+00,\n",
       "                        1.4438e+00, -8.1671e-02, -1.6945e+00, -3.9296e-01, -1.2316e+00,\n",
       "                       -4.9123e-01,  9.2813e-01, -7.7932e-01, -9.3026e-01, -1.3559e-01,\n",
       "                       -7.6879e-02, -5.8973e-01, -1.8929e-01,  9.8717e-02, -2.5000e+00,\n",
       "                       -1.0249e+00, -5.2291e-01, -7.8661e-01, -1.1228e+00,  2.9105e+00,\n",
       "                       -1.0390e+00,  3.2417e-01,  5.0080e-01, -2.1876e+00, -1.7619e+00,\n",
       "                       -6.6131e-01], device='cuda:0')),\n",
       "              ('module.layer3.1.bn2.running_var',\n",
       "               tensor([ 2.6829,  2.2498,  1.9784,  2.1285,  2.0324,  4.3653,  2.4961,  2.0092,\n",
       "                        1.8924,  2.4236,  1.4972,  2.4345,  2.2968,  4.2435,  2.2117,  4.1838,\n",
       "                        3.1631,  1.4223,  1.7859,  2.0957,  2.2625,  1.6604,  1.9394,  2.3875,\n",
       "                        1.7139,  2.1125,  1.7547,  1.7494, 10.2691,  1.7646,  1.5486,  2.6390,\n",
       "                        2.1228,  2.7866,  3.8810,  2.2636,  2.2034,  1.8435,  3.1469,  1.3093,\n",
       "                        1.5696,  7.0713,  2.4561,  1.8282,  1.4206,  1.3079,  1.2629,  1.8684,\n",
       "                        2.0263,  3.1376,  2.4768,  1.9777,  2.4639,  2.1607,  0.9543,  2.1173,\n",
       "                        2.4646,  2.1168,  1.7542,  1.7992,  1.8304,  1.7792,  5.5382,  2.2176,\n",
       "                        3.3691,  1.3843,  2.1464,  2.0487,  2.0988,  2.3939,  1.8834,  1.7926,\n",
       "                        1.9266,  2.0406,  3.5115,  1.7157,  1.8949,  1.4502,  2.0867,  2.4830,\n",
       "                        2.1466,  1.5345,  1.1878,  2.0015,  1.6294,  1.3728,  1.5825,  1.9413,\n",
       "                        1.6509,  1.7573,  1.5908,  2.4791,  1.5889,  1.8087,  1.7799,  3.0738,\n",
       "                        5.5621,  1.8515,  3.5822,  1.8428,  3.2144,  1.3439,  1.9649,  1.6551,\n",
       "                        1.6122,  4.3228,  3.5248,  2.1514,  1.3275,  3.9657,  1.7624,  1.4043,\n",
       "                        3.0096,  1.3199,  1.2500,  2.0442,  3.8932,  2.3723,  1.4873,  1.8361,\n",
       "                        2.9429,  3.2329,  1.7619,  3.1947,  2.4331,  1.9905,  2.3967,  2.2332,\n",
       "                        2.3197,  1.9611,  3.1558,  3.1735,  1.2117,  2.7577,  2.6826,  1.1698,\n",
       "                       13.3171,  3.5516,  1.1952,  1.3781,  1.5624,  2.0890,  1.5475,  1.9104,\n",
       "                        1.5940,  1.7222,  1.6060,  1.0024,  3.2248,  2.3195,  1.8766,  3.3175,\n",
       "                        2.0485,  3.7727,  2.0774,  2.0950,  2.9625,  1.6179,  2.1542,  2.3935,\n",
       "                        1.6571,  2.1155,  1.9886,  2.9332,  2.7572,  1.7095,  1.5572,  4.2046,\n",
       "                        1.0174,  1.9417,  1.5966,  4.0892,  1.5742,  1.7867,  3.0413,  1.9614,\n",
       "                        2.1958,  1.8552,  2.3143,  1.8660,  1.5993,  1.3106,  1.5466,  1.6054,\n",
       "                        1.7158,  2.5377,  1.4531,  1.7800,  1.5096,  2.5227,  1.6672,  1.8191,\n",
       "                        1.6822,  1.8057,  1.7298,  1.7421,  2.3629,  1.8839,  9.3518,  2.0512,\n",
       "                        2.3308,  2.5682,  1.8238,  1.0075,  1.6430,  2.0028,  1.6449,  1.9564,\n",
       "                        2.0678,  2.1275,  2.1642,  5.0937,  6.5547,  1.6835,  3.7336,  2.1661,\n",
       "                        1.1080,  2.7080,  3.2121,  1.6037,  1.2271,  2.3597,  2.5254,  2.9694,\n",
       "                        1.9192,  2.7077,  3.5229,  1.7139,  2.7365,  4.0205,  2.1882,  1.4590,\n",
       "                        1.7406,  1.6679,  1.9274,  1.4729,  1.5513,  2.2964,  1.4952,  1.6530,\n",
       "                        1.8845,  2.2470,  2.5273,  3.1100,  3.1607,  2.6555,  2.4827,  2.3847,\n",
       "                        1.4982,  1.7091,  2.4666,  1.8473,  7.7497,  1.8160,  2.9414,  2.0758],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.1.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.1.conv3.weight',\n",
       "               tensor([[[[ 1.2212e-03]],\n",
       "               \n",
       "                        [[-2.7410e-01]],\n",
       "               \n",
       "                        [[ 1.0689e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.9700e-03]],\n",
       "               \n",
       "                        [[-4.6869e-02]],\n",
       "               \n",
       "                        [[ 5.9657e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.9693e-04]],\n",
       "               \n",
       "                        [[-1.0377e-04]],\n",
       "               \n",
       "                        [[ 5.2806e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.1997e-03]],\n",
       "               \n",
       "                        [[-2.2389e-02]],\n",
       "               \n",
       "                        [[-1.5097e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2420e-02]],\n",
       "               \n",
       "                        [[ 9.3898e-02]],\n",
       "               \n",
       "                        [[ 1.3883e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.6744e-02]],\n",
       "               \n",
       "                        [[ 2.0225e-02]],\n",
       "               \n",
       "                        [[-1.3927e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-5.3764e-03]],\n",
       "               \n",
       "                        [[ 1.8936e-02]],\n",
       "               \n",
       "                        [[ 1.1511e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.0180e-02]],\n",
       "               \n",
       "                        [[-4.4297e-02]],\n",
       "               \n",
       "                        [[-5.3543e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0396e-02]],\n",
       "               \n",
       "                        [[-3.8333e-04]],\n",
       "               \n",
       "                        [[ 2.7030e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.7431e-03]],\n",
       "               \n",
       "                        [[ 8.2265e-03]],\n",
       "               \n",
       "                        [[-1.3219e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.3062e-02]],\n",
       "               \n",
       "                        [[ 1.0835e-02]],\n",
       "               \n",
       "                        [[ 2.3951e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3402e-02]],\n",
       "               \n",
       "                        [[ 3.0478e-02]],\n",
       "               \n",
       "                        [[ 4.7763e-03]]]], device='cuda:0')),\n",
       "              ('module.layer3.1.bn3.weight',\n",
       "               tensor([0.8321, 0.6254, 0.6698,  ..., 0.8812, 0.3027, 0.2520], device='cuda:0')),\n",
       "              ('module.layer3.1.bn3.bias',\n",
       "               tensor([-0.9298, -0.6902, -0.7458,  ..., -0.8911,  0.0020, -0.2509],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.1.bn3.running_mean',\n",
       "               tensor([-0.3535, -0.4838, -0.5874,  ..., -0.3591, -0.0875,  0.1568],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.1.bn3.running_var',\n",
       "               tensor([0.2154, 0.0801, 0.1476,  ..., 0.1069, 0.0706, 0.0335], device='cuda:0')),\n",
       "              ('module.layer3.1.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.2.conv1.weight',\n",
       "               tensor([[[[ 0.0031]],\n",
       "               \n",
       "                        [[ 0.0034]],\n",
       "               \n",
       "                        [[-0.0195]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0075]],\n",
       "               \n",
       "                        [[-0.0076]],\n",
       "               \n",
       "                        [[-0.0350]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0215]],\n",
       "               \n",
       "                        [[ 0.0121]],\n",
       "               \n",
       "                        [[-0.0389]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0303]],\n",
       "               \n",
       "                        [[-0.0234]],\n",
       "               \n",
       "                        [[-0.0467]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0157]],\n",
       "               \n",
       "                        [[ 0.0030]],\n",
       "               \n",
       "                        [[-0.0098]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0336]],\n",
       "               \n",
       "                        [[ 0.0001]],\n",
       "               \n",
       "                        [[ 0.0189]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0162]],\n",
       "               \n",
       "                        [[-0.0159]],\n",
       "               \n",
       "                        [[-0.0233]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0151]],\n",
       "               \n",
       "                        [[ 0.0502]],\n",
       "               \n",
       "                        [[-0.0183]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0167]],\n",
       "               \n",
       "                        [[-0.0102]],\n",
       "               \n",
       "                        [[-0.0142]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0126]],\n",
       "               \n",
       "                        [[-0.0260]],\n",
       "               \n",
       "                        [[-0.0484]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0079]],\n",
       "               \n",
       "                        [[-0.0025]],\n",
       "               \n",
       "                        [[-0.0168]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0095]],\n",
       "               \n",
       "                        [[-0.0085]],\n",
       "               \n",
       "                        [[-0.0067]]]], device='cuda:0')),\n",
       "              ('module.layer3.2.bn1.weight',\n",
       "               tensor([1.3504, 1.9467, 1.3654, 1.4641, 1.4338, 1.3016, 1.0746, 1.8266, 1.0154,\n",
       "                       1.4740, 1.2601, 2.0397, 1.5108, 2.0503, 0.8981, 0.8138, 1.4882, 1.1331,\n",
       "                       1.0353, 1.4888, 1.8693, 1.1994, 1.7230, 1.1535, 1.5982, 1.4372, 1.7109,\n",
       "                       2.1863, 0.8395, 1.3546, 1.7391, 1.2769, 1.3471, 1.5536, 1.1793, 1.4574,\n",
       "                       1.1418, 1.6774, 1.1161, 1.2736, 1.2917, 1.5839, 1.7255, 0.9591, 1.8587,\n",
       "                       1.2923, 0.9098, 0.8209, 1.0680, 1.3248, 1.6279, 1.0067, 2.3298, 1.2841,\n",
       "                       1.1408, 1.3519, 1.7305, 1.0571, 1.8976, 1.3765, 1.6978, 0.8164, 1.2532,\n",
       "                       1.1905, 1.9194, 1.5147, 1.3773, 1.2502, 1.9674, 0.9693, 0.9132, 1.9784,\n",
       "                       1.4910, 1.3182, 1.5398, 1.2675, 1.6777, 1.3406, 1.2054, 1.6049, 1.2301,\n",
       "                       0.8640, 1.6767, 1.1570, 1.0760, 1.1856, 0.8796, 1.5166, 1.2022, 0.9139,\n",
       "                       1.4180, 1.3965, 1.2456, 1.7330, 1.4520, 1.1757, 0.8881, 1.1231, 0.9462,\n",
       "                       1.8996, 1.6613, 1.4560, 1.6146, 1.3955, 1.1046, 0.9248, 1.0486, 1.2380,\n",
       "                       1.3761, 1.1723, 1.5067, 1.4849, 1.4495, 1.4448, 0.8155, 1.1143, 1.2723,\n",
       "                       1.1309, 1.6727, 1.1987, 1.0462, 2.1211, 0.9558, 1.4615, 1.2449, 1.6683,\n",
       "                       1.4448, 1.1340, 1.6241, 1.0907, 1.8680, 0.9726, 1.1462, 1.0132, 1.3211,\n",
       "                       1.4089, 0.9520, 1.4355, 1.5251, 0.9327, 1.2529, 1.1806, 1.5261, 1.6009,\n",
       "                       1.5330, 1.3656, 1.3899, 1.5150, 1.0830, 1.1913, 1.4939, 0.6433, 1.4038,\n",
       "                       2.0874, 2.0408, 1.3010, 0.9632, 1.2565, 0.9428, 2.2048, 1.5137, 1.2302,\n",
       "                       1.3531, 1.1142, 0.7603, 1.8129, 1.3724, 0.9474, 1.4781, 1.1053, 1.9089,\n",
       "                       1.3750, 1.5384, 1.4409, 1.3088, 1.5605, 0.9900, 1.9052, 1.5108, 0.5466,\n",
       "                       1.1541, 0.8558, 1.1760, 1.0531, 1.7117, 2.1170, 1.7298, 1.8896, 1.5645,\n",
       "                       1.4681, 1.4361, 1.2108, 1.6401, 1.3053, 1.6488, 1.3664, 1.4043, 1.4036,\n",
       "                       1.4679, 1.0986, 1.6028, 1.1677, 1.6659, 1.8304, 1.3909, 1.3599, 1.4748,\n",
       "                       1.4569, 1.9222, 1.6191, 1.0924, 1.2405, 1.6949, 1.3386, 1.2689, 1.0332,\n",
       "                       1.2954, 1.0139, 1.2178, 1.7245, 0.9447, 2.2171, 1.8509, 1.5838, 1.4324,\n",
       "                       1.2839, 1.4000, 0.6890, 1.3419, 1.1297, 1.2293, 1.8959, 1.4771, 1.2502,\n",
       "                       2.1340, 1.5807, 1.2034, 1.6185, 0.8913, 1.1443, 1.4213, 1.6591, 1.5597,\n",
       "                       1.6639, 1.4234, 1.2723, 1.0717, 1.5498, 1.2761, 1.9964, 2.0206, 1.5257,\n",
       "                       1.2303, 1.8234, 1.3508, 1.2108], device='cuda:0')),\n",
       "              ('module.layer3.2.bn1.bias',\n",
       "               tensor([-7.4954e-01, -2.0694e+00, -1.6300e+00, -1.0233e+00, -2.0755e+00,\n",
       "                       -4.7964e-01, -3.7947e-01, -2.0795e+00, -1.4404e-01, -1.3717e+00,\n",
       "                       -7.0232e-01, -3.2709e+00, -1.4199e+00, -4.2548e+00,  7.4816e-01,\n",
       "                        5.6529e-01, -1.4949e+00, -8.0423e-02, -3.4632e-01, -1.5168e+00,\n",
       "                       -1.6202e+00, -1.7855e-01, -2.8714e+00, -3.2301e-01, -1.7316e+00,\n",
       "                       -1.2110e+00, -2.3439e+00, -1.1670e+00,  3.2561e-01, -1.0312e+00,\n",
       "                       -1.2503e+00, -2.5721e-01, -1.1861e+00, -1.7029e+00, -2.2992e-01,\n",
       "                       -1.4980e+00, -5.0173e-01, -2.8016e+00, -1.6435e-01, -6.7240e-01,\n",
       "                       -8.2859e-01, -1.9169e+00, -1.5567e+00, -7.7981e-02, -2.7406e+00,\n",
       "                       -9.8191e-01,  4.5735e-01,  2.6480e-01, -5.3642e-01, -4.6639e-01,\n",
       "                       -1.1345e+00, -2.9939e-01, -2.5197e+00, -3.3195e-01, -2.5558e-01,\n",
       "                       -7.7743e-01, -2.4862e+00, -1.0925e-01, -2.2577e+00, -1.4541e+00,\n",
       "                       -2.1295e+00,  4.9367e-01, -9.0740e-01, -4.6139e-01, -6.9265e-01,\n",
       "                       -1.4480e+00, -1.2653e+00, -5.1632e-01, -1.7743e+00, -1.2513e-01,\n",
       "                        6.0399e-02, -2.0120e+00, -1.4589e+00, -1.0913e+00, -1.1867e+00,\n",
       "                       -7.4368e-01, -1.3224e+00, -3.9584e-01, -9.9764e-01, -1.4701e+00,\n",
       "                       -7.6730e-01,  5.0143e-01, -1.8123e+00, -8.0442e-01, -4.8897e-01,\n",
       "                       -6.9602e-01,  8.1721e-02, -1.9929e+00, -7.2584e-01,  7.1369e-02,\n",
       "                       -8.3993e-01, -6.9037e-01, -7.1820e-01, -1.9003e+00, -1.7958e+00,\n",
       "                       -2.1540e-01,  1.3956e-01, -1.2682e+00, -1.9882e-01, -1.7588e+00,\n",
       "                       -1.7186e+00, -1.3783e+00, -1.1422e+00, -1.0630e+00, -1.3919e-01,\n",
       "                       -9.4924e-02, -1.0323e-01, -4.6640e-01, -9.5919e-01, -3.0091e-01,\n",
       "                       -1.5683e+00, -1.0021e+00, -9.4184e-01, -1.6030e+00,  2.1809e-01,\n",
       "                       -6.4996e-01, -4.2509e-01, -6.7618e-01, -9.7272e-01, -5.4673e-01,\n",
       "                        5.2607e-03, -2.4275e+00,  2.8358e-02, -2.0830e+00, -4.7208e-01,\n",
       "                       -1.0492e+00, -1.1558e+00, -2.2032e-01, -2.2398e+00, -4.7058e-01,\n",
       "                       -3.1245e+00, -4.0171e-01, -4.1047e-01,  2.6496e-02, -4.2432e-01,\n",
       "                       -8.4500e-01,  1.4168e-01, -1.5664e+00, -1.3663e+00,  8.0860e-02,\n",
       "                       -8.3980e-01, -3.5138e-01, -1.2659e+00, -1.9228e+00, -9.4054e-01,\n",
       "                       -1.2168e+00, -6.9925e-01, -1.6529e+00, -1.8252e-01, -1.0022e+00,\n",
       "                       -1.4272e+00,  8.2563e-01, -8.8522e-01, -2.5472e+00, -2.6300e+00,\n",
       "                       -5.4146e-01,  7.6599e-03, -4.7140e-01,  6.7159e-01, -3.5862e+00,\n",
       "                       -5.9410e-01, -4.0244e-01, -7.0885e-01, -1.3548e-01,  7.4599e-01,\n",
       "                       -2.1916e+00, -1.1720e+00, -6.1492e-05, -1.1343e+00, -5.0658e-02,\n",
       "                       -1.8854e+00, -1.0064e+00, -2.4401e+00, -1.2496e+00, -8.9297e-01,\n",
       "                       -1.3989e+00, -4.8628e-01, -1.7334e+00, -1.1598e+00,  7.9543e-01,\n",
       "                       -4.5844e-01,  4.3296e-01, -1.6834e-02, -6.3429e-02, -2.6905e+00,\n",
       "                       -2.2011e+00, -1.5507e+00, -1.8871e+00, -1.7786e+00, -1.9533e-01,\n",
       "                       -1.1911e+00, -6.6628e-01, -1.8564e+00, -4.3613e-01, -2.2944e+00,\n",
       "                       -1.0705e+00, -1.3122e+00, -1.7335e+00, -1.7767e+00, -4.9105e-01,\n",
       "                       -2.1963e+00, -8.0670e-01, -1.8863e+00, -1.5574e+00, -8.4698e-01,\n",
       "                       -1.3826e+00, -1.3281e+00, -1.6973e+00, -2.3100e+00, -2.0210e+00,\n",
       "                       -9.9427e-02, -4.1542e-01, -1.8920e+00, -9.7919e-01, -9.3969e-01,\n",
       "                       -3.5636e-01, -5.7992e-01,  1.7825e-01, -6.8426e-01, -1.0631e+00,\n",
       "                        7.6013e-01, -2.3310e+00, -2.1676e+00, -2.4623e+00, -1.2062e+00,\n",
       "                       -1.0590e+00, -1.0469e+00,  9.6870e-01, -8.9049e-01, -8.5224e-01,\n",
       "                       -1.4554e+00, -1.6606e+00, -2.1378e+00, -9.1374e-01, -3.9587e+00,\n",
       "                       -2.1601e+00, -8.5371e-01, -9.5013e-01,  1.5245e-01, -3.5260e-01,\n",
       "                       -1.5482e+00, -1.8112e+00, -1.7704e+00, -1.8749e+00, -2.5931e+00,\n",
       "                       -1.0194e+00, -2.0008e-01, -1.1697e+00, -1.1064e+00, -2.7425e+00,\n",
       "                       -2.4570e+00, -1.4369e+00, -3.1092e-01, -2.1561e+00, -9.6128e-01,\n",
       "                       -1.0414e-01], device='cuda:0')),\n",
       "              ('module.layer3.2.bn1.running_mean',\n",
       "               tensor([-2.3574e+00, -1.8475e+00,  3.9324e-01, -3.6712e-01, -1.2294e+00,\n",
       "                        9.3724e-01, -5.9933e-01, -2.1470e+00, -1.5898e-01, -1.0453e+00,\n",
       "                       -4.6973e-01, -2.4237e+00,  6.8861e-02, -2.4686e+00,  1.7311e+00,\n",
       "                        5.9723e-01, -8.7429e-01, -2.1147e-01,  1.4117e-03, -3.6786e-01,\n",
       "                       -8.4550e-01,  4.3203e-01, -1.2189e+00, -2.9451e-01, -1.7646e+00,\n",
       "                        2.2537e-01, -1.6839e+00, -3.3426e-01, -1.5541e+00, -1.3944e+00,\n",
       "                       -4.9676e-01, -5.2005e-01, -1.0998e+00, -4.5693e-01, -6.3098e-01,\n",
       "                        3.8904e-01,  1.0264e+00, -8.8838e-01, -1.2169e+00, -3.6587e-01,\n",
       "                        2.3427e-01, -6.8743e-02, -2.0426e+00,  9.3413e-02, -2.0133e+00,\n",
       "                        1.1891e+00, -3.0397e+00, -3.2259e-01, -3.1242e+00, -2.5302e+00,\n",
       "                       -1.4441e+00,  4.7029e-01, -6.6969e-01, -6.7029e-01, -1.7410e+00,\n",
       "                       -1.3992e+00, -3.2320e-01, -1.3188e+00, -1.9328e+00, -7.0568e-01,\n",
       "                       -1.5520e+00, -1.2002e+00, -1.2274e+00, -2.2769e-01,  1.0551e+00,\n",
       "                       -6.4670e-01, -2.1094e+00,  4.7745e-03, -3.8917e-01, -3.3137e-01,\n",
       "                       -2.2392e-02, -9.0481e-01, -1.8385e+00, -1.4150e+00, -1.3291e+00,\n",
       "                       -1.9166e+00, -3.1547e-01, -2.1746e+00, -4.8540e-01, -1.3791e+00,\n",
       "                       -1.0954e+00, -3.1510e+00, -1.3568e+00, -2.0782e+00,  7.6211e-02,\n",
       "                       -9.1812e-01,  1.0825e+00, -6.1908e-01,  1.6501e-01,  8.6943e-01,\n",
       "                       -6.2202e-02, -1.4186e+00, -2.5915e+00, -1.8691e+00,  2.5850e-01,\n",
       "                       -9.8864e-01,  1.0693e+00, -1.1227e+00, -1.8144e+00, -1.4338e+00,\n",
       "                       -3.9197e-01, -9.1814e-01, -8.3898e-01, -3.5267e-02, -6.8077e-01,\n",
       "                       -1.0257e+00, -1.4863e+00, -1.4306e-01, -9.2921e-01, -1.8518e-01,\n",
       "                        9.4287e-01, -1.2958e+00, -3.5850e+00, -1.8416e+00, -1.9784e+00,\n",
       "                       -5.9204e-01, -1.7415e+00,  1.7101e+00, -4.3026e-01, -2.7181e+00,\n",
       "                       -1.5716e+00, -6.3550e-01, -1.0689e+00, -1.7990e+00,  9.0511e-01,\n",
       "                       -1.3316e+00, -2.9992e+00,  1.4505e-01, -7.1894e-01, -1.8283e+00,\n",
       "                       -1.2151e+00, -1.0080e+00,  2.5595e-01, -7.6837e-01, -8.0853e-01,\n",
       "                       -4.3630e-01, -1.3376e+00, -5.8495e-01, -5.5591e-01, -4.6662e-01,\n",
       "                       -9.4572e-01, -1.3722e+00, -1.1542e+00, -1.1935e+00, -2.3964e+00,\n",
       "                       -2.0180e+00,  2.6372e-01, -1.7895e+00, -1.0405e+00, -8.3897e-01,\n",
       "                       -9.1110e-01, -2.0546e+00, -2.5561e-02, -1.5765e+00,  2.8527e-01,\n",
       "                       -2.3364e+00, -1.6542e+00, -5.1545e-01, -6.5201e+00, -1.4418e+00,\n",
       "                        1.8615e-01, -4.6049e-01, -5.4531e-01, -4.8995e-01, -2.2190e+00,\n",
       "                       -5.2463e-01, -2.2673e-01,  2.2661e-01, -2.2621e+00,  4.0096e-01,\n",
       "                       -1.3690e+00, -8.7062e-01, -1.6078e+00, -8.5981e-02, -1.0088e+00,\n",
       "                       -2.7527e+00, -2.0730e+00, -1.6626e+00,  2.2024e-01,  2.6032e+00,\n",
       "                        5.2090e-01, -2.2090e+00, -1.9297e+00, -1.9484e+00,  5.9084e-01,\n",
       "                       -1.6104e+00, -8.2677e-01, -8.5790e-01, -2.0650e+00, -2.2687e+00,\n",
       "                        8.9931e-01, -2.3402e+00,  9.4682e-02, -1.9085e+00, -2.6333e+00,\n",
       "                       -1.6602e+00,  6.2503e-02, -9.1239e-02,  2.7481e-01,  2.2725e-02,\n",
       "                       -2.6312e-01, -6.9625e-01, -1.5676e+00, -2.1730e+00, -2.2048e+00,\n",
       "                       -1.6224e+00, -1.2837e+00, -1.2495e+00, -1.0147e+00, -6.4770e-01,\n",
       "                       -4.4438e-01, -2.1366e+00, -4.2249e-01,  2.8246e-02, -2.1569e-01,\n",
       "                        4.2808e-01,  7.6931e-02, -3.7351e+00,  1.1858e+00, -2.1189e-01,\n",
       "                       -4.7380e-01, -9.1275e-01, -1.7833e+00, -6.9755e-01, -1.4674e+00,\n",
       "                       -1.6917e-01, -2.0336e+00, -3.7914e+00, -1.5716e+00, -1.2468e-01,\n",
       "                        9.7084e-01, -2.4795e+00, -3.8848e-01, -4.9997e-01, -1.7780e+00,\n",
       "                       -1.4919e+00, -1.8678e-02, -2.0660e+00,  1.7388e-01, -7.2860e-01,\n",
       "                       -2.1986e+00, -8.5079e-01,  5.5256e-01, -1.8629e+00, -1.4545e+00,\n",
       "                       -9.9568e-02, -1.3087e+00,  2.2748e-01, -4.9113e-01, -1.5858e+00,\n",
       "                       -8.9318e-02, -8.7462e-01, -1.6849e+00, -2.0506e+00, -1.4712e+00,\n",
       "                       -1.8907e+00], device='cuda:0')),\n",
       "              ('module.layer3.2.bn1.running_var',\n",
       "               tensor([3.7352, 2.4390, 1.0646, 3.3484, 3.6090, 4.6401, 2.5699, 4.1076, 3.6027,\n",
       "                       1.8548, 3.8545, 1.6314, 3.2113, 1.4711, 3.6636, 4.3834, 2.7731, 5.3428,\n",
       "                       3.1884, 2.8841, 3.8166, 5.3137, 1.4886, 3.2962, 3.2042, 3.1621, 1.7596,\n",
       "                       5.7842, 4.0614, 2.7697, 2.6636, 3.9826, 2.1199, 2.0586, 3.9357, 2.5959,\n",
       "                       2.9750, 1.5545, 4.0594, 2.8423, 2.1457, 2.2262, 2.6150, 2.9461, 1.3379,\n",
       "                       1.6138, 4.9542, 3.5857, 2.4262, 4.3403, 4.7153, 3.0568, 3.6317, 4.6560,\n",
       "                       4.0413, 2.8170, 1.5347, 4.1050, 3.6636, 1.5009, 2.1389, 4.4112, 4.4708,\n",
       "                       2.8692, 7.4801, 2.7432, 2.3586, 3.1659, 2.9230, 2.3575, 3.6182, 3.3664,\n",
       "                       2.3057, 2.3165, 3.1830, 2.3877, 2.3495, 4.7855, 2.3742, 3.1767, 2.8266,\n",
       "                       7.0247, 2.6926, 2.1951, 2.5295, 2.5185, 3.7326, 1.8308, 3.1238, 3.2105,\n",
       "                       3.4302, 3.1643, 4.1341, 2.6816, 1.7664, 5.6445, 4.1066, 1.3470, 2.3800,\n",
       "                       2.7307, 2.4058, 2.7503, 4.8136, 4.0559, 4.7034, 2.7132, 3.8933, 4.1812,\n",
       "                       3.3348, 4.0277, 2.3866, 5.1616, 3.4130, 2.2895, 2.9514, 2.2965, 4.2003,\n",
       "                       2.2530, 3.6351, 3.0530, 3.3720, 2.4738, 3.5841, 1.2991, 2.9762, 5.3556,\n",
       "                       2.6079, 3.6393, 1.7135, 2.5493, 1.2673, 2.1477, 3.6872, 3.9101, 4.9853,\n",
       "                       3.3808, 3.8842, 1.4582, 2.5911, 5.6654, 2.3939, 3.5005, 3.7007, 2.3049,\n",
       "                       4.1511, 2.6877, 3.8099, 1.7482, 4.1220, 2.1749, 3.2718, 2.7685, 4.2324,\n",
       "                       1.9653, 1.8576, 3.1688, 4.1078, 3.3392, 5.4000, 1.6355, 5.5615, 3.6029,\n",
       "                       4.5510, 4.1393, 2.9273, 2.4275, 2.2881, 2.8984, 3.2958, 5.3284, 3.7106,\n",
       "                       3.0777, 1.1998, 2.6084, 3.0649, 3.5598, 3.0053, 2.6051, 2.8138, 2.4509,\n",
       "                       3.4329, 4.7072, 4.7399, 4.1175, 1.8485, 2.4041, 2.2620, 2.0757, 1.9718,\n",
       "                       7.5685, 2.5955, 2.6932, 2.5048, 4.0539, 2.1776, 3.0951, 3.1374, 1.7023,\n",
       "                       1.8488, 3.0756, 1.8486, 1.9217, 1.2104, 5.0436, 3.6931, 2.2638, 3.3716,\n",
       "                       1.5603, 1.8029, 2.0914, 4.6881, 3.5458, 3.5191, 3.2280, 2.2990, 2.3300,\n",
       "                       3.4121, 3.6351, 3.3479, 4.4894, 7.4213, 3.0850, 2.4349, 1.4936, 1.7906,\n",
       "                       2.5430, 2.7619, 2.9456, 3.5844, 2.4083, 1.9345, 2.3136, 1.3962, 3.7360,\n",
       "                       1.5488, 2.8519, 2.3652, 4.6439, 4.2328, 3.6446, 2.2748, 2.0628, 1.7435,\n",
       "                       2.3790, 1.3577, 2.1359, 3.9994, 2.6655, 2.3464, 2.4128, 2.0843, 2.9744,\n",
       "                       4.7166, 2.7652, 3.3403, 5.4011], device='cuda:0')),\n",
       "              ('module.layer3.2.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.2.conv2.weight',\n",
       "               tensor([[[[ 1.0842e-02, -3.8596e-02, -2.0276e-02],\n",
       "                         [ 9.1686e-03, -2.6906e-02, -2.1428e-02],\n",
       "                         [ 2.0230e-02,  3.5724e-02,  2.9525e-02]],\n",
       "               \n",
       "                        [[-6.6030e-03,  3.1886e-02, -1.7515e-02],\n",
       "                         [-4.6628e-02, -2.5100e-02, -2.5062e-02],\n",
       "                         [-8.9841e-03, -3.5488e-02, -8.1334e-03]],\n",
       "               \n",
       "                        [[ 1.7976e-02, -2.4962e-02, -7.7814e-03],\n",
       "                         [-3.5662e-03, -2.7592e-03, -6.5582e-05],\n",
       "                         [-3.8571e-02, -2.2654e-02, -2.5547e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3898e-02, -5.8673e-02, -4.3579e-02],\n",
       "                         [ 1.0636e-02, -2.9228e-03, -5.1584e-02],\n",
       "                         [-6.1222e-03, -1.2229e-02, -1.0665e-02]],\n",
       "               \n",
       "                        [[ 2.0869e-02,  6.0651e-02,  3.9762e-02],\n",
       "                         [ 2.5171e-02,  1.3427e-02,  2.9512e-02],\n",
       "                         [-6.0203e-03, -1.4539e-02, -2.3799e-02]],\n",
       "               \n",
       "                        [[-1.5598e-02, -7.1479e-03, -1.0216e-02],\n",
       "                         [-8.3880e-03, -2.2559e-02,  8.1484e-03],\n",
       "                         [ 1.5305e-02, -2.6874e-02, -3.2427e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.9274e-03, -1.9693e-02,  1.9317e-02],\n",
       "                         [ 3.0829e-02,  1.4158e-02,  1.9968e-02],\n",
       "                         [ 1.2112e-02,  1.8964e-02, -2.1242e-02]],\n",
       "               \n",
       "                        [[ 1.1772e-02,  3.6248e-02,  1.1473e-02],\n",
       "                         [-1.2566e-02, -2.0935e-02, -1.0543e-02],\n",
       "                         [-1.6010e-02, -7.2444e-04, -1.5757e-02]],\n",
       "               \n",
       "                        [[-1.8573e-02, -6.9270e-03, -4.6437e-02],\n",
       "                         [-2.3036e-02, -1.4041e-03, -1.9874e-02],\n",
       "                         [-3.2634e-02, -5.1676e-02, -3.7527e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.1044e-02, -9.5538e-03,  1.4587e-02],\n",
       "                         [ 1.9540e-02, -5.1698e-03, -3.8781e-03],\n",
       "                         [ 1.3879e-02, -1.9435e-02,  3.0050e-02]],\n",
       "               \n",
       "                        [[ 2.2391e-02,  3.2819e-02,  1.4340e-02],\n",
       "                         [-1.7668e-02,  1.9020e-03, -4.5532e-03],\n",
       "                         [-1.4903e-02, -2.0073e-02,  1.8535e-03]],\n",
       "               \n",
       "                        [[ 5.8531e-04,  2.5805e-02,  2.7868e-02],\n",
       "                         [ 4.4150e-02,  3.3299e-02, -1.9301e-02],\n",
       "                         [ 1.5337e-02, -2.2496e-03, -2.3979e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2023e-02,  5.5950e-02,  6.1912e-03],\n",
       "                         [ 1.8138e-02, -3.6949e-05,  2.2979e-02],\n",
       "                         [ 1.2434e-02,  1.5520e-03, -1.8993e-02]],\n",
       "               \n",
       "                        [[ 2.1516e-02,  3.2390e-02,  9.1856e-03],\n",
       "                         [ 7.1283e-02, -1.0788e-02, -5.3207e-02],\n",
       "                         [ 2.1684e-02, -2.7707e-02, -2.1978e-03]],\n",
       "               \n",
       "                        [[ 1.9214e-02, -8.5337e-03, -2.6699e-02],\n",
       "                         [-6.6080e-03, -1.5277e-02, -3.7136e-03],\n",
       "                         [-2.4965e-02,  1.4461e-02,  3.2619e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4974e-03,  1.0997e-02, -7.1666e-02],\n",
       "                         [ 5.1309e-03, -3.3409e-02,  2.5849e-02],\n",
       "                         [-2.3998e-02, -6.1292e-02, -3.1771e-03]],\n",
       "               \n",
       "                        [[ 1.8165e-02, -1.6534e-02,  3.6212e-03],\n",
       "                         [-1.9519e-02, -1.4484e-02,  6.2128e-02],\n",
       "                         [ 4.0114e-02, -4.7249e-02,  1.5371e-02]],\n",
       "               \n",
       "                        [[ 3.7794e-03, -4.2862e-02, -1.8196e-02],\n",
       "                         [ 6.3944e-02, -2.2420e-02,  3.6381e-02],\n",
       "                         [-1.0408e-02,  1.8693e-02,  5.6248e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1575e-02,  1.0938e-02, -1.8352e-02],\n",
       "                         [ 1.3699e-02,  3.5955e-02, -1.1720e-02],\n",
       "                         [ 1.0568e-02,  1.5697e-02,  3.6541e-04]],\n",
       "               \n",
       "                        [[ 1.8825e-02,  5.6973e-02,  9.5855e-03],\n",
       "                         [ 3.7390e-02,  1.1900e-01,  3.8447e-02],\n",
       "                         [-1.9707e-02, -1.0655e-02, -1.9036e-02]],\n",
       "               \n",
       "                        [[ 1.2477e-02,  1.3132e-02,  6.1487e-03],\n",
       "                         [ 1.0101e-02,  2.7425e-02, -1.4621e-02],\n",
       "                         [-9.4212e-03, -1.2669e-02, -1.8250e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.2960e-02, -1.2302e-02,  9.8624e-03],\n",
       "                         [-1.1943e-02, -6.8224e-03, -1.4033e-02],\n",
       "                         [ 4.6906e-03, -5.1907e-03,  7.4889e-03]],\n",
       "               \n",
       "                        [[-6.4628e-03, -2.0477e-02,  7.6777e-04],\n",
       "                         [ 3.6992e-04, -1.8172e-02, -2.1202e-02],\n",
       "                         [-2.8477e-02, -9.2484e-03, -2.9050e-02]],\n",
       "               \n",
       "                        [[-1.8513e-02,  2.0151e-02,  9.7674e-03],\n",
       "                         [-1.0989e-02,  1.9531e-02,  1.6037e-02],\n",
       "                         [-4.1731e-03, -1.4478e-02, -1.2136e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.4404e-02, -2.0312e-03,  1.0112e-02],\n",
       "                         [-1.2561e-02,  9.3399e-03,  1.6826e-02],\n",
       "                         [-1.4144e-02, -3.9160e-04,  1.1259e-02]],\n",
       "               \n",
       "                        [[-5.2205e-04, -7.7809e-03, -1.4781e-02],\n",
       "                         [-2.7194e-03, -6.0388e-03, -5.4811e-03],\n",
       "                         [ 6.3127e-03, -1.1224e-02, -8.7145e-03]],\n",
       "               \n",
       "                        [[-1.2366e-02,  6.6050e-04, -1.1360e-04],\n",
       "                         [-3.8439e-03,  3.5704e-03, -6.8619e-03],\n",
       "                         [ 6.8600e-03,  8.6639e-04,  1.6635e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.7790e-03,  8.1517e-03,  6.9404e-03],\n",
       "                         [-8.9155e-03,  6.1753e-04,  1.3941e-03],\n",
       "                         [-1.4475e-02, -1.2134e-02,  7.2510e-04]],\n",
       "               \n",
       "                        [[-1.4172e-02,  2.4636e-03,  1.0393e-02],\n",
       "                         [-1.1618e-02, -2.0262e-02, -1.6606e-03],\n",
       "                         [-7.8455e-03, -1.1246e-03, -6.2162e-03]],\n",
       "               \n",
       "                        [[ 5.2103e-03, -1.5021e-04,  5.1968e-03],\n",
       "                         [-5.7403e-03, -1.1328e-02, -4.3580e-03],\n",
       "                         [ 6.2003e-03, -1.6628e-02, -1.2554e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.1634e-03, -4.0518e-02, -3.1084e-02],\n",
       "                         [ 1.7240e-02, -4.2109e-02, -2.2600e-03],\n",
       "                         [ 1.5892e-02,  4.2368e-02,  5.9307e-02]],\n",
       "               \n",
       "                        [[-1.4316e-02, -2.8012e-02, -1.4945e-02],\n",
       "                         [ 3.8433e-02,  5.1339e-02,  1.8745e-02],\n",
       "                         [ 3.4143e-02,  7.9382e-02,  4.2852e-02]],\n",
       "               \n",
       "                        [[ 7.0910e-03,  1.7413e-02,  7.6439e-03],\n",
       "                         [ 1.2568e-02,  2.9080e-02,  8.8979e-03],\n",
       "                         [-8.3776e-03,  6.6301e-03, -1.5848e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.8677e-02, -3.6977e-02,  8.1124e-03],\n",
       "                         [-4.2285e-02, -5.5975e-02,  1.0521e-02],\n",
       "                         [-3.9407e-03, -1.2311e-02,  5.0437e-02]],\n",
       "               \n",
       "                        [[-3.2179e-03,  7.1109e-03,  9.4143e-03],\n",
       "                         [-3.1255e-02,  3.5642e-02, -9.5838e-03],\n",
       "                         [-4.5776e-02, -5.9341e-02, -2.5869e-02]],\n",
       "               \n",
       "                        [[-2.1272e-02,  1.7666e-02,  5.1873e-03],\n",
       "                         [-8.9501e-03,  2.5004e-02,  1.3293e-02],\n",
       "                         [-1.4088e-02, -4.8743e-02, -4.3353e-02]]]], device='cuda:0')),\n",
       "              ('module.layer3.2.bn2.weight',\n",
       "               tensor([1.5901, 0.7332, 1.6739, 1.7815, 1.7631, 1.2928, 1.1229, 2.1953, 1.4245,\n",
       "                       1.5031, 2.1027, 1.4456, 1.2357, 1.2095, 1.4881, 2.1154, 1.6643, 1.0017,\n",
       "                       1.5068, 1.1862, 1.8654, 0.8630, 3.6172, 0.7618, 1.7857, 0.7934, 1.4973,\n",
       "                       1.7664, 1.6960, 1.0434, 1.3389, 0.7433, 1.4027, 1.2650, 1.6982, 1.7034,\n",
       "                       1.0033, 1.1689, 1.5322, 1.5859, 1.8769, 1.8511, 2.0966, 1.9249, 1.3257,\n",
       "                       1.1295, 1.2804, 1.8835, 0.7896, 1.3247, 1.5508, 1.4394, 1.3847, 1.7081,\n",
       "                       1.7387, 1.7871, 1.4635, 1.8713, 1.6088, 1.4028, 1.3485, 2.2123, 1.2534,\n",
       "                       1.0663, 1.7535, 1.7733, 1.9220, 1.1303, 1.3560, 1.8153, 1.2116, 2.0133,\n",
       "                       0.7537, 0.7429, 1.6169, 1.6774, 1.7931, 1.7891, 1.3363, 2.5017, 1.2908,\n",
       "                       0.8912, 1.1716, 2.0397, 1.6460, 1.4664, 1.5916, 1.6304, 1.2804, 1.4905,\n",
       "                       1.6227, 1.2906, 1.4220, 1.6649, 1.5133, 1.3342, 0.7697, 1.1198, 1.3613,\n",
       "                       1.2563, 2.0042, 0.9487, 1.7056, 1.5421, 1.4764, 0.8810, 1.5513, 1.5287,\n",
       "                       1.3896, 0.9811, 0.9552, 1.4518, 2.4243, 1.9889, 1.2423, 1.2894, 1.3928,\n",
       "                       1.4789, 1.7047, 1.3639, 1.6015, 1.9370, 1.7837, 1.7233, 1.7138, 1.8052,\n",
       "                       1.7641, 2.3279, 1.2817, 1.5153, 1.4735, 1.0014, 1.6682, 2.0195, 2.5230,\n",
       "                       1.6515, 2.0518, 1.9572, 1.3105, 1.4111, 2.6621, 0.8860, 1.4847, 1.4324,\n",
       "                       1.7551, 1.9209, 1.9297, 1.0262, 1.5778, 1.8105, 1.4531, 1.8569, 1.4393,\n",
       "                       1.8237, 1.0785, 1.7572, 1.2361, 1.4120, 1.6035, 1.6070, 1.2884, 1.8847,\n",
       "                       2.0218, 1.1634, 1.0720, 2.0987, 1.5027, 1.6831, 1.6958, 1.4310, 1.5836,\n",
       "                       2.0561, 1.7088, 1.5093, 1.9380, 1.1037, 1.4380, 1.4470, 1.0584, 0.7447,\n",
       "                       1.8734, 1.2004, 2.0669, 1.5505, 0.8347, 1.6990, 1.2808, 2.0198, 1.8117,\n",
       "                       1.4588, 1.6064, 1.5961, 1.5012, 1.8498, 0.7852, 0.8190, 0.9857, 1.7227,\n",
       "                       1.3623, 1.0394, 2.2128, 1.3479, 1.3550, 3.6980, 1.5265, 1.2750, 1.1137,\n",
       "                       1.5687, 0.8292, 1.7267, 1.4550, 1.7581, 1.8108, 1.6344, 1.5417, 1.5338,\n",
       "                       1.5320, 1.3060, 0.9316, 2.3204, 1.2677, 1.4683, 1.7818, 1.6589, 1.4119,\n",
       "                       0.9061, 1.6738, 1.0395, 1.5972, 1.2777, 1.3547, 1.7902, 1.9200, 1.4869,\n",
       "                       1.5532, 0.8465, 1.0743, 1.0899, 1.6711, 1.5279, 2.0123, 1.2846, 1.4538,\n",
       "                       1.1584, 1.0949, 1.5110, 0.9812, 1.2809, 1.6123, 1.0796, 1.2238, 1.7621,\n",
       "                       1.6473, 1.6880, 1.8146, 1.0273], device='cuda:0')),\n",
       "              ('module.layer3.2.bn2.bias',\n",
       "               tensor([-9.0779e-01,  1.3672e+00, -1.2388e+00, -1.5462e+00, -1.5128e+00,\n",
       "                       -8.3933e-01,  5.2584e-02, -1.1745e+00, -4.9487e-01, -1.2977e-01,\n",
       "                       -2.2286e+00, -7.5909e-01, -3.2875e-01,  1.2578e+00, -9.0366e-01,\n",
       "                       -2.9476e+00, -1.7233e+00,  1.8673e-01, -5.7967e-01, -3.3337e-02,\n",
       "                       -1.2861e+00,  5.2034e-01, -4.5887e+00,  1.1749e+00, -1.2012e+00,\n",
       "                        2.0409e+00, -1.3929e+00, -1.7608e+00, -1.5216e+00,  7.0671e-02,\n",
       "                       -3.6455e-01,  2.1087e+00, -6.1077e-01, -4.5119e-01, -1.1028e+00,\n",
       "                       -1.3528e+00,  2.8859e-01, -2.1688e-01, -8.8206e-01, -1.1677e+00,\n",
       "                       -1.4200e+00, -1.5237e+00, -1.7634e+00, -2.6970e+00, -8.4294e-01,\n",
       "                       -1.3354e-01, -4.9380e-01, -9.7588e-01,  1.5250e+00, -7.5034e-01,\n",
       "                       -1.0729e+00, -8.4938e-01, -7.5864e-01, -1.0794e+00, -1.7541e+00,\n",
       "                       -1.3138e+00, -1.0560e+00, -1.8503e+00, -8.2114e-01, -5.4324e-01,\n",
       "                       -4.8814e-02, -1.3464e+00, -4.2851e-01,  6.2221e-01, -1.4733e+00,\n",
       "                       -2.3448e+00, -2.4634e+00, -1.0283e-02, -5.5542e-01, -1.6104e+00,\n",
       "                       -3.1691e-01, -1.1463e+00,  1.8839e+00,  1.5132e+00, -1.6492e+00,\n",
       "                       -9.7256e-01, -1.5062e+00, -2.0045e+00, -4.5456e-01, -2.5586e+00,\n",
       "                       -6.5120e-01,  2.5572e+00, -4.3393e-01, -1.7310e+00, -1.7825e+00,\n",
       "                       -1.0387e+00, -8.6240e-01, -1.3364e+00, -2.2928e-01, -1.0029e+00,\n",
       "                       -1.1386e+00, -4.8283e-01, -1.8681e+00, -8.7038e-01, -9.6191e-01,\n",
       "                       -6.2974e-01,  2.0213e+00, -1.3889e-03, -5.9273e-01, -3.6175e-01,\n",
       "                       -1.9372e+00,  5.9086e-01, -1.4448e+00, -9.8546e-01, -1.4896e+00,\n",
       "                        4.0620e-01, -8.7574e-01, -1.3479e+00, -3.7567e-03,  5.6394e-01,\n",
       "                        4.8328e-01, -9.6702e-01, -2.1026e+00, -3.5086e+00, -1.6592e-01,\n",
       "                       -3.8151e-01, -8.0197e-01, -9.1016e-01, -1.5068e+00, -9.7156e-01,\n",
       "                       -1.2149e+00, -1.7098e+00, -1.2488e+00, -1.4822e+00, -1.3711e+00,\n",
       "                       -1.6753e+00, -1.7187e+00, -2.4684e+00, -7.0876e-01, -8.6981e-01,\n",
       "                       -9.8134e-01,  2.3944e-01, -1.2052e+00, -1.8066e+00, -2.6310e+00,\n",
       "                       -1.1928e+00, -1.9851e+00, -2.3551e+00, -5.4560e-01, -9.3275e-01,\n",
       "                       -2.7653e+00,  3.4330e-01, -1.2555e+00,  5.8161e-01, -1.6528e+00,\n",
       "                       -2.2957e+00, -1.5307e+00,  3.7158e-01, -1.1551e+00, -1.3619e+00,\n",
       "                       -8.0753e-01, -1.2684e+00, -7.0833e-01, -1.8676e+00, -9.2135e-02,\n",
       "                       -9.9662e-01, -3.4316e-01, -8.1013e-01, -1.1141e+00, -9.2781e-01,\n",
       "                       -1.6946e-01, -1.6573e+00, -2.8814e+00, -6.1795e-01, -1.1405e-01,\n",
       "                       -1.8316e+00, -1.3544e+00, -6.3705e-01, -2.3452e+00, -1.0522e+00,\n",
       "                       -1.2552e+00, -3.1163e+00, -1.5098e+00, -2.3417e+00, -1.8670e+00,\n",
       "                        2.5423e-01, -3.2602e-01, -1.0124e+00,  3.0757e-01,  1.6924e+00,\n",
       "                       -1.5461e+00, -3.2100e-01, -2.7041e+00, -1.0892e+00,  3.3903e-01,\n",
       "                       -1.9842e+00, -3.8426e-01, -1.6491e+00, -1.2452e+00, -1.1834e+00,\n",
       "                       -1.2398e+00, -1.4413e+00, -9.7647e-01, -2.2692e+00,  2.0240e+00,\n",
       "                        7.7097e-01,  3.7675e-01, -9.4404e-01, -7.4587e-01,  4.6780e-01,\n",
       "                       -1.8697e+00, -8.5724e-01, -5.1451e-01, -8.4463e+00, -1.0783e+00,\n",
       "                       -5.9641e-01, -5.9472e-02, -1.1114e+00,  2.1207e+00, -1.4931e+00,\n",
       "                       -4.8836e-01, -1.5289e+00, -1.5004e+00, -1.3439e+00, -9.1155e-01,\n",
       "                       -7.0148e-01, -1.1415e+00, -6.4641e-01,  5.3601e-01, -2.3839e+00,\n",
       "                       -3.8925e-02, -1.0151e+00, -1.7415e+00, -1.1883e+00, -3.4954e-01,\n",
       "                        3.3181e-01, -1.4698e+00,  9.8413e-02, -1.5439e+00, -1.9800e-01,\n",
       "                       -9.7308e-01, -1.3927e+00, -2.0008e+00, -9.9892e-01, -9.2076e-01,\n",
       "                        5.2055e-01,  9.6200e-02,  8.1863e-02, -7.4603e-01, -9.4868e-01,\n",
       "                       -2.6681e+00,  7.0454e-01, -8.4188e-01, -1.6136e-01,  4.3289e-01,\n",
       "                       -1.1514e+00,  3.3855e-01, -4.5654e-01, -9.2130e-01, -2.4551e-01,\n",
       "                       -2.8643e-01, -1.4330e+00, -1.2592e+00, -5.8127e-01, -2.7365e+00,\n",
       "                        1.9653e-01], device='cuda:0')),\n",
       "              ('module.layer3.2.bn2.running_mean',\n",
       "               tensor([-0.2311,  0.2396, -0.7627, -0.4071, -1.0001, -0.4895, -0.3547, -0.5891,\n",
       "                       -0.7200,  0.2852,  0.1626, -0.4282, -0.6556,  0.2074, -0.8366, -1.2843,\n",
       "                       -1.0692,  0.2032,  0.6990, -0.3152, -1.1996, -0.6922, -1.1815,  0.7301,\n",
       "                       -0.7421,  1.2917, -0.5740, -0.3139, -1.3586, -0.2242, -0.7971, -0.5207,\n",
       "                       -0.3863,  0.1171, -0.0832, -0.8015,  0.0449,  0.2120, -0.5910,  0.4168,\n",
       "                       -0.4348, -0.1886, -0.5198, -1.1051, -0.6203, -0.4609, -0.1495, -1.9361,\n",
       "                        0.2745, -0.7224, -0.7500, -0.6343, -0.1724, -0.6442, -0.8868, -0.0541,\n",
       "                       -0.7094, -2.0714, -1.1874, -0.0756,  0.5832, -0.4949, -0.2782, -0.5983,\n",
       "                       -0.5033, -1.0595, -1.5084, -1.0574, -0.5546, -0.6034, -0.4691, -0.4266,\n",
       "                        0.4940, -0.7557, -1.3398, -0.4230, -0.0525, -0.6027, -0.0920, -1.3122,\n",
       "                        0.3953, -3.1143, -0.3506, -0.5857, -0.8282, -0.3077, -0.4322, -0.1080,\n",
       "                        0.1202, -1.6258, -1.1980, -0.5461, -1.1869, -0.5247, -0.4251, -0.2316,\n",
       "                       -1.3606, -0.5220, -0.1943, -0.6970,  0.2131, -0.4032, -0.1148,  0.0188,\n",
       "                       -0.8890, -2.3145, -0.9121, -0.6303,  0.4965, -0.0148,  0.1186, -0.2275,\n",
       "                       -0.9849, -1.0625, -0.5042, -0.5980, -0.6595, -1.1078, -1.2719, -0.6382,\n",
       "                       -1.4138, -0.1651, -0.4344, -0.8015, -0.6011, -0.4629, -0.5346, -0.3750,\n",
       "                       -0.5394, -0.3116, -0.8074,  0.3631, -0.6255, -1.2727, -1.2640, -1.0910,\n",
       "                       -1.9288, -0.8876, -0.0113, -0.4561, -1.2249,  0.1682, -0.4721,  1.5026,\n",
       "                       -0.4660, -0.3380, -0.3620,  0.3327, -0.3782, -0.4485, -0.4868, -0.3014,\n",
       "                       -0.8501, -0.4821, -0.9157, -1.2163,  0.2468, -0.4212, -0.1468, -0.7247,\n",
       "                        0.0127, -0.0200, -1.0111, -0.5928, -0.1803, -0.4974,  0.6272, -0.7311,\n",
       "                        0.0785,  0.1069, -0.6594, -1.3194, -0.1781,  0.1444, -0.6660, -1.4271,\n",
       "                       -0.4569, -0.3799,  0.2917,  0.3812, -0.6182,  0.1255, -1.9656, -0.3448,\n",
       "                       -0.9673, -0.7344, -0.8045, -1.0063, -0.4977, -0.3992, -0.4826, -0.9751,\n",
       "                       -1.1001, -0.4037, -0.6631,  0.2978,  0.3858, -0.6642, -0.3652,  0.3509,\n",
       "                       -0.8756, -0.8356, -1.1391, -2.7456, -0.9648, -0.1900, -0.2375, -0.6013,\n",
       "                       -1.0519,  0.5181, -0.5695, -0.0150, -0.5917, -0.8121, -0.8160, -0.4608,\n",
       "                       -0.1995, -0.4731, -0.0123, -0.2632, -0.0767, -0.4714, -1.4186, -1.4157,\n",
       "                        0.7495, -0.3364, -0.2074, -0.6635, -0.9458, -0.3601, -0.1414, -0.9843,\n",
       "                       -1.0104, -1.0690, -0.4666, -0.0787,  0.0841, -0.6032, -0.8940, -0.2297,\n",
       "                       -1.5670,  2.2982, -0.5515, -0.2107,  0.0978, -0.7697,  0.1789, -0.6288,\n",
       "                       -0.6374, -0.5206, -0.2230, -0.8337, -1.1833,  1.0743, -1.5005,  0.3884],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.2.bn2.running_var',\n",
       "               tensor([2.0405, 1.3197, 1.3578, 1.0425, 1.0762, 1.0449, 1.6109, 2.4068, 2.2730,\n",
       "                       2.8032, 1.5646, 1.3351, 1.6229, 4.3729, 1.6103, 1.1321, 0.8453, 1.4407,\n",
       "                       1.8340, 2.3726, 3.4738, 1.4232, 1.6728, 1.3785, 1.1454, 1.3002, 0.9449,\n",
       "                       1.2275, 0.9023, 1.1930, 1.6164, 1.4223, 1.4894, 1.5635, 1.6049, 1.6974,\n",
       "                       1.6287, 1.3164, 1.7907, 1.4252, 2.1442, 1.1532, 1.7480, 0.8082, 1.6745,\n",
       "                       1.2308, 1.5856, 1.4398, 1.5602, 1.1999, 1.6060, 1.2233, 1.3526, 2.3835,\n",
       "                       1.1242, 1.3148, 1.2749, 1.0815, 1.8349, 1.5962, 2.5050, 2.3612, 1.1045,\n",
       "                       2.5939, 1.1772, 1.2020, 1.4423, 1.6314, 1.2194, 1.1756, 1.0323, 1.7142,\n",
       "                       1.2972, 1.3756, 1.7634, 1.9043, 1.5471, 1.1415, 1.3641, 1.2222, 1.1798,\n",
       "                       2.3251, 1.0394, 1.1421, 1.0659, 1.5211, 1.5986, 1.4449, 1.8125, 1.1647,\n",
       "                       1.4870, 2.0700, 1.2461, 2.1477, 0.9299, 1.3614, 1.9188, 1.6504, 1.1623,\n",
       "                       1.6786, 1.7586, 1.9330, 1.5215, 1.1665, 0.7463, 1.8430, 1.3450, 1.0335,\n",
       "                       2.3971, 1.7325, 1.7734, 1.2239, 1.6331, 0.5455, 1.1417, 1.7750, 1.5657,\n",
       "                       1.0303, 1.4156, 1.1157, 1.4850, 1.3928, 1.7427, 1.1646, 1.6707, 0.9831,\n",
       "                       1.2343, 1.2846, 0.9783, 1.4442, 1.6016, 1.3202, 1.1598, 1.6039, 1.5775,\n",
       "                       0.9792, 2.9807, 0.8760, 1.5126, 1.1364, 0.9773, 1.2650, 0.7513, 3.1216,\n",
       "                       1.1633, 1.2710, 2.0793, 1.8135, 1.5711, 3.8035, 0.9155, 1.9060, 2.0720,\n",
       "                       1.2126, 1.6031, 1.4565, 1.4961, 1.5495, 1.0022, 2.2258, 1.9958, 1.3137,\n",
       "                       0.7498, 0.9572, 1.4323, 1.7451, 2.0692, 1.9961, 1.5412, 0.9196, 1.2964,\n",
       "                       0.5427, 1.2969, 1.5090, 1.9980, 2.3482, 2.2710, 1.7702, 1.6393, 1.2959,\n",
       "                       1.6054, 1.5061, 1.5724, 1.0060, 1.0931, 0.9471, 1.1738, 1.5661, 1.8160,\n",
       "                       2.0952, 1.6711, 1.5478, 1.6535, 0.8334, 1.2999, 1.5719, 1.5756, 1.8624,\n",
       "                       1.2811, 2.2879, 1.1979, 1.5331, 1.5746, 1.3879, 1.0939, 1.2256, 1.3362,\n",
       "                       1.4750, 2.1300, 3.1471, 1.7344, 1.5749, 1.7930, 0.9582, 1.4237, 1.8176,\n",
       "                       1.4028, 1.2322, 1.3128, 1.3809, 2.7240, 1.4973, 1.3005, 1.4853, 2.1145,\n",
       "                       1.3426, 0.9868, 1.4465, 0.8630, 1.6579, 1.3069, 1.7119, 1.1129, 1.0471,\n",
       "                       1.2816, 1.1193, 1.4897, 2.1586, 1.7488, 1.4049, 0.8713, 5.7339, 1.1520,\n",
       "                       1.4151, 2.2771, 0.9785, 1.7684, 1.6124, 1.5391, 1.3234, 1.2237, 1.6443,\n",
       "                       1.2176, 1.4102, 0.4459, 1.2927], device='cuda:0')),\n",
       "              ('module.layer3.2.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.2.conv3.weight',\n",
       "               tensor([[[[-0.0013]],\n",
       "               \n",
       "                        [[ 0.0350]],\n",
       "               \n",
       "                        [[-0.0034]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0140]],\n",
       "               \n",
       "                        [[-0.0503]],\n",
       "               \n",
       "                        [[-0.0109]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0043]],\n",
       "               \n",
       "                        [[-0.0422]],\n",
       "               \n",
       "                        [[ 0.0039]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0164]],\n",
       "               \n",
       "                        [[ 0.0414]],\n",
       "               \n",
       "                        [[ 0.0160]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0095]],\n",
       "               \n",
       "                        [[ 0.0313]],\n",
       "               \n",
       "                        [[ 0.0086]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0338]],\n",
       "               \n",
       "                        [[ 0.0141]],\n",
       "               \n",
       "                        [[-0.0186]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0179]],\n",
       "               \n",
       "                        [[ 0.0079]],\n",
       "               \n",
       "                        [[-0.0203]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0305]],\n",
       "               \n",
       "                        [[-0.0307]],\n",
       "               \n",
       "                        [[-0.0065]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0039]],\n",
       "               \n",
       "                        [[-0.0558]],\n",
       "               \n",
       "                        [[ 0.0002]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0673]],\n",
       "               \n",
       "                        [[-0.0331]],\n",
       "               \n",
       "                        [[-0.0248]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2286]],\n",
       "               \n",
       "                        [[-0.0246]],\n",
       "               \n",
       "                        [[-0.0298]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0096]],\n",
       "               \n",
       "                        [[-0.0029]],\n",
       "               \n",
       "                        [[-0.0738]]]], device='cuda:0')),\n",
       "              ('module.layer3.2.bn3.weight',\n",
       "               tensor([0.1273, 0.2827, 0.2611,  ..., 1.0161, 0.8975, 1.9101], device='cuda:0')),\n",
       "              ('module.layer3.2.bn3.bias',\n",
       "               tensor([-0.0247, -0.2912, -0.1471,  ..., -1.0785, -0.9503, -0.7910],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.2.bn3.running_mean',\n",
       "               tensor([ 0.0337,  0.2268,  0.0930,  ..., -0.0785, -0.8896, -0.0289],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.2.bn3.running_var',\n",
       "               tensor([0.0209, 0.0262, 0.0495,  ..., 0.0988, 0.1710, 0.3556], device='cuda:0')),\n",
       "              ('module.layer3.2.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.3.conv1.weight',\n",
       "               tensor([[[[-0.0294]],\n",
       "               \n",
       "                        [[-0.0393]],\n",
       "               \n",
       "                        [[-0.0563]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0131]],\n",
       "               \n",
       "                        [[ 0.0119]],\n",
       "               \n",
       "                        [[ 0.0148]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0115]],\n",
       "               \n",
       "                        [[ 0.0146]],\n",
       "               \n",
       "                        [[-0.0480]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0445]],\n",
       "               \n",
       "                        [[ 0.0232]],\n",
       "               \n",
       "                        [[ 0.0083]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0430]],\n",
       "               \n",
       "                        [[-0.0426]],\n",
       "               \n",
       "                        [[ 0.0203]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0500]],\n",
       "               \n",
       "                        [[-0.0472]],\n",
       "               \n",
       "                        [[ 0.0002]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0069]],\n",
       "               \n",
       "                        [[ 0.0035]],\n",
       "               \n",
       "                        [[-0.0376]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0314]],\n",
       "               \n",
       "                        [[-0.0154]],\n",
       "               \n",
       "                        [[-0.0086]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0559]],\n",
       "               \n",
       "                        [[-0.0075]],\n",
       "               \n",
       "                        [[ 0.0316]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0445]],\n",
       "               \n",
       "                        [[-0.0428]],\n",
       "               \n",
       "                        [[-0.0281]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0511]],\n",
       "               \n",
       "                        [[-0.0186]],\n",
       "               \n",
       "                        [[-0.0052]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0277]],\n",
       "               \n",
       "                        [[-0.0233]],\n",
       "               \n",
       "                        [[ 0.0190]]]], device='cuda:0')),\n",
       "              ('module.layer3.3.bn1.weight',\n",
       "               tensor([2.1960, 1.0323, 1.3393, 1.7554, 1.1358, 1.6153, 2.0540, 1.3146, 1.4179,\n",
       "                       1.6092, 1.3139, 1.2483, 1.3159, 0.7567, 1.4386, 1.3292, 1.1012, 1.7629,\n",
       "                       1.6159, 1.5027, 0.7131, 1.7636, 1.6599, 1.8112, 1.4279, 1.1906, 1.2321,\n",
       "                       1.8665, 0.7464, 1.1310, 0.9592, 1.8583, 1.3743, 1.8542, 1.8103, 1.3010,\n",
       "                       1.6380, 1.1444, 2.0832, 1.3843, 1.1461, 2.0539, 1.4454, 0.7882, 1.4110,\n",
       "                       1.4441, 1.6669, 1.8661, 1.2219, 1.1454, 1.7313, 1.2826, 1.3831, 1.8431,\n",
       "                       1.5762, 1.2255, 1.5727, 1.4910, 1.2005, 1.1299, 1.5201, 0.8582, 2.7887,\n",
       "                       1.0024, 1.6299, 1.9316, 1.1846, 1.6603, 1.7809, 1.4568, 1.2614, 1.3210,\n",
       "                       1.3080, 1.9054, 1.2215, 1.0767, 1.9334, 1.7181, 1.5806, 1.4539, 1.1643,\n",
       "                       0.7003, 1.4586, 1.7662, 2.4081, 1.3480, 1.3803, 2.0418, 1.7982, 1.2446,\n",
       "                       1.5803, 1.7491, 0.8813, 1.9794, 1.1719, 1.1669, 1.1748, 1.7415, 2.1175,\n",
       "                       2.4921, 1.9381, 1.6262, 0.8577, 1.2931, 1.5218, 1.7660, 1.1317, 2.5437,\n",
       "                       0.7752, 1.1395, 2.6325, 1.1574, 1.0732, 1.0660, 1.0361, 1.3219, 1.1045,\n",
       "                       1.3130, 1.6423, 1.1063, 1.0430, 1.2153, 0.9147, 1.7110, 1.6916, 1.8955,\n",
       "                       1.9293, 1.3222, 0.8812, 1.2695, 1.7298, 1.4817, 1.2713, 1.0594, 1.0950,\n",
       "                       0.8918, 1.7745, 1.0277, 2.4782, 1.0835, 0.9115, 0.7418, 1.1838, 1.7044,\n",
       "                       1.3940, 0.7291, 1.1172, 1.1328, 1.2090, 1.6262, 1.6290, 1.5574, 1.5089,\n",
       "                       1.5606, 1.3927, 2.4826, 1.3911, 1.0091, 1.3568, 1.1041, 0.8593, 1.5829,\n",
       "                       2.0058, 1.3641, 1.0516, 0.9304, 1.3097, 1.3188, 1.5520, 2.2331, 1.3487,\n",
       "                       1.8139, 1.0264, 1.1762, 1.1861, 1.9122, 1.3884, 1.2629, 1.3401, 1.0362,\n",
       "                       1.1710, 1.3390, 1.7287, 0.8782, 1.7986, 1.3426, 1.0443, 1.4267, 0.8281,\n",
       "                       1.9630, 1.5913, 1.6243, 1.5319, 2.1502, 1.6805, 2.0875, 1.7054, 1.4191,\n",
       "                       0.8918, 1.4103, 1.4457, 1.5840, 0.9057, 1.4785, 0.9212, 2.1774, 1.0633,\n",
       "                       0.9400, 1.4291, 1.7334, 1.3391, 1.4043, 0.6807, 1.3516, 1.2630, 1.7846,\n",
       "                       1.2134, 1.4399, 1.4531, 1.7733, 0.8141, 0.9210, 1.4321, 1.2282, 1.9396,\n",
       "                       1.6161, 1.5871, 1.6591, 1.5839, 1.4784, 1.3219, 1.2973, 1.4495, 0.8298,\n",
       "                       2.8071, 1.7134, 1.2074, 1.8155, 1.6096, 1.0525, 1.4136, 0.9180, 1.4081,\n",
       "                       1.2373, 0.9191, 1.1631, 1.1250, 1.7919, 2.1607, 1.5276, 1.6795, 1.3040,\n",
       "                       1.2323, 1.0727, 1.5054, 1.1179], device='cuda:0')),\n",
       "              ('module.layer3.3.bn1.bias',\n",
       "               tensor([-2.9421, -0.2131, -0.8808, -2.0501, -0.5425, -1.8178, -3.0894, -0.3980,\n",
       "                       -1.2019, -1.5747, -0.9811, -0.5684, -0.6483,  0.5033, -0.4030, -0.9096,\n",
       "                       -0.3733, -2.3131, -1.6703, -0.6183,  1.0856, -1.3445, -2.1318, -2.3137,\n",
       "                       -1.2303, -0.3458, -0.2166, -2.0835,  0.7961, -0.5276,  0.1346, -2.3494,\n",
       "                       -0.6982, -1.7038, -2.0972, -0.8107, -0.8734, -0.2528, -2.2700, -1.3600,\n",
       "                       -0.3361, -3.3960, -1.2430,  0.7380, -0.8924, -1.0201, -1.3286, -2.3404,\n",
       "                       -0.8540, -0.0670, -1.9794, -1.1555, -0.8941, -2.5428, -2.2485, -0.4890,\n",
       "                       -1.7671, -1.2358, -0.3599, -0.3891, -1.2710,  0.2576, -4.4479,  0.1635,\n",
       "                       -2.4025, -2.4178, -0.4444, -1.7428, -1.8834, -0.9041, -0.8868, -0.9515,\n",
       "                       -0.2864, -2.2571, -0.2951, -0.0833, -2.7565, -1.3968, -2.0256, -1.2655,\n",
       "                       -0.6160,  0.8089, -1.6444, -2.2256, -3.0176, -0.8564, -1.0030, -2.6979,\n",
       "                       -2.0664, -0.5990, -1.4402, -1.7094,  0.2272, -2.3958, -0.6160, -0.5313,\n",
       "                        0.0186, -1.7113, -2.2959, -2.8446, -1.2118, -1.4291,  0.4449, -0.6388,\n",
       "                       -1.6248, -1.7408, -0.0518, -4.8610,  0.9178, -0.4618, -3.8203, -0.6369,\n",
       "                       -0.3043,  0.0193, -0.1266, -1.0448, -0.0801, -0.8782, -1.5045, -0.4920,\n",
       "                       -0.1496, -0.4006,  0.2312, -1.8247, -1.5359, -2.1263, -3.1192, -0.7864,\n",
       "                        0.3417, -1.1722, -1.2949, -1.3224, -0.7077, -0.3616, -0.3933,  0.4117,\n",
       "                       -2.1592, -0.1914, -3.4411, -0.2717,  0.5403,  0.6138, -0.4891, -1.5573,\n",
       "                       -0.4917,  0.9276, -0.3859, -0.1520, -0.5253, -1.4533, -1.8863, -1.1901,\n",
       "                       -1.4663, -1.2743, -0.9078, -3.5922, -0.9549, -0.0427, -0.6027,  0.0969,\n",
       "                        0.2669, -1.6559, -2.1969, -0.8224, -0.0465,  0.0584, -0.8665, -0.8995,\n",
       "                       -1.3565, -4.2757, -0.4260, -2.2972, -0.2408, -0.6107, -0.0389, -2.6405,\n",
       "                       -0.3770, -0.6938, -1.0480,  0.1753, -0.6299, -1.0784, -2.2156,  0.4821,\n",
       "                       -1.4519, -0.6769, -0.3868, -0.4412,  1.2862, -1.7576, -1.5609, -1.6285,\n",
       "                       -0.8886, -1.8456, -1.8415, -3.9255, -1.9002, -0.9391,  0.2844, -1.3887,\n",
       "                       -1.2015, -1.5466,  0.2869, -1.4406,  0.2172, -2.3027, -0.1220,  0.3005,\n",
       "                       -2.1222, -1.3104, -0.3329, -1.1734,  1.1155, -0.8909, -0.8118, -2.4426,\n",
       "                       -0.6560, -1.2870, -1.2560, -1.9958,  0.9030,  0.2327, -0.6324, -0.4978,\n",
       "                       -1.7481, -2.1721, -1.1893, -2.0474, -1.3126, -0.9862, -1.0107, -0.5329,\n",
       "                       -1.5147,  0.1493, -3.8525, -1.5584, -0.6251, -1.8148, -1.8627,  0.0187,\n",
       "                       -1.6844,  0.2358, -1.1166, -0.3720,  0.2292, -0.4948, -0.1148, -2.3545,\n",
       "                       -3.3343, -0.9359, -2.3194, -0.5819, -0.7240,  0.0473, -1.4434, -0.1456],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.3.bn1.running_mean',\n",
       "               tensor([-1.1555,  1.0120, -0.2094, -1.1265,  0.0617, -0.3499, -0.5181, -0.8889,\n",
       "                       -0.6531, -0.6328, -1.2504, -0.4805, -1.4646,  0.6434,  0.2363, -0.3033,\n",
       "                       -0.5999, -1.7074, -0.1489, -3.8938,  3.7559, -0.6161, -0.1540, -1.6712,\n",
       "                       -0.3057,  0.4073, -0.0541, -0.6872, -3.5690,  1.0344,  1.1526, -1.6414,\n",
       "                       -1.0364,  0.1315, -1.7157, -0.7098, -0.1185,  1.3958, -0.5903, -0.5471,\n",
       "                        0.2100, -2.1656, -1.4024,  0.3432, -1.0415, -0.8969, -0.1227, -1.9594,\n",
       "                        0.5198, -0.0656, -0.9602,  2.0892, -0.4082, -1.8240,  0.3436,  0.4276,\n",
       "                       -1.5819, -0.3926, -1.6579, -1.5666, -1.5033, -1.4900, -2.1062, -0.4201,\n",
       "                       -0.6593, -0.8465,  2.0354, -1.7610, -0.9802, -1.0398,  0.1064,  0.4916,\n",
       "                       -0.3117, -0.4915,  0.9725, -0.2360, -2.0981, -0.8497, -1.9440,  0.0279,\n",
       "                       -1.0116,  0.0564,  0.8591,  0.0436,  0.2262,  1.0272, -0.9357, -0.4090,\n",
       "                       -0.7812,  0.1170, -1.0952, -0.5367,  1.3278, -2.7558,  0.6846,  0.3477,\n",
       "                        1.0931, -1.0051, -1.7714, -1.8949, -1.2799, -1.1701,  0.0806,  0.3051,\n",
       "                       -0.3922, -0.7467, -0.8534, -1.1395, -2.1050, -0.7926, -2.3146, -0.1600,\n",
       "                       -3.4427, -0.0433,  0.1394,  1.4994,  1.1903, -1.0002, -0.8366, -0.5066,\n",
       "                       -0.1659, -0.0594, -0.8491, -1.5183,  0.4101,  0.0047, -1.1211, -1.2792,\n",
       "                       -0.2294, -1.0560,  0.0553, -1.7072, -0.1813,  1.4183,  0.2818,  0.3775,\n",
       "                       -2.0507,  1.3156, -1.9221, -1.1131, -1.4002,  0.1120,  0.0986, -1.2508,\n",
       "                       -1.6591, -4.2518,  0.1135, -0.6467, -0.4631, -1.4975,  0.1285, -0.6893,\n",
       "                       -1.1196, -1.4064, -0.3611, -2.1454, -0.4447,  0.0976, -0.7200, -0.3599,\n",
       "                        1.1743, -0.3590, -1.5015, -1.2688, -0.7238,  0.6078, -0.7770, -0.5603,\n",
       "                       -1.0585, -2.4407,  0.2009, -0.2834,  0.7608, -1.7639,  0.2063, -2.9283,\n",
       "                        0.7519, -0.2881, -1.1566,  0.8917, -1.0718, -0.9818, -0.5942, -1.4136,\n",
       "                       -1.6280, -0.8931,  0.1530,  0.7058,  4.0625, -1.0719, -0.8588, -0.3501,\n",
       "                        0.4297, -2.2031, -1.2813, -1.6371, -0.5271, -0.3071,  0.8096, -1.7132,\n",
       "                        0.2276, -1.1559, -0.2223, -0.3864, -0.5788, -3.1220,  1.1476,  0.0949,\n",
       "                       -0.5827, -0.7919, -0.3402, -0.6996,  1.3849, -1.1728, -1.6572, -0.4507,\n",
       "                        0.3441, -0.7767, -0.7949, -2.0408,  0.7651,  0.7501,  1.2414,  0.7645,\n",
       "                       -0.4411, -0.4562, -1.2918, -0.8151, -0.0248, -1.2676, -1.4142, -0.5653,\n",
       "                        0.5411,  0.3371, -2.2451, -0.9421, -1.6590, -1.5126, -0.3888, -1.7700,\n",
       "                        0.2823, -0.3586,  0.4926, -0.8216,  0.6853, -0.7420, -1.7206, -1.7160,\n",
       "                       -1.6834,  0.0062, -0.2569, -0.1965,  0.7155, -0.4529, -0.2083, -2.6034],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.3.bn1.running_var',\n",
       "               tensor([2.3301, 2.7225, 2.7692, 2.2962, 2.1674, 1.6236, 1.3078, 3.3664, 2.9117,\n",
       "                       2.8264, 2.5123, 2.8314, 4.3928, 3.9117, 3.8944, 2.4122, 2.5290, 1.5858,\n",
       "                       2.9096, 4.3614, 3.3804, 2.6707, 1.7005, 1.7191, 3.1201, 4.3520, 3.7532,\n",
       "                       2.5014, 2.8554, 2.8327, 3.9464, 2.2633, 2.1980, 3.6695, 2.2740, 2.4295,\n",
       "                       2.9889, 3.1524, 2.0882, 2.8006, 3.2156, 1.5583, 1.9069, 4.3627, 3.1157,\n",
       "                       2.6071, 3.5104, 2.0639, 1.8184, 4.2109, 1.7644, 1.9279, 2.6254, 1.8419,\n",
       "                       1.4102, 2.5973, 1.9566, 2.7523, 3.2752, 2.9616, 2.7581, 3.3920, 1.7025,\n",
       "                       2.9134, 1.5391, 2.5817, 2.9806, 2.4938, 2.5423, 2.9972, 2.4355, 2.9851,\n",
       "                       5.1341, 2.8478, 3.1612, 3.3005, 2.8208, 3.7396, 1.8488, 2.4588, 2.5557,\n",
       "                       2.2862, 2.2671, 1.9860, 1.8660, 3.2005, 2.4560, 1.8166, 2.2441, 2.8898,\n",
       "                       2.0068, 2.4200, 3.0415, 2.5667, 2.0740, 2.6934, 4.0511, 2.3098, 3.5324,\n",
       "                       3.0265, 6.4943, 2.2154, 3.2319, 2.4026, 1.6693, 2.2336, 4.1394, 1.7500,\n",
       "                       4.1798, 2.8017, 2.4476, 2.3125, 3.1737, 3.2663, 3.6434, 2.2435, 3.4990,\n",
       "                       2.6311, 3.1283, 2.8747, 3.7382, 2.7230, 4.9532, 2.7190, 2.9907, 2.3953,\n",
       "                       1.4379, 2.5709, 4.0579, 2.2357, 4.0654, 2.4652, 2.2677, 2.8305, 3.2876,\n",
       "                       3.9411, 2.1268, 3.2187, 2.3765, 3.1589, 3.3051, 2.9411, 3.0859, 2.4273,\n",
       "                       2.2958, 3.5392, 2.1569, 4.6116, 3.0994, 2.8588, 1.8704, 2.6114, 2.1037,\n",
       "                       2.4769, 2.6378, 2.1586, 2.9026, 3.1604, 3.5530, 4.8399, 2.4882, 2.0064,\n",
       "                       2.0784, 2.8568, 3.5695, 2.7633, 2.5332, 2.7405, 2.7097, 1.5211, 3.5887,\n",
       "                       1.8510, 2.4657, 1.9801, 3.8499, 1.7771, 4.2382, 2.9112, 2.1266, 4.2216,\n",
       "                       2.5986, 2.3044, 1.7360, 3.8766, 3.7961, 2.6698, 2.8122, 3.9440, 9.7850,\n",
       "                       3.9479, 2.0737, 2.8104, 3.3862, 1.7098, 1.7972, 1.8835, 2.0912, 2.9561,\n",
       "                       3.7418, 1.9515, 2.7832, 3.1156, 3.4988, 2.3940, 3.8214, 2.9519, 3.7587,\n",
       "                       3.3768, 1.0960, 3.2794, 4.1345, 2.3865, 4.9566, 3.0296, 2.7820, 1.6439,\n",
       "                       2.4422, 2.5372, 2.2243, 1.6544, 3.7274, 3.8822, 4.1421, 2.7469, 3.0686,\n",
       "                       1.3594, 2.4072, 1.7687, 3.0514, 2.7301, 2.1367, 3.0852, 1.8845, 2.3850,\n",
       "                       2.6572, 1.8974, 3.1708, 2.6101, 2.2170, 4.0935, 1.7274, 3.2598, 3.0422,\n",
       "                       2.6312, 4.0158, 2.4841, 3.9591, 2.0702, 1.6151, 3.7723, 1.9238, 3.2712,\n",
       "                       2.3144, 4.6309, 1.9802, 4.5277], device='cuda:0')),\n",
       "              ('module.layer3.3.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.3.conv2.weight',\n",
       "               tensor([[[[-1.6706e-02, -2.5175e-02, -1.9307e-03],\n",
       "                         [-2.5279e-02, -2.1971e-02, -1.1359e-02],\n",
       "                         [-1.8040e-02, -2.8956e-02, -1.1002e-02]],\n",
       "               \n",
       "                        [[ 2.9489e-02, -2.9191e-03,  1.3067e-02],\n",
       "                         [-1.0698e-02,  8.4601e-03,  3.7382e-03],\n",
       "                         [ 2.4763e-02,  2.2505e-02,  4.4987e-03]],\n",
       "               \n",
       "                        [[ 1.1358e-02,  2.1272e-02,  1.0867e-02],\n",
       "                         [ 1.2919e-02, -6.2862e-03,  1.4273e-03],\n",
       "                         [-1.1311e-02,  5.3264e-05,  3.8347e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.0781e-02,  3.1577e-02,  1.0681e-03],\n",
       "                         [-7.6339e-03,  6.4336e-02,  1.7186e-02],\n",
       "                         [-9.4746e-03,  1.4722e-02,  1.8777e-02]],\n",
       "               \n",
       "                        [[-1.1117e-02,  2.4403e-02, -2.8142e-03],\n",
       "                         [-9.6767e-03,  3.0555e-02,  1.4847e-03],\n",
       "                         [ 5.5132e-03, -6.2397e-03, -1.0904e-02]],\n",
       "               \n",
       "                        [[ 2.1434e-02, -1.8276e-02,  8.4593e-03],\n",
       "                         [ 9.0681e-03,  2.9520e-02,  1.2969e-02],\n",
       "                         [ 2.3857e-03,  1.4429e-02,  6.8212e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0452e-02, -1.3692e-02, -1.3539e-02],\n",
       "                         [-2.2418e-02, -2.6475e-02, -1.2772e-02],\n",
       "                         [-2.8254e-02, -1.5773e-02, -1.3554e-02]],\n",
       "               \n",
       "                        [[ 4.1646e-02,  2.0620e-02,  5.5115e-02],\n",
       "                         [ 2.5936e-02,  5.9599e-03,  4.9055e-03],\n",
       "                         [ 2.4455e-02,  1.6863e-02,  2.2458e-02]],\n",
       "               \n",
       "                        [[-1.2604e-02,  1.5547e-02, -1.2080e-02],\n",
       "                         [ 6.0382e-04, -1.0227e-02,  1.0688e-02],\n",
       "                         [-3.7989e-03,  3.3534e-02,  6.3284e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.9490e-03,  1.1438e-03,  5.0369e-03],\n",
       "                         [ 2.3289e-02,  2.7194e-02,  1.0857e-02],\n",
       "                         [ 1.0578e-02,  1.7608e-02,  6.7394e-03]],\n",
       "               \n",
       "                        [[ 3.2121e-03,  3.6730e-02, -1.2431e-02],\n",
       "                         [ 3.6086e-02,  9.2175e-02,  2.8883e-02],\n",
       "                         [ 4.6477e-03,  5.5749e-02,  1.1363e-02]],\n",
       "               \n",
       "                        [[ 1.4563e-02,  7.3644e-03,  2.1042e-02],\n",
       "                         [-1.4389e-03, -3.5676e-02,  1.5346e-02],\n",
       "                         [ 3.4382e-03, -2.1956e-03,  1.2215e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.6529e-04,  2.2268e-03, -4.5561e-03],\n",
       "                         [ 2.7350e-03,  8.1444e-03, -2.0116e-03],\n",
       "                         [ 1.5538e-02,  1.5223e-02,  4.4040e-03]],\n",
       "               \n",
       "                        [[-1.1261e-02, -1.7603e-02,  5.3183e-03],\n",
       "                         [-9.5149e-03, -2.7590e-02,  7.1992e-05],\n",
       "                         [-2.0070e-02, -3.7452e-03, -2.3163e-02]],\n",
       "               \n",
       "                        [[-1.6261e-02, -1.1070e-02, -3.3331e-02],\n",
       "                         [ 6.3775e-03,  2.9156e-03,  7.1279e-03],\n",
       "                         [-1.8463e-02, -3.9412e-03,  5.0263e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.8895e-03, -4.1000e-02, -9.2047e-03],\n",
       "                         [ 2.0509e-02,  2.0136e-03,  4.3950e-02],\n",
       "                         [ 1.9679e-02,  1.6343e-02,  3.5173e-02]],\n",
       "               \n",
       "                        [[-2.7404e-03, -1.6892e-02, -7.6039e-03],\n",
       "                         [-3.1225e-03, -2.9576e-02, -1.7719e-02],\n",
       "                         [ 7.5404e-03, -7.0235e-03,  6.7589e-03]],\n",
       "               \n",
       "                        [[-7.3958e-04, -1.3357e-02,  1.9327e-02],\n",
       "                         [ 1.5647e-02,  1.1127e-02,  2.9956e-02],\n",
       "                         [ 2.6689e-02,  1.1160e-02,  3.5055e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-4.1566e-02, -1.6407e-02, -2.8708e-02],\n",
       "                         [-1.9470e-02, -7.7606e-03, -2.2549e-02],\n",
       "                         [-2.5747e-02, -3.1873e-02, -2.5201e-02]],\n",
       "               \n",
       "                        [[ 5.0249e-02,  4.5030e-02,  5.8583e-02],\n",
       "                         [ 3.4689e-02,  4.2907e-02,  3.2546e-02],\n",
       "                         [ 2.7261e-02,  3.0397e-02,  1.9790e-02]],\n",
       "               \n",
       "                        [[-1.3979e-03, -2.2895e-03,  1.2680e-02],\n",
       "                         [ 6.7063e-03,  9.8379e-03,  4.5781e-03],\n",
       "                         [ 1.7836e-02,  1.9926e-02,  2.4977e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.1375e-03, -2.0388e-02,  1.0902e-02],\n",
       "                         [ 3.0977e-02, -2.3468e-02,  2.1261e-02],\n",
       "                         [ 4.0914e-03,  1.5326e-02,  9.1625e-03]],\n",
       "               \n",
       "                        [[ 6.6071e-03, -2.3326e-02, -7.7708e-03],\n",
       "                         [-2.5419e-02, -7.4514e-03, -1.8730e-02],\n",
       "                         [-6.2311e-03, -1.3146e-02, -1.6219e-02]],\n",
       "               \n",
       "                        [[ 5.7972e-02,  5.0722e-02,  4.8038e-02],\n",
       "                         [ 4.1042e-02,  1.0739e-03,  3.9717e-02],\n",
       "                         [ 5.1119e-02,  5.9311e-02,  4.4164e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1950e-02,  2.5051e-02,  2.1027e-02],\n",
       "                         [-7.2664e-03, -7.1058e-02,  7.5653e-03],\n",
       "                         [ 2.4290e-03,  4.9838e-03,  2.2313e-02]],\n",
       "               \n",
       "                        [[-3.7456e-02, -3.1930e-02, -5.5281e-02],\n",
       "                         [-4.4011e-02, -7.9314e-03, -6.3693e-02],\n",
       "                         [-5.4876e-02, -6.7640e-02, -6.6374e-02]],\n",
       "               \n",
       "                        [[-2.7209e-02, -3.3891e-02, -4.0883e-02],\n",
       "                         [-4.8012e-02, -1.9680e-03, -3.2825e-02],\n",
       "                         [-4.0438e-02, -2.3407e-02, -4.3170e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.0787e-02, -1.7331e-02, -2.3690e-02],\n",
       "                         [-2.4957e-02,  3.9045e-02, -3.8622e-02],\n",
       "                         [-1.5309e-03, -1.3719e-03, -8.1653e-03]],\n",
       "               \n",
       "                        [[ 3.4359e-02,  4.6520e-02,  4.5927e-02],\n",
       "                         [ 3.9236e-02, -8.8606e-03,  3.4576e-02],\n",
       "                         [ 3.4430e-02,  3.3453e-02,  3.2875e-02]],\n",
       "               \n",
       "                        [[-4.0433e-03,  2.0107e-02,  4.6587e-03],\n",
       "                         [ 1.8476e-02,  4.5820e-02,  1.2828e-02],\n",
       "                         [-1.2352e-02,  8.5591e-03, -2.8101e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2763e-02, -2.3075e-02, -7.3702e-03],\n",
       "                         [-5.2035e-03,  5.8755e-02,  1.4070e-02],\n",
       "                         [-8.7495e-04, -1.3755e-04, -2.8618e-03]],\n",
       "               \n",
       "                        [[ 1.9882e-02,  1.3838e-02,  2.7973e-02],\n",
       "                         [ 1.2906e-02,  1.5318e-02,  2.3484e-03],\n",
       "                         [ 1.3211e-02,  1.0100e-02,  1.1521e-02]],\n",
       "               \n",
       "                        [[ 4.9188e-03,  1.1102e-02,  1.3855e-03],\n",
       "                         [-4.8089e-05,  2.7743e-02, -4.2669e-03],\n",
       "                         [-1.3532e-02, -1.7514e-02,  2.7476e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.1378e-02, -2.1398e-02,  1.2862e-02],\n",
       "                         [ 7.0463e-03, -2.3401e-03, -5.9643e-05],\n",
       "                         [-4.2906e-03, -5.1827e-03, -5.4418e-03]],\n",
       "               \n",
       "                        [[-1.6662e-03, -4.9060e-03,  2.1763e-03],\n",
       "                         [ 4.0323e-03,  6.6602e-03, -3.3650e-02],\n",
       "                         [ 1.7806e-02, -1.2174e-02,  3.0053e-03]],\n",
       "               \n",
       "                        [[-3.1769e-02, -4.1710e-02, -1.6995e-02],\n",
       "                         [-3.4329e-02, -3.0063e-02, -3.7028e-02],\n",
       "                         [-2.4938e-02, -3.0880e-02, -3.9979e-02]]]], device='cuda:0')),\n",
       "              ('module.layer3.3.bn2.weight',\n",
       "               tensor([1.6516, 1.7710, 1.3823, 1.4840, 1.4556, 1.3794, 1.7062, 1.4640, 1.4968,\n",
       "                       1.1312, 1.0537, 1.5218, 1.5398, 1.4284, 1.1887, 1.3997, 2.0546, 1.0566,\n",
       "                       1.8527, 1.9531, 1.3272, 1.7662, 1.7274, 1.8181, 1.3148, 1.4938, 1.1417,\n",
       "                       1.9220, 0.8209, 1.6145, 1.6027, 2.1242, 1.4879, 1.3802, 1.3322, 2.3461,\n",
       "                       1.8299, 1.7415, 0.8545, 1.8384, 1.5815, 1.6528, 1.1963, 1.0935, 1.0501,\n",
       "                       1.6268, 1.5010, 1.5004, 1.8564, 2.0425, 1.3671, 0.7738, 1.1175, 1.0360,\n",
       "                       1.4486, 1.4853, 1.5652, 1.9250, 1.7231, 1.4899, 1.5628, 1.2753, 1.4962,\n",
       "                       1.8137, 1.4310, 1.3848, 1.2031, 1.6128, 1.7184, 1.6755, 1.1795, 1.5559,\n",
       "                       1.6813, 1.6201, 1.5114, 1.8887, 2.1576, 1.1049, 1.1050, 1.3152, 1.4652,\n",
       "                       1.9670, 1.3074, 1.4157, 1.8780, 1.3535, 0.7864, 3.1697, 1.1523, 1.5193,\n",
       "                       1.2562, 1.0628, 1.8335, 1.3940, 1.5276, 1.6564, 1.7427, 1.2380, 0.8013,\n",
       "                       1.7241, 1.6968, 1.4838, 1.0276, 1.5759, 1.4046, 1.4044, 1.2721, 0.7607,\n",
       "                       1.5851, 0.9549, 1.0762, 1.4724, 0.7955, 2.1584, 1.0776, 2.1199, 1.0779,\n",
       "                       1.3955, 1.1245, 1.0358, 1.3771, 0.7817, 1.0358, 1.8277, 1.2212, 0.9618,\n",
       "                       1.8312, 0.9139, 1.6005, 1.2631, 1.6488, 1.5710, 1.0127, 1.7426, 1.8173,\n",
       "                       1.6897, 1.5905, 1.3629, 2.0782, 1.1216, 1.4179, 2.1884, 1.8732, 1.5742,\n",
       "                       1.5038, 0.8059, 1.5684, 1.7161, 1.1273, 1.0796, 1.1867, 1.2686, 1.3389,\n",
       "                       1.4514, 2.0239, 1.5128, 1.3321, 1.7178, 1.2111, 1.3284, 1.8987, 1.7112,\n",
       "                       1.6759, 1.1454, 1.4270, 1.5241, 1.1756, 1.2179, 1.5018, 0.7760, 1.3389,\n",
       "                       1.4077, 1.6264, 2.0817, 1.3626, 0.6924, 1.5284, 1.4888, 2.1404, 1.0940,\n",
       "                       1.6986, 0.7991, 1.4703, 0.9650, 1.9978, 0.8170, 1.9059, 1.2575, 1.7042,\n",
       "                       2.0793, 2.0528, 1.6472, 1.5405, 1.7849, 1.6966, 1.2396, 1.4895, 1.1303,\n",
       "                       2.3768, 0.8205, 1.7191, 1.0350, 1.7848, 1.2005, 1.1092, 0.9586, 1.1595,\n",
       "                       1.3347, 1.3869, 1.4631, 0.8866, 1.3050, 1.5654, 1.8842, 0.7711, 2.0447,\n",
       "                       1.5073, 1.6111, 2.0302, 1.4294, 1.8016, 1.5158, 1.0629, 1.1385, 1.2743,\n",
       "                       1.7719, 1.7339, 1.3402, 1.4582, 1.2129, 1.3226, 1.8950, 1.3928, 1.4227,\n",
       "                       0.9649, 1.6114, 0.7716, 2.0528, 1.5147, 1.1405, 0.8330, 0.7437, 1.2539,\n",
       "                       0.7679, 2.6076, 1.6523, 1.4844, 1.0364, 1.6342, 1.7002, 1.1193, 0.7627,\n",
       "                       1.9411, 1.2701, 1.0455, 1.4989], device='cuda:0')),\n",
       "              ('module.layer3.3.bn2.bias',\n",
       "               tensor([-1.6167, -1.5951, -0.6463, -0.5878, -0.7968, -0.3826, -1.2337, -0.7866,\n",
       "                       -0.7482,  0.0348,  0.2468, -0.8704, -1.2649, -0.6447, -0.0527, -0.9762,\n",
       "                       -2.4150, -0.0311, -1.6451, -1.3145, -0.7740, -1.4475, -1.1264, -2.2132,\n",
       "                       -0.5153, -1.2628, -0.1996, -1.8222,  2.1414, -1.0625, -0.6212, -2.2804,\n",
       "                       -1.2082, -0.9166, -0.5949, -1.5331, -2.7589, -0.8310,  2.4785, -1.4523,\n",
       "                       -1.2566, -1.3601, -0.2178, -0.1451,  1.7908, -1.5756, -0.9320, -1.0755,\n",
       "                       -1.7512, -2.4939, -0.5083,  1.2749, -0.0651,  0.2073, -1.2914, -0.4224,\n",
       "                       -1.2398, -1.5186, -1.5062, -1.1714, -0.9580, -0.5163, -1.0539, -2.0648,\n",
       "                       -0.6623, -0.6387, -0.3368, -0.8022, -1.7338, -1.8010, -0.3627, -0.7412,\n",
       "                       -1.1679, -1.3897, -0.6355, -1.8917, -1.6171,  0.1310, -0.0201, -0.5449,\n",
       "                       -1.3410, -2.2746, -1.0546, -0.7354, -2.1418, -0.6831,  1.7643, -2.6889,\n",
       "                       -0.2965, -1.1900, -0.4015,  2.3851, -1.6203, -0.7725, -1.2340, -1.3047,\n",
       "                       -1.6877, -0.1232,  1.7005, -2.0980, -2.2355, -1.1293,  0.0422, -1.3570,\n",
       "                       -0.8539, -1.9842, -0.3367,  0.8602, -0.8599,  0.7444,  0.2462, -0.6437,\n",
       "                        1.5087, -2.0925,  0.0460, -1.9794,  0.0848, -0.4548, -0.3224,  0.1879,\n",
       "                       -1.1678,  1.0680,  0.6693, -0.8650, -0.3003,  0.7121, -1.8620,  0.7050,\n",
       "                       -1.0950, -0.5254, -1.1993, -0.9852,  0.7396, -0.8284, -2.2576, -0.8471,\n",
       "                       -2.2937, -1.2901, -1.5291,  0.3989, -1.3593, -2.1390, -1.5781, -1.2843,\n",
       "                       -1.0729,  0.6678, -1.0066, -1.7238,  0.2763, -0.0784, -0.4945, -0.4960,\n",
       "                       -0.6808, -0.8014, -2.1040, -1.1153, -0.5380, -1.3277, -0.1825, -0.6128,\n",
       "                       -1.5948, -1.8816, -1.3654, -0.2475, -0.6680, -1.0523, -0.5722, -0.4845,\n",
       "                       -1.2676,  1.6824, -0.6299, -0.6328, -1.4509, -1.6883, -1.0140,  1.6599,\n",
       "                       -0.8419, -1.6368, -2.0912,  0.2135, -1.4133,  1.9924, -1.1876,  0.5712,\n",
       "                       -1.8687,  2.2259, -2.0990, -0.1899, -1.0792, -1.8201, -1.5629, -1.6959,\n",
       "                       -1.0224, -2.2083, -1.3578, -0.2914, -0.7426, -0.0720, -2.7692,  1.8961,\n",
       "                       -1.2760,  0.0178, -1.7381, -0.3195,  0.0222,  0.0587, -0.0453, -0.7240,\n",
       "                       -0.4762, -1.0693,  0.8184, -0.9001, -1.1600, -1.2060,  0.8406, -1.8120,\n",
       "                       -0.6974, -1.4741, -1.9344, -0.8117, -1.6394, -0.8411,  0.1414, -0.1505,\n",
       "                       -0.4520, -1.1792, -1.2581, -0.6465, -1.2583, -0.3560, -0.5887, -1.3673,\n",
       "                       -1.3195, -0.4837,  0.4008, -1.6328,  1.6666, -1.8309, -1.3053, -0.0104,\n",
       "                        2.1232,  1.3853, -0.6664,  2.0676, -2.1874, -1.1449, -0.9849,  0.6578,\n",
       "                       -0.7886, -1.4862,  0.8401,  1.6761, -1.8237, -0.5433,  0.2585, -1.2808],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.3.bn2.running_mean',\n",
       "               tensor([ 7.7161e-02, -1.7916e+00, -5.7572e-01,  6.5964e-01, -6.1810e-01,\n",
       "                        5.7025e-01, -5.5052e-01, -7.3678e-01, -5.0754e-01, -1.4649e+00,\n",
       "                        6.5545e-01, -4.0573e-01, -9.1190e-01, -5.4068e-01, -5.0904e-01,\n",
       "                       -1.8819e-01,  5.1336e-02, -2.8633e-01, -5.3979e-01, -1.4308e+00,\n",
       "                       -4.0847e-01, -4.7218e-01, -4.2287e-01, -9.0638e-01, -9.2747e-02,\n",
       "                       -6.7367e-01, -4.4716e-01,  8.3025e-01, -3.9435e-01, -7.6832e-01,\n",
       "                       -9.9728e-01, -9.9603e-01,  1.9724e+00, -1.3829e+00, -4.0130e-01,\n",
       "                       -1.5825e+00, -8.2154e-01, -1.2658e+00,  9.4188e-02, -2.8831e-01,\n",
       "                       -1.3621e+00, -1.0189e+00, -3.5337e-01,  2.1724e-01,  4.4378e+00,\n",
       "                       -1.1748e+00, -4.1263e-01, -7.2871e-01, -9.3322e-01, -9.6049e-01,\n",
       "                       -4.9462e-01, -6.2961e-02,  5.9482e-01,  1.7275e-01, -1.0029e+00,\n",
       "                       -7.6457e-01, -1.1384e-03,  3.1576e-02, -1.1359e+00,  2.2070e-01,\n",
       "                       -4.7822e-01, -2.2883e-01, -3.1394e-01, -1.6845e+00, -1.4080e-01,\n",
       "                       -6.9399e-01,  4.6882e-01, -7.1065e-01,  2.9185e-01, -7.4861e-01,\n",
       "                        4.3625e-02, -2.8860e-02, -3.2119e-01,  3.8192e-01,  3.5705e-01,\n",
       "                       -1.6152e+00, -1.2759e+00,  8.3228e-01, -8.4793e-01, -6.6885e-01,\n",
       "                       -9.3874e-01, -1.0308e+00,  1.6295e-01, -6.2723e-01, -3.2607e-01,\n",
       "                       -7.8110e-01,  6.4760e-01, -1.1310e+00, -1.4462e+00, -1.0392e+00,\n",
       "                       -8.7731e-01, -1.1845e+00, -8.5037e-01, -5.3273e-01, -1.1169e+00,\n",
       "                       -4.9664e-01, -5.9585e-01, -2.8909e-01,  5.6489e-02,  2.1183e-01,\n",
       "                        5.7842e-01, -1.3111e+00, -6.1344e-01, -1.1113e+00, -8.0368e-01,\n",
       "                       -8.6465e-01,  2.6869e-01, -7.0266e-01, -1.1440e+00, -3.6664e-02,\n",
       "                        9.4196e-01, -1.7144e+00,  3.6028e-01, -7.4858e-01, -1.7835e-01,\n",
       "                       -2.6209e-01, -2.7615e-01, -5.1286e-01, -1.4847e-01,  1.8875e-01,\n",
       "                       -3.0303e-01, -1.6634e+00,  1.4256e+00, -8.1991e-01,  4.7143e-02,\n",
       "                       -8.3950e-01, -1.2777e+00,  9.7958e-01, -6.1934e-01, -5.0906e-02,\n",
       "                       -1.1716e+00, -3.9339e-01,  1.3880e+00, -1.3054e+00,  1.7021e-01,\n",
       "                        5.2785e-01, -8.8515e-01, -4.7094e-01, -2.2838e+00,  1.2341e+00,\n",
       "                       -1.2189e+00, -5.7953e-01, -3.3173e-01, -5.7634e-01, -2.0287e-01,\n",
       "                       -9.7358e-03, -9.3136e-01,  1.3597e+00, -1.0053e+00, -3.6973e-01,\n",
       "                       -1.7609e+00,  4.3223e-01, -7.0056e-01,  1.9480e-01, -1.0829e-01,\n",
       "                       -1.4065e+00, -4.3610e-01, -7.8180e-01,  6.3391e-01, -3.6517e-01,\n",
       "                       -6.4425e-01, -5.8096e-01, -7.8692e-01, -2.3529e-02, -1.1237e-01,\n",
       "                       -1.8626e-01, -3.2840e-01, -5.8141e-01, -7.9674e-01,  6.0785e-01,\n",
       "                        5.3908e-01, -7.0650e-01, -1.3271e+00, -1.4995e+00, -1.8006e-01,\n",
       "                        7.7528e-01, -1.0535e+00, -7.9935e-01, -3.8139e-01, -3.2903e-01,\n",
       "                       -8.8987e-01,  2.2841e-01, -4.2764e-01,  9.2767e-01, -6.5276e-02,\n",
       "                       -1.1254e+00, -6.2866e-01, -9.8725e-01,  1.2361e-01, -1.1461e+00,\n",
       "                       -4.3019e-01, -4.3456e-01, -2.8230e-01, -1.3607e+00,  9.3714e-02,\n",
       "                        4.9515e-01,  5.5865e-02,  8.0900e-01, -3.5482e-01, -2.0187e+00,\n",
       "                        1.4110e-01, -7.6066e-01,  2.3108e-01,  5.5814e-01, -8.8350e-01,\n",
       "                       -1.2259e+00,  4.8234e-01, -4.0068e-03, -6.6506e-01, -1.1411e+00,\n",
       "                       -2.1169e-01, -1.2157e+00,  1.5057e+00, -1.5499e+00,  3.9135e-01,\n",
       "                       -3.7483e-01, -8.2577e-01, -6.4764e-01, -3.4185e-02, -6.9491e-02,\n",
       "                       -1.4532e+00, -4.2340e-01, -2.9115e-01, -6.6502e-01, -1.5774e+00,\n",
       "                       -9.8144e-01, -1.5107e+00, -6.6568e-01, -1.9179e-01, -3.8351e-01,\n",
       "                       -5.1878e-01, -9.7922e-01, -3.9174e-01, -5.3565e-01, -4.7504e-01,\n",
       "                       -1.1339e-01, -6.8815e-02, -1.7321e+00, -1.7094e-01,  2.7021e-01,\n",
       "                       -2.1254e+00, -5.1162e-01, -1.7371e-01, -1.9792e+00, -3.7833e+00,\n",
       "                       -4.6710e-01, -1.4110e-01,  9.7957e-01, -1.1322e+00, -5.0382e-01,\n",
       "                       -4.1131e-01,  1.3576e+00, -7.1660e-01, -9.8035e-01, -3.5863e-01,\n",
       "                       -1.1502e+00], device='cuda:0')),\n",
       "              ('module.layer3.3.bn2.running_var',\n",
       "               tensor([0.6954, 1.2938, 1.7334, 1.4966, 1.3685, 1.0057, 1.1497, 1.1685, 1.0925,\n",
       "                       1.5296, 1.0628, 1.0034, 0.7993, 1.4488, 1.7295, 0.8895, 0.7561, 1.0704,\n",
       "                       1.0168, 1.4339, 1.2627, 0.9022, 1.3534, 0.6982, 1.2705, 1.0560, 1.0056,\n",
       "                       1.1459, 1.5256, 1.2600, 2.0038, 0.8044, 2.0983, 1.4229, 1.1909, 1.3541,\n",
       "                       0.6457, 1.8000, 2.2419, 0.9727, 0.9179, 1.1608, 1.4813, 0.9465, 2.4462,\n",
       "                       0.7524, 0.8535, 1.1742, 0.8529, 0.8722, 1.7573, 1.7866, 1.2895, 1.8086,\n",
       "                       0.8425, 2.0123, 0.7489, 1.0427, 1.1022, 0.7086, 1.0340, 1.0936, 1.1766,\n",
       "                       0.8592, 1.3916, 1.3162, 1.2607, 1.2486, 0.7098, 1.9018, 1.0280, 1.4469,\n",
       "                       1.2951, 1.0749, 1.5679, 1.0134, 1.4053, 1.1315, 1.2965, 0.9695, 0.8820,\n",
       "                       0.7255, 1.0671, 1.1552, 0.7169, 1.4967, 1.2950, 1.1758, 1.2196, 0.8362,\n",
       "                       1.4742, 3.4738, 0.9901, 1.0719, 1.1893, 0.9217, 0.9158, 1.5417, 1.5793,\n",
       "                       1.4006, 1.3201, 1.1688, 1.0702, 1.1402, 1.2563, 1.0047, 0.9146, 1.0210,\n",
       "                       1.3187, 2.1907, 1.3180, 1.2758, 1.2707, 0.8902, 0.9432, 1.1879, 1.6476,\n",
       "                       2.7326, 0.9632, 1.4582, 0.9182, 1.5776, 1.9075, 2.1443, 0.9885, 2.2809,\n",
       "                       1.0913, 1.4556, 1.0798, 0.8757, 1.3203, 0.8461, 2.0242, 2.1061, 0.7061,\n",
       "                       1.3728, 0.5638, 1.1582, 1.1489, 1.6579, 0.8420, 1.0698, 0.8182, 0.8346,\n",
       "                       1.0215, 1.2633, 1.1340, 1.6437, 2.2976, 1.4419, 1.3790, 1.0412, 1.4743,\n",
       "                       1.2003, 0.8836, 0.8076, 1.3449, 1.2075, 1.4607, 1.0995, 1.0060, 0.6929,\n",
       "                       1.1339, 0.9377, 1.3859, 1.0232, 0.9281, 0.9839, 0.7064, 1.0863, 1.0335,\n",
       "                       1.0887, 0.7518, 1.2423, 0.8285, 0.9467, 1.6668, 0.8529, 1.0376, 1.7040,\n",
       "                       1.1578, 1.2967, 1.3974, 1.4724, 0.8682, 1.6318, 0.9616, 1.9263, 1.0041,\n",
       "                       1.3000, 0.9218, 0.7597, 1.2206, 0.8507, 0.9318, 1.1356, 1.0442, 1.2459,\n",
       "                       1.5858, 1.4917, 1.0989, 1.9197, 0.8213, 1.3842, 1.2033, 1.5083, 1.6143,\n",
       "                       0.7574, 1.5170, 0.8958, 1.5843, 1.0170, 1.4601, 1.1267, 1.2440, 1.2942,\n",
       "                       1.6494, 1.0522, 0.8542, 0.8329, 0.8601, 1.4704, 1.3138, 1.3733, 1.2353,\n",
       "                       1.3408, 1.3477, 1.2491, 0.6786, 1.4600, 1.1255, 1.1307, 0.7453, 1.5733,\n",
       "                       1.5546, 0.8837, 1.2383, 0.9872, 0.8109, 1.3437, 1.3767, 0.9805, 1.0635,\n",
       "                       1.6077, 2.9933, 1.0004, 1.0578, 1.6662, 1.1943, 0.8434, 2.8482, 1.0082,\n",
       "                       1.0584, 1.4634, 1.4683, 0.7262], device='cuda:0')),\n",
       "              ('module.layer3.3.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.3.conv3.weight',\n",
       "               tensor([[[[-0.0234]],\n",
       "               \n",
       "                        [[-0.0079]],\n",
       "               \n",
       "                        [[ 0.0204]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0301]],\n",
       "               \n",
       "                        [[ 0.0464]],\n",
       "               \n",
       "                        [[ 0.0415]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0187]],\n",
       "               \n",
       "                        [[-0.0300]],\n",
       "               \n",
       "                        [[ 0.0189]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0251]],\n",
       "               \n",
       "                        [[-0.0094]],\n",
       "               \n",
       "                        [[-0.0617]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0095]],\n",
       "               \n",
       "                        [[ 0.0176]],\n",
       "               \n",
       "                        [[-0.0433]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0197]],\n",
       "               \n",
       "                        [[-0.0079]],\n",
       "               \n",
       "                        [[ 0.0452]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0261]],\n",
       "               \n",
       "                        [[-0.0347]],\n",
       "               \n",
       "                        [[-0.0138]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0033]],\n",
       "               \n",
       "                        [[-0.0192]],\n",
       "               \n",
       "                        [[-0.0334]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0031]],\n",
       "               \n",
       "                        [[-0.0492]],\n",
       "               \n",
       "                        [[-0.0107]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0247]],\n",
       "               \n",
       "                        [[-0.0285]],\n",
       "               \n",
       "                        [[ 0.0116]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0088]],\n",
       "               \n",
       "                        [[-0.0105]],\n",
       "               \n",
       "                        [[-0.0113]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0302]],\n",
       "               \n",
       "                        [[-0.0146]],\n",
       "               \n",
       "                        [[-0.0033]]]], device='cuda:0')),\n",
       "              ('module.layer3.3.bn3.weight',\n",
       "               tensor([0.5148, 0.8189, 0.5715,  ..., 0.8109, 0.2740, 0.3542], device='cuda:0')),\n",
       "              ('module.layer3.3.bn3.bias',\n",
       "               tensor([-0.5703, -0.9680, -0.4827,  ..., -0.8118, -0.4065, -0.0845],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.3.bn3.running_mean',\n",
       "               tensor([-0.6441, -0.1888,  0.1785,  ..., -0.3571,  0.4383,  0.1770],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.3.bn3.running_var',\n",
       "               tensor([0.1398, 0.1406, 0.1191,  ..., 0.0796, 0.0603, 0.0638], device='cuda:0')),\n",
       "              ('module.layer3.3.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.4.conv1.weight',\n",
       "               tensor([[[[ 0.0263]],\n",
       "               \n",
       "                        [[-0.0244]],\n",
       "               \n",
       "                        [[ 0.0399]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0097]],\n",
       "               \n",
       "                        [[-0.0424]],\n",
       "               \n",
       "                        [[-0.0497]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0147]],\n",
       "               \n",
       "                        [[ 0.0013]],\n",
       "               \n",
       "                        [[ 0.0018]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0348]],\n",
       "               \n",
       "                        [[ 0.0202]],\n",
       "               \n",
       "                        [[ 0.0096]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0034]],\n",
       "               \n",
       "                        [[-0.0346]],\n",
       "               \n",
       "                        [[ 0.0317]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0162]],\n",
       "               \n",
       "                        [[ 0.0514]],\n",
       "               \n",
       "                        [[ 0.0090]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0258]],\n",
       "               \n",
       "                        [[-0.0046]],\n",
       "               \n",
       "                        [[ 0.0098]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0114]],\n",
       "               \n",
       "                        [[ 0.0378]],\n",
       "               \n",
       "                        [[-0.0021]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0158]],\n",
       "               \n",
       "                        [[-0.0177]],\n",
       "               \n",
       "                        [[ 0.0131]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0126]],\n",
       "               \n",
       "                        [[ 0.0152]],\n",
       "               \n",
       "                        [[ 0.0208]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0051]],\n",
       "               \n",
       "                        [[-0.0026]],\n",
       "               \n",
       "                        [[ 0.0061]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0273]],\n",
       "               \n",
       "                        [[-0.0515]],\n",
       "               \n",
       "                        [[-0.0211]]]], device='cuda:0')),\n",
       "              ('module.layer3.4.bn1.weight',\n",
       "               tensor([0.8866, 1.3234, 1.4856, 2.1163, 1.5588, 1.6289, 1.6724, 1.7092, 0.9052,\n",
       "                       1.3290, 1.2371, 1.7147, 1.1289, 1.4885, 0.9355, 1.3360, 2.0464, 0.9276,\n",
       "                       1.2920, 0.8602, 1.1755, 1.3212, 1.5957, 1.4699, 1.4462, 1.6066, 1.6981,\n",
       "                       1.5549, 1.3098, 1.5529, 1.7349, 0.8957, 0.9915, 2.6990, 1.3660, 1.5762,\n",
       "                       1.6300, 1.6297, 0.9954, 0.9957, 1.4328, 1.4326, 1.5879, 1.0505, 1.2119,\n",
       "                       1.1060, 1.6257, 1.2146, 1.6711, 1.4031, 2.1443, 1.9331, 1.0301, 1.3456,\n",
       "                       1.2866, 1.3976, 1.2535, 1.5508, 1.4033, 1.4237, 0.9387, 1.6521, 1.4813,\n",
       "                       1.0965, 1.8478, 1.8916, 1.3195, 1.6129, 1.4677, 1.4241, 1.5622, 1.5796,\n",
       "                       1.1349, 1.3796, 2.2504, 1.6573, 1.3708, 1.0565, 0.8629, 0.7198, 1.8071,\n",
       "                       1.4194, 0.9037, 1.1740, 1.0537, 1.4735, 0.9660, 1.0826, 2.0733, 1.9692,\n",
       "                       1.0691, 0.9510, 1.2183, 1.3700, 1.7804, 1.7804, 0.8630, 0.7424, 1.6524,\n",
       "                       1.2605, 1.7785, 1.2581, 1.1057, 1.4427, 0.9804, 1.8271, 1.2677, 1.3807,\n",
       "                       1.5380, 1.2181, 1.5268, 0.8227, 0.9131, 1.3934, 1.8012, 1.5819, 1.3862,\n",
       "                       1.5371, 0.9398, 0.8485, 0.8056, 1.3749, 1.3905, 1.6036, 1.5919, 1.3647,\n",
       "                       1.7367, 1.5486, 0.8734, 0.8965, 1.7088, 1.3143, 1.7513, 1.5060, 1.0859,\n",
       "                       2.3084, 1.2033, 2.1712, 1.9599, 1.8267, 1.5608, 1.4867, 1.3394, 1.4092,\n",
       "                       1.3201, 1.4917, 1.5882, 2.0617, 1.4562, 1.6510, 1.5106, 1.7165, 1.6285,\n",
       "                       1.5318, 1.2358, 1.5902, 1.6728, 1.3266, 0.8492, 1.3108, 1.5374, 1.7035,\n",
       "                       1.5449, 0.9490, 0.8791, 1.4962, 1.6693, 1.5034, 1.1550, 1.6750, 1.1940,\n",
       "                       1.8951, 0.9057, 1.3910, 0.9509, 1.1866, 1.6652, 1.1846, 0.8386, 1.0599,\n",
       "                       1.5842, 0.9911, 1.4669, 1.8497, 1.2522, 1.9664, 1.1242, 1.8778, 1.5694,\n",
       "                       1.9857, 1.8095, 1.4512, 1.3063, 1.0306, 1.1081, 1.5191, 0.9855, 0.6381,\n",
       "                       2.1522, 1.3558, 1.4835, 1.1257, 1.6004, 2.2130, 1.6039, 1.4801, 1.3546,\n",
       "                       1.2915, 1.9348, 1.6436, 1.0447, 1.7217, 1.7292, 1.0422, 1.4930, 3.1727,\n",
       "                       1.4318, 1.6276, 1.4134, 1.0055, 1.4640, 1.0988, 1.0836, 1.4757, 0.7406,\n",
       "                       1.3986, 1.0991, 1.3308, 1.1169, 1.0134, 1.5793, 1.2913, 1.3872, 1.1389,\n",
       "                       1.5479, 1.5887, 0.7016, 0.8008, 1.5040, 1.2434, 3.3525, 1.5775, 0.8145,\n",
       "                       1.0553, 1.3259, 1.4511, 1.1982, 1.2534, 1.7176, 1.0658, 1.6883, 1.4954,\n",
       "                       1.5521, 1.6510, 1.3492, 1.4119], device='cuda:0')),\n",
       "              ('module.layer3.4.bn1.bias',\n",
       "               tensor([ 0.1665, -1.0468, -1.4865, -3.5894, -1.5170, -2.0449, -2.4766, -2.2554,\n",
       "                        0.1924, -1.2245, -0.8776, -2.1209, -0.6343, -0.7917,  0.0102, -1.4557,\n",
       "                       -3.8943,  0.1170, -0.4909,  0.0928,  0.9380, -0.9907, -1.3316, -0.8328,\n",
       "                       -1.4481, -2.1290, -1.8006, -1.0119, -1.1042, -2.1922, -2.0795,  0.1202,\n",
       "                       -0.1438, -5.3583, -1.2143, -2.0455, -1.9535, -1.4645, -0.1339, -0.2229,\n",
       "                       -1.3420, -1.4868, -2.1857, -0.2182, -0.5912, -0.6845, -1.9511, -1.0954,\n",
       "                       -2.3121, -1.4453, -3.7934, -2.7458, -0.1390, -1.1600, -0.8610, -0.9617,\n",
       "                       -0.5529, -2.4659, -1.6780, -1.5592,  0.1033, -1.7700, -1.3070, -0.3933,\n",
       "                       -2.6096, -2.3103, -0.9840, -2.3121, -1.6155, -0.9896, -1.4478, -2.2077,\n",
       "                       -0.8343, -1.2248, -4.4169, -1.6374, -1.3084,  0.8336,  0.1774,  0.5159,\n",
       "                       -2.3321, -0.9840,  0.2039, -0.4484, -0.3649, -1.6434,  0.0892, -0.5355,\n",
       "                       -2.0734, -3.5725, -0.3600, -0.0303, -0.8392, -0.8298, -1.6157, -3.0261,\n",
       "                        0.2744,  0.4441, -1.7780, -0.2149, -2.6397, -0.5395, -0.3792, -0.5052,\n",
       "                        0.0381, -1.8600, -0.9397, -1.0331, -1.9631, -0.8142, -1.3533,  0.7021,\n",
       "                        0.0748, -1.2926, -2.0245, -2.5058, -1.2246, -2.1057, -0.0743, -0.0542,\n",
       "                        0.4192, -1.2937, -1.5480, -1.6342, -2.0459, -0.8085, -1.6272, -1.3944,\n",
       "                       -0.0422,  0.0944, -1.2576, -0.9643, -2.3323, -1.6632, -0.4408, -4.2151,\n",
       "                       -0.7214, -3.8314, -3.0375, -3.1852, -1.7898, -1.1884, -1.2260, -0.9798,\n",
       "                       -0.8704, -1.5440, -2.0155, -3.7809, -1.4316, -1.6286, -1.7880, -2.1835,\n",
       "                       -2.5390, -1.6890, -0.8006, -1.2835, -2.0657, -1.2069,  0.0504, -0.9851,\n",
       "                       -1.0950, -1.2559, -1.2136,  0.0782, -0.0142, -1.4997, -1.9721, -0.9887,\n",
       "                       -0.0341, -2.6381, -0.8432, -2.0177,  0.1261, -1.2545,  0.2667, -0.9491,\n",
       "                       -1.0784, -0.5852, -0.1776, -0.4135, -2.1221, -0.2882, -1.8455, -2.8942,\n",
       "                       -0.9624, -3.3694, -0.2261, -2.3483, -1.1556, -3.1229, -3.4043, -1.8661,\n",
       "                       -0.9774, -0.2521, -0.3119, -1.1778, -0.2141,  1.1403, -4.0696, -0.6843,\n",
       "                       -1.5301, -0.1552, -1.8414, -3.5398, -1.6284, -1.5795, -1.0257, -1.4461,\n",
       "                       -2.8378, -1.7312, -0.3073, -1.7473, -2.1946, -0.2711, -1.2835, -3.8819,\n",
       "                       -0.8909, -0.8816, -1.2846, -0.3286, -1.7060, -0.2362, -0.6233, -1.0983,\n",
       "                        0.6111, -1.3014, -0.2907, -1.0242, -0.1552, -0.6039, -1.5754, -1.1544,\n",
       "                       -1.6371,  0.0546, -1.6025, -1.8234,  0.4519,  0.4576, -2.5947, -0.6447,\n",
       "                       -2.7987, -1.5994,  0.3622, -0.3933, -1.0096, -1.6085, -0.2553, -0.7598,\n",
       "                       -2.1647, -0.4210, -2.2654, -1.6273, -1.4398, -1.8063, -0.9716, -1.7839],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.4.bn1.running_mean',\n",
       "               tensor([-0.4905, -1.8363,  0.2765, -1.8917, -1.1489, -0.6678, -1.9474, -2.5662,\n",
       "                        0.6673, -1.6991, -0.9694, -2.4343,  0.2813, -0.5987, -0.5139,  0.2971,\n",
       "                       -1.1735,  0.8053, -0.4390, -1.5538,  0.5397, -1.0572, -0.9343, -2.4122,\n",
       "                       -0.1205, -1.5292, -1.1437, -1.0553, -0.4998, -1.9979, -1.1449,  0.2241,\n",
       "                       -0.4459, -1.7839, -0.8190, -1.0910,  0.6788, -0.6396, -0.8254, -0.4490,\n",
       "                       -1.3141, -2.1614, -2.6181,  0.3082, -1.3865,  0.1392, -0.5903, -0.4804,\n",
       "                       -2.0876, -0.3795, -2.2690, -1.8580,  0.8116, -0.5988, -0.4440, -1.1177,\n",
       "                       -0.3222, -2.1904, -2.2194,  0.2324, -0.5755, -0.8433, -1.5088, -1.3331,\n",
       "                       -0.6707, -1.7141, -1.3550, -0.1883, -0.6031, -0.5795, -1.9052, -0.5625,\n",
       "                       -1.6412, -1.6872, -1.0842, -2.0920, -0.8214, -0.0894, -0.6148, -0.9896,\n",
       "                       -0.7119, -0.9287, -0.3427, -0.5779, -0.5031, -0.8090,  0.2716, -0.3286,\n",
       "                       -1.3428,  0.1901, -0.4394, -0.9239, -0.1518, -1.8853, -0.6629, -1.6060,\n",
       "                       -0.0223, -2.3813, -1.0448,  0.3328, -1.0384, -0.5873, -1.7506, -0.2744,\n",
       "                       -0.3132, -0.9035, -0.3910, -0.7132, -0.9283, -0.0665, -1.1394,  0.0177,\n",
       "                       -0.7055, -1.2816, -1.1066, -0.9224, -1.2470, -0.7671, -0.1578,  0.0563,\n",
       "                       -0.9807, -0.7648, -1.3875, -2.0493, -0.6084, -0.9040, -2.4887, -1.8383,\n",
       "                        0.0197,  0.0696, -1.2714, -0.7637, -1.6274, -1.3031, -1.1013, -0.8397,\n",
       "                       -0.5871, -1.5377, -1.7349, -1.0203, -0.0424, -0.7227, -1.0381, -1.3131,\n",
       "                       -1.5509, -1.0250, -1.6305, -2.1775, -1.4648, -1.4161, -0.0864, -0.0950,\n",
       "                       -0.4321, -1.7204, -0.4812, -2.5592, -0.2894, -1.6199, -0.6142, -1.2177,\n",
       "                       -2.7458, -1.3789, -1.7453, -1.3232, -0.9762,  0.2880, -0.8997, -2.1386,\n",
       "                       -0.2493, -2.1062, -0.9116, -1.3091, -1.2532, -0.6358,  0.7266, -0.7775,\n",
       "                       -2.7187, -1.3100, -0.6877, -0.9666, -0.9662, -0.9895, -1.6965, -0.7826,\n",
       "                       -1.1788, -1.6105, -0.4646, -1.0883, -0.5317, -2.1664, -1.4840,  0.3606,\n",
       "                       -1.3846, -0.4798,  0.4016, -1.2520, -0.0386,  3.0393, -0.5247, -0.0870,\n",
       "                       -0.0183, -0.6633, -1.4023, -1.1813, -1.5273, -0.8596, -0.5567, -0.9663,\n",
       "                       -1.4412, -0.2979,  0.1554, -0.8303,  0.2071, -1.4424, -1.1619, -0.6216,\n",
       "                       -1.0960, -0.7114,  0.2708, -0.3484, -0.3204, -0.7552, -0.8172,  0.0739,\n",
       "                       -1.8565, -0.5430,  0.4292,  1.2333, -1.2392, -0.1654, -0.9285, -0.8015,\n",
       "                       -1.1460,  0.2939, -0.7072, -1.4049, -1.9853,  0.0814, -0.8020, -0.6281,\n",
       "                       -0.1762, -1.3464, -0.3160, -1.3320,  0.0815, -1.5663,  0.7670,  0.9392,\n",
       "                        0.1949, -1.2156, -1.3624, -1.2919, -1.3173, -1.7792, -0.8335, -2.0544],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.4.bn1.running_var',\n",
       "               tensor([ 4.4590,  3.1540,  2.0835,  1.8159,  2.7028,  2.7710,  1.4223,  1.9180,\n",
       "                        3.5237,  2.5129,  2.6115,  1.9484,  2.7936,  3.6886,  3.6381,  1.7270,\n",
       "                        1.2554,  3.0903,  3.2188,  2.8536, 16.1760,  2.6637,  4.4892,  4.0721,\n",
       "                        2.6969,  1.6952,  2.1606,  2.5372,  3.2149,  1.8608,  2.1289,  3.7868,\n",
       "                        4.3608,  2.2694,  3.1090,  1.7778,  2.6089,  2.6524,  3.8110,  3.0408,\n",
       "                        2.3294,  2.4691,  1.6003,  4.0241,  3.1287,  2.4046,  2.3592,  1.9455,\n",
       "                        1.9424,  2.5047,  1.7539,  1.7931,  4.3365,  3.2805,  3.1408,  4.5251,\n",
       "                        2.7976,  1.1470,  2.1281,  2.3828,  3.5069,  2.2266,  4.0717,  3.1573,\n",
       "                        1.9105,  2.2895,  2.3920,  1.8272,  2.1855,  2.5943,  3.2641,  1.5501,\n",
       "                        2.7609,  2.8211,  1.4953,  3.9454,  2.2135, 11.5614,  3.6410,  3.3729,\n",
       "                        1.4764,  2.9774,  6.0998,  3.3516,  2.6859,  2.2344,  6.5029,  2.8761,\n",
       "                        7.6525,  1.5048,  3.8415,  3.7635,  2.4847,  3.0790,  2.2743,  1.4297,\n",
       "                        3.5465,  3.5697,  2.7654,  5.1794,  2.3482,  4.3899,  3.0893,  3.6282,\n",
       "                        4.1953,  2.3898,  2.1432,  2.9281,  2.2246,  2.7527,  3.7109,  4.4764,\n",
       "                        3.8607,  3.1281,  1.8426,  0.9685,  3.1894,  1.7379,  2.9444,  2.7511,\n",
       "                        3.5263,  2.1335,  1.7777,  2.4637,  2.1506,  2.3158,  4.5768,  2.2170,\n",
       "                        3.2773,  3.1694,  2.9117,  4.1120,  1.8673,  2.5363,  4.2786,  1.6538,\n",
       "                        2.5464,  1.3952,  2.0192,  1.4229,  2.1695,  3.5850,  2.8946,  4.7240,\n",
       "                        2.7246,  2.4143,  1.9650,  1.9012,  3.0485,  2.8416,  1.9213,  2.6073,\n",
       "                        1.1476,  2.4685,  2.6506,  2.7274,  2.0842,  2.1985,  4.3177,  3.2994,\n",
       "                        3.7675,  2.5981,  3.8284,  3.9790,  2.5602,  2.2139,  1.8873,  3.7012,\n",
       "                        4.3183,  1.6257,  2.5363,  3.1088,  4.7145,  2.2093,  5.7717,  2.2404,\n",
       "                        5.4716,  3.2003,  1.7574,  2.8597,  1.7419,  2.8954,  1.8313,  1.7412,\n",
       "                        2.6651,  1.7223,  4.4781,  2.0482,  3.0148,  1.5980,  1.3138,  1.9330,\n",
       "                        2.6260,  3.8003,  3.6389,  3.7987,  3.6161,  3.1594,  0.9603,  3.4777,\n",
       "                        1.9688,  5.1487,  1.7201,  1.9020,  2.3478,  1.8236,  2.9060,  1.5770,\n",
       "                        2.2852,  2.5358,  3.3328,  2.1771,  1.5944,  3.9743,  2.8166,  2.5836,\n",
       "                        3.8368,  3.7285,  1.9535,  2.7687,  1.8198,  4.2647,  3.0536,  2.3808,\n",
       "                        3.7785,  2.6903,  3.6965,  3.1438,  3.6056,  2.4747,  3.3993,  2.8051,\n",
       "                        1.8681,  5.1396,  2.4640,  2.7024,  4.8114,  4.3905,  1.3907,  3.1407,\n",
       "                        4.8713,  3.8322,  3.3754,  3.0578,  2.1779,  2.2511,  4.6752,  3.7168,\n",
       "                        1.9986,  2.6026,  2.0380,  2.1206,  4.0367,  2.6056,  3.6073,  1.7809],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.4.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.4.conv2.weight',\n",
       "               tensor([[[[ 0.0247,  0.0078,  0.0240],\n",
       "                         [-0.0092, -0.0178,  0.0025],\n",
       "                         [-0.0273, -0.0025,  0.0098]],\n",
       "               \n",
       "                        [[-0.0115, -0.0350, -0.0646],\n",
       "                         [-0.0065,  0.0087, -0.0526],\n",
       "                         [-0.0255, -0.0250, -0.0398]],\n",
       "               \n",
       "                        [[ 0.0179,  0.0129,  0.0110],\n",
       "                         [-0.0025, -0.0060,  0.0164],\n",
       "                         [ 0.0012,  0.0124,  0.0252]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0084,  0.0049, -0.0021],\n",
       "                         [ 0.1236,  0.0172, -0.0592],\n",
       "                         [ 0.0317, -0.0104, -0.0242]],\n",
       "               \n",
       "                        [[ 0.0267, -0.0078,  0.0496],\n",
       "                         [ 0.0550,  0.0482,  0.0717],\n",
       "                         [ 0.0528,  0.0152,  0.0344]],\n",
       "               \n",
       "                        [[ 0.0363,  0.0055, -0.0203],\n",
       "                         [ 0.0680, -0.0178, -0.0310],\n",
       "                         [-0.0071, -0.0127, -0.0068]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0078, -0.0149, -0.0058],\n",
       "                         [ 0.0029, -0.0307,  0.0082],\n",
       "                         [-0.0005,  0.0141, -0.0002]],\n",
       "               \n",
       "                        [[-0.0326, -0.0136,  0.0027],\n",
       "                         [-0.0163, -0.0166, -0.0235],\n",
       "                         [-0.0141,  0.0028, -0.0030]],\n",
       "               \n",
       "                        [[-0.0061, -0.0070, -0.0093],\n",
       "                         [ 0.0327, -0.0215,  0.0013],\n",
       "                         [-0.0180,  0.0037, -0.0017]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0181,  0.0135,  0.0406],\n",
       "                         [ 0.0114, -0.0199,  0.0125],\n",
       "                         [ 0.0026, -0.0134,  0.0082]],\n",
       "               \n",
       "                        [[ 0.0072,  0.0167, -0.0293],\n",
       "                         [ 0.0060, -0.0096, -0.0042],\n",
       "                         [-0.0088, -0.0123,  0.0060]],\n",
       "               \n",
       "                        [[-0.0037, -0.0056,  0.0017],\n",
       "                         [ 0.0053,  0.0072, -0.0131],\n",
       "                         [ 0.0117,  0.0135,  0.0104]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0147, -0.0139, -0.0283],\n",
       "                         [ 0.0350,  0.0013, -0.0222],\n",
       "                         [-0.0067, -0.0122, -0.0238]],\n",
       "               \n",
       "                        [[-0.0128, -0.0227, -0.0324],\n",
       "                         [ 0.0049, -0.0142, -0.0258],\n",
       "                         [ 0.0138, -0.0025, -0.0075]],\n",
       "               \n",
       "                        [[ 0.0211,  0.0173, -0.0164],\n",
       "                         [ 0.0037,  0.0035, -0.0173],\n",
       "                         [ 0.0334,  0.0063, -0.0237]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0099,  0.0064,  0.0253],\n",
       "                         [-0.0024, -0.0297, -0.0017],\n",
       "                         [ 0.0019, -0.0105,  0.0194]],\n",
       "               \n",
       "                        [[ 0.0068, -0.0102, -0.0251],\n",
       "                         [ 0.0295, -0.0121, -0.0090],\n",
       "                         [-0.0062, -0.0134,  0.0213]],\n",
       "               \n",
       "                        [[-0.0074,  0.0113,  0.0066],\n",
       "                         [ 0.0013,  0.0243,  0.0149],\n",
       "                         [-0.0014, -0.0121,  0.0100]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0046, -0.0054,  0.0337],\n",
       "                         [-0.0055, -0.0332, -0.0048],\n",
       "                         [ 0.0072, -0.0138, -0.0099]],\n",
       "               \n",
       "                        [[-0.0210,  0.0085,  0.0156],\n",
       "                         [-0.0096,  0.0016, -0.0088],\n",
       "                         [ 0.0233, -0.0069, -0.0392]],\n",
       "               \n",
       "                        [[-0.0171,  0.0022,  0.0273],\n",
       "                         [-0.0130, -0.0166,  0.0015],\n",
       "                         [ 0.0286,  0.0016, -0.0007]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0004,  0.0024,  0.0066],\n",
       "                         [-0.0273, -0.0218,  0.0005],\n",
       "                         [ 0.0009, -0.0048, -0.0166]],\n",
       "               \n",
       "                        [[ 0.0015, -0.0231, -0.0037],\n",
       "                         [-0.0148, -0.0641, -0.0336],\n",
       "                         [ 0.0232, -0.0024,  0.0102]],\n",
       "               \n",
       "                        [[-0.0009, -0.0014,  0.0191],\n",
       "                         [ 0.0132, -0.0060, -0.0150],\n",
       "                         [ 0.0081,  0.0081, -0.0084]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0022, -0.0075, -0.0073],\n",
       "                         [-0.0080, -0.0190,  0.0012],\n",
       "                         [-0.0061, -0.0132, -0.0136]],\n",
       "               \n",
       "                        [[ 0.0151, -0.0216,  0.0198],\n",
       "                         [ 0.0163, -0.0684,  0.0201],\n",
       "                         [ 0.0217, -0.0164,  0.0484]],\n",
       "               \n",
       "                        [[ 0.0194, -0.0079, -0.0244],\n",
       "                         [ 0.0265,  0.0002, -0.0363],\n",
       "                         [ 0.0352,  0.0162, -0.0151]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0112, -0.0106, -0.0146],\n",
       "                         [ 0.0248, -0.0023, -0.0032],\n",
       "                         [ 0.0261,  0.0049, -0.0379]],\n",
       "               \n",
       "                        [[-0.0201, -0.0314,  0.0026],\n",
       "                         [-0.0198, -0.0200,  0.0284],\n",
       "                         [ 0.0103,  0.0171,  0.0077]],\n",
       "               \n",
       "                        [[ 0.0221, -0.0093, -0.0243],\n",
       "                         [ 0.0273, -0.0235,  0.0077],\n",
       "                         [-0.0018,  0.0179,  0.0161]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0013,  0.0111, -0.0054],\n",
       "                         [ 0.0044,  0.0222, -0.0151],\n",
       "                         [-0.0146,  0.0200, -0.0084]],\n",
       "               \n",
       "                        [[-0.0250, -0.0411, -0.0327],\n",
       "                         [-0.0365, -0.0082, -0.0232],\n",
       "                         [-0.0005,  0.0133, -0.0158]],\n",
       "               \n",
       "                        [[ 0.0232,  0.0221, -0.0071],\n",
       "                         [ 0.0210,  0.0119, -0.0369],\n",
       "                         [ 0.0149,  0.0032, -0.0224]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0053, -0.0041,  0.0047],\n",
       "                         [ 0.0270,  0.0007, -0.0029],\n",
       "                         [-0.0186, -0.0238, -0.0205]],\n",
       "               \n",
       "                        [[ 0.0177,  0.0735,  0.1002],\n",
       "                         [ 0.0260,  0.0762,  0.0510],\n",
       "                         [-0.0234, -0.0207,  0.0065]],\n",
       "               \n",
       "                        [[ 0.0131, -0.0159, -0.0244],\n",
       "                         [-0.0201, -0.0332, -0.0079],\n",
       "                         [ 0.0017,  0.0022,  0.0149]]]], device='cuda:0')),\n",
       "              ('module.layer3.4.bn2.weight',\n",
       "               tensor([1.9144, 2.1779, 2.2744, 1.8237, 1.6773, 1.3029, 1.9003, 0.9426, 0.9724,\n",
       "                       1.8496, 1.6188, 1.7687, 1.7671, 1.0774, 1.3519, 1.5676, 1.7447, 1.1621,\n",
       "                       1.4392, 1.8115, 1.8114, 1.6021, 1.3561, 1.7228, 1.6932, 1.4507, 1.2649,\n",
       "                       1.7279, 1.8393, 0.8892, 1.3349, 1.0017, 1.7259, 1.5884, 2.0481, 1.6731,\n",
       "                       0.8208, 1.7723, 1.8154, 2.1898, 1.7590, 1.1023, 1.8234, 1.1900, 1.8297,\n",
       "                       1.8559, 1.1183, 1.6554, 1.6212, 2.0544, 1.6601, 1.2693, 1.6412, 1.5002,\n",
       "                       2.0516, 1.7740, 1.8271, 1.8637, 1.2103, 1.6885, 1.1286, 1.8225, 1.7643,\n",
       "                       1.5172, 1.3602, 2.0981, 1.8818, 2.0733, 1.4310, 2.5685, 2.2269, 2.0031,\n",
       "                       1.6609, 1.6089, 1.7984, 1.7481, 1.7004, 1.4511, 1.4482, 1.4336, 1.7550,\n",
       "                       2.0204, 0.9695, 2.2692, 0.9709, 0.9937, 0.8449, 1.6579, 1.4268, 1.8305,\n",
       "                       1.7406, 1.2444, 1.9176, 2.2052, 1.6875, 1.6646, 1.7477, 1.7109, 1.9153,\n",
       "                       1.2548, 1.7038, 1.8128, 1.5549, 1.3690, 1.6376, 1.6683, 1.0898, 1.7144,\n",
       "                       1.3843, 1.8357, 1.6902, 1.8099, 1.1929, 0.7881, 1.5765, 0.8733, 1.6627,\n",
       "                       1.5984, 0.8518, 1.8988, 1.7178, 1.7941, 0.8250, 1.7337, 1.1557, 1.8920,\n",
       "                       2.0962, 1.8744, 1.4663, 1.3064, 1.7263, 0.8618, 1.3921, 1.5991, 1.2602,\n",
       "                       1.7350, 1.4129, 1.7421, 1.8522, 1.9956, 1.6424, 1.6741, 1.7441, 1.1448,\n",
       "                       1.2019, 1.7895, 2.5245, 1.4847, 1.8288, 1.4781, 1.3283, 1.7524, 1.1496,\n",
       "                       1.6613, 1.9401, 1.8814, 2.0100, 0.9424, 1.8095, 2.1407, 1.8103, 1.5508,\n",
       "                       1.7843, 1.6105, 1.8590, 1.6698, 1.7403, 1.6046, 1.6975, 1.2985, 1.6529,\n",
       "                       1.4499, 1.6934, 1.6726, 1.3764, 1.9627, 1.0034, 1.5923, 2.0343, 1.9545,\n",
       "                       1.8910, 1.6618, 1.3752, 1.9176, 0.9754, 1.2214, 1.8501, 1.5645, 1.1445,\n",
       "                       1.2770, 1.0954, 2.2161, 1.7348, 1.7574, 1.7031, 1.6246, 0.8155, 1.3241,\n",
       "                       0.8425, 1.8633, 1.2812, 1.2498, 1.3285, 1.6662, 1.9510, 1.7159, 1.7402,\n",
       "                       2.0161, 1.9153, 1.6123, 1.4011, 1.7058, 0.8336, 2.0424, 2.2293, 1.5537,\n",
       "                       1.4725, 1.6721, 2.0187, 1.5871, 1.3664, 1.7133, 2.1848, 1.6258, 1.1204,\n",
       "                       2.2112, 1.7676, 1.7797, 1.3208, 2.0380, 1.4662, 1.1528, 1.6762, 1.8750,\n",
       "                       1.6554, 1.7002, 0.8741, 1.6279, 1.6309, 1.9985, 1.5684, 2.1882, 1.5654,\n",
       "                       1.9495, 1.5997, 1.3910, 1.2783, 1.7466, 1.6736, 2.1348, 1.4315, 1.0041,\n",
       "                       1.2205, 1.9629, 0.9803, 1.7405], device='cuda:0')),\n",
       "              ('module.layer3.4.bn2.bias',\n",
       "               tensor([-1.4200, -1.2855, -2.1746, -1.7560, -0.8734, -0.8479, -1.8848,  3.3426,\n",
       "                        0.4003, -1.7067, -1.4029, -1.5000, -1.4767,  0.2240, -0.6284, -0.8399,\n",
       "                       -1.3752,  0.0853, -0.3811, -1.6628, -0.9884, -1.4027, -0.6143, -1.4485,\n",
       "                       -0.6424, -0.6736, -0.2089, -1.4215, -2.1743,  0.8880, -0.3628,  0.5589,\n",
       "                       -0.4821, -0.9705, -2.5871, -2.1660,  1.1660, -1.1998, -2.0513, -1.8586,\n",
       "                       -1.2093,  0.7827, -1.5342, -0.1441, -1.4059, -0.9543,  0.1745, -1.0011,\n",
       "                       -0.8598, -1.6290, -0.6731,  0.6709, -1.0588, -0.7502, -1.6872, -1.7325,\n",
       "                       -2.1487, -2.3736, -1.1380, -1.4718,  0.3134, -2.5187, -0.9045, -0.3427,\n",
       "                       -0.0836, -1.8550, -1.4081, -1.4610, -0.8177, -1.3573, -1.2171, -2.0897,\n",
       "                       -1.0948, -0.9074, -0.7071, -1.0726, -1.1809, -0.5133, -0.2269, -0.4342,\n",
       "                       -1.5282, -1.7949,  1.1248, -2.6943,  2.1861,  0.5276,  1.6929, -1.4234,\n",
       "                       -0.4568, -1.6354, -1.6425,  0.1275, -1.2854, -2.3775, -0.3807, -1.2015,\n",
       "                       -1.3859, -1.0880, -0.4201,  0.0850, -1.0356, -1.5901, -1.1961, -0.4703,\n",
       "                       -0.3770, -1.3777,  0.3007, -1.7581, -0.4061, -1.1017, -1.0513, -1.6995,\n",
       "                       -0.1210,  1.7535, -0.5455,  1.6107, -0.3686, -1.6819,  0.6694, -1.3293,\n",
       "                       -1.3733, -1.3759,  1.9157, -2.2572, -0.0180, -2.4378, -1.6534, -1.7286,\n",
       "                       -0.3694, -0.5866, -1.3075,  0.8393, -0.1171, -1.3064, -0.5672, -1.5710,\n",
       "                       -0.7041, -1.2321, -1.7728, -2.2092, -1.0968, -0.9288, -1.6588,  0.0761,\n",
       "                       -0.3415, -1.9301, -2.1153, -0.6284, -0.8496, -0.8343, -0.2075, -2.1741,\n",
       "                       -0.2371, -1.5817, -1.8120, -1.4313, -1.0896,  2.6320, -1.2192, -1.8388,\n",
       "                       -1.1782, -1.1839, -1.4587, -0.8618, -1.6037, -2.0486, -0.9908, -0.3017,\n",
       "                       -0.9795, -0.3989, -1.5569, -0.2505, -1.3766, -0.9208, -0.2383, -2.3335,\n",
       "                        2.2808, -0.6995, -2.3157, -1.2893, -1.3081, -1.0424, -0.2492, -1.2574,\n",
       "                        1.1036,  0.0261, -1.1877, -0.6420,  0.4111, -0.2988,  0.4797, -2.2715,\n",
       "                       -1.0057, -1.4653, -1.4351, -2.1570,  1.1825, -0.6698,  1.9096, -1.1226,\n",
       "                        2.1023,  0.1218,  0.1248, -1.4877, -2.3891, -1.7693, -1.3627, -1.3160,\n",
       "                       -2.7110, -0.7301, -0.3939, -1.7308,  1.8206, -1.4926, -1.7120, -0.8428,\n",
       "                       -1.0641, -0.7672, -1.8437, -1.3106, -0.7106, -0.7702, -0.6762, -1.8975,\n",
       "                        0.2779, -2.5611, -1.3212, -0.5327, -0.0094, -2.1747, -1.0912,  0.3597,\n",
       "                       -1.4558, -1.5059, -0.8211, -1.6590,  1.2646, -0.7210, -1.3979, -1.5654,\n",
       "                       -1.3706, -1.9958, -0.8583, -2.0504, -0.9311, -0.3128, -0.3891, -1.4578,\n",
       "                       -1.2670, -1.0663, -0.3784,  0.5540, -0.1526, -1.0136,  1.1649, -1.0854],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.4.bn2.running_mean',\n",
       "               tensor([-1.0366, -1.6366, -0.7622, -0.7809, -0.3568, -0.9275, -0.7642, -0.6594,\n",
       "                       -0.0324, -0.9560, -0.8858, -0.8657, -0.9412, -0.4435, -0.9013, -0.8309,\n",
       "                       -0.8140, -0.8435,  0.4182, -0.9377, -1.0467,  2.2881, -0.3420, -0.9246,\n",
       "                       -1.3609, -1.1323, -0.7387, -0.8391, -0.3982, -0.3171, -0.5563, -0.6688,\n",
       "                       -0.2119, -0.6345, -0.6646, -0.9540,  0.5733, -0.9045, -0.7851, -1.0718,\n",
       "                       -0.6792, -0.0177,  2.4773, -0.9869, -0.9813, -0.7980, -0.1714, -0.5710,\n",
       "                       -0.9902, -0.5665, -1.1783,  0.8952, -1.2649, -0.3897, -1.2486, -0.3253,\n",
       "                       -0.8954, -1.3515,  0.0234, -0.7836, -1.7222, -0.9351, -1.0634, -1.4536,\n",
       "                        0.1838, -0.1422, -0.2354, -1.1420,  0.0815, -1.3979, -0.3488, -0.8905,\n",
       "                       -1.1141, -0.7608, -0.5790, -1.1114, -1.1204, -1.5175, -0.6469, -0.8636,\n",
       "                       -0.6593, -0.8428, -1.0701, -1.1387, -2.7087,  0.1333, -0.0690, -1.5402,\n",
       "                       -0.6325, -0.7759, -0.2137, -0.1884, -0.8085, -1.1348, -0.0535, -0.7726,\n",
       "                       -0.9504, -1.1585, -0.2518, -0.2725, -0.5611, -0.8937, -0.3313, -0.5696,\n",
       "                       -1.2773, -0.8136,  0.0403,  0.1098, -0.1212, -0.8370, -1.0630, -0.8227,\n",
       "                       -0.5570, -0.6595, -1.5754, -0.5169,  0.1112, -0.5383, -0.7501, -0.7190,\n",
       "                       -0.5380, -0.9716, -0.4140,  0.2720, -0.2136, -1.1489, -1.0883, -0.8722,\n",
       "                       -0.0777, -0.3785, -1.0261, -0.3419, -0.7773, -0.6242, -0.4117, -0.7950,\n",
       "                       -0.3192, -1.1691, -0.6758, -1.4316, -0.9941, -0.8755, -0.7468, -0.5367,\n",
       "                       -0.7885, -0.5047, -0.7384, -0.3739, -0.1671, -0.4701, -0.8373, -0.1481,\n",
       "                       -0.6137, -0.4877, -1.1918, -0.5886, -1.3337,  1.5383, -0.7087, -0.6169,\n",
       "                       -0.8588, -1.1407, -0.4704, -1.0343, -0.8824, -0.5615,  0.0389,  0.1164,\n",
       "                       -1.0355, -0.8846, -0.4304, -0.8460, -0.7821, -1.1029, -0.8497, -0.6984,\n",
       "                       -1.2254, -0.7697, -1.2240, -1.6950, -0.7726, -0.5920, -0.8684, -0.9227,\n",
       "                        0.3055,  0.5848,  0.8391, -1.1813, -0.3701, -0.6294,  0.5466, -1.2971,\n",
       "                       -0.7459, -1.1811,  0.3809,  0.1568, -0.9107, -0.7682, -0.4469, -1.0193,\n",
       "                       -0.6448,  0.2102,  0.6558, -0.9047, -1.3285, -0.1395, -0.7953, -0.6051,\n",
       "                       -0.8711, -0.7569, -0.8964, -0.7783, -0.7104, -1.0034, -1.6461, -0.0696,\n",
       "                       -0.6667, -1.0950, -1.5225, -0.9540, -0.9611, -1.0509, -0.7387, -0.5481,\n",
       "                       -0.3890, -1.7525, -1.1974, -0.6181,  0.0100, -0.7853, -0.4454,  0.0293,\n",
       "                       -1.6631, -1.2539, -1.1051, -0.6596, -0.6269, -1.1723, -1.0017, -1.1020,\n",
       "                       -1.3193, -0.1144, -0.5135, -1.1226, -0.1417, -0.8722, -0.9806, -0.7468,\n",
       "                       -1.3020,  0.2207, -0.2761, -0.5952, -0.3742, -0.2164,  0.0032, -0.5299],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.4.bn2.running_var',\n",
       "               tensor([1.0053, 5.4274, 0.9952, 1.0377, 0.9870, 0.7416, 1.1430, 1.6867, 1.0819,\n",
       "                       0.8217, 0.9858, 1.1382, 1.1303, 0.9473, 0.7859, 1.6414, 1.1104, 1.2292,\n",
       "                       1.5280, 0.6458, 1.7870, 2.2851, 0.7520, 1.0038, 1.7997, 1.6865, 1.1887,\n",
       "                       0.7475, 0.5823, 0.8774, 1.2980, 1.2234, 2.2592, 0.9702, 0.7344, 0.6082,\n",
       "                       1.0122, 1.0651, 1.0669, 1.2223, 1.0348, 1.8369, 2.3939, 1.0694, 1.4121,\n",
       "                       1.7234, 1.3617, 0.9835, 2.0539, 1.1944, 2.3371, 2.7316, 1.2038, 1.1235,\n",
       "                       1.2608, 0.5593, 0.8227, 0.6422, 0.5262, 0.7948, 1.5110, 0.6134, 1.4146,\n",
       "                       1.3627, 1.2908, 0.9866, 1.0188, 2.0368, 0.6510, 1.9865, 0.8397, 0.9375,\n",
       "                       1.1451, 1.3352, 0.9269, 1.4608, 0.9357, 1.1660, 1.2428, 1.6308, 1.1848,\n",
       "                       0.9571, 1.0713, 0.7511, 1.5791, 1.2565, 1.1273, 0.7802, 1.5719, 0.8638,\n",
       "                       0.8346, 1.3455, 1.2074, 0.9311, 2.3654, 0.9297, 1.1479, 1.0100, 3.7036,\n",
       "                       1.1542, 1.6346, 2.0233, 1.0121, 0.7109, 2.0800, 0.8163, 0.8947, 1.3186,\n",
       "                       0.9639, 1.4563, 1.9828, 0.7815, 1.0322, 0.9504, 1.1421, 1.2265, 2.1323,\n",
       "                       0.6314, 1.0326, 1.1973, 0.9936, 1.0556, 1.0931, 1.1271, 1.1690, 0.8349,\n",
       "                       1.3011, 1.2544, 1.8418, 0.7619, 1.0485, 1.2128, 2.5406, 0.9873, 0.7580,\n",
       "                       0.8713, 0.7541, 1.1085, 1.1899, 1.0002, 0.7874, 1.5770, 0.9617, 1.4533,\n",
       "                       1.1041, 0.6096, 1.1579, 1.1595, 1.2360, 1.0200, 1.1991, 0.6486, 0.9338,\n",
       "                       0.6976, 1.3415, 1.0260, 1.2295, 2.0531, 1.0076, 1.2224, 1.4135, 1.0258,\n",
       "                       0.7378, 1.0507, 0.8210, 0.6543, 1.4542, 2.2011, 1.8327, 0.9002, 0.7364,\n",
       "                       1.2152, 0.8999, 1.8477, 1.4251, 0.7822, 1.2479, 1.9652, 0.8332, 1.4650,\n",
       "                       1.4232, 0.9819, 1.7559, 1.3569, 1.1091, 1.2268, 1.7093, 2.6958, 1.1521,\n",
       "                       1.6460, 1.1683, 1.1151, 1.4695, 1.0487, 0.5304, 0.8350, 0.9676, 0.8504,\n",
       "                       1.0371, 2.2983, 2.1995, 1.1551, 1.8136, 1.1025, 0.9085, 0.6152, 1.0112,\n",
       "                       1.5350, 0.4745, 1.2376, 1.1034, 0.7867, 1.0826, 1.7260, 1.1177, 0.7090,\n",
       "                       0.7572, 2.3239, 1.6749, 0.7207, 1.1200, 1.1172, 3.2122, 0.5565, 1.2730,\n",
       "                       0.8187, 0.9188, 2.2650, 1.1186, 0.9479, 0.7821, 1.0978, 0.7217, 1.3959,\n",
       "                       1.9350, 0.7354, 0.9943, 1.3009, 1.0356, 1.2092, 0.7205, 0.9772, 1.4317,\n",
       "                       1.1832, 0.8990, 1.2377, 1.1572, 1.0631, 0.8547, 2.4668, 1.1129, 1.0079,\n",
       "                       1.1249, 0.7633, 1.1624, 1.3048], device='cuda:0')),\n",
       "              ('module.layer3.4.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.4.conv3.weight',\n",
       "               tensor([[[[ 0.0076]],\n",
       "               \n",
       "                        [[-0.0024]],\n",
       "               \n",
       "                        [[ 0.0074]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0048]],\n",
       "               \n",
       "                        [[-0.0184]],\n",
       "               \n",
       "                        [[-0.0238]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0027]],\n",
       "               \n",
       "                        [[-0.0080]],\n",
       "               \n",
       "                        [[ 0.0073]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0087]],\n",
       "               \n",
       "                        [[ 0.0081]],\n",
       "               \n",
       "                        [[-0.0170]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0049]],\n",
       "               \n",
       "                        [[-0.0188]],\n",
       "               \n",
       "                        [[-0.0106]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0142]],\n",
       "               \n",
       "                        [[-0.0089]],\n",
       "               \n",
       "                        [[-0.0229]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0037]],\n",
       "               \n",
       "                        [[-0.0111]],\n",
       "               \n",
       "                        [[-0.0194]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0065]],\n",
       "               \n",
       "                        [[ 0.0022]],\n",
       "               \n",
       "                        [[ 0.0351]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0012]],\n",
       "               \n",
       "                        [[-0.0290]],\n",
       "               \n",
       "                        [[-0.0056]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0197]],\n",
       "               \n",
       "                        [[ 0.0170]],\n",
       "               \n",
       "                        [[ 0.0074]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0413]],\n",
       "               \n",
       "                        [[ 0.0124]],\n",
       "               \n",
       "                        [[-0.0080]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0146]],\n",
       "               \n",
       "                        [[ 0.0161]],\n",
       "               \n",
       "                        [[ 0.0137]]]], device='cuda:0')),\n",
       "              ('module.layer3.4.bn3.weight',\n",
       "               tensor([0.0778, 0.2106, 0.2031,  ..., 0.6376, 0.2449, 1.3943], device='cuda:0')),\n",
       "              ('module.layer3.4.bn3.bias',\n",
       "               tensor([-0.0043, -0.3595, -0.0468,  ..., -0.7507,  0.5905, -1.9348],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.4.bn3.running_mean',\n",
       "               tensor([-0.0685,  0.1146,  0.2788,  ..., -0.2306, -0.4851,  0.5445],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.4.bn3.running_var',\n",
       "               tensor([0.0169, 0.0351, 0.0438,  ..., 0.0816, 0.1107, 0.1995], device='cuda:0')),\n",
       "              ('module.layer3.4.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.5.conv1.weight',\n",
       "               tensor([[[[-0.0156]],\n",
       "               \n",
       "                        [[-0.0076]],\n",
       "               \n",
       "                        [[-0.0369]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0372]],\n",
       "               \n",
       "                        [[ 0.0251]],\n",
       "               \n",
       "                        [[ 0.0131]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0056]],\n",
       "               \n",
       "                        [[ 0.0143]],\n",
       "               \n",
       "                        [[-0.0002]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0202]],\n",
       "               \n",
       "                        [[ 0.0107]],\n",
       "               \n",
       "                        [[ 0.0212]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0442]],\n",
       "               \n",
       "                        [[-0.0074]],\n",
       "               \n",
       "                        [[-0.0964]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0312]],\n",
       "               \n",
       "                        [[-0.0071]],\n",
       "               \n",
       "                        [[ 0.0551]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0021]],\n",
       "               \n",
       "                        [[-0.0322]],\n",
       "               \n",
       "                        [[-0.0136]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0144]],\n",
       "               \n",
       "                        [[ 0.0024]],\n",
       "               \n",
       "                        [[-0.0886]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0300]],\n",
       "               \n",
       "                        [[ 0.0103]],\n",
       "               \n",
       "                        [[ 0.0178]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0272]],\n",
       "               \n",
       "                        [[-0.0017]],\n",
       "               \n",
       "                        [[-0.0108]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0123]],\n",
       "               \n",
       "                        [[-0.0300]],\n",
       "               \n",
       "                        [[-0.0316]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0201]],\n",
       "               \n",
       "                        [[-0.0645]],\n",
       "               \n",
       "                        [[ 0.0175]]]], device='cuda:0')),\n",
       "              ('module.layer3.5.bn1.weight',\n",
       "               tensor([1.5286, 1.2234, 1.0797, 1.6024, 1.3226, 0.7306, 0.9089, 1.2280, 1.4100,\n",
       "                       2.3228, 2.8964, 1.0963, 1.4831, 0.8768, 1.6318, 2.0070, 1.5365, 1.8284,\n",
       "                       1.9696, 1.3131, 1.6307, 1.0247, 1.4775, 1.5169, 0.9275, 1.2799, 1.1245,\n",
       "                       1.4150, 1.0962, 2.8868, 1.4257, 1.3555, 0.9323, 1.1821, 1.4291, 1.5534,\n",
       "                       1.4182, 1.4179, 2.1922, 1.5200, 2.0916, 1.7293, 1.7529, 0.8084, 2.1776,\n",
       "                       1.6484, 1.6200, 2.2422, 1.4185, 2.1706, 1.7104, 1.4083, 0.8733, 1.1535,\n",
       "                       1.3529, 1.3212, 1.4808, 1.0034, 1.6516, 2.3543, 1.7636, 1.7556, 1.3461,\n",
       "                       1.4143, 1.4971, 1.2728, 0.9534, 1.2581, 1.6129, 1.2389, 0.9352, 0.7549,\n",
       "                       2.3467, 2.3703, 2.0180, 1.5361, 1.0167, 2.2171, 1.8344, 1.0566, 1.0293,\n",
       "                       1.3432, 1.6868, 1.4111, 1.3360, 1.6810, 1.8699, 1.5934, 1.2571, 1.5069,\n",
       "                       1.1116, 1.1312, 1.4175, 2.1891, 1.5226, 1.9045, 1.8353, 0.8451, 1.5425,\n",
       "                       2.0901, 1.6169, 1.2903, 1.5636, 1.5352, 1.2693, 1.9732, 2.1980, 1.3022,\n",
       "                       1.2936, 1.2019, 0.8603, 0.9954, 1.2907, 2.1511, 1.6453, 1.4666, 2.3515,\n",
       "                       1.5915, 1.2063, 1.4433, 1.6676, 0.9046, 2.1370, 1.1882, 1.0980, 1.8102,\n",
       "                       1.7227, 1.3164, 2.2781, 1.2292, 1.7880, 1.0504, 1.9373, 1.3752, 1.8167,\n",
       "                       1.4431, 1.5395, 2.0100, 0.9189, 1.5032, 1.7530, 1.2649, 1.7722, 0.8802,\n",
       "                       1.1275, 1.1642, 1.4054, 1.2337, 2.0874, 1.3834, 1.1335, 1.0109, 1.6406,\n",
       "                       1.3090, 2.7351, 1.1169, 1.1275, 1.3182, 1.5295, 1.5319, 2.5494, 0.9661,\n",
       "                       1.1394, 1.3280, 1.2741, 1.6399, 1.7426, 2.1853, 1.3635, 2.1429, 1.7582,\n",
       "                       1.3647, 1.4443, 2.5781, 1.3731, 1.4655, 1.5181, 1.2413, 1.5548, 2.2149,\n",
       "                       1.2203, 2.9252, 1.1735, 1.7889, 1.4037, 1.8943, 1.3937, 1.1551, 1.5284,\n",
       "                       1.1111, 1.9742, 2.2125, 1.4666, 1.8073, 1.7431, 1.4765, 1.6742, 1.4869,\n",
       "                       1.3245, 1.9216, 1.6132, 1.5704, 1.9510, 1.2981, 1.9857, 1.7096, 1.4019,\n",
       "                       1.4624, 1.6227, 1.4874, 1.1667, 1.6329, 1.6788, 1.9620, 1.6595, 1.2216,\n",
       "                       1.4454, 1.2790, 2.1951, 1.2318, 1.4004, 1.7499, 1.5368, 1.4877, 1.5697,\n",
       "                       1.3349, 1.3218, 1.4999, 0.8532, 1.8136, 1.7133, 1.4081, 1.4968, 1.6901,\n",
       "                       1.6708, 2.7711, 0.9639, 1.8155, 1.2643, 1.2111, 1.6268, 0.7097, 1.2610,\n",
       "                       1.7034, 1.4685, 1.5501, 1.6990, 1.7033, 1.5780, 1.6425, 2.5429, 1.6449,\n",
       "                       1.1687, 1.5707, 1.2307, 2.1455], device='cuda:0')),\n",
       "              ('module.layer3.5.bn1.bias',\n",
       "               tensor([-0.8133, -0.4769, -0.1506, -1.6054, -0.9613,  0.5477, -0.1300, -0.0885,\n",
       "                       -1.6268, -3.3855, -4.6845, -0.3545, -1.5549,  0.7871, -2.1187, -3.2305,\n",
       "                       -1.6021, -2.4148, -1.7663, -1.2043, -1.7507, -0.2048, -1.1604, -1.3914,\n",
       "                        0.1252, -0.9226,  0.0347, -1.1986, -0.5821, -5.2660, -0.7833,  0.1557,\n",
       "                       -0.1077, -0.9580, -1.1438, -1.4261, -0.9023, -1.1212, -3.2740, -1.4831,\n",
       "                       -3.0742, -2.0806, -2.1999,  0.7193, -3.0480, -1.9588, -1.4569, -3.3107,\n",
       "                       -1.4153, -2.4486, -2.3488, -1.1374,  0.2162, -0.1715, -1.0274, -0.9450,\n",
       "                       -1.3961, -0.2125, -1.6849, -3.1564, -1.3717, -1.7902, -0.8941, -1.2283,\n",
       "                       -1.1537, -0.1576,  0.2357, -0.8489, -1.8102, -0.6504,  0.4061,  0.6559,\n",
       "                       -3.3411, -3.8075, -2.7014, -1.5789,  0.0930, -2.4719, -2.6169, -0.2538,\n",
       "                       -0.1972, -0.9269, -2.5253, -1.2899, -0.9763, -1.8816, -2.8789, -1.8410,\n",
       "                       -0.7340, -1.5803, -0.4775, -0.4738, -1.3766, -3.5608, -1.7535, -2.0639,\n",
       "                       -2.2823,  0.7331, -1.2769, -2.5917, -1.4719, -0.5706, -1.4910, -1.7344,\n",
       "                       -0.9277, -2.8455, -3.7659, -1.0220, -1.0385, -0.8632,  0.3971, -0.1657,\n",
       "                       -1.0484, -2.4080, -1.9840, -1.6585, -3.6912, -1.7608, -0.7115, -1.0729,\n",
       "                       -1.8382,  0.1423, -2.8632, -0.2257, -0.2066, -2.5906, -2.2068, -1.0247,\n",
       "                       -2.9637, -0.9105, -1.4426,  0.0940, -2.7973, -1.5859, -2.0664, -1.3304,\n",
       "                       -1.6053, -2.9583, -0.0256, -1.1372, -2.0280, -0.8064, -2.3771,  0.3033,\n",
       "                       -0.5319, -0.6508, -1.0097, -0.3522, -2.6750, -1.0522, -0.6428,  0.0336,\n",
       "                       -1.8255, -0.7952, -4.3817,  0.2338, -0.3559, -1.0610, -2.0768, -1.2439,\n",
       "                       -4.4906,  0.0291, -0.4415, -0.9839, -0.8400, -1.6319, -2.2899, -2.8498,\n",
       "                       -0.9625, -2.5364, -2.3278, -1.0813, -0.7913, -2.5001, -1.0919, -1.5058,\n",
       "                       -0.8754, -0.5760, -1.3927, -2.8891, -0.7615, -5.1573, -0.3176, -2.3210,\n",
       "                       -1.3177, -2.8636, -1.0472, -0.7376, -0.8432, -0.2108, -3.2264, -3.5317,\n",
       "                       -1.4648, -2.3598, -2.3454, -0.9809, -2.5126, -1.2406, -0.7706, -1.6951,\n",
       "                       -1.5908, -1.1799, -2.0565, -1.0929, -2.5127, -1.5859, -1.1331, -1.5175,\n",
       "                       -1.9925, -1.6827, -0.2063, -1.7704, -2.4153, -1.6272, -1.7933, -0.3572,\n",
       "                       -1.0468, -0.5864, -2.9942, -1.0432, -0.8420, -1.5454, -2.0690, -1.7301,\n",
       "                       -1.3375, -0.8058, -0.5181, -1.7309,  0.3258, -2.7105, -2.2020, -0.9956,\n",
       "                       -1.3919, -2.4641, -2.2693, -4.8465,  0.2022, -1.9108, -0.8265, -0.7278,\n",
       "                       -2.0431,  0.6769, -0.9994, -1.8256, -1.0334, -1.6266, -1.8009, -1.8222,\n",
       "                       -1.6284, -2.3105, -3.5754, -1.8836, -0.6151, -1.3998, -0.2776, -2.8544],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.5.bn1.running_mean',\n",
       "               tensor([-0.7064, -1.7190, -0.1989, -1.1735, -0.2527, -0.2010, -0.2406,  0.5751,\n",
       "                       -0.3381, -1.1598, -1.6449, -0.5784, -1.4409,  2.1051, -1.2830, -1.9194,\n",
       "                       -0.9524, -1.9550, -0.4017, -1.0831, -0.3394, -1.3173, -1.4898, -0.4755,\n",
       "                       -1.3999, -0.7150,  0.8566,  0.1505,  2.1764, -2.6591, -0.9994, -0.2938,\n",
       "                        0.3741, -0.8016, -0.4211, -2.0445, -1.0786, -1.0943, -1.5129,  0.0610,\n",
       "                       -1.6623, -0.2225, -1.5088, -2.2125, -1.9333, -0.9514,  0.3931, -1.4592,\n",
       "                       -0.8415, -0.0611, -1.9376,  1.1525,  1.2466, -0.4802, -1.5355, -0.0489,\n",
       "                       -1.3434,  0.0304, -1.2765, -1.0931, -2.1061, -0.5863, -1.6765,  0.7088,\n",
       "                        1.0091,  0.5386,  1.3224, -1.9893, -0.5926,  1.2163, -0.3027, -3.8030,\n",
       "                       -2.0003, -1.7287, -1.5779, -1.5328,  2.1727, -1.3266, -1.3972, -0.2121,\n",
       "                       -0.0263, -1.1930, -1.4927, -0.7106, -1.2503, -1.1694, -0.6811, -1.0143,\n",
       "                       -0.1157, -1.0413,  0.2873, -0.3938, -0.3512, -0.8448, -1.1695, -0.4167,\n",
       "                       -1.1792,  4.0262, -0.9328, -1.6403, -1.0883, -0.8185, -0.4126, -1.2488,\n",
       "                       -0.4474, -0.3705, -2.0579, -1.6170, -1.6664, -1.4293,  0.4785, -0.9599,\n",
       "                       -1.4395, -0.2641, -1.4142, -0.7867, -2.1705, -1.7001, -1.5804, -0.2261,\n",
       "                       -1.6832, -1.2998, -2.4006, -0.4408,  0.2432, -1.9727, -0.7910, -0.1185,\n",
       "                       -0.8299,  0.5096, -0.5225, -1.4299, -0.5024, -0.3222, -0.5851, -0.2168,\n",
       "                       -0.5041, -1.7829,  0.3520, -0.1490, -0.6570,  0.7703, -1.3240, -0.7821,\n",
       "                       -0.1493, -0.3805, -1.8429, -0.3631, -0.5686, -0.3737, -0.5714, -5.1203,\n",
       "                       -0.9027, -2.2711, -1.5968,  0.3753, -1.0441, -1.3653, -0.3583, -0.8201,\n",
       "                       -2.4251, -0.7233, -0.4748, -0.7760, -1.1735, -0.5667, -0.6833, -1.6923,\n",
       "                       -1.0179, -2.1604, -0.9144, -1.7323, -1.4128, -1.3123, -0.8329, -0.5453,\n",
       "                       -0.8770, -1.1039, -0.5872, -1.5988, -0.5912, -2.4414, -1.9037, -0.4954,\n",
       "                       -0.2842, -1.4927, -2.1126, -0.4361, -0.2598,  0.2423, -2.6322, -0.6128,\n",
       "                       -0.3368, -1.6199, -0.9102, -0.8749, -1.7703, -1.8743, -0.9525, -1.2460,\n",
       "                       -1.3192, -0.9892, -1.9671, -0.7770, -1.5921, -0.6251, -1.1471, -1.2191,\n",
       "                       -1.3023, -0.7222,  0.4593, -1.2463, -1.8667, -0.4979, -0.8047, -0.4098,\n",
       "                       -0.4414, -0.2849, -0.4030, -1.3868,  0.6905, -0.8224, -0.0341, -0.7090,\n",
       "                       -0.1815, -1.4247, -0.4915,  0.5057,  1.0220, -1.1353, -0.1521, -1.0935,\n",
       "                       -1.2941, -1.1361, -0.6907, -2.2988,  1.2250, -1.5838,  0.6634, -0.7242,\n",
       "                       -1.3601, -0.6296, -0.4476, -1.1884, -1.1661, -1.7206, -1.2719, -2.3858,\n",
       "                       -1.0921, -1.0195, -0.2528, -1.8307,  0.0978, -0.4761, -0.2761, -1.4688],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.5.bn1.running_var',\n",
       "               tensor([4.2308, 3.3930, 3.7948, 2.4079, 2.4927, 3.5716, 2.3387, 5.2288, 1.6560,\n",
       "                       1.8356, 2.6365, 3.3324, 2.0512, 3.5443, 1.9581, 1.9975, 2.1598, 2.0719,\n",
       "                       1.9198, 2.2591, 2.3558, 3.1339, 2.4545, 2.2691, 3.3395, 2.3562, 5.4083,\n",
       "                       2.2896, 2.5653, 2.7236, 4.5846, 8.3674, 3.5600, 2.4780, 2.5394, 3.0342,\n",
       "                       3.2300, 2.5502, 1.9759, 2.7096, 1.9672, 2.3696, 2.0893, 3.5206, 2.4509,\n",
       "                       2.0497, 1.7853, 2.3584, 2.0751, 2.3163, 1.9227, 2.6498, 2.8730, 5.2044,\n",
       "                       2.3344, 2.0747, 1.8917, 3.0243, 1.9383, 2.9693, 3.4923, 2.3021, 2.9858,\n",
       "                       2.2085, 2.6477, 4.6416, 2.9872, 2.3325, 2.2431, 2.8634, 3.8826, 2.9639,\n",
       "                       2.9716, 1.9710, 1.8335, 1.8105, 3.6229, 2.4500, 1.6956, 2.5901, 3.0603,\n",
       "                       2.6373, 2.1183, 2.3550, 2.5081, 2.1971, 1.9462, 1.8480, 2.6135, 2.1262,\n",
       "                       1.9499, 2.2769, 2.0191, 1.3871, 1.9174, 2.2464, 2.1358, 4.7482, 2.3646,\n",
       "                       2.1851, 3.1381, 3.5273, 2.0275, 2.7469, 1.9136, 2.1860, 2.0176, 2.5981,\n",
       "                       2.4690, 2.6296, 3.0477, 2.8013, 3.1123, 2.4184, 1.8843, 1.9546, 2.4679,\n",
       "                       2.1908, 2.9375, 2.9697, 1.9819, 3.4235, 2.3657, 3.3454, 3.0491, 2.0539,\n",
       "                       1.8605, 2.6039, 1.8996, 2.0962, 2.1541, 4.2858, 1.9494, 1.7207, 1.8891,\n",
       "                       1.9823, 1.9942, 1.6646, 2.4841, 2.8227, 2.4285, 2.3183, 2.5475, 3.9710,\n",
       "                       2.4108, 3.0289, 2.6029, 2.4105, 2.7242, 3.2321, 2.6540, 4.3392, 2.0975,\n",
       "                       3.3452, 2.9902, 6.3352, 2.1336, 2.5463, 1.9912, 3.3780, 2.3275, 3.2569,\n",
       "                       3.5222, 2.6954, 2.6389, 2.1934, 2.1454, 1.8191, 2.9444, 3.2328, 2.0887,\n",
       "                       2.5858, 2.7360, 1.9974, 2.6288, 2.3160, 3.0587, 3.9500, 2.9840, 1.7746,\n",
       "                       2.1652, 2.5686, 5.0865, 1.6372, 2.4503, 1.7431, 4.3844, 2.9725, 2.0968,\n",
       "                       3.6257, 1.8549, 1.4589, 2.1833, 1.7006, 1.9433, 2.4469, 1.9024, 2.6156,\n",
       "                       2.0972, 3.2450, 1.7566, 3.3482, 3.0543, 2.1875, 2.1554, 2.4191, 2.8027,\n",
       "                       1.8394, 2.4582, 1.6129, 2.4643, 2.2356, 1.7550, 3.2455, 2.1483, 4.0564,\n",
       "                       2.2867, 3.6209, 1.7595, 2.6774, 2.6289, 2.3678, 1.9590, 1.8686, 2.5509,\n",
       "                       2.2659, 4.3498, 1.7265, 3.4752, 2.1067, 2.2843, 2.3718, 1.9966, 2.1699,\n",
       "                       2.0742, 2.4663, 3.0211, 2.2556, 2.2624, 3.2166, 1.9968, 3.1022, 1.9658,\n",
       "                       2.0941, 4.0679, 2.3232, 3.4861, 2.4868, 1.8616, 1.8900, 2.4143, 2.5164,\n",
       "                       2.7381, 2.8330, 3.9997, 2.3655], device='cuda:0')),\n",
       "              ('module.layer3.5.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.5.conv2.weight',\n",
       "               tensor([[[[-0.0270, -0.0180, -0.0173],\n",
       "                         [ 0.0044, -0.0388, -0.0130],\n",
       "                         [-0.0127,  0.0107,  0.0088]],\n",
       "               \n",
       "                        [[ 0.0020,  0.0139,  0.0154],\n",
       "                         [-0.0153, -0.0187, -0.0046],\n",
       "                         [-0.0077, -0.0017, -0.0020]],\n",
       "               \n",
       "                        [[ 0.0120,  0.0044,  0.0196],\n",
       "                         [-0.0206, -0.0435, -0.0166],\n",
       "                         [-0.0238, -0.0521, -0.0245]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0024, -0.0136, -0.0065],\n",
       "                         [-0.0125, -0.0061,  0.0052],\n",
       "                         [ 0.0284,  0.0054,  0.0235]],\n",
       "               \n",
       "                        [[ 0.0106,  0.0121, -0.0060],\n",
       "                         [ 0.0210, -0.0243,  0.0102],\n",
       "                         [-0.0425, -0.0378, -0.0083]],\n",
       "               \n",
       "                        [[-0.0131, -0.0122, -0.0233],\n",
       "                         [-0.0035,  0.0505,  0.0029],\n",
       "                         [-0.0060,  0.0034,  0.0067]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0096,  0.0064,  0.0072],\n",
       "                         [-0.0001,  0.0437,  0.0242],\n",
       "                         [-0.0003, -0.0013, -0.0081]],\n",
       "               \n",
       "                        [[-0.0040, -0.0160,  0.0020],\n",
       "                         [ 0.0241, -0.0954, -0.0228],\n",
       "                         [-0.0347, -0.0341, -0.0341]],\n",
       "               \n",
       "                        [[ 0.0290, -0.0222,  0.0325],\n",
       "                         [-0.0095, -0.0123, -0.0182],\n",
       "                         [ 0.0316,  0.0057,  0.0400]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0067,  0.0426, -0.0056],\n",
       "                         [ 0.0328,  0.0917,  0.0277],\n",
       "                         [ 0.0122,  0.0489,  0.0013]],\n",
       "               \n",
       "                        [[-0.0058,  0.0057,  0.0113],\n",
       "                         [-0.0179, -0.0022,  0.0052],\n",
       "                         [-0.0194, -0.0065, -0.0191]],\n",
       "               \n",
       "                        [[ 0.0064, -0.0297, -0.0126],\n",
       "                         [-0.0093, -0.0806,  0.0026],\n",
       "                         [-0.0021, -0.0071,  0.0076]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0064,  0.0047, -0.0034],\n",
       "                         [ 0.0069,  0.0002, -0.0228],\n",
       "                         [ 0.0051, -0.0055, -0.0075]],\n",
       "               \n",
       "                        [[-0.0146, -0.0065, -0.0134],\n",
       "                         [-0.0236,  0.0093, -0.0251],\n",
       "                         [-0.0253, -0.0142, -0.0228]],\n",
       "               \n",
       "                        [[ 0.0001,  0.0027, -0.0089],\n",
       "                         [-0.0007, -0.0309,  0.0023],\n",
       "                         [ 0.0013,  0.0042,  0.0101]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0204, -0.0112, -0.0115],\n",
       "                         [-0.0246, -0.0438, -0.0356],\n",
       "                         [-0.0233, -0.0333, -0.0350]],\n",
       "               \n",
       "                        [[ 0.0507, -0.0120, -0.0520],\n",
       "                         [ 0.0711,  0.0074, -0.0596],\n",
       "                         [ 0.0631,  0.0059, -0.0350]],\n",
       "               \n",
       "                        [[-0.0061,  0.0215,  0.0050],\n",
       "                         [ 0.0145,  0.0447,  0.0200],\n",
       "                         [ 0.0034,  0.0358, -0.0013]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0020, -0.0218,  0.0116],\n",
       "                         [-0.0262, -0.0074, -0.0200],\n",
       "                         [-0.0153,  0.0004, -0.0247]],\n",
       "               \n",
       "                        [[ 0.0175, -0.0035,  0.0101],\n",
       "                         [ 0.0090,  0.0025,  0.0379],\n",
       "                         [ 0.0438,  0.0441,  0.0535]],\n",
       "               \n",
       "                        [[-0.0077,  0.0067, -0.0190],\n",
       "                         [-0.0321, -0.0088, -0.0250],\n",
       "                         [-0.0278, -0.0444, -0.0215]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0029, -0.0126, -0.0093],\n",
       "                         [-0.0327, -0.0189, -0.0424],\n",
       "                         [-0.0166, -0.0216, -0.0275]],\n",
       "               \n",
       "                        [[-0.0110, -0.0109,  0.0027],\n",
       "                         [-0.0082,  0.0037, -0.0086],\n",
       "                         [ 0.0012, -0.0113, -0.0222]],\n",
       "               \n",
       "                        [[-0.0097, -0.0381, -0.0211],\n",
       "                         [-0.0071, -0.0068, -0.0181],\n",
       "                         [ 0.0009, -0.0048,  0.0002]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0157,  0.0146,  0.0132],\n",
       "                         [-0.0115, -0.0120, -0.0127],\n",
       "                         [-0.0197, -0.0414, -0.0102]],\n",
       "               \n",
       "                        [[ 0.0274,  0.0414,  0.0189],\n",
       "                         [-0.0195, -0.0497,  0.0082],\n",
       "                         [ 0.0079, -0.0092, -0.0038]],\n",
       "               \n",
       "                        [[ 0.0070, -0.0144,  0.0009],\n",
       "                         [ 0.0204,  0.0154,  0.0259],\n",
       "                         [ 0.0059, -0.0175, -0.0126]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0048,  0.0056, -0.0056],\n",
       "                         [-0.0052, -0.0184, -0.0103],\n",
       "                         [ 0.0021, -0.0055, -0.0016]],\n",
       "               \n",
       "                        [[-0.0084, -0.0141, -0.0305],\n",
       "                         [ 0.0111,  0.0143,  0.0063],\n",
       "                         [ 0.0235,  0.0299,  0.0074]],\n",
       "               \n",
       "                        [[-0.0007,  0.0173,  0.0052],\n",
       "                         [-0.0100, -0.0098, -0.0033],\n",
       "                         [ 0.0006, -0.0087, -0.0075]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0034, -0.0064,  0.0081],\n",
       "                         [-0.0015, -0.0434, -0.0065],\n",
       "                         [-0.0013, -0.0349, -0.0148]],\n",
       "               \n",
       "                        [[ 0.0275,  0.0076,  0.0006],\n",
       "                         [-0.0090, -0.0377, -0.0226],\n",
       "                         [-0.0089, -0.0299, -0.0037]],\n",
       "               \n",
       "                        [[ 0.0228,  0.0055,  0.0019],\n",
       "                         [ 0.0311, -0.0304,  0.0112],\n",
       "                         [ 0.0407,  0.0309,  0.0125]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0042,  0.0095,  0.0122],\n",
       "                         [-0.0124,  0.0109, -0.0071],\n",
       "                         [-0.0231, -0.0036, -0.0040]],\n",
       "               \n",
       "                        [[-0.0056,  0.0132, -0.0057],\n",
       "                         [ 0.0112,  0.0030,  0.0133],\n",
       "                         [ 0.0096, -0.0018,  0.0039]],\n",
       "               \n",
       "                        [[ 0.0097,  0.0103,  0.0080],\n",
       "                         [ 0.0084,  0.0280, -0.0071],\n",
       "                         [ 0.0052,  0.0159, -0.0066]]]], device='cuda:0')),\n",
       "              ('module.layer3.5.bn2.weight',\n",
       "               tensor([2.1926, 2.6517, 1.8155, 1.0408, 1.5416, 1.4953, 1.3360, 1.6809, 1.4494,\n",
       "                       1.8346, 1.2234, 1.4425, 1.4748, 1.3419, 1.7824, 1.6247, 1.1533, 1.4183,\n",
       "                       1.7412, 1.2051, 1.3364, 1.9158, 2.2568, 1.2704, 1.6891, 2.0397, 1.8963,\n",
       "                       1.5447, 0.8899, 1.3915, 1.3049, 1.1096, 1.9630, 1.7580, 1.8171, 0.8865,\n",
       "                       3.5511, 2.1819, 1.5528, 1.4151, 1.2523, 1.5709, 2.1129, 1.6461, 1.2250,\n",
       "                       1.4668, 1.6466, 1.6713, 0.9285, 1.2811, 1.2456, 1.6241, 1.4107, 1.2724,\n",
       "                       2.2947, 1.2123, 1.1240, 1.6489, 1.4255, 1.5317, 1.5895, 1.3729, 2.3198,\n",
       "                       1.6308, 1.4325, 1.5294, 2.0466, 1.7313, 1.9501, 1.7515, 1.5988, 1.1780,\n",
       "                       1.4156, 1.1499, 1.9016, 1.5518, 0.9722, 1.6148, 1.4128, 1.5257, 1.3879,\n",
       "                       2.2588, 1.6626, 1.6347, 1.7268, 2.1338, 1.8113, 1.5200, 1.7955, 1.3615,\n",
       "                       1.9863, 1.4840, 1.3761, 1.6365, 1.9326, 2.4657, 1.7961, 0.9441, 1.6264,\n",
       "                       1.9025, 1.1105, 1.0706, 2.9515, 1.0267, 1.2159, 1.4147, 2.4122, 1.3457,\n",
       "                       1.7614, 2.1013, 1.2307, 1.7425, 1.6206, 0.9729, 1.6534, 1.1529, 1.9061,\n",
       "                       2.0894, 1.6187, 1.1467, 1.8363, 0.9152, 1.2309, 1.5511, 1.5465, 1.2039,\n",
       "                       1.7108, 0.9487, 1.7400, 1.5529, 1.7271, 1.3443, 1.5424, 0.8928, 1.9193,\n",
       "                       1.5255, 1.8849, 1.9167, 1.6752, 1.3321, 1.7943, 1.4251, 1.9112, 2.3810,\n",
       "                       1.7094, 1.8546, 1.7435, 1.0280, 1.2275, 1.8815, 1.4328, 1.4655, 1.8130,\n",
       "                       1.3538, 1.4465, 1.1045, 1.9584, 2.0712, 1.7763, 1.6377, 1.8839, 1.3622,\n",
       "                       1.9649, 1.8518, 1.7472, 1.6146, 2.0664, 1.9791, 1.2728, 2.0454, 1.5859,\n",
       "                       1.4919, 1.6245, 1.8946, 1.6143, 1.8187, 0.9349, 1.5174, 1.8194, 1.4969,\n",
       "                       0.9716, 1.4913, 1.7736, 1.4758, 1.5393, 1.6248, 0.8539, 1.5971, 2.5242,\n",
       "                       0.8963, 1.2908, 2.0011, 1.4844, 1.8118, 1.9774, 0.9501, 1.5684, 2.1872,\n",
       "                       1.8792, 1.3354, 1.5559, 1.6882, 1.5202, 1.7870, 1.6239, 1.5985, 1.5543,\n",
       "                       1.7701, 1.6251, 1.4273, 1.7916, 1.8312, 1.7275, 1.7642, 1.8465, 1.5552,\n",
       "                       1.3845, 1.3821, 2.0633, 1.8137, 2.0735, 1.9621, 1.6882, 1.1225, 2.0229,\n",
       "                       1.7574, 1.3151, 1.8011, 1.4074, 1.3237, 1.7198, 1.4115, 1.7938, 1.4978,\n",
       "                       1.6732, 1.9324, 1.7593, 1.0515, 1.9694, 1.8842, 1.3688, 1.8526, 1.4609,\n",
       "                       1.9174, 1.5266, 0.9106, 1.7008, 1.9472, 0.8354, 1.6192, 0.9725, 1.5556,\n",
       "                       1.5489, 1.8397, 1.1594, 1.8697], device='cuda:0')),\n",
       "              ('module.layer3.5.bn2.bias',\n",
       "               tensor([-2.0447, -1.8422, -1.1329,  0.2907,  0.1023, -0.2011, -0.5402, -1.9549,\n",
       "                       -0.5339, -1.5940,  0.0625, -0.9324, -0.4783, -0.4005, -1.3076, -0.4531,\n",
       "                        0.0198, -0.7667, -0.8156,  0.0243, -0.2863, -1.2965, -2.2265, -0.3366,\n",
       "                       -1.2899, -1.3164, -1.1407, -0.6743,  1.0398, -0.4798, -0.1183,  0.4548,\n",
       "                       -2.8205, -0.4192, -1.5021,  1.8597, -3.5668, -1.2357, -0.6038, -0.1938,\n",
       "                        0.0493, -0.9374, -2.5299, -1.3334, -0.3172, -0.8568, -0.8487, -1.5344,\n",
       "                        1.5524, -0.3728, -0.0124, -0.5504, -0.4220,  0.0701, -1.2859,  0.3683,\n",
       "                        0.2944, -1.4493, -1.2326, -0.5038, -0.9944, -0.3549, -2.5166, -0.3899,\n",
       "                       -0.1630, -0.2371, -1.2245, -0.6813, -1.6576, -1.6391, -0.8377, -0.1250,\n",
       "                       -0.6456,  0.2166, -1.6389, -1.1080,  0.4057, -0.6651, -0.7441, -1.1678,\n",
       "                       -0.3581, -2.4729, -1.0925, -0.4733, -1.2592, -1.5704, -1.2781, -0.3637,\n",
       "                       -0.6199, -0.6244, -2.3184, -0.6965, -0.2980, -0.6984, -1.0781, -3.0164,\n",
       "                       -1.6347,  0.7098, -0.9802, -2.1747,  0.6552,  0.3860, -1.9287,  2.4487,\n",
       "                        0.3139, -0.5156, -1.8630, -0.3388, -0.9758, -1.3412, -0.0786, -1.2683,\n",
       "                       -0.7691,  1.4745, -1.4539,  0.1382, -1.1742, -2.4263, -1.1429, -0.0214,\n",
       "                       -2.1492,  1.4539, -0.1381, -0.5309, -0.8089,  0.8467, -0.9449,  0.4165,\n",
       "                       -0.9283, -0.3606, -1.3637,  0.2830, -0.3875,  2.3297, -0.5910, -0.9586,\n",
       "                       -1.5464, -2.2354, -1.6074, -0.4775, -2.4068, -0.3996, -1.2806, -1.8252,\n",
       "                       -1.2066, -2.6916, -1.9910,  0.5822,  0.0149, -1.7011, -0.1137, -0.5664,\n",
       "                       -1.6111, -0.3520, -0.3320,  0.2235, -1.5582, -0.8793, -0.9555, -0.8859,\n",
       "                       -1.0780, -0.2792, -1.5453, -1.3158, -1.1728, -1.1194, -1.2685, -2.5667,\n",
       "                        0.0270, -1.3032, -1.0278, -0.3594, -1.1383, -1.7105, -0.9728, -2.5781,\n",
       "                        0.9102, -0.4918, -1.3146, -0.6055,  0.5359, -0.9625, -1.0218, -0.3540,\n",
       "                       -0.8794, -0.4796,  1.9269, -0.7649, -3.0765,  1.1414, -0.3111, -1.2163,\n",
       "                       -0.5250, -1.8804, -1.0508,  2.4256, -0.7944, -0.9103, -1.2395, -0.3060,\n",
       "                       -0.2484, -0.8179, -0.3388, -0.9704, -0.9535, -0.4040, -0.6760, -2.0434,\n",
       "                       -1.1369, -0.5496, -0.8966, -1.5174, -1.0769, -1.7831, -1.3831, -1.4980,\n",
       "                       -0.4047, -0.3586, -1.7927, -1.1253, -2.4087, -1.7489, -1.0158,  2.1601,\n",
       "                       -1.9294, -1.1172,  0.2491, -1.3449, -0.1658, -0.1593, -0.5741, -0.0657,\n",
       "                       -2.7010, -0.8906, -1.2680, -1.5830, -1.7622,  0.1917, -1.1399, -1.3048,\n",
       "                       -0.8475, -1.7747, -0.5245, -1.5709,  0.1407,  1.0829, -0.8334, -1.6207,\n",
       "                        1.7694, -0.7509,  0.5270, -0.7337, -1.0332, -1.9074,  0.8506, -1.6484],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.5.bn2.running_mean',\n",
       "               tensor([-1.1781e+00,  1.8368e-01, -4.8005e-01, -2.2112e-01,  5.9004e-01,\n",
       "                       -9.9244e-01, -4.8836e-01, -1.5796e+00,  1.2083e-01, -2.5759e-01,\n",
       "                       -5.9529e-01, -1.0755e+00, -4.4750e-01, -5.9845e-01,  3.8286e-01,\n",
       "                       -9.7154e-01, -5.6792e-01,  1.8132e-02,  4.0036e-01, -1.0399e+00,\n",
       "                       -6.0516e-01, -3.6239e-02, -9.9974e-01,  1.2774e-01, -6.2280e-01,\n",
       "                       -5.4824e-01,  1.7496e-01, -9.3021e-01, -7.8125e-02, -7.3384e-01,\n",
       "                       -4.4919e-01, -6.7620e-01,  9.2164e-01, -2.4264e-01, -5.2356e-01,\n",
       "                       -1.9096e+00, -1.7023e+00, -1.0692e+00, -5.2968e-01, -1.5551e+00,\n",
       "                       -5.8028e-01, -3.7638e-01,  5.2803e-01, -7.9980e-01, -6.8943e-01,\n",
       "                       -7.5850e-01, -3.6918e-01, -1.3570e+00,  2.0391e+00, -5.0375e-01,\n",
       "                       -5.2189e-01,  5.3843e-01, -9.9439e-01, -4.5966e-01, -5.9056e-01,\n",
       "                       -7.5923e-01, -6.0694e-01,  9.0133e-01, -3.7201e-01, -5.6061e-01,\n",
       "                       -7.2462e-01, -5.9704e-01, -1.1117e-01, -7.9343e-01, -1.0841e+00,\n",
       "                       -4.7401e-01, -8.7351e-01, -6.1942e-01, -7.5398e-01,  7.9013e-01,\n",
       "                       -8.6045e-01, -5.4204e-01, -8.8718e-01, -9.6358e-01, -3.7229e-01,\n",
       "                       -3.9649e-01,  1.9099e-01, -6.6373e-01, -6.2976e-01, -1.4991e+00,\n",
       "                       -9.1050e-01, -1.1272e+00, -5.6029e-01, -1.2127e+00, -3.8507e-01,\n",
       "                       -1.4604e+00, -7.3547e-01, -1.7568e+00, -1.4517e+00, -3.0542e-01,\n",
       "                       -5.4864e-01, -7.2595e-01, -2.7272e-01, -7.7321e-02, -9.5582e-01,\n",
       "                       -4.6649e-01, -3.5418e-01, -5.2773e-01, -5.2492e-01,  2.2839e-02,\n",
       "                       -1.4339e+00, -4.9876e-01, -7.9887e-01,  8.3875e-01, -1.2231e+00,\n",
       "                       -6.9442e-01, -2.8878e-01, -6.3825e-01, -8.2949e-01, -7.1397e-01,\n",
       "                       -9.4972e-01, -1.1208e+00, -9.0364e-01, -2.3829e-02,  4.6591e-01,\n",
       "                       -6.3176e-01, -1.0351e+00, -1.2666e+00,  1.1715e-01, -3.6520e-01,\n",
       "                       -1.1408e+00,  2.8910e-02, -6.9068e-01,  9.6044e-02, -6.5980e-01,\n",
       "                        2.5273e-01, -7.0783e-01, -7.8675e-01,  4.3510e-01, -6.8938e-01,\n",
       "                       -3.6999e-01,  6.1331e-01, -7.5535e-01, -1.6129e+00, -1.2616e+00,\n",
       "                       -1.9053e-01, -6.2978e-01,  6.1742e-01, -5.3699e-01, -5.7108e-01,\n",
       "                       -4.2142e-01, -6.9873e-01, -8.9851e-01, -2.7139e-01, -1.3736e+00,\n",
       "                       -9.8780e-01, -5.1356e-01, -5.2751e-01, -2.2404e-01,  6.5934e-01,\n",
       "                       -9.9703e-01, -6.6211e-01,  5.1546e-01, -4.2612e-01, -3.2353e-01,\n",
       "                       -9.3546e-01, -8.0513e-01, -6.3283e-01, -7.3511e-01, -4.7844e-01,\n",
       "                       -1.0636e+00, -7.6611e-01, -1.6157e+00, -4.1097e-01, -4.5680e-01,\n",
       "                       -4.7535e-01, -1.0096e+00, -1.0906e+00, -3.3240e-01, -3.1313e-01,\n",
       "                       -3.2382e-01, -3.7510e-01, -2.2368e-01, -8.9084e-01, -8.3662e-01,\n",
       "                       -5.1677e-01, -7.9177e-01, -1.0676e+00, -8.0100e-01, -1.0652e+00,\n",
       "                       -5.8501e-01, -4.3891e-01, -5.2916e-01, -1.2796e+00, -8.1488e-02,\n",
       "                       -2.2895e-01,  1.3875e-01, -7.9511e-01, -2.4540e-01,  3.5508e-02,\n",
       "                        4.1401e-02, -1.5200e+00, -1.1681e-01, -1.1083e+00,  9.8167e-01,\n",
       "                        9.4932e-01, -9.7868e-01, -6.5079e-01, -7.8322e-01, -4.5775e-01,\n",
       "                       -8.0816e-04, -1.2920e+00, -6.2671e-01, -6.5029e-01, -6.1073e-01,\n",
       "                       -7.7462e-01, -9.0257e-01, -8.4009e-01, -7.5356e-01, -3.0984e-01,\n",
       "                       -3.2637e+00, -1.2827e-01, -8.0642e-01, -9.4826e-01, -1.0320e+00,\n",
       "                       -1.1327e+00, -8.3116e-01, -7.6261e-01, -8.6471e-01, -6.8612e-01,\n",
       "                        1.3129e+00, -1.1116e-01, -4.1539e-01, -2.1729e+00, -1.1195e+00,\n",
       "                       -1.1190e+00,  4.7779e-01, -7.5272e-01, -8.8564e-01, -9.1617e-01,\n",
       "                       -5.6513e-01, -4.7293e-01, -2.1858e-03, -4.0376e-01, -8.8846e-01,\n",
       "                       -9.7967e-01, -1.0682e+00, -1.1674e-01, -1.0464e+00, -8.9685e-01,\n",
       "                       -4.9245e-01, -8.6348e-01, -4.8580e-01, -7.6550e-01,  8.7310e-01,\n",
       "                        6.6718e-01, -1.3783e-01, -1.7950e+00, -1.3414e+00, -8.3035e-01,\n",
       "                       -6.2915e-01, -4.3208e-01, -7.5960e-01, -1.3014e+00, -3.6031e-02,\n",
       "                        8.4811e-01], device='cuda:0')),\n",
       "              ('module.layer3.5.bn2.running_var',\n",
       "               tensor([0.7837, 1.1458, 1.6355, 1.0868, 1.6382, 1.4830, 1.1175, 0.7407, 1.4537,\n",
       "                       0.8389, 1.3472, 0.7514, 1.2752, 1.3327, 1.2294, 1.2399, 1.1456, 1.0558,\n",
       "                       1.0112, 1.0781, 1.3709, 0.7727, 0.8568, 1.7525, 1.2465, 1.1470, 1.0208,\n",
       "                       1.2934, 1.0289, 1.0436, 1.4409, 1.0382, 1.3486, 1.0082, 0.9438, 1.2633,\n",
       "                       2.4149, 1.1476, 1.3395, 1.5065, 1.2018, 0.8037, 0.8107, 0.9579, 1.0294,\n",
       "                       0.7820, 0.8833, 0.7984, 1.4862, 0.7738, 0.9930, 1.2538, 0.9910, 1.1755,\n",
       "                       1.0908, 1.3523, 1.1858, 1.0197, 0.6820, 1.4478, 0.9318, 1.1715, 1.1690,\n",
       "                       1.4376, 2.2354, 1.8576, 1.1239, 1.4798, 2.2782, 1.1889, 0.9406, 1.2476,\n",
       "                       0.7747, 1.6045, 1.5000, 1.1076, 1.1337, 1.3246, 0.9833, 1.0314, 1.1935,\n",
       "                       0.7621, 0.7513, 1.1303, 1.0459, 1.3930, 0.8423, 1.0331, 1.5959, 1.1809,\n",
       "                       0.9620, 1.0352, 1.1089, 1.3218, 1.0126, 0.7563, 1.1310, 1.2356, 1.2140,\n",
       "                       1.3146, 2.1060, 1.2436, 1.4897, 1.4881, 1.1626, 1.1702, 1.1484, 1.1090,\n",
       "                       0.8979, 1.2414, 1.4415, 1.0760, 1.4303, 1.4111, 1.0608, 1.2845, 1.0699,\n",
       "                       0.8989, 0.8025, 0.9808, 0.8945, 1.1952, 1.2917, 1.2064, 0.9859, 1.9611,\n",
       "                       1.2414, 1.0894, 0.8497, 1.6198, 0.7041, 1.8076, 1.2185, 1.4742, 1.9800,\n",
       "                       0.8829, 0.8143, 1.1072, 0.8967, 0.7709, 0.6106, 1.2014, 1.1556, 1.1225,\n",
       "                       1.2699, 0.7370, 0.9152, 1.3376, 1.4106, 0.8877, 1.8012, 1.0200, 1.5904,\n",
       "                       1.0879, 1.2103, 1.4436, 0.8669, 1.2927, 0.9856, 1.0243, 1.2477, 1.0704,\n",
       "                       1.3263, 0.9656, 0.8220, 0.9277, 1.5178, 0.7336, 1.4204, 1.2295, 1.2146,\n",
       "                       1.1417, 1.1586, 0.8697, 1.3008, 0.5034, 1.1443, 1.4951, 1.0043, 1.1882,\n",
       "                       1.0354, 0.8444, 1.1655, 2.0141, 0.7755, 1.2515, 1.2585, 0.9729, 1.2818,\n",
       "                       1.0887, 1.1914, 0.9284, 1.4378, 1.1521, 1.1943, 1.6361, 1.4315, 1.7038,\n",
       "                       1.5869, 0.8813, 1.3063, 1.2712, 1.3391, 1.2640, 1.0547, 1.2984, 1.6632,\n",
       "                       1.0536, 1.4789, 0.8742, 1.8442, 0.7206, 1.1044, 0.9694, 1.1801, 0.8365,\n",
       "                       1.0037, 1.1566, 0.9033, 1.1858, 1.3088, 1.3289, 0.9387, 2.1802, 0.8546,\n",
       "                       1.5282, 1.6084, 1.0926, 1.4832, 1.3942, 1.3958, 1.7197, 1.6317, 1.0319,\n",
       "                       1.2384, 0.8457, 1.2116, 1.2312, 1.4551, 1.3892, 1.0327, 0.6529, 0.9548,\n",
       "                       1.3744, 1.7728, 1.3812, 1.3527, 0.8494, 1.0990, 1.2956, 0.9247, 1.1868,\n",
       "                       0.7593, 0.8332, 1.2403, 1.5617], device='cuda:0')),\n",
       "              ('module.layer3.5.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer3.5.conv3.weight',\n",
       "               tensor([[[[ 0.0436]],\n",
       "               \n",
       "                        [[-0.0539]],\n",
       "               \n",
       "                        [[ 0.0207]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0024]],\n",
       "               \n",
       "                        [[-0.0234]],\n",
       "               \n",
       "                        [[-0.0097]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0039]],\n",
       "               \n",
       "                        [[ 0.0512]],\n",
       "               \n",
       "                        [[ 0.0046]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0368]],\n",
       "               \n",
       "                        [[ 0.0037]],\n",
       "               \n",
       "                        [[ 0.0365]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0027]],\n",
       "               \n",
       "                        [[-0.0048]],\n",
       "               \n",
       "                        [[ 0.0393]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0560]],\n",
       "               \n",
       "                        [[ 0.0162]],\n",
       "               \n",
       "                        [[ 0.0036]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0034]],\n",
       "               \n",
       "                        [[ 0.0424]],\n",
       "               \n",
       "                        [[-0.0505]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0537]],\n",
       "               \n",
       "                        [[-0.0141]],\n",
       "               \n",
       "                        [[-0.0231]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0046]],\n",
       "               \n",
       "                        [[-0.0348]],\n",
       "               \n",
       "                        [[-0.0205]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0627]],\n",
       "               \n",
       "                        [[-0.0349]],\n",
       "               \n",
       "                        [[-0.0561]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0105]],\n",
       "               \n",
       "                        [[-0.0414]],\n",
       "               \n",
       "                        [[ 0.0069]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0151]],\n",
       "               \n",
       "                        [[ 0.0275]],\n",
       "               \n",
       "                        [[-0.0057]]]], device='cuda:0')),\n",
       "              ('module.layer3.5.bn3.weight',\n",
       "               tensor([0.2539, 0.2332, 0.4970,  ..., 0.8529, 0.4440, 0.8925], device='cuda:0')),\n",
       "              ('module.layer3.5.bn3.bias',\n",
       "               tensor([-0.2881,  0.5176, -0.6999,  ...,  0.1879,  0.2105, -0.7470],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.5.bn3.running_mean',\n",
       "               tensor([ 0.0144,  0.5522,  0.2099,  ..., -0.5653, -0.5665, -0.6931],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer3.5.bn3.running_var',\n",
       "               tensor([0.0917, 0.1490, 0.1503,  ..., 0.2423, 0.3009, 0.1886], device='cuda:0')),\n",
       "              ('module.layer3.5.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.0.conv1.weight',\n",
       "               tensor([[[[-0.0141]],\n",
       "               \n",
       "                        [[-0.0314]],\n",
       "               \n",
       "                        [[-0.0087]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0075]],\n",
       "               \n",
       "                        [[ 0.0370]],\n",
       "               \n",
       "                        [[ 0.0046]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0269]],\n",
       "               \n",
       "                        [[-0.0149]],\n",
       "               \n",
       "                        [[ 0.0371]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0763]],\n",
       "               \n",
       "                        [[ 0.0226]],\n",
       "               \n",
       "                        [[ 0.0157]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0072]],\n",
       "               \n",
       "                        [[ 0.0247]],\n",
       "               \n",
       "                        [[ 0.0661]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0075]],\n",
       "               \n",
       "                        [[-0.0296]],\n",
       "               \n",
       "                        [[-0.0157]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0153]],\n",
       "               \n",
       "                        [[ 0.0015]],\n",
       "               \n",
       "                        [[ 0.0243]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0802]],\n",
       "               \n",
       "                        [[ 0.0631]],\n",
       "               \n",
       "                        [[-0.0015]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0060]],\n",
       "               \n",
       "                        [[ 0.0490]],\n",
       "               \n",
       "                        [[-0.0248]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0149]],\n",
       "               \n",
       "                        [[-0.0228]],\n",
       "               \n",
       "                        [[-0.0062]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0151]],\n",
       "               \n",
       "                        [[-0.0371]],\n",
       "               \n",
       "                        [[-0.0018]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0499]],\n",
       "               \n",
       "                        [[-0.0365]],\n",
       "               \n",
       "                        [[-0.0355]]]], device='cuda:0')),\n",
       "              ('module.layer4.0.bn1.weight',\n",
       "               tensor([2.1782, 2.3229, 2.2135, 1.9732, 2.6623, 2.0507, 1.2803, 1.9218, 2.3355,\n",
       "                       1.5010, 1.9416, 2.5289, 2.0975, 1.8442, 1.1207, 1.9155, 2.2864, 1.7987,\n",
       "                       2.0248, 2.1578, 2.0783, 2.0130, 2.1404, 2.1158, 2.1950, 2.0599, 2.0999,\n",
       "                       2.1499, 2.1730, 1.9845, 2.8708, 2.1502, 1.8240, 1.6811, 2.2586, 2.9559,\n",
       "                       1.6276, 1.8291, 1.9599, 2.2740, 2.0472, 1.0127, 1.8371, 1.7471, 1.8193,\n",
       "                       2.3002, 2.7261, 1.5636, 1.5122, 1.9732, 1.9269, 2.0439, 2.2152, 1.7089,\n",
       "                       2.3576, 1.9863, 1.6119, 2.0321, 1.8002, 2.2338, 2.0865, 2.3880, 1.9277,\n",
       "                       1.8974, 2.4693, 2.0106, 2.4365, 1.8398, 1.7250, 2.5661, 1.7662, 1.7161,\n",
       "                       2.4078, 2.2796, 2.4248, 2.3927, 1.6324, 1.9070, 1.6659, 2.1140, 2.3583,\n",
       "                       1.8369, 1.9308, 2.3378, 2.0041, 2.1494, 2.4705, 1.7851, 1.8540, 2.0622,\n",
       "                       2.0815, 2.1651, 2.0472, 1.9287, 1.9805, 1.9674, 2.1613, 2.0829, 2.0390,\n",
       "                       1.7472, 2.4213, 2.0520, 1.9031, 1.6789, 1.9627, 2.2385, 1.9909, 2.2547,\n",
       "                       2.0587, 1.8627, 1.6745, 2.5682, 1.4448, 1.7576, 2.1213, 2.3372, 2.0590,\n",
       "                       2.0958, 2.2064, 2.2550, 1.8739, 2.1653, 2.4237, 1.7043, 2.3814, 1.9823,\n",
       "                       2.3373, 2.5522, 2.3169, 1.6017, 2.4290, 2.2636, 1.8309, 2.0659, 2.3689,\n",
       "                       2.7943, 2.5259, 2.4658, 2.5464, 1.8955, 2.6470, 2.1927, 1.8365, 1.7676,\n",
       "                       1.7600, 1.9615, 1.9030, 2.2646, 2.6070, 2.0946, 1.9417, 2.3791, 2.4602,\n",
       "                       1.7059, 2.3009, 2.2007, 2.1201, 2.7570, 2.1368, 2.0711, 2.1970, 2.0041,\n",
       "                       1.9679, 0.9408, 2.0700, 2.3764, 2.1994, 2.3445, 1.7665, 1.8698, 2.5100,\n",
       "                       2.1813, 1.9084, 1.6558, 2.0357, 2.1165, 2.5607, 2.2553, 2.2417, 2.4434,\n",
       "                       2.3991, 1.9911, 1.9124, 2.6402, 2.4921, 1.7423, 2.3406, 2.1908, 2.3445,\n",
       "                       2.3938, 2.4624, 2.1023, 2.0670, 2.0935, 1.9948, 2.4327, 2.2425, 2.2077,\n",
       "                       2.2664, 2.0794, 0.8090, 2.2358, 2.4195, 2.5778, 2.3807, 2.3563, 1.7072,\n",
       "                       2.1249, 1.5588, 2.3338, 2.1752, 1.5789, 2.0360, 1.8972, 2.1835, 2.2218,\n",
       "                       2.1119, 2.1271, 2.5304, 2.0400, 2.1962, 2.4877, 2.2261, 1.5685, 2.3918,\n",
       "                       1.7692, 2.4686, 2.0084, 2.2482, 2.1088, 2.1343, 2.0821, 2.3885, 2.2425,\n",
       "                       2.3343, 2.1552, 2.3608, 2.0307, 2.2922, 1.9988, 2.2303, 2.4331, 2.3087,\n",
       "                       2.4756, 1.6693, 2.7658, 0.9794, 2.0289, 2.3763, 2.2999, 2.6998, 2.4150,\n",
       "                       2.1582, 2.8873, 2.1593, 1.9417, 2.0881, 2.3907, 2.4643, 1.7457, 2.1990,\n",
       "                       1.9802, 2.2184, 2.1774, 2.0388, 2.0190, 1.0389, 2.5289, 2.0689, 1.6968,\n",
       "                       1.9292, 2.0538, 1.1816, 2.1198, 1.7779, 1.8811, 2.0455, 2.1277, 1.4345,\n",
       "                       2.3512, 1.9760, 2.3431, 2.3584, 0.9803, 2.4028, 2.1692, 1.9608, 1.9237,\n",
       "                       1.4887, 2.0468, 2.2438, 2.0552, 1.8521, 1.8824, 1.6132, 2.0640, 2.2291,\n",
       "                       1.9797, 1.1971, 2.0020, 1.8266, 1.9007, 2.4079, 2.4688, 2.0846, 2.2735,\n",
       "                       2.1823, 2.0443, 2.6925, 2.3711, 1.9474, 2.2494, 1.7406, 1.7139, 2.4616,\n",
       "                       1.6909, 2.1336, 2.4359, 1.2212, 2.2396, 2.3072, 2.4351, 2.4028, 1.9435,\n",
       "                       2.0034, 1.7131, 2.3662, 2.2720, 2.0954, 1.9718, 1.9428, 2.2941, 1.9676,\n",
       "                       2.0087, 2.0079, 1.8324, 1.2575, 1.3777, 2.1317, 2.1734, 1.9254, 1.9591,\n",
       "                       2.5569, 2.4291, 2.0496, 2.4113, 2.0236, 2.2560, 2.4156, 2.2601, 2.1152,\n",
       "                       1.8133, 1.6820, 1.8551, 2.4742, 2.8234, 2.3517, 1.7450, 1.8958, 1.9582,\n",
       "                       1.7625, 2.0470, 2.8771, 2.5107, 2.2200, 2.1175, 2.0639, 2.1443, 2.2355,\n",
       "                       2.9272, 2.3072, 2.3268, 2.2525, 2.2453, 2.3684, 1.9119, 1.8305, 2.3061,\n",
       "                       2.3897, 1.8632, 2.0541, 1.9572, 2.6929, 1.9420, 2.3559, 2.6528, 1.9263,\n",
       "                       2.0037, 1.7037, 2.1902, 2.0781, 2.0266, 1.9730, 2.1019, 2.4083, 2.0994,\n",
       "                       2.4353, 1.8408, 1.9104, 2.1643, 1.8703, 2.0901, 2.0343, 2.0746, 2.0278,\n",
       "                       2.2500, 2.3079, 1.9465, 1.8195, 2.3885, 1.9544, 2.1371, 2.2840, 2.2687,\n",
       "                       2.0909, 2.5435, 2.1855, 2.1121, 2.1551, 2.0643, 1.7984, 2.4631, 2.8421,\n",
       "                       1.7291, 2.3847, 1.7656, 2.2790, 1.8133, 2.3648, 2.2758, 2.0436, 2.1211,\n",
       "                       2.3046, 2.2696, 1.9484, 2.0698, 2.0837, 2.3503, 2.3873, 1.6603, 1.6921,\n",
       "                       1.8536, 1.9545, 2.3767, 2.1616, 2.5863, 1.8644, 2.1456, 2.1945, 2.2320,\n",
       "                       2.2181, 1.7788, 2.0202, 2.4096, 2.3629, 2.1234, 1.1344, 1.3864, 2.4498,\n",
       "                       2.4649, 1.2390, 1.6671, 2.4912, 2.0459, 0.9947, 2.4160, 2.4726, 1.7951,\n",
       "                       1.8668, 2.4181, 1.8965, 2.3237, 1.9551, 1.9365, 2.2511, 1.7900, 2.6946,\n",
       "                       2.0940, 2.0727, 1.7854, 2.1268, 1.5748, 2.2485, 2.1244, 2.0901, 1.9417,\n",
       "                       1.9163, 2.5257, 2.5907, 2.1540, 2.2609, 1.9057, 1.9314, 2.2589, 2.0544,\n",
       "                       2.1428, 2.1619, 1.8643, 2.3332, 2.0379, 2.0442, 2.4409, 2.2876, 2.6130,\n",
       "                       2.9460, 2.0180, 2.4125, 2.0564, 1.7659, 2.3155, 2.2068, 2.0987],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn1.bias',\n",
       "               tensor([-2.4971, -2.8635, -2.4072, -2.0503, -4.3509, -2.7737, -0.3985, -1.7467,\n",
       "                       -3.0063, -1.0447, -1.8629, -3.5590, -3.0553, -1.5589,  0.4348, -1.7389,\n",
       "                       -2.3537, -1.6918, -1.7258, -2.4533, -2.5340, -1.8282, -2.3614, -2.6679,\n",
       "                       -3.0717, -2.1702, -2.7882, -2.4791, -2.6164, -1.5914, -4.3572, -2.4137,\n",
       "                       -1.3119, -1.0572, -3.2794, -4.8660, -1.1593, -1.8453, -1.6403, -2.2534,\n",
       "                       -1.8707,  0.4617, -1.3055, -1.4691, -1.4686, -2.9065, -3.5387, -0.1810,\n",
       "                       -0.9465, -2.4365, -1.7442, -2.1373, -2.6533, -1.1952, -3.1929, -1.8754,\n",
       "                       -0.9767, -1.8890, -1.4530, -2.9181, -2.3138, -2.8964, -1.9706, -1.6627,\n",
       "                       -3.3640, -2.0978, -3.3809, -1.9216, -1.2818, -3.5232, -1.6287, -1.2928,\n",
       "                       -2.6797, -2.5775, -3.8852, -3.4780, -1.1084, -1.9265, -1.3136, -2.4461,\n",
       "                       -2.6949, -1.5458, -1.5817, -2.4816, -1.9090, -2.4150, -4.1221, -1.4602,\n",
       "                       -1.8972, -1.9227, -1.9049, -2.7754, -1.7719, -1.8572, -1.7849, -2.0145,\n",
       "                       -2.6022, -2.7475, -2.3510, -1.6251, -3.0587, -1.7957, -1.7832, -1.4227,\n",
       "                       -1.9237, -2.2038, -2.1549, -3.1893, -2.4299, -1.5647, -1.1848, -4.2703,\n",
       "                       -0.7632, -1.2634, -2.3575, -2.9497, -2.2004, -2.3029, -2.5760, -2.4733,\n",
       "                       -1.8441, -3.0638, -3.0311, -1.0683, -2.7448, -1.8240, -2.8423, -3.9212,\n",
       "                       -2.7670, -1.2378, -3.8256, -2.3399, -1.6733, -2.2437, -2.9932, -4.5392,\n",
       "                       -2.7250, -3.3060, -3.2046, -1.7751, -3.9574, -2.5628, -1.7964, -1.5685,\n",
       "                       -1.0935, -1.8077, -1.3745, -2.6134, -3.7371, -2.4578, -2.4009, -3.6041,\n",
       "                       -3.1923, -1.2585, -3.1059, -2.4793, -2.1266, -4.6993, -2.4369, -2.0966,\n",
       "                       -2.7019, -2.2122, -2.2455,  0.1079, -2.5029, -3.4124, -2.4669, -3.3783,\n",
       "                       -1.3554, -1.6776, -2.9585, -2.1194, -2.1816, -1.1417, -2.1048, -2.8205,\n",
       "                       -3.3067, -2.0410, -2.2235, -3.1626, -2.8042, -2.0495, -1.9143, -4.1372,\n",
       "                       -3.5022, -1.6497, -3.2483, -1.6847, -2.8289, -3.2571, -2.9943, -2.4969,\n",
       "                       -1.9978, -2.6200, -1.6879, -3.5049, -2.5800, -2.7513, -2.4958, -2.6364,\n",
       "                        0.7286, -2.4105, -3.8887, -3.0626, -2.4947, -2.7521, -1.5230, -2.3507,\n",
       "                       -1.0019, -2.6624, -2.2017, -1.2401, -1.8509, -1.6453, -2.5729, -3.0558,\n",
       "                       -1.9271, -2.1750, -3.4144, -1.7243, -2.0545, -3.9876, -2.7517, -0.7709,\n",
       "                       -3.6178, -1.6215, -3.0382, -1.8252, -2.3920, -2.0642, -2.3517, -2.0001,\n",
       "                       -2.2711, -2.0694, -2.6301, -2.6109, -2.9558, -2.2598, -2.6241, -2.3800,\n",
       "                       -2.8394, -3.6651, -2.9285, -2.8835, -1.3069, -3.9490,  1.0522, -2.3179,\n",
       "                       -2.5762, -2.4634, -4.0275, -2.8989, -2.8185, -5.3022, -2.1566, -1.8942,\n",
       "                       -2.3483, -3.4518, -3.8815, -1.3177, -3.1609, -1.6470, -3.0963, -3.2263,\n",
       "                       -2.3024, -1.6564,  0.4920, -3.2751, -2.0842, -1.0650, -1.6543, -1.9747,\n",
       "                        0.1694, -2.9670, -1.2311, -2.2477, -2.2892, -2.2339, -0.8563, -3.1889,\n",
       "                       -2.1749, -4.0271, -2.7697,  0.5749, -2.9154, -3.0562, -1.9693, -1.9159,\n",
       "                       -0.6331, -2.3231, -2.6866, -2.0042, -1.6337, -2.1477, -1.0521, -2.2271,\n",
       "                       -2.9990, -1.5798, -0.1896, -2.0372, -1.3849, -1.9066, -3.3459, -3.9070,\n",
       "                       -2.6984, -2.6923, -3.0327, -1.8902, -3.6561, -2.7329, -1.8366, -2.4036,\n",
       "                       -1.4335, -1.4313, -2.8319, -1.4909, -2.6708, -2.6477,  0.1861, -2.9564,\n",
       "                       -3.0134, -3.1381, -3.4440, -2.1870, -2.0499, -1.4484, -2.8197, -2.9721,\n",
       "                       -2.7412, -1.8054, -2.2299, -3.0830, -1.9981, -2.2948, -2.2193, -1.3239,\n",
       "                        0.3703, -0.6948, -2.7559, -2.7896, -1.7882, -1.8479, -3.8170, -3.0718,\n",
       "                       -2.4942, -3.6299, -2.2417, -2.7986, -2.7021, -2.8584, -2.6034, -1.3859,\n",
       "                       -1.0608, -1.5864, -3.8534, -4.0570, -3.3303, -1.3504, -1.7477, -1.9063,\n",
       "                       -1.1021, -2.0739, -4.7107, -4.0863, -2.7806, -2.2161, -2.4208, -2.6606,\n",
       "                       -3.1872, -4.3138, -3.0043, -2.6857, -2.7848, -3.0937, -2.4026, -2.0397,\n",
       "                       -1.5789, -2.7377, -3.0116, -1.6043, -2.2365, -1.8350, -4.2034, -2.1896,\n",
       "                       -2.7710, -4.2792, -1.7502, -1.9576, -1.4563, -2.9002, -2.1473, -2.0457,\n",
       "                       -2.1513, -2.3101, -3.8983, -2.2578, -3.3552, -1.7400, -2.1051, -2.2754,\n",
       "                       -1.1650, -2.4900, -2.5765, -2.4014, -1.9577, -2.5393, -3.0585, -1.8054,\n",
       "                       -1.4580, -3.2092, -1.8233, -2.1076, -2.8627, -2.7441, -2.1298, -4.0557,\n",
       "                       -2.2407, -2.3247, -1.6623, -1.9309, -1.6153, -2.9539, -4.2312, -1.3831,\n",
       "                       -2.9587, -1.6056, -3.1796, -1.7510, -3.0171, -2.9971, -2.1751, -2.1970,\n",
       "                       -2.6692, -2.5923, -1.5530, -2.1955, -2.0620, -2.9354, -2.8248, -1.3091,\n",
       "                       -1.2694, -1.4593, -2.2204, -2.7216, -1.8682, -3.5114, -1.5841, -2.3479,\n",
       "                       -2.3240, -2.7165, -2.9217, -1.3568, -2.1226, -3.2144, -2.9656, -2.1247,\n",
       "                        0.0293, -0.4563, -2.3572, -2.8532, -0.3482, -1.2198, -3.9638, -1.8879,\n",
       "                        0.2999, -3.7249, -3.3889, -1.2284, -1.8378, -3.9299, -1.7395, -2.7731,\n",
       "                       -1.8776, -1.6493, -2.3141, -1.4026, -3.1457, -2.5019, -2.2258, -1.5063,\n",
       "                       -2.1619, -0.7665, -2.4952, -2.7604, -2.6642, -1.4982, -1.7825, -3.3428,\n",
       "                       -4.5128, -2.7524, -2.5862, -1.4201, -1.5971, -2.3537, -1.9084, -2.2817,\n",
       "                       -2.5262, -1.4762, -2.7715, -1.8489, -2.3885, -2.3501, -2.4306, -2.9854,\n",
       "                       -4.5074, -2.0086, -3.2267, -2.2503, -1.7069, -2.9166, -1.9866, -2.0568],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn1.running_mean',\n",
       "               tensor([-1.6631, -1.4853, -1.7729, -1.0292, -1.1010, -0.8067, -1.1972, -0.4782,\n",
       "                       -2.1127, -1.6717, -1.5471, -1.9813, -2.2689, -3.0290,  0.7542, -0.4705,\n",
       "                       -2.4745, -1.8628, -1.0128, -1.3507, -1.5917, -2.1931, -1.5441, -0.1452,\n",
       "                       -0.9162, -0.6210, -1.4706, -1.3629, -1.8214, -1.1669, -1.1598, -2.2450,\n",
       "                       -1.3140, -1.3481, -1.0219, -1.0034, -1.1555, -0.6503, -1.7304, -1.1963,\n",
       "                       -0.3419,  0.4244, -0.4867, -0.1427, -1.2356, -0.9755, -2.8586,  0.7717,\n",
       "                       -0.0960, -0.6632, -1.8031, -1.3335, -1.2916, -2.1183, -1.7055, -1.0311,\n",
       "                       -0.7764, -0.7713, -0.1342, -1.3787, -2.0474, -2.3499, -1.2831, -2.1317,\n",
       "                       -1.6703, -0.8842, -2.0785, -1.4440, -1.6407, -0.9617, -0.5147, -0.5729,\n",
       "                       -1.3118, -1.9576, -1.3673, -0.9839, -1.8008, -1.4876, -0.2363, -1.1048,\n",
       "                       -1.4388, -2.4789, -1.6662, -1.4092, -1.8183, -0.8549,  0.0164, -1.8170,\n",
       "                       -0.4519, -1.1179, -1.0770, -1.7502, -1.5507, -1.2159, -1.1776, -1.9394,\n",
       "                       -0.9928, -1.3844, -0.4865, -1.7022, -1.8097, -0.8151, -1.0723, -0.9859,\n",
       "                       -1.8719, -2.4476, -1.4797, -2.2312, -1.1597, -1.0702, -1.5133, -1.7699,\n",
       "                       -0.9439, -2.7628, -0.2835, -1.3467, -1.0350, -1.8259, -0.4160, -1.6457,\n",
       "                       -2.2392, -0.7410, -1.8084, -1.0920, -0.7904, -0.4258, -1.4508, -2.0383,\n",
       "                       -0.9052, -1.4178, -0.7260, -1.2054, -2.1848, -0.0857, -2.4972, -1.1246,\n",
       "                       -1.8944, -2.4369, -1.3376, -1.7408, -1.2208, -1.3194, -0.4440, -1.8302,\n",
       "                       -1.6591, -1.5184, -0.5648, -0.9022, -2.0733, -1.3201, -0.8611, -1.4923,\n",
       "                       -1.5211, -2.1229, -0.7802, -1.9456, -0.7073, -1.6226, -1.4358, -1.8272,\n",
       "                        0.0513, -2.0481, -1.4003, -0.5806, -1.2971, -1.9263, -2.0786, -0.6382,\n",
       "                       -1.4091, -0.3153, -1.7300, -2.7075, -0.8970, -1.0419, -1.8675, -1.9877,\n",
       "                       -1.9020, -0.3983, -0.7082, -1.6227, -1.7235, -1.8474, -0.8617, -1.2938,\n",
       "                       -1.1420, -0.2388, -1.8550, -0.2505, -1.2394, -1.0813, -1.6008, -1.4564,\n",
       "                       -1.1589, -1.3625,  0.1252, -1.3366, -1.9547, -2.3233, -2.5257, -1.5715,\n",
       "                       -0.8976, -1.5829, -1.7611, -1.4072, -1.1941, -1.3678, -1.3371, -1.8101,\n",
       "                       -0.1938, -1.0448, -1.7535, -1.2296, -0.9513, -1.2660, -1.3994, -1.5606,\n",
       "                       -1.2025, -1.8805, -0.7724, -2.1492, -1.8099, -1.3574, -1.5660, -1.8521,\n",
       "                       -1.9252, -1.4442, -2.3740, -2.3073, -1.7517, -2.1725, -1.4278, -1.0803,\n",
       "                       -1.0596, -2.2255, -2.2702, -1.1647, -2.0813, -1.1771, -1.8189, -1.3834,\n",
       "                       -1.1917, -1.1255, -1.0818, -2.4952, -1.6831, -2.4764,  3.3332, -2.1988,\n",
       "                       -1.6329, -0.5920, -1.4638, -2.8574, -1.6865, -1.9270, -1.8901, -1.3489,\n",
       "                       -1.1435, -1.7582, -1.7893, -2.1108, -1.2572, -1.4864, -1.9349, -0.8838,\n",
       "                       -1.6477, -1.0730,  1.1549, -1.8104, -2.1253, -0.8371, -1.8842, -1.2442,\n",
       "                        0.3212, -1.7039, -2.4182, -0.2800, -1.1939, -1.3882, -0.1730, -1.4277,\n",
       "                       -1.8307, -0.8210, -1.8338, -0.0724, -1.7208, -2.0010, -1.9813, -0.6134,\n",
       "                       -1.6796, -2.3451, -0.6656, -1.6926, -2.0003, -0.7765, -0.9282, -1.3342,\n",
       "                       -1.2686, -1.3373,  0.2948, -1.7693, -2.4459, -1.1507, -1.6179, -0.7867,\n",
       "                       -1.2766, -0.4889, -1.2247, -2.5632, -2.7573, -1.9114, -1.5727, -1.2442,\n",
       "                       -1.9347, -0.4486, -1.9276, -1.0387, -1.6473, -1.2340,  0.1821, -1.5923,\n",
       "                       -1.5773, -1.4717, -1.1917, -1.5332, -1.2473, -1.1211, -1.4081, -1.2462,\n",
       "                       -1.8674, -1.2965, -1.3368, -1.5764, -1.3067, -1.0304, -1.9943, -1.4460,\n",
       "                       -2.0005, -0.8941, -1.7837, -0.2423, -1.8923, -1.0033, -1.3624, -1.2702,\n",
       "                       -1.5198, -2.3374, -1.1717, -2.3117, -1.5339, -1.4800, -1.5203, -0.7966,\n",
       "                        0.4571, -1.4059, -0.2543, -2.1312, -1.7912, -0.9669, -1.6310, -1.1644,\n",
       "                       -0.9780, -2.3759, -2.2671, -0.9872, -1.5026, -1.5312, -0.7051, -1.2048,\n",
       "                       -1.5866, -0.9616, -0.3670, -0.3847, -1.3970, -1.8749, -2.1736, -1.8129,\n",
       "                       -0.5818, -2.0916, -1.0489, -0.6355, -1.3166, -1.3705, -1.8931, -0.4476,\n",
       "                       -0.7212, -1.2280, -2.3898, -2.2082, -0.8790, -0.5025, -1.2665, -0.9148,\n",
       "                       -1.4389, -0.5127, -1.2171, -2.2310, -1.6289, -0.6515, -1.0023, -0.7030,\n",
       "                       -1.7446, -1.1146, -1.7957, -2.9829, -1.8463, -2.8665, -2.2443, -3.2723,\n",
       "                       -2.0492, -1.1663, -0.9369, -1.2468, -2.5050, -1.2653, -2.4354, -1.3226,\n",
       "                       -2.1417, -0.4213, -0.7625, -1.3486, -0.8428, -1.8378, -2.2740, -0.3678,\n",
       "                       -1.1595, -0.6595, -1.8954, -0.7767, -2.0504, -1.4941, -2.4092, -2.4924,\n",
       "                       -2.7182, -1.2864, -0.9268, -0.2032, -0.8941, -2.0492, -2.1069, -1.3254,\n",
       "                       -0.8764, -1.8145, -1.0545, -2.2719, -1.1847, -1.5355, -1.9639, -1.1595,\n",
       "                       -1.8915, -2.1539, -0.8074, -1.3173, -1.2724, -2.9316, -1.1817, -1.5426,\n",
       "                        0.7156, -0.5476, -1.5411, -0.2314, -0.7763, -1.7171, -1.8833, -1.6279,\n",
       "                        1.8412, -1.8473, -0.6008, -2.1114, -0.8807, -2.9465, -1.3127, -1.6454,\n",
       "                       -0.9966, -1.3050, -2.3204, -1.7379, -1.0088, -1.0804, -1.1969, -1.9800,\n",
       "                       -2.6718, -2.1264, -2.3200, -1.7121, -0.9360,  0.6999, -1.5140, -1.4153,\n",
       "                       -1.5443, -0.6848, -1.3811, -0.3214, -0.0338, -1.3161, -0.7657, -1.4245,\n",
       "                       -1.3569, -0.8527, -1.3708, -0.9856, -1.7627, -1.1959, -1.2136, -0.9735,\n",
       "                       -1.8812, -1.9368, -1.5025, -1.6753, -2.2389, -0.6484, -1.2744, -1.5977],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn1.running_var',\n",
       "               tensor([2.0813, 1.9745, 3.6097, 2.2725, 1.9129, 1.9327, 3.4544, 2.8752, 1.8956,\n",
       "                       3.0320, 2.5146, 2.1457, 1.9675, 2.6418, 5.3718, 2.5901, 2.5236, 2.6626,\n",
       "                       4.0354, 2.1935, 2.3295, 4.1316, 2.3829, 1.8659, 1.8653, 2.1880, 2.1589,\n",
       "                       2.2381, 2.2108, 2.5993, 2.1463, 2.6167, 2.5497, 2.3194, 2.2504, 1.9648,\n",
       "                       2.5018, 2.2817, 2.4745, 2.6848, 2.9227, 3.3520, 3.1663, 3.1115, 3.7614,\n",
       "                       2.7196, 3.3943, 5.1053, 2.6565, 1.9848, 2.3150, 2.6853, 2.0493, 2.6909,\n",
       "                       1.9268, 2.1250, 2.3162, 3.2603, 2.1899, 2.3383, 1.8878, 2.4703, 2.4888,\n",
       "                       2.9962, 2.3391, 2.6974, 2.1037, 2.2310, 2.6588, 2.4641, 2.1883, 2.2682,\n",
       "                       2.6875, 2.4240, 1.9999, 1.9541, 2.6025, 2.2575, 2.3150, 1.7305, 3.6527,\n",
       "                       3.3334, 3.4116, 3.4111, 2.6193, 1.8976, 1.9009, 3.0255, 3.1716, 3.1745,\n",
       "                       2.6063, 2.4099, 4.0149, 2.5633, 2.5945, 2.0766, 2.7231, 2.0149, 2.0687,\n",
       "                       2.3204, 2.1020, 2.7852, 3.0571, 2.6050, 2.7429, 3.6581, 2.2340, 2.2838,\n",
       "                       2.1665, 2.8009, 2.9477, 2.1007, 2.9029, 4.1549, 2.1065, 2.7701, 3.0677,\n",
       "                       2.5914, 2.2075, 2.9443, 2.3516, 1.7846, 2.2627, 2.4772, 3.0385, 3.6097,\n",
       "                       2.5695, 2.4799, 2.3682, 2.3491, 1.7544, 2.7251, 3.0915, 2.0457, 2.6656,\n",
       "                       2.1610, 2.6022, 2.7454, 2.7875, 2.5431, 2.1334, 2.4323, 2.6401, 2.7232,\n",
       "                       2.9226, 2.9016, 3.1719, 2.6454, 2.0499, 1.8695, 2.0856, 1.8433, 2.8427,\n",
       "                       2.1415, 2.3044, 2.6152, 2.5414, 2.1196, 2.0394, 2.7573, 2.0358, 2.4036,\n",
       "                       2.0971, 2.5764, 2.3540, 2.0658, 3.0019, 2.2727, 2.8477, 2.2884, 2.6903,\n",
       "                       3.9780, 1.9110, 2.6504, 2.6769, 2.1902, 2.2347, 4.3742, 2.2352, 2.1582,\n",
       "                       2.6925, 1.9930, 2.1996, 2.2215, 2.2664, 2.4019, 2.1928, 2.8213, 1.7958,\n",
       "                       2.4505, 2.0962, 1.9403, 3.4656, 2.2540, 3.0751, 2.1173, 2.4767, 2.1314,\n",
       "                       2.8786, 2.0934, 2.6332, 2.6768, 1.8890, 2.1179, 3.3729, 1.7987, 2.3929,\n",
       "                       2.2368, 2.8646, 2.0965, 3.4916, 2.7099, 2.2853, 2.4085, 2.0665, 2.2888,\n",
       "                       2.5966, 3.5856, 2.5008, 3.4573, 2.6132, 2.0020, 2.0781, 2.4933, 1.9846,\n",
       "                       2.0171, 2.3490, 2.7669, 2.7048, 3.4657, 2.0749, 2.8285, 2.7222, 2.1965,\n",
       "                       2.7557, 2.3737, 1.8526, 2.8961, 2.4727, 2.0811, 2.0253, 1.7777, 2.3051,\n",
       "                       3.6468, 2.6338, 2.1030, 3.3858, 2.2134, 2.0715, 2.3848, 2.1520, 4.0266,\n",
       "                       1.7778, 1.9157, 2.4696, 2.4150, 2.2956, 2.3442, 1.8500, 2.7316, 2.2908,\n",
       "                       2.8829, 1.9701, 1.7185, 2.3559, 3.7610, 3.6519, 2.7384, 2.9769, 2.3484,\n",
       "                       2.5926, 2.4050, 4.2187, 1.7947, 3.4489, 2.3160, 2.4121, 3.0049, 3.4720,\n",
       "                       2.1326, 2.8458, 1.7550, 2.6635, 5.0533, 2.0386, 1.8874, 3.0332, 2.1050,\n",
       "                       2.9676, 2.3872, 2.4001, 2.9593, 3.2836, 2.4060, 3.0889, 2.3447, 2.0657,\n",
       "                       3.1592, 2.7301, 2.1409, 3.5603, 3.1942, 2.2073, 1.6644, 1.8773, 1.6483,\n",
       "                       2.3912, 2.8241, 1.8322, 3.6869, 2.1578, 2.4217, 2.5236, 2.7583, 3.7098,\n",
       "                       2.3671, 2.2976, 3.5748, 4.5807, 2.3105, 2.3796, 2.6994, 2.0927, 2.1882,\n",
       "                       2.1165, 2.2040, 2.1916, 2.5326, 2.2605, 2.5834, 2.2349, 2.2651, 2.2985,\n",
       "                       1.9152, 2.1063, 3.9820, 2.6583, 2.6462, 1.7033, 2.3475, 2.6087, 2.6390,\n",
       "                       2.1806, 2.4972, 2.0273, 2.6950, 2.3888, 2.0510, 3.3017, 2.1693, 2.5541,\n",
       "                       3.1152, 3.6138, 3.2081, 1.8074, 1.8549, 2.5707, 3.4107, 2.2977, 2.4929,\n",
       "                       2.7925, 2.7780, 2.8005, 1.9363, 1.6846, 2.7999, 2.2966, 2.1534, 1.8239,\n",
       "                       2.0506, 1.8822, 2.7525, 2.7586, 2.2663, 2.4681, 2.2714, 2.3820, 3.1950,\n",
       "                       2.3153, 2.9189, 2.8630, 2.8817, 2.0812, 2.1176, 2.3267, 1.9484, 3.2319,\n",
       "                       2.7196, 2.4545, 2.4471, 2.7814, 1.8998, 1.9173, 2.7143, 1.8053, 2.3839,\n",
       "                       2.2977, 2.5171, 2.3172, 2.6091, 6.2396, 2.2648, 2.1688, 2.6057, 1.9519,\n",
       "                       2.4182, 2.4081, 4.0128, 2.8994, 2.0941, 2.5430, 2.6594, 2.7351, 2.3400,\n",
       "                       2.8148, 2.0848, 2.8895, 2.2979, 2.9280, 3.6919, 2.5780, 2.7231, 2.2552,\n",
       "                       3.1190, 2.4448, 2.3125, 1.9017, 2.1446, 2.4391, 1.8787, 2.1446, 2.6588,\n",
       "                       2.8156, 2.4619, 2.4750, 2.3548, 2.5833, 2.5910, 3.3684, 2.2908, 2.6058,\n",
       "                       3.8231, 2.2469, 3.3609, 2.5969, 1.8451, 3.5185, 2.5359, 2.8503, 2.3093,\n",
       "                       2.0739, 2.8439, 2.6093, 2.6644, 2.2447, 2.9717, 2.4529, 2.2329, 2.6370,\n",
       "                       2.6080, 2.8273, 2.1484, 1.9191, 2.9685, 3.0582, 1.9103, 2.1425, 4.4474,\n",
       "                       2.5174, 2.2144, 2.1360, 2.7836, 3.0240, 3.0919, 3.9603, 3.4230, 4.1677,\n",
       "                       2.6657, 2.9190, 2.6422, 3.3790, 3.6213, 2.5728, 2.2751, 2.1357, 3.1897,\n",
       "                       2.2469, 2.8051, 1.9486, 2.0764, 2.5061, 4.5261, 1.9980, 2.8461, 2.7968,\n",
       "                       2.1129, 2.5998, 2.4268, 2.9653, 2.5048, 1.8759, 2.2573, 2.6381, 2.2730,\n",
       "                       2.8732, 2.9623, 2.2420, 2.2227, 2.4010, 2.7152, 2.3760, 2.9132],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.0.conv2.weight',\n",
       "               tensor([[[[-1.2182e-02, -1.5989e-02, -5.3063e-03],\n",
       "                         [-1.4310e-02, -2.5547e-02, -2.1790e-02],\n",
       "                         [-9.3227e-03, -2.0370e-02, -1.5649e-02]],\n",
       "               \n",
       "                        [[ 6.4872e-03, -6.8566e-03,  1.1829e-02],\n",
       "                         [-1.3990e-02, -6.5579e-03, -1.2576e-02],\n",
       "                         [-2.2260e-03, -1.6661e-02, -5.8151e-04]],\n",
       "               \n",
       "                        [[-1.6791e-02, -1.8913e-02, -2.8358e-02],\n",
       "                         [-3.4615e-02, -4.9398e-02, -2.2838e-02],\n",
       "                         [-1.9577e-02, -2.4877e-02, -2.4494e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.6050e-02, -2.9673e-02, -1.3330e-02],\n",
       "                         [-2.8793e-02, -3.6461e-02, -1.0773e-02],\n",
       "                         [-2.0534e-02, -3.6591e-02, -2.1597e-02]],\n",
       "               \n",
       "                        [[-2.3415e-02, -2.2683e-02, -2.2700e-02],\n",
       "                         [-3.0645e-02, -5.3324e-02, -3.2166e-02],\n",
       "                         [-3.1242e-02, -4.9083e-02, -2.3331e-02]],\n",
       "               \n",
       "                        [[-1.7960e-02, -1.7145e-02, -1.8490e-02],\n",
       "                         [-2.7768e-02, -2.4840e-02, -3.3441e-02],\n",
       "                         [-1.8217e-02, -4.5688e-02, -2.7271e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3272e-02,  2.3036e-02,  1.5777e-02],\n",
       "                         [ 1.1733e-02,  3.1997e-02,  8.6798e-03],\n",
       "                         [ 5.0810e-03,  7.5628e-03,  1.1331e-04]],\n",
       "               \n",
       "                        [[-2.3187e-03, -1.0798e-03, -7.7345e-04],\n",
       "                         [ 1.5615e-02,  9.4414e-03,  1.3656e-02],\n",
       "                         [ 8.7711e-03,  4.2432e-04,  6.3753e-03]],\n",
       "               \n",
       "                        [[-1.6137e-02,  1.1312e-04, -2.0825e-02],\n",
       "                         [-1.1891e-02, -7.9382e-03, -9.6464e-03],\n",
       "                         [-5.1962e-03, -8.0139e-03, -1.4792e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.0055e-03,  1.4273e-02,  2.3044e-02],\n",
       "                         [ 2.6191e-03,  1.6591e-02,  1.4779e-02],\n",
       "                         [ 1.1059e-02,  1.8533e-02,  1.2510e-02]],\n",
       "               \n",
       "                        [[-1.4152e-03,  1.6029e-02,  1.3978e-02],\n",
       "                         [ 9.9934e-03,  6.2944e-03,  3.9285e-03],\n",
       "                         [ 8.0443e-03,  2.2678e-02,  1.7672e-02]],\n",
       "               \n",
       "                        [[ 1.4320e-02,  1.4418e-02,  9.7080e-03],\n",
       "                         [ 1.5724e-03,  4.4369e-03,  7.8621e-04],\n",
       "                         [-1.7588e-02,  1.8863e-04, -1.5851e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.7690e-03,  3.8699e-03,  6.9504e-03],\n",
       "                         [ 7.6346e-03, -1.7365e-02,  4.9189e-03],\n",
       "                         [-2.3893e-02, -4.0320e-03, -1.1878e-02]],\n",
       "               \n",
       "                        [[-3.8427e-02, -4.4140e-02, -2.9983e-02],\n",
       "                         [-5.6240e-02, -4.2613e-02, -5.0791e-02],\n",
       "                         [-4.6334e-02, -5.6169e-02, -3.9868e-02]],\n",
       "               \n",
       "                        [[ 1.3067e-02,  2.5731e-02,  6.5245e-03],\n",
       "                         [ 8.4609e-03,  2.7072e-02,  2.0675e-02],\n",
       "                         [ 1.3266e-02,  3.5062e-02,  2.3753e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.6598e-03,  1.6838e-02,  2.1862e-02],\n",
       "                         [ 3.0919e-02,  2.6776e-02,  1.5642e-02],\n",
       "                         [ 2.6520e-02,  1.9390e-02,  2.5323e-02]],\n",
       "               \n",
       "                        [[ 3.7546e-03,  9.0023e-03,  1.6492e-02],\n",
       "                         [-4.2174e-03,  2.1764e-02,  7.2929e-03],\n",
       "                         [ 5.0372e-03,  1.4640e-02,  1.6966e-02]],\n",
       "               \n",
       "                        [[-1.3338e-02, -3.2552e-02, -1.6116e-02],\n",
       "                         [-3.0557e-02, -4.2636e-02, -3.6378e-02],\n",
       "                         [-1.2706e-02, -1.5841e-02, -3.6992e-04]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.1415e-02, -3.3736e-02, -3.6429e-02],\n",
       "                         [-3.1723e-02, -3.4285e-02, -3.5004e-02],\n",
       "                         [-2.0020e-02, -2.0202e-02, -2.6643e-02]],\n",
       "               \n",
       "                        [[-1.9419e-03, -1.5210e-02,  7.1902e-03],\n",
       "                         [-2.1756e-03, -5.4315e-03,  4.9891e-03],\n",
       "                         [ 1.1685e-02,  5.1404e-03,  4.6728e-04]],\n",
       "               \n",
       "                        [[ 6.6344e-04,  2.6988e-03, -3.1382e-03],\n",
       "                         [ 8.4769e-04, -1.0486e-02, -4.4449e-03],\n",
       "                         [-1.2814e-02, -2.7996e-03, -3.6654e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.8117e-03,  7.8036e-03,  5.1508e-03],\n",
       "                         [-6.5274e-04,  3.9901e-03,  6.2325e-04],\n",
       "                         [-3.2069e-04, -7.7915e-04, -8.6069e-03]],\n",
       "               \n",
       "                        [[-1.0439e-02, -9.5149e-04, -4.5245e-03],\n",
       "                         [-1.8051e-02,  2.9825e-03, -1.4082e-02],\n",
       "                         [-8.8136e-03, -1.6462e-02, -2.0531e-02]],\n",
       "               \n",
       "                        [[-8.4060e-03, -3.4512e-02, -9.5894e-03],\n",
       "                         [-1.0877e-02,  2.3779e-03,  6.0047e-03],\n",
       "                         [-2.5928e-03, -4.0884e-03, -2.0470e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0288e-02, -1.3894e-02, -3.0038e-03],\n",
       "                         [-1.9812e-02, -2.5803e-02, -2.6760e-02],\n",
       "                         [-2.4983e-02, -2.9766e-02, -1.0428e-02]],\n",
       "               \n",
       "                        [[-2.3178e-02, -2.6648e-02, -1.3998e-02],\n",
       "                         [-2.1513e-02, -2.4599e-02, -1.2341e-02],\n",
       "                         [-1.1783e-02, -1.7166e-02, -1.1590e-02]],\n",
       "               \n",
       "                        [[-3.7051e-02, -4.1131e-02, -1.5130e-02],\n",
       "                         [-5.9437e-03, -2.5192e-02, -8.4698e-03],\n",
       "                         [ 3.1978e-03, -1.2716e-02,  5.2007e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.0569e-03, -8.3216e-05, -7.0002e-03],\n",
       "                         [-9.9817e-03,  3.0304e-03,  2.9743e-03],\n",
       "                         [ 1.2217e-02,  2.7568e-02, -4.5539e-03]],\n",
       "               \n",
       "                        [[-1.2638e-02,  7.0011e-03,  3.1544e-03],\n",
       "                         [-1.1447e-03,  4.3716e-03, -3.6690e-04],\n",
       "                         [-8.9174e-04,  8.4449e-03,  1.4502e-02]],\n",
       "               \n",
       "                        [[-1.6463e-02, -1.9342e-02, -1.7137e-02],\n",
       "                         [-2.1818e-02, -3.2484e-02, -1.9532e-02],\n",
       "                         [-1.3934e-02, -1.4864e-02, -1.4337e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.0281e-03, -8.4993e-03, -4.0535e-03],\n",
       "                         [-3.2962e-02, -1.7905e-02, -3.5040e-02],\n",
       "                         [-1.8935e-02, -2.9549e-02, -1.7524e-02]],\n",
       "               \n",
       "                        [[-2.2020e-03, -6.4207e-03, -2.1632e-02],\n",
       "                         [-1.4366e-02, -8.2380e-03, -1.0922e-02],\n",
       "                         [-1.3571e-02, -1.0185e-02, -1.0631e-02]],\n",
       "               \n",
       "                        [[-2.3351e-02, -3.4176e-02, -2.2528e-02],\n",
       "                         [-3.6115e-02, -5.2159e-02, -5.0909e-02],\n",
       "                         [-2.2278e-02, -4.1952e-02, -3.3797e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.0516e-04, -1.3283e-03, -1.3279e-02],\n",
       "                         [ 2.2899e-03, -1.2098e-02,  3.0977e-03],\n",
       "                         [-1.3836e-02, -5.3833e-03, -7.7435e-03]],\n",
       "               \n",
       "                        [[-1.2204e-02, -4.4866e-02, -2.8521e-02],\n",
       "                         [-4.3672e-02, -2.9551e-02, -3.3498e-02],\n",
       "                         [-3.0744e-02, -5.5384e-02, -3.2520e-02]],\n",
       "               \n",
       "                        [[-1.9541e-03,  3.3408e-03,  3.3753e-04],\n",
       "                         [-8.7967e-03, -6.4928e-04, -1.6261e-02],\n",
       "                         [-7.6746e-04, -1.3013e-02, -3.9416e-03]]]], device='cuda:0')),\n",
       "              ('module.layer4.0.bn2.weight',\n",
       "               tensor([1.7343, 1.3047, 1.3082, 2.1254, 1.6560, 1.1998, 1.8333, 1.5983, 0.9039,\n",
       "                       1.2082, 1.2294, 1.0602, 1.6682, 2.1495, 1.5981, 1.6750, 1.0155, 1.8259,\n",
       "                       1.9529, 1.7741, 1.1845, 1.7273, 1.6179, 1.2008, 1.1084, 1.4702, 1.8647,\n",
       "                       1.5375, 1.6721, 1.6004, 1.6968, 1.0814, 1.5833, 1.8049, 2.0953, 1.4792,\n",
       "                       1.6556, 1.7759, 1.7745, 1.8615, 1.5848, 1.4255, 1.8924, 1.9959, 1.3125,\n",
       "                       2.2191, 1.7445, 1.5176, 1.8062, 1.9184, 1.6596, 1.6158, 1.7431, 1.9085,\n",
       "                       2.1324, 1.6981, 1.2117, 1.4321, 1.4119, 1.8328, 1.4397, 1.6373, 1.6735,\n",
       "                       1.3883, 1.6465, 0.9936, 1.6416, 1.0398, 1.4326, 0.9787, 1.8381, 1.5709,\n",
       "                       1.9172, 1.0578, 1.9951, 1.5106, 1.2173, 1.8219, 1.4823, 1.3268, 1.4158,\n",
       "                       1.4955, 1.6651, 1.6679, 2.0693, 1.8382, 1.8053, 1.7587, 2.1000, 1.7366,\n",
       "                       1.9671, 1.1812, 1.7545, 1.7297, 2.1045, 1.2194, 1.5991, 1.9897, 1.9211,\n",
       "                       1.5949, 1.7194, 1.7736, 1.8560, 1.3192, 2.0835, 1.7931, 1.8671, 2.2090,\n",
       "                       0.9360, 1.8166, 1.2244, 1.8049, 1.1362, 1.3252, 2.0105, 1.7997, 1.8570,\n",
       "                       1.0981, 1.1103, 1.1097, 1.7858, 0.8896, 1.8701, 0.9499, 1.2842, 1.6720,\n",
       "                       1.7131, 1.1724, 0.8802, 1.5322, 1.4726, 2.0867, 1.4073, 1.9920, 1.6789,\n",
       "                       1.5417, 2.4025, 1.5443, 1.8531, 1.9408, 1.6760, 1.7302, 1.4789, 1.6944,\n",
       "                       1.2124, 1.3482, 1.6535, 1.6038, 1.5949, 1.6990, 0.9182, 1.4764, 1.2905,\n",
       "                       1.3149, 1.1669, 1.1745, 1.9360, 1.4253, 1.3844, 1.4834, 1.5557, 1.6870,\n",
       "                       1.7794, 1.9971, 1.8899, 1.4682, 1.5297, 1.7889, 0.9615, 1.7952, 1.7880,\n",
       "                       1.6880, 1.4518, 1.8449, 1.0834, 1.9247, 1.3309, 1.4718, 1.7377, 1.9529,\n",
       "                       1.5141, 1.3734, 1.1546, 1.7706, 1.4526, 2.1073, 1.9366, 1.9907, 1.4985,\n",
       "                       1.9670, 1.8370, 1.6168, 1.7562, 1.5352, 2.0102, 2.2327, 1.2348, 1.5449,\n",
       "                       1.7225, 1.5903, 1.6884, 1.6604, 1.6692, 1.6065, 1.5164, 1.4898, 1.6722,\n",
       "                       1.7614, 1.9640, 1.9311, 1.5867, 2.2695, 0.9487, 1.4352, 1.1145, 1.0507,\n",
       "                       2.0924, 1.7654, 1.7321, 1.0651, 1.6944, 1.4948, 1.0566, 1.0307, 1.0372,\n",
       "                       1.9286, 1.2082, 1.8413, 2.1706, 2.2421, 2.0059, 2.0157, 1.2530, 1.0276,\n",
       "                       1.7550, 1.4512, 1.1831, 1.6457, 1.9340, 2.2930, 1.3460, 1.7491, 1.8600,\n",
       "                       1.3707, 1.0564, 1.9474, 1.6878, 1.5532, 2.1031, 1.7051, 1.9426, 1.1413,\n",
       "                       1.8148, 2.1637, 1.7600, 0.9168, 1.4994, 1.4070, 1.6214, 1.8746, 0.9497,\n",
       "                       1.9151, 1.1867, 1.5338, 1.5237, 1.8558, 1.5329, 1.8571, 2.0531, 1.7027,\n",
       "                       1.2443, 1.4697, 1.5779, 1.4815, 1.6446, 1.7942, 1.5130, 1.9236, 2.0626,\n",
       "                       1.7640, 2.0164, 1.5317, 1.4674, 2.0677, 1.8220, 2.2996, 0.9838, 1.6520,\n",
       "                       1.9367, 1.7848, 1.8137, 1.6633, 1.6826, 2.2161, 1.6543, 1.8036, 1.7119,\n",
       "                       1.8962, 1.2613, 0.9607, 0.9697, 1.7723, 1.4279, 1.4863, 1.3686, 1.5745,\n",
       "                       1.8386, 1.5463, 1.0884, 1.6630, 1.2320, 1.5962, 1.7452, 1.3253, 1.7022,\n",
       "                       1.5922, 1.5411, 1.0370, 1.6034, 1.5433, 2.0679, 1.1779, 1.4063, 1.1729,\n",
       "                       1.4439, 0.8933, 1.8120, 1.4973, 1.7665, 1.4717, 2.0603, 1.6889, 1.5945,\n",
       "                       1.4200, 1.8392, 1.6315, 1.9366, 1.4991, 1.4061, 1.4239, 1.2671, 2.0495,\n",
       "                       2.0415, 1.7752, 1.9792, 1.0577, 2.0054, 1.4041, 1.0280, 1.6496, 1.4088,\n",
       "                       2.2002, 1.8180, 1.7554, 1.7254, 1.7029, 1.5521, 1.5797, 1.8252, 1.3177,\n",
       "                       1.8704, 1.5168, 1.4375, 1.9177, 1.1942, 1.0631, 1.8225, 2.0755, 2.0035,\n",
       "                       0.9823, 2.0850, 1.4094, 1.6410, 1.7402, 0.8712, 1.5103, 1.4818, 2.0399,\n",
       "                       1.6886, 1.9461, 2.0292, 1.9942, 2.0005, 0.9233, 1.6818, 1.3714, 1.2743,\n",
       "                       1.1420, 2.1009, 1.9757, 1.4069, 1.9219, 1.9768, 1.6600, 1.0113, 1.4990,\n",
       "                       2.0267, 1.7532, 1.6216, 2.1051, 1.3838, 1.4953, 1.8470, 1.2271, 1.6387,\n",
       "                       1.9901, 2.2623, 1.4295, 0.9336, 0.9243, 1.3823, 1.3498, 0.9864, 1.5078,\n",
       "                       1.9906, 2.0402, 1.4017, 1.7993, 1.0459, 1.4107, 1.9331, 1.7030, 1.4825,\n",
       "                       1.9868, 1.4175, 1.6859, 0.9363, 1.6660, 1.7140, 1.5300, 1.7330, 1.5092,\n",
       "                       1.4042, 1.7033, 1.6225, 1.6830, 1.5232, 1.7703, 1.7883, 1.5221, 1.9697,\n",
       "                       1.5350, 1.7157, 1.4737, 1.5351, 1.3508, 1.8297, 1.8389, 1.8468, 1.4269,\n",
       "                       2.0652, 1.1348, 1.5282, 1.7002, 1.6755, 1.9244, 0.9623, 1.3460, 1.8850,\n",
       "                       2.0374, 1.6617, 1.7396, 0.9996, 1.4138, 1.2634, 1.5977, 1.7684, 1.2811,\n",
       "                       1.5803, 1.7171, 1.5134, 1.4163, 1.7566, 2.2715, 1.6920, 1.8008, 1.8143,\n",
       "                       1.5794, 2.2326, 1.5932, 1.0107, 1.7228, 1.8976, 1.7863, 1.6011, 1.6646,\n",
       "                       0.9074, 2.0211, 1.6726, 1.8043, 1.5388, 1.6145, 1.7310, 1.5822, 2.1494,\n",
       "                       1.0657, 1.5470, 1.8323, 1.4520, 1.6546, 1.8584, 1.6565, 1.7084, 1.6853,\n",
       "                       1.9411, 1.7202, 1.1990, 0.9142, 1.6056, 1.6212, 1.9667, 1.0968],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn2.bias',\n",
       "               tensor([-3.1510e-01,  3.7874e-01,  2.2681e-01, -1.2905e+00, -5.0967e-01,\n",
       "                        4.8925e-01, -5.8901e-01, -2.6603e-01,  1.8353e+00,  3.8036e-01,\n",
       "                        3.6544e-01,  8.1896e-01, -4.3080e-01, -1.7643e+00, -2.1241e-01,\n",
       "                       -5.8416e-01,  1.3071e+00, -1.4478e+00, -9.8866e-01, -1.1390e+00,\n",
       "                        4.3294e-01, -3.6667e-01, -2.4699e-01,  5.8096e-01,  7.5053e-01,\n",
       "                       -5.3752e-02, -6.1612e-01, -1.0491e-01, -2.4774e-01, -8.3429e-02,\n",
       "                       -4.6363e-01,  8.6579e-01, -2.9296e-01, -7.2636e-01, -8.1850e-01,\n",
       "                       -1.8036e-01, -1.4574e+00, -7.1213e-01, -6.5317e-01, -8.4744e-01,\n",
       "                       -4.2049e-01,  5.4837e-02, -8.1005e-01, -9.6213e-01,  3.4495e-01,\n",
       "                       -1.7660e+00, -6.6893e-01,  1.3739e-02, -8.4845e-01, -6.6483e-01,\n",
       "                       -2.9618e-01, -1.7480e-01, -3.7455e-01, -9.1739e-01, -7.6857e-01,\n",
       "                       -1.1680e+00,  5.1153e-01,  3.7564e-03,  4.7183e-01, -1.2172e+00,\n",
       "                        9.7610e-02, -3.3796e-01, -3.4985e-01,  3.3910e-01, -3.9348e-01,\n",
       "                        1.0999e+00, -1.5902e-01,  2.9787e+00,  7.9752e-02,  1.0201e+00,\n",
       "                       -1.0256e+00, -7.5859e-02, -6.8341e-01,  1.0101e+00, -6.1241e-01,\n",
       "                        2.5180e-02,  2.1012e-01, -7.1955e-01, -2.7977e-01,  3.1211e-01,\n",
       "                        1.6744e-01, -1.3376e-01, -3.6787e-01, -7.7045e-01, -1.3183e+00,\n",
       "                       -5.2233e-01, -5.6801e-01, -4.6782e-01, -1.0464e+00, -7.3357e-01,\n",
       "                       -1.7823e+00,  5.6442e-01, -6.8384e-01, -1.0020e+00, -1.5460e+00,\n",
       "                        3.5721e-01, -3.6512e-01, -1.1267e+00, -7.8979e-01, -3.1303e-01,\n",
       "                       -4.3665e-01, -8.0575e-01, -1.2158e+00,  1.3704e-01, -9.3649e-01,\n",
       "                       -9.8364e-01, -7.6460e-01, -1.3011e+00,  1.3890e+00, -1.5313e+00,\n",
       "                        5.5851e-01, -7.9228e-01,  6.4360e-01,  5.4133e-01, -6.3634e-01,\n",
       "                       -4.5841e-01, -1.3050e+00,  6.0744e-01,  1.3490e+00,  6.8768e-01,\n",
       "                       -5.7188e-01,  2.2699e+00, -9.6403e-01,  1.5101e+00,  3.4736e-01,\n",
       "                       -2.4253e-01, -4.6573e-01,  6.3976e-01,  1.6208e+00,  9.9164e-02,\n",
       "                       -6.0285e-02, -1.2109e+00, -1.2169e-01, -1.6042e+00, -2.9047e-01,\n",
       "                        4.3333e+00, -1.0254e+00, -7.8345e-02, -9.5263e-01, -1.5356e+00,\n",
       "                       -3.6182e-01, -4.6415e-01,  2.4381e-01, -4.0568e-01,  5.7590e-01,\n",
       "                        1.5858e-01, -2.2220e-01, -6.4181e-01, -1.4612e-01, -2.6335e-01,\n",
       "                        2.1633e+00, -2.2028e-01,  3.1327e-01,  2.8595e-01,  5.5426e-01,\n",
       "                        5.4957e-01, -5.5472e-01,  2.5706e-01,  1.0935e-01, -9.3842e-02,\n",
       "                       -2.6675e-01, -6.9062e-01, -5.7833e-01, -1.0401e+00, -5.1398e-01,\n",
       "                       -6.7749e-03, -4.7826e-02, -1.7400e+00,  1.5968e+00, -1.5227e+00,\n",
       "                       -1.2947e+00, -5.3824e-01, -1.1812e-01, -7.6242e-01,  8.5732e-01,\n",
       "                       -9.9374e-01,  2.2744e-01,  3.1693e-01, -3.0981e-01, -9.8678e-01,\n",
       "                       -1.1104e-01,  3.1895e-01,  8.3771e-01, -3.6388e-01, -6.6930e-02,\n",
       "                       -1.2180e+00, -6.2134e-01, -7.9797e-01, -2.1054e-01, -1.1482e+00,\n",
       "                       -5.2575e-01, -4.8675e-01, -4.6806e-01, -3.2364e-02, -1.0585e+00,\n",
       "                       -1.6418e+00,  4.6084e-01,  2.1720e-02, -4.0252e-01, -3.8347e-01,\n",
       "                       -4.3312e-01, -1.6728e-01, -7.4134e-01, -3.3495e-01, -1.3719e-01,\n",
       "                       -2.0366e-01, -3.5514e-01, -4.7134e-01, -8.5538e-01, -1.4266e+00,\n",
       "                       -2.0696e-01, -1.2480e+00,  1.2760e+00,  5.9695e-02,  7.3404e-01,\n",
       "                        1.1889e+00, -1.9548e+00, -5.1239e-01, -4.8864e-01,  8.6100e-01,\n",
       "                       -5.7065e-01, -5.0876e-02,  8.5822e-01,  9.1238e-01,  1.0296e+00,\n",
       "                       -1.2707e+00,  4.6505e-01, -6.8548e-01, -1.1652e+00, -1.4401e+00,\n",
       "                       -1.0906e+00, -2.0822e+00,  3.9856e-01,  9.5399e-01, -2.1882e-01,\n",
       "                       -2.1745e-01,  3.5039e+00, -4.3320e-01, -6.6830e-01, -1.3065e+00,\n",
       "                        4.8706e-01, -4.7353e-01, -9.8071e-01,  2.0911e-01,  9.4602e-01,\n",
       "                       -1.7511e+00, -5.7209e-01,  2.4225e-02, -1.4744e+00, -5.2760e-01,\n",
       "                       -9.0434e-01,  1.0856e+00, -1.2422e+00, -1.0099e+00, -4.4365e-01,\n",
       "                        1.6080e+00, -1.6404e-01, -5.8818e-02, -2.3232e-01, -7.7280e-01,\n",
       "                        1.5253e+00, -1.0932e+00,  4.8706e-01, -1.7647e-01, -9.9936e-02,\n",
       "                       -8.6356e-01, -4.4317e-01, -3.6824e-01, -1.2366e+00, -1.5743e-01,\n",
       "                        8.6680e-01, -9.8618e-02, -9.5626e-01, -3.1262e-02, -9.6310e-02,\n",
       "                       -5.3154e-01, -2.3560e-01, -8.3625e-01, -7.3692e-01, -4.8222e-01,\n",
       "                       -9.6781e-01,  3.2127e-02, -2.8266e-02, -8.4870e-01, -7.2068e-01,\n",
       "                       -1.5058e+00,  1.2421e+00, -6.5635e-01, -1.4386e+00, -4.8457e-01,\n",
       "                       -6.5712e-01, -3.4201e-01, -2.9511e-01, -1.3698e+00, -5.5439e-01,\n",
       "                       -3.3100e-01, -6.5144e-01, -6.6906e-01,  2.8380e-01,  1.2674e+00,\n",
       "                        1.3847e+00, -3.0020e-01,  3.1628e-03, -3.0058e-02,  1.4305e-01,\n",
       "                        2.4741e-02, -1.1200e+00, -2.0387e-01,  3.5504e+00, -3.7468e-01,\n",
       "                        3.4861e-01, -4.9571e-01, -5.1211e-01,  3.8067e-01, -2.9855e-01,\n",
       "                       -9.2659e-02, -2.1948e-01,  1.0319e+00, -1.5946e-01, -2.4758e-01,\n",
       "                       -6.0473e-01,  5.9348e-01,  1.3728e-01,  8.8479e-01,  4.1278e-02,\n",
       "                        1.7772e+00, -7.8255e-01,  8.2056e-03, -2.1738e-01, -3.4986e-01,\n",
       "                       -1.8468e+00, -5.7402e-01, -3.0703e-01,  1.2652e-01, -5.8306e-01,\n",
       "                       -3.1652e-01, -7.6435e-01, -2.4911e-02, -1.7175e-01, -5.2884e-02,\n",
       "                        4.5371e-01, -1.7084e+00, -2.0453e+00, -7.7844e-01, -1.2839e+00,\n",
       "                        8.3942e-01, -8.3917e-01,  5.4890e-02,  9.4184e-01, -6.7194e-01,\n",
       "                       -8.3990e-02, -1.1714e+00, -1.0209e+00, -6.2663e-01, -5.5678e-01,\n",
       "                       -1.0076e+00, -1.2578e-03, -3.9111e-02, -4.9875e-01,  3.2634e-01,\n",
       "                       -6.6374e-01, -7.0604e-02,  1.1313e-01, -1.1179e+00,  4.6311e-01,\n",
       "                        9.1152e-01, -6.7500e-01, -1.6640e+00, -1.7618e+00,  1.0065e+00,\n",
       "                       -1.0127e+00,  1.3875e-01, -2.8643e-01, -4.8768e-01,  2.0490e+00,\n",
       "                        2.4958e-02, -1.4314e-01, -1.1516e+00, -4.6273e-01, -1.2171e+00,\n",
       "                       -9.3942e-01, -1.0544e+00, -1.7586e+00,  1.3708e+00, -4.8774e-01,\n",
       "                        1.0630e-01,  4.4996e-01,  6.9985e-01, -7.4510e-01, -1.9982e+00,\n",
       "                        7.2883e-02, -7.3891e-01, -8.2758e-01, -4.6913e-01,  1.3729e+00,\n",
       "                       -2.4536e-01, -8.0921e-01, -5.1557e-01, -5.0780e-02, -1.4764e+00,\n",
       "                        2.0429e-02, -2.9356e-01, -1.6111e+00,  4.9712e-01, -1.6188e-01,\n",
       "                       -2.1290e+00, -1.0212e+00,  8.5338e-02,  1.9584e+00,  2.9722e+00,\n",
       "                       -1.2733e-03,  3.4034e-01,  1.3031e+00, -1.9823e-01, -1.2352e+00,\n",
       "                       -1.0474e+00,  3.4755e+00, -5.9712e-01,  8.8577e-01,  1.6112e-01,\n",
       "                       -9.1133e-01, -5.6537e-01, -1.0966e-01, -8.7047e-01,  1.9432e-01,\n",
       "                       -3.3240e-01,  1.9790e+00, -5.6712e-01, -3.3875e-01, -1.2043e-01,\n",
       "                       -4.7979e-01, -5.7926e-02,  3.0907e-01, -6.8400e-01, -2.3298e-01,\n",
       "                       -6.5954e-01, -4.3891e-02, -5.4033e-01, -4.9926e-01, -1.2565e-01,\n",
       "                       -1.2703e+00, -3.1553e-01, -1.3538e-01, -2.9061e-01, -2.1952e-01,\n",
       "                        1.3236e-01, -6.3930e-01, -6.2525e-01, -7.7572e-01,  1.2328e-01,\n",
       "                       -1.1436e+00,  8.3008e-01, -1.9830e-01, -3.5251e-01, -4.0338e-01,\n",
       "                       -9.1109e-01,  1.1013e+00,  1.0246e-01, -4.8279e-01, -1.0754e+00,\n",
       "                       -9.4369e-01, -5.5058e-01,  1.0934e+00,  1.6799e-01,  3.7055e-01,\n",
       "                        2.0036e-04, -1.1493e+00,  4.0884e-01, -2.4810e-01, -3.1267e-01,\n",
       "                       -3.1473e-01,  2.1533e-02, -5.2999e-01, -1.1072e+00, -2.1258e-01,\n",
       "                       -1.0449e+00, -7.3630e-01, -3.9539e-01, -1.7785e+00, -4.8229e-02,\n",
       "                        9.8584e-01, -4.3615e-01, -6.7698e-01, -2.2516e-01, -7.2692e-01,\n",
       "                       -3.2983e-01,  1.8969e+00, -6.1445e-01, -4.5280e-01, -8.0175e-01,\n",
       "                       -9.0999e-02, -4.5393e-01, -6.6996e-01, -3.0238e-01, -1.4432e+00,\n",
       "                        1.2012e+00, -3.7771e-01, -6.2849e-01,  6.3673e-02, -4.6733e-01,\n",
       "                       -7.4089e-01, -3.9570e-01, -4.3178e-01, -5.5360e-01, -1.6415e+00,\n",
       "                       -7.6542e-01,  4.0158e-01,  2.7900e+00, -1.2235e-01, -5.0806e-01,\n",
       "                       -9.2980e-01,  8.1849e-01], device='cuda:0')),\n",
       "              ('module.layer4.0.bn2.running_mean',\n",
       "               tensor([-1.2383, -0.3819, -0.6604, -1.7541, -1.1956, -0.2812, -1.3041, -0.8079,\n",
       "                        0.3421, -0.6221, -0.4839, -0.4895, -0.9853, -1.3707, -0.7629, -0.9304,\n",
       "                       -0.0461, -0.6750, -1.4163, -0.5726, -0.6848, -0.6216, -0.7557, -0.0201,\n",
       "                       -0.5299, -0.5655, -1.1433, -0.8387, -0.9924, -0.5502, -1.0082, -0.2621,\n",
       "                       -0.5672, -0.7732, -1.1489, -0.7052,  0.1825, -1.1395, -1.3301, -1.5909,\n",
       "                       -1.0307, -0.7439, -0.7149, -1.2088, -0.1186, -1.1110, -1.5204, -0.5790,\n",
       "                       -0.7971, -1.4514, -0.6401, -1.2105, -0.8868, -0.8021, -1.3810, -1.0388,\n",
       "                       -0.3811, -0.5553, -0.6601, -0.7906, -0.5116, -0.8072, -0.5942, -0.6542,\n",
       "                       -0.7535,  0.2188, -0.8016, -0.8195, -0.9249, -0.0714, -0.7042, -1.1644,\n",
       "                       -1.4133, -0.3709, -1.0996, -0.9932, -0.4013, -1.2858, -0.9474, -0.8269,\n",
       "                       -0.6482, -0.4131, -1.6443, -0.7259, -1.1842, -1.0122, -1.2605, -1.3260,\n",
       "                       -0.8614, -1.5597, -0.7691, -0.5011, -0.8480, -0.6575, -0.8105, -0.1753,\n",
       "                       -0.9072, -1.6338, -1.4546, -1.2380, -0.7379, -0.6918, -0.9613, -0.3598,\n",
       "                       -1.5831, -0.8371, -1.1265, -1.0604,  0.1514, -0.6949, -0.5819, -1.1751,\n",
       "                       -0.2324, -0.4812, -1.5581, -1.2110, -0.6821, -0.0774,  0.0761, -0.3568,\n",
       "                       -1.0825,  0.0156, -1.3522,  0.1411, -0.6413, -1.0227, -1.0811,  0.2581,\n",
       "                       -0.0107, -1.1181, -0.4472, -1.0259, -0.6634, -0.4591, -1.0073, -1.1318,\n",
       "                       -1.4402, -0.5886, -0.6406, -0.6019, -1.1863, -1.0611, -1.4620, -0.8632,\n",
       "                       -0.5349, -0.6360, -0.9887, -0.8391, -0.8507, -1.1567,  0.3436, -0.7503,\n",
       "                        0.0183, -0.8542, -0.2742, -0.2343, -1.2881, -0.3078, -0.4423, -0.5510,\n",
       "                       -1.1691, -0.7615, -0.9654, -1.4036, -1.0135, -0.7267, -0.9817, -0.8880,\n",
       "                       -0.1728, -0.4717, -0.1931, -1.6550, -0.9044, -1.1736, -0.0353, -1.0467,\n",
       "                       -0.2390, -0.8057, -1.2440, -0.6493, -0.6521, -0.8844, -0.4660, -0.9979,\n",
       "                       -0.5396, -1.2937, -0.8058, -1.2296, -0.9395, -0.6332, -1.2268, -0.6913,\n",
       "                       -1.4897, -0.5551, -0.5045, -1.0196, -0.2041, -0.9398, -1.2604, -0.8007,\n",
       "                       -1.1281, -1.1142, -0.7869, -1.1085, -0.7263, -0.4145, -1.3053, -1.1609,\n",
       "                       -0.9306, -1.1004, -0.8594, -1.2058,  0.9415, -1.0117, -0.7687, -0.0129,\n",
       "                       -1.0470, -1.2046, -1.1287, -0.3440, -1.1676, -0.6972,  0.3473, -0.1519,\n",
       "                       -0.3362, -0.8835,  0.1180, -0.8376, -1.2485, -0.7013, -1.0142, -0.7589,\n",
       "                       -0.2093, -0.1391, -0.9705, -0.6480, -1.3223, -0.7364, -1.3715, -1.5359,\n",
       "                       -0.3042, -0.9623, -0.5426, -0.5609, -0.4426, -0.5699, -0.9749, -0.5209,\n",
       "                       -1.1681, -0.9142, -1.6702, -0.5097, -0.6839, -1.2565, -0.5928,  0.4252,\n",
       "                       -0.8396, -0.5323, -0.7695, -1.2354, -0.6405, -1.4305, -0.2918, -0.5303,\n",
       "                       -0.8400, -0.9835, -0.6259, -0.5637, -1.1390, -0.7785, -0.6167, -1.0564,\n",
       "                        0.0438, -0.0505, -0.6951, -1.1755, -0.9657, -0.7693, -1.0127, -0.6964,\n",
       "                       -1.1553, -0.7710, -0.3285, -1.4341, -1.1022, -1.0861,  0.2122, -0.9502,\n",
       "                       -0.6396, -1.3398, -1.1113, -1.2285, -0.7216, -1.1543, -0.6267, -0.8840,\n",
       "                       -1.4275, -1.5115, -0.4841, -0.3215,  0.2109, -1.2314, -0.5289, -0.5380,\n",
       "                       -0.4364, -0.4536, -1.1731, -0.8794, -0.8709, -0.9078, -0.4825, -0.7674,\n",
       "                       -1.0125, -0.6244, -0.7520, -0.5408, -0.7300, -0.4568, -0.7902, -0.9425,\n",
       "                       -1.3313, -0.5441, -1.1124, -0.0519, -1.0274,  0.4624, -0.7517, -0.9410,\n",
       "                       -0.6378, -0.6886, -0.9014, -0.4221, -0.7705,  0.0458, -1.1577, -0.8056,\n",
       "                       -0.9355, -1.0129, -0.5279, -0.6462, -0.8429, -0.7074, -0.7813, -1.0963,\n",
       "                       -1.1411, -0.1596, -1.1750, -0.6704, -0.1525, -0.6518, -0.3870, -1.6457,\n",
       "                       -1.4514, -0.9246, -1.4622, -0.8931, -0.6728, -1.3456, -1.3150, -0.3717,\n",
       "                       -0.7394, -1.0124, -1.0485, -1.0104, -0.3068,  0.0512, -0.9007, -1.1474,\n",
       "                       -0.6559, -0.1579, -1.7170, -0.3646, -0.8717, -0.7715, -0.5217, -0.9776,\n",
       "                       -1.0628, -1.2957, -0.7993, -1.1845, -1.2013, -1.0065, -0.7984,  0.5514,\n",
       "                       -1.2941, -0.5362, -0.2665, -0.0870, -1.7779, -0.8729, -0.6059, -1.5332,\n",
       "                       -0.9438, -0.3210,  0.0535, -0.9648, -0.9839, -0.7701, -0.9354, -0.9107,\n",
       "                       -0.5921, -0.7735, -0.4518, -0.6274, -0.5274, -0.5484, -1.3487, -0.6762,\n",
       "                       -0.0556, -0.1732, -0.4954, -0.5916,  0.1872, -0.8241, -1.4144, -1.1848,\n",
       "                        0.7636, -0.7742, -0.1569, -0.2926, -0.8264, -1.0016, -0.4938, -1.7448,\n",
       "                       -0.6541, -0.8436,  0.0241, -1.1752, -1.1527, -0.5971, -1.0060, -0.5348,\n",
       "                       -1.3813, -0.8260, -0.8902, -1.3328, -0.9135, -1.2484, -0.9477, -0.6387,\n",
       "                       -1.3186, -0.6700, -1.3476, -0.9709, -0.8882, -0.8235, -1.0125, -1.3480,\n",
       "                       -0.8443, -0.4270, -1.4075, -0.2160, -0.5962, -1.5651, -0.6529, -1.3021,\n",
       "                        0.1697, -0.7425, -1.3251, -1.0372, -0.0230, -0.7033, -0.1222, -0.8138,\n",
       "                       -0.2724, -0.8037, -1.1089, -1.1804, -0.9799, -1.3641, -0.6925, -0.9956,\n",
       "                       -0.8505, -1.2502, -1.1851, -0.8827, -1.0225, -0.9394, -1.2809, -1.0839,\n",
       "                       -0.3057, -1.2447, -1.1125, -1.1422, -0.7736, -0.8205, -0.0603, -1.1858,\n",
       "                       -0.8311, -0.9695, -0.8970, -1.2232, -0.7295, -0.8295, -1.2198, -0.3725,\n",
       "                       -0.7665, -1.3057, -0.2269, -0.5342, -1.0116, -1.1384, -1.1763, -0.7448,\n",
       "                       -0.9900, -1.0503, -0.6111,  0.2078, -0.8768, -0.6855, -1.1599, -0.3234],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn2.running_var',\n",
       "               tensor([2.7817, 2.4107, 2.2481, 2.6888, 2.5401, 2.1771, 2.7626, 2.7420, 2.2280,\n",
       "                       2.3840, 2.0522, 1.9204, 2.5703, 2.2318, 3.0342, 2.0903, 1.9943, 1.8139,\n",
       "                       2.6097, 2.0736, 2.5001, 2.3519, 2.3152, 2.4777, 2.2390, 2.1057, 2.5666,\n",
       "                       2.4257, 2.7526, 2.9825, 2.3634, 2.1363, 2.4035, 1.9778, 2.8664, 1.8988,\n",
       "                       1.9308, 2.2968, 2.3311, 2.5959, 2.2494, 2.4369, 2.4852, 2.7002, 2.5216,\n",
       "                       2.6872, 2.6935, 2.5938, 2.4851, 2.7572, 2.3063, 2.9251, 2.4561, 2.1818,\n",
       "                       3.4731, 1.7274, 2.2674, 2.1327, 2.9773, 1.8521, 2.9483, 2.3714, 2.4203,\n",
       "                       2.3242, 2.3501, 2.0417, 2.8286, 2.6511, 2.2299, 1.8473, 1.6440, 2.7197,\n",
       "                       2.6115, 1.9819, 3.3267, 2.5756, 1.8159, 2.5222, 2.0410, 2.3067, 2.1728,\n",
       "                       2.4803, 2.6829, 1.8544, 2.4654, 2.4984, 3.1674, 2.6577, 2.5060, 2.5275,\n",
       "                       1.8526, 2.5614, 2.0925, 2.3313, 2.3442, 1.9981, 2.3335, 2.6356, 3.0448,\n",
       "                       2.2802, 2.8993, 2.0501, 2.1128, 2.1786, 2.9604, 2.3321, 2.7168, 2.6219,\n",
       "                       2.0230, 1.5691, 2.4659, 2.3601, 2.3292, 2.3373, 3.1344, 2.6851, 1.9070,\n",
       "                       2.1133, 2.5907, 2.1377, 2.4162, 1.7578, 2.4766, 1.8961, 2.2045, 2.8842,\n",
       "                       2.8231, 2.1698, 1.7989, 2.9317, 2.3907, 2.0863, 2.4468, 2.0149, 2.8803,\n",
       "                       8.4976, 3.4991, 2.3372, 2.2153, 1.7549, 2.6806, 2.2518, 3.4844, 2.2743,\n",
       "                       2.2599, 2.1239, 2.4044, 2.1830, 2.8912, 2.8484, 2.3537, 2.3378, 1.9273,\n",
       "                       2.2464, 2.0601, 2.3550, 2.8287, 2.4382, 2.2663, 2.2513, 2.4727, 2.2627,\n",
       "                       2.3162, 2.4568, 2.8422, 2.1836, 2.7963, 1.7795, 2.0522, 1.8915, 1.9813,\n",
       "                       2.2655, 2.1869, 2.6454, 1.8867, 1.9511, 2.1924, 3.0580, 3.0571, 2.3773,\n",
       "                       2.5196, 2.3585, 2.3464, 2.6267, 2.1521, 2.5807, 2.9983, 2.9835, 2.1126,\n",
       "                       2.1647, 2.8261, 2.3844, 2.8533, 2.3163, 2.3439, 1.9443, 2.1381, 2.5109,\n",
       "                       2.8185, 2.1357, 2.4182, 2.9807, 2.3837, 2.4186, 2.1172, 2.3625, 2.6728,\n",
       "                       2.6503, 2.6505, 2.0528, 2.5232, 2.8581, 1.9297, 2.2025, 2.2609, 2.1669,\n",
       "                       1.8836, 2.3585, 2.2139, 2.1238, 2.4204, 2.3759, 1.8962, 2.0138, 2.3030,\n",
       "                       2.0999, 2.0713, 2.5397, 2.6099, 2.2639, 2.5491, 2.1062, 2.0553, 1.8898,\n",
       "                       2.8868, 2.2317, 5.2983, 2.1420, 2.4795, 2.6051, 3.0907, 2.4510, 2.1829,\n",
       "                       2.3210, 2.1408, 1.7707, 2.4208, 2.4526, 2.1884, 2.4541, 3.1123, 3.3754,\n",
       "                       2.1075, 2.9575, 2.2382, 1.9428, 2.6136, 1.8784, 2.4276, 2.3880, 2.0158,\n",
       "                       2.4571, 1.9250, 2.4053, 2.2928, 2.7640, 2.0365, 3.2271, 2.0758, 3.2832,\n",
       "                       3.2426, 2.1684, 2.0152, 2.1248, 2.4960, 2.3491, 2.3277, 2.3778, 2.6797,\n",
       "                       2.6143, 2.2800, 2.6570, 2.5360, 2.7488, 2.2936, 2.7311, 1.9556, 2.4344,\n",
       "                       1.9416, 2.8043, 2.6548, 2.5894, 2.5601, 2.5524, 2.1106, 2.9576, 2.4176,\n",
       "                       2.7820, 1.9689, 2.1181, 2.1239, 3.0316, 2.0894, 2.3971, 2.4220, 2.1642,\n",
       "                       2.1325, 2.1252, 3.3709, 2.6464, 2.1053, 2.0707, 2.6930, 2.3118, 2.9240,\n",
       "                       2.2899, 2.0201, 2.0749, 2.4198, 2.0865, 2.9612, 2.6991, 2.6441, 2.5848,\n",
       "                       2.4132, 1.8939, 2.1724, 2.3801, 2.6568, 2.0014, 1.8755, 2.5298, 2.2081,\n",
       "                       2.1686, 2.6248, 2.7277, 2.6357, 2.4331, 2.2787, 2.2388, 2.6035, 2.0166,\n",
       "                       2.0817, 2.5718, 2.1666, 2.0559, 2.9363, 2.1661, 2.0381, 1.9637, 2.3571,\n",
       "                       3.2500, 2.3004, 2.4129, 2.5071, 2.0028, 2.9707, 3.6241, 2.9436, 2.1216,\n",
       "                       2.5377, 2.7952, 2.5896, 2.1834, 1.9278, 1.9694, 2.9781, 2.3790, 2.3016,\n",
       "                       1.8455, 3.1040, 2.0435, 2.5856, 2.6613, 1.8902, 3.0544, 2.3483, 2.4961,\n",
       "                       2.5368, 2.3103, 2.5835, 2.9158, 1.3681, 2.1140, 2.5076, 1.9969, 2.1950,\n",
       "                       2.4380, 3.7761, 2.1508, 2.6132, 2.7687, 2.6912, 1.9699, 2.0812, 2.5875,\n",
       "                       2.6239, 2.2648, 2.6921, 2.2751, 2.2931, 2.2607, 2.0200, 1.9399, 2.4901,\n",
       "                       1.6547, 2.9418, 2.5490, 1.9951, 2.0876, 1.9925, 2.3308, 2.0049, 1.9756,\n",
       "                       2.3374, 2.6315, 9.3075, 2.5593, 2.0711, 2.1477, 2.5105, 2.3684, 2.1321,\n",
       "                       2.7006, 2.7564, 2.3444, 1.9753, 2.2473, 2.6006, 2.1058, 2.9399, 2.5180,\n",
       "                       3.6401, 2.2543, 2.5760, 2.6850, 2.4183, 2.6764, 2.4806, 2.3471, 2.4078,\n",
       "                       2.1271, 2.7856, 2.1443, 2.4205, 2.2015, 2.5474, 2.7527, 2.5831, 2.0952,\n",
       "                       2.3465, 2.0953, 2.5493, 3.1169, 2.4468, 2.4103, 2.0835, 2.0015, 3.2707,\n",
       "                       2.4329, 1.5737, 2.7416, 2.0308, 2.6415, 2.3267, 2.6023, 1.8403, 2.8472,\n",
       "                       2.2928, 2.6599, 2.3801, 2.5648, 2.5031, 2.8025, 2.7758, 2.1548, 2.0939,\n",
       "                       2.0506, 2.8920, 2.5791, 1.8043, 2.6978, 2.7304, 2.6844, 1.8662, 2.6515,\n",
       "                       1.8579, 3.3160, 2.1489, 2.3481, 2.9287, 2.5865, 2.3629, 2.0594, 2.3663,\n",
       "                       2.0948, 2.1519, 2.9944, 2.3841, 2.2013, 2.8042, 2.5176, 2.7683, 2.3421,\n",
       "                       2.0245, 1.9030, 1.8075, 2.0333, 2.7525, 2.3211, 2.4496, 2.1496],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.0.conv3.weight',\n",
       "               tensor([[[[-0.0028]],\n",
       "               \n",
       "                        [[-0.0060]],\n",
       "               \n",
       "                        [[-0.0232]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0056]],\n",
       "               \n",
       "                        [[ 0.0189]],\n",
       "               \n",
       "                        [[-0.0069]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0194]],\n",
       "               \n",
       "                        [[ 0.0713]],\n",
       "               \n",
       "                        [[ 0.0255]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0014]],\n",
       "               \n",
       "                        [[ 0.0231]],\n",
       "               \n",
       "                        [[ 0.0141]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0179]],\n",
       "               \n",
       "                        [[ 0.0333]],\n",
       "               \n",
       "                        [[ 0.0209]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0302]],\n",
       "               \n",
       "                        [[ 0.0152]],\n",
       "               \n",
       "                        [[-0.0308]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0391]],\n",
       "               \n",
       "                        [[ 0.0093]],\n",
       "               \n",
       "                        [[-0.0108]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0214]],\n",
       "               \n",
       "                        [[ 0.0032]],\n",
       "               \n",
       "                        [[-0.0720]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0173]],\n",
       "               \n",
       "                        [[-0.0048]],\n",
       "               \n",
       "                        [[ 0.0230]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0016]],\n",
       "               \n",
       "                        [[-0.0248]],\n",
       "               \n",
       "                        [[ 0.0981]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0339]],\n",
       "               \n",
       "                        [[-0.0473]],\n",
       "               \n",
       "                        [[ 0.0176]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0055]],\n",
       "               \n",
       "                        [[-0.0014]],\n",
       "               \n",
       "                        [[-0.0085]]]], device='cuda:0')),\n",
       "              ('module.layer4.0.bn3.weight',\n",
       "               tensor([3.4003, 2.3378, 2.7563,  ..., 3.2989, 3.5372, 2.7936], device='cuda:0')),\n",
       "              ('module.layer4.0.bn3.bias',\n",
       "               tensor([-2.7040, -1.2675, -2.3707,  ..., -2.7784, -3.5187, -2.1350],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn3.running_mean',\n",
       "               tensor([-0.4010,  0.5222,  0.1642,  ..., -0.8345, -1.0756,  0.4349],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.bn3.running_var',\n",
       "               tensor([0.4395, 0.4344, 0.5263,  ..., 0.5195, 0.6390, 0.3690], device='cuda:0')),\n",
       "              ('module.layer4.0.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.0.downsample.0.weight',\n",
       "               tensor([[[[ 0.0143]],\n",
       "               \n",
       "                        [[-0.0187]],\n",
       "               \n",
       "                        [[-0.0231]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0226]],\n",
       "               \n",
       "                        [[ 0.0282]],\n",
       "               \n",
       "                        [[ 0.0192]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0341]],\n",
       "               \n",
       "                        [[-0.0241]],\n",
       "               \n",
       "                        [[ 0.0768]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0262]],\n",
       "               \n",
       "                        [[ 0.0270]],\n",
       "               \n",
       "                        [[-0.0214]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0199]],\n",
       "               \n",
       "                        [[ 0.0234]],\n",
       "               \n",
       "                        [[-0.0145]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0079]],\n",
       "               \n",
       "                        [[ 0.0331]],\n",
       "               \n",
       "                        [[-0.0409]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0667]],\n",
       "               \n",
       "                        [[-0.0689]],\n",
       "               \n",
       "                        [[ 0.0120]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0099]],\n",
       "               \n",
       "                        [[-0.0367]],\n",
       "               \n",
       "                        [[-0.0212]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0315]],\n",
       "               \n",
       "                        [[ 0.0084]],\n",
       "               \n",
       "                        [[ 0.0351]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0011]],\n",
       "               \n",
       "                        [[ 0.0289]],\n",
       "               \n",
       "                        [[ 0.0283]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0639]],\n",
       "               \n",
       "                        [[ 0.0251]],\n",
       "               \n",
       "                        [[-0.0185]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0059]],\n",
       "               \n",
       "                        [[-0.0037]],\n",
       "               \n",
       "                        [[ 0.0281]]]], device='cuda:0')),\n",
       "              ('module.layer4.0.downsample.1.weight',\n",
       "               tensor([1.9745, 2.1314, 2.4899,  ..., 2.2553, 2.4982, 2.2552], device='cuda:0')),\n",
       "              ('module.layer4.0.downsample.1.bias',\n",
       "               tensor([-2.7040, -1.2675, -2.3707,  ..., -2.7784, -3.5187, -2.1350],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.downsample.1.running_mean',\n",
       "               tensor([ 0.5705, -0.6058,  0.0760,  ..., -0.1024, -0.5070,  0.5048],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.0.downsample.1.running_var',\n",
       "               tensor([0.2875, 0.5161, 0.6124,  ..., 0.4523, 0.6549, 0.4333], device='cuda:0')),\n",
       "              ('module.layer4.0.downsample.1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.1.conv1.weight',\n",
       "               tensor([[[[-0.0313]],\n",
       "               \n",
       "                        [[ 0.0063]],\n",
       "               \n",
       "                        [[ 0.0132]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0559]],\n",
       "               \n",
       "                        [[-0.0225]],\n",
       "               \n",
       "                        [[ 0.0458]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0073]],\n",
       "               \n",
       "                        [[-0.0142]],\n",
       "               \n",
       "                        [[ 0.0257]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0601]],\n",
       "               \n",
       "                        [[-0.0292]],\n",
       "               \n",
       "                        [[-0.0088]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0010]],\n",
       "               \n",
       "                        [[-0.0314]],\n",
       "               \n",
       "                        [[-0.0041]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0377]],\n",
       "               \n",
       "                        [[-0.0005]],\n",
       "               \n",
       "                        [[-0.0008]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0025]],\n",
       "               \n",
       "                        [[-0.0109]],\n",
       "               \n",
       "                        [[ 0.0228]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0281]],\n",
       "               \n",
       "                        [[-0.0327]],\n",
       "               \n",
       "                        [[ 0.0142]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0238]],\n",
       "               \n",
       "                        [[ 0.0207]],\n",
       "               \n",
       "                        [[-0.0072]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0324]],\n",
       "               \n",
       "                        [[-0.0605]],\n",
       "               \n",
       "                        [[-0.0402]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0307]],\n",
       "               \n",
       "                        [[-0.0365]],\n",
       "               \n",
       "                        [[-0.0474]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0088]],\n",
       "               \n",
       "                        [[-0.0043]],\n",
       "               \n",
       "                        [[ 0.0227]]]], device='cuda:0')),\n",
       "              ('module.layer4.1.bn1.weight',\n",
       "               tensor([1.3025, 1.7469, 1.2354, 2.0333, 1.9025, 1.4729, 1.5222, 1.3373, 1.2763,\n",
       "                       1.1639, 1.3096, 1.4580, 1.6065, 1.7456, 2.6976, 1.1790, 1.5863, 1.3488,\n",
       "                       1.8437, 1.3365, 1.2074, 1.1925, 1.5489, 1.5581, 1.2555, 1.0436, 1.5695,\n",
       "                       2.1245, 1.5017, 1.5199, 1.3874, 1.6139, 1.5155, 1.7030, 1.3971, 1.0690,\n",
       "                       1.3720, 1.3957, 1.8827, 1.1030, 1.7965, 1.3729, 1.5208, 1.2869, 1.2036,\n",
       "                       1.7485, 1.7221, 1.1636, 1.6256, 1.3690, 1.7006, 1.4620, 0.8388, 1.1530,\n",
       "                       1.4514, 1.9967, 2.1421, 1.3758, 1.2387, 1.5402, 1.1066, 1.1471, 1.6914,\n",
       "                       1.4788, 1.5299, 1.3363, 1.8056, 1.6644, 1.1260, 1.2124, 1.5501, 1.1659,\n",
       "                       1.4339, 1.4055, 1.6534, 1.7571, 1.3300, 1.6846, 1.8666, 1.3494, 1.4160,\n",
       "                       1.4820, 1.2385, 1.6235, 1.6494, 1.7818, 1.3521, 2.3186, 2.0665, 1.7301,\n",
       "                       1.4959, 1.6320, 1.5482, 1.2294, 3.0516, 1.3638, 1.7155, 1.0610, 2.2648,\n",
       "                       1.0863, 1.4460, 2.7067, 1.2052, 1.1057, 1.3072, 1.2855, 1.2228, 1.3821,\n",
       "                       1.7436, 1.6470, 1.0504, 1.1526, 1.0759, 2.9910, 1.4360, 1.5521, 1.2022,\n",
       "                       1.4141, 1.7975, 1.2001, 1.2717, 1.1346, 1.5079, 2.7010, 1.6063, 1.0602,\n",
       "                       1.0332, 1.7840, 1.2975, 1.4072, 1.4970, 1.4418, 1.8114, 1.9756, 2.5000,\n",
       "                       1.4402, 1.2452, 1.1594, 1.8234, 1.3591, 1.1973, 1.6718, 1.3078, 1.5812,\n",
       "                       2.1111, 1.2229, 1.3860, 2.8090, 1.2500, 1.1933, 1.0036, 1.6257, 1.5044,\n",
       "                       1.4206, 1.0893, 1.7827, 1.4055, 1.2207, 1.3768, 1.4634, 1.2912, 1.7924,\n",
       "                       1.2490, 1.1426, 1.2592, 1.4623, 1.3244, 1.0761, 1.5064, 1.5971, 1.2380,\n",
       "                       1.3254, 1.8029, 1.2861, 1.5718, 1.2921, 1.0341, 1.4815, 2.7138, 1.4851,\n",
       "                       1.6464, 1.6145, 1.2877, 1.1902, 1.2355, 1.2385, 1.1936, 1.1884, 1.7280,\n",
       "                       1.8241, 1.7294, 1.2191, 1.1291, 1.3334, 1.1946, 1.1167, 1.4569, 1.2842,\n",
       "                       2.0011, 1.6271, 1.4737, 0.9785, 1.8814, 1.4941, 1.2849, 1.4454, 1.3155,\n",
       "                       1.2209, 1.6674, 1.6331, 1.0149, 2.4831, 1.3003, 1.2067, 1.4128, 1.0091,\n",
       "                       1.3436, 1.5917, 1.7033, 1.1308, 1.2685, 1.2091, 1.5119, 1.3939, 1.5741,\n",
       "                       1.3736, 2.5786, 1.2483, 1.2567, 1.5990, 1.3645, 1.9444, 1.0691, 1.4460,\n",
       "                       1.4751, 1.6217, 1.5823, 1.5232, 1.3583, 1.3623, 1.1276, 0.9610, 1.4370,\n",
       "                       1.5350, 1.2043, 1.4548, 1.7325, 0.7132, 2.4821, 1.3003, 1.3486, 1.4911,\n",
       "                       1.4205, 1.4417, 1.2591, 2.5635, 1.0554, 1.5884, 2.0025, 1.0028, 1.5653,\n",
       "                       1.5172, 1.4669, 1.8290, 1.5778, 1.7223, 1.2794, 1.0391, 1.5047, 1.0301,\n",
       "                       1.4218, 1.3530, 1.4318, 1.3562, 1.3846, 1.4380, 1.5524, 1.2983, 1.3165,\n",
       "                       1.9957, 1.2441, 1.6923, 1.1378, 1.2027, 1.3981, 0.8527, 1.1553, 1.6853,\n",
       "                       1.3456, 1.2441, 1.3079, 1.9823, 1.7126, 1.3781, 1.4525, 1.4541, 1.5479,\n",
       "                       1.3374, 1.3105, 1.2350, 1.4878, 1.7040, 1.4004, 1.3722, 1.2003, 1.7597,\n",
       "                       1.3188, 1.4737, 1.1905, 1.3130, 1.8954, 1.3961, 1.3192, 1.1967, 1.6450,\n",
       "                       1.3930, 1.9575, 1.7561, 1.6925, 1.2777, 1.2538, 1.2233, 1.3811, 1.7147,\n",
       "                       1.5380, 1.5533, 2.0075, 2.8700, 2.3028, 1.6251, 1.1850, 1.4593, 1.3418,\n",
       "                       1.3786, 1.4411, 1.5941, 1.2072, 1.2045, 1.5093, 1.4338, 1.0930, 1.5199,\n",
       "                       1.3693, 1.3949, 1.1985, 2.0442, 1.4390, 1.3670, 1.3527, 1.0723, 1.6635,\n",
       "                       1.2638, 1.4502, 2.5344, 1.2446, 1.0396, 1.6853, 1.4310, 1.5228, 1.3518,\n",
       "                       1.4246, 1.7641, 1.7815, 1.6034, 1.6465, 1.2853, 1.0841, 1.1782, 1.2464,\n",
       "                       1.3597, 1.8922, 1.5601, 1.4970, 1.2405, 1.4763, 2.9728, 2.5759, 1.0483,\n",
       "                       2.2982, 1.5187, 1.8761, 1.8410, 1.3620, 1.7116, 1.3789, 1.6586, 1.6143,\n",
       "                       1.3992, 1.6024, 1.2821, 1.8035, 0.9761, 2.0353, 1.9028, 0.8075, 1.2944,\n",
       "                       1.9241, 1.5756, 1.7188, 1.4384, 1.3740, 1.9081, 1.6664, 1.7098, 1.5863,\n",
       "                       1.5436, 1.3349, 2.2872, 1.4207, 1.3240, 1.3569, 1.1521, 1.4692, 1.7719,\n",
       "                       1.7980, 1.4839, 1.1966, 1.6556, 1.8727, 1.4886, 1.1709, 1.4890, 1.2119,\n",
       "                       1.4570, 1.0661, 1.8756, 1.3235, 1.5891, 2.2289, 1.4550, 1.5659, 1.5327,\n",
       "                       1.2775, 1.5048, 1.8179, 1.6828, 0.6388, 1.0413, 1.0650, 1.1978, 1.0592,\n",
       "                       1.4701, 1.1564, 1.1231, 1.8948, 1.9262, 1.7123, 1.1315, 1.5587, 1.4093,\n",
       "                       1.3181, 1.7093, 1.3176, 1.2996, 1.1606, 1.3433, 1.3349, 1.3081, 1.4179,\n",
       "                       1.1435, 1.1454, 0.7907, 2.0188, 1.2939, 1.6068, 1.4370, 1.4939, 1.4641,\n",
       "                       1.1072, 1.2402, 1.2350, 1.3755, 1.2583, 1.6519, 1.0514, 1.3456, 1.3224,\n",
       "                       1.3095, 1.0930, 1.3467, 1.9543, 1.4657, 1.1238, 2.5965, 1.9748, 1.6144,\n",
       "                       0.9610, 1.8227, 1.2314, 1.9073, 1.3948, 1.4227, 1.6246, 1.5402, 1.6262,\n",
       "                       1.7530, 1.4613, 1.0928, 1.3004, 1.4598, 1.6208, 1.5593, 1.0770, 1.1379,\n",
       "                       1.2424, 1.2895, 1.3483, 1.5264, 1.6155, 1.1942, 1.0166, 1.3896],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn1.bias',\n",
       "               tensor([-0.8016, -1.5869, -0.8956, -1.6900, -1.3146, -1.0076, -1.3229, -0.8211,\n",
       "                       -0.8558, -0.4344, -0.7268, -1.2739, -1.0699, -1.5736, -3.0783, -0.3065,\n",
       "                       -1.1763, -0.9630, -1.3059, -1.0114, -0.4439, -0.3647, -1.0756, -1.5476,\n",
       "                       -0.6067, -0.1650, -1.4277, -2.2654, -1.0833, -0.9712, -1.0332, -0.7253,\n",
       "                       -1.0027, -1.5064, -0.9063, -0.1439, -0.2320, -0.9860, -1.5645, -0.3813,\n",
       "                       -1.3564, -0.7806, -0.9716, -0.6552, -0.5397, -1.5454, -1.5056, -0.4007,\n",
       "                       -1.4850, -1.0812, -1.6430, -1.1664,  0.1459, -0.3489, -0.9505, -2.0152,\n",
       "                       -2.1499, -0.7951, -0.6331, -0.9519,  0.1054, -0.4111, -1.5426, -0.8976,\n",
       "                       -0.7634, -1.0021, -1.5596, -1.3834, -0.2410, -0.5136,  0.6169, -0.3835,\n",
       "                       -1.0320, -0.8211, -1.4594, -1.3309, -0.8840, -1.4947, -1.4513, -0.8391,\n",
       "                       -0.8602, -1.3428, -0.6758, -0.9083, -0.6333, -0.8582, -0.6216, -2.4058,\n",
       "                       -1.9023, -1.1681, -0.5920, -1.0531, -1.6245, -0.6765, -3.7947, -0.9038,\n",
       "                       -1.8079, -0.0518, -2.1951, -0.4115, -1.2211, -2.9739, -0.6162, -0.1693,\n",
       "                       -0.4581, -0.6607, -0.6408, -0.7925, -1.8590, -1.4223, -0.0577, -0.4938,\n",
       "                       -0.1734, -3.6527, -0.8323, -1.0662, -0.4374, -1.2293, -1.4868, -0.4741,\n",
       "                       -0.7902, -0.3325, -1.2704, -2.8488, -1.4026, -0.1874, -0.2867, -1.4762,\n",
       "                       -0.8275, -0.8509, -1.0437, -1.0964, -1.2940, -1.7480, -2.7937, -0.8626,\n",
       "                       -0.4154, -0.2675, -1.5258, -0.7090, -0.4470, -1.3323, -0.8958, -1.1859,\n",
       "                       -1.9774, -0.4438, -0.8061, -3.1588, -0.3928, -0.3620,  0.0412, -1.3018,\n",
       "                       -1.0836, -0.8741, -0.3424, -1.6201, -0.8145, -0.4292, -0.5019, -1.0118,\n",
       "                       -0.2944, -1.6726, -0.6490, -0.3624, -0.5445, -1.0058, -0.6473, -0.4221,\n",
       "                       -1.0504, -1.3061, -0.5015, -0.6968, -0.9213, -0.6728, -0.9424, -0.7237,\n",
       "                       -0.0762, -0.8372, -3.1095, -1.1212, -1.5275, -1.5075, -0.6448, -0.5789,\n",
       "                       -0.4827, -0.5350, -0.4694, -0.4065, -0.8807, -2.0888, -1.2040, -0.8294,\n",
       "                       -0.3451, -0.6849, -0.4921, -0.4679, -0.3094, -0.6828, -1.8145, -1.3458,\n",
       "                       -1.3631, -0.0206, -1.8016, -1.1407, -0.7232, -1.3532, -0.6931, -0.6907,\n",
       "                       -1.2286, -1.2537, -0.1415, -2.8022, -0.7405, -0.5314, -1.0198, -0.1751,\n",
       "                       -0.6482, -1.0372, -1.5599, -0.3570, -0.6344, -0.3298, -1.3153, -0.8747,\n",
       "                       -1.1949, -0.8284, -2.9126, -0.6227, -0.7173, -1.7537, -0.9591, -1.7954,\n",
       "                       -0.1434, -0.8972, -0.9674, -1.0963, -1.3672, -1.1368, -0.8868, -0.3517,\n",
       "                       -0.3429,  0.0678, -0.8979, -1.2412, -0.5758, -0.1463, -1.6012,  1.2318,\n",
       "                       -2.8506, -0.4711, -0.8512, -0.7406, -0.9487, -1.1250, -0.5659, -2.9151,\n",
       "                        0.0098, -1.2848, -2.0696, -0.1825, -0.9639, -0.9880, -0.9168, -0.9054,\n",
       "                       -1.1396, -1.4259, -0.5373, -0.1878, -0.8638, -0.1904, -0.8050, -0.7196,\n",
       "                       -1.0037, -0.9325, -1.0714, -1.0724, -1.0566, -0.9232, -0.8487, -1.7383,\n",
       "                       -0.2748, -1.1561, -0.3118, -0.1409, -0.8597,  0.1092, -0.1946, -1.5512,\n",
       "                       -0.7603, -0.6081, -0.6240, -0.4933, -1.7349, -0.9148, -0.8754, -0.8264,\n",
       "                       -1.0810, -0.0786, -0.9177, -0.7840, -0.8446, -1.3799, -0.7095, -0.8883,\n",
       "                       -0.2467, -1.4975, -0.9117, -0.8677, -0.6774, -0.7336, -1.5625, -0.7846,\n",
       "                       -0.6634, -0.5915, -1.1826, -0.8016, -1.1690, -1.1832, -1.5442, -0.5922,\n",
       "                       -0.5271, -0.4105, -0.9256, -1.6701, -1.3060, -1.2015, -1.8571, -3.5895,\n",
       "                       -1.1901, -1.6401, -0.4322, -1.0077, -0.8813, -0.7553, -1.1157, -1.5402,\n",
       "                       -0.8169, -0.6324, -1.1210, -0.8758, -0.2666, -1.3187, -0.6756, -1.0678,\n",
       "                       -0.6818, -1.8184, -0.5399, -0.6341, -0.7904, -0.1226, -1.5618, -0.6470,\n",
       "                       -1.0641, -2.8627,  0.0729, -0.1808, -1.3216,  0.0386,  0.7016, -0.8143,\n",
       "                       -1.0190, -1.8850, -1.6113, -0.4755, -1.4801, -0.7763, -0.3610, -0.4693,\n",
       "                       -0.6960, -0.7422, -1.7623, -1.1172, -1.5353, -0.6641, -1.2500, -3.5960,\n",
       "                       -2.8330, -0.1046, -2.5173, -0.9893, -1.4876, -1.6402, -1.0924, -1.4256,\n",
       "                       -0.7466, -1.2856, -1.2655, -0.9856, -0.8884, -0.8200, -1.5899,  0.0409,\n",
       "                       -1.8796, -1.9893,  0.4004, -0.6805, -2.0010, -1.3533, -1.3776, -1.1053,\n",
       "                       -0.8203, -1.8023, -1.4071, -1.3928, -1.1178, -0.7931, -1.2099, -2.2911,\n",
       "                       -0.9906, -0.1719, -0.9709, -0.3499, -0.8753, -1.3567, -0.9244, -1.1120,\n",
       "                       -0.5142, -1.0312, -0.5037, -1.0917, -0.3668, -1.0159, -0.6023, -1.1443,\n",
       "                       -0.0090, -1.8277, -0.6764, -1.3454, -0.3721, -1.1711, -0.2621, -0.9741,\n",
       "                       -0.4895, -1.2620, -2.1957, -1.3490,  0.9368, -0.1184,  1.0638, -0.6073,\n",
       "                        0.1135, -0.8036, -0.3613, -0.1240, -1.5976, -1.6858, -1.4903, -0.4178,\n",
       "                       -0.6567, -0.6902, -0.7457, -1.2398, -0.7918, -0.6987, -0.4165, -0.6334,\n",
       "                       -1.0901, -0.6714, -1.2219, -0.2461, -0.2929,  0.4318, -1.2010, -0.8351,\n",
       "                       -1.5305, -1.0714, -0.6151, -1.0348, -0.0066, -0.7870, -0.4858, -0.6784,\n",
       "                       -0.7301, -1.0942, -0.2372, -0.9427, -0.7109, -0.5637, -0.2392, -0.8376,\n",
       "                       -1.5786, -1.0888, -0.0200, -2.8661, -1.7378, -1.0072, -0.0563, -1.3499,\n",
       "                       -0.4811, -1.0197, -0.7482, -0.6820, -1.9012, -1.0572, -1.1814, -1.4348,\n",
       "                       -1.0617, -0.3189, -0.7796, -1.0974, -1.0037, -0.8111, -0.2936, -0.5445,\n",
       "                       -0.4283, -0.9474, -0.9115, -0.7086, -1.4113, -0.4169, -0.1947, -0.9344],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn1.running_mean',\n",
       "               tensor([-2.0602e+00, -1.5669e+00, -1.8380e+00, -2.8005e+00, -2.8692e+00,\n",
       "                       -1.3308e+00, -2.1459e+00, -8.3068e-01, -1.9552e+00, -1.4320e+00,\n",
       "                       -9.4377e-01, -1.8677e+00, -1.6803e+00, -2.2193e+00, -2.4555e+00,\n",
       "                       -2.2403e+00, -2.5006e+00, -1.1657e+00, -2.9252e+00, -9.9079e-01,\n",
       "                       -1.5398e+00, -2.4408e+00, -2.3224e+00, -1.5140e+00, -1.4671e+00,\n",
       "                       -2.5271e+00, -1.1243e+00, -1.6026e+00, -1.0527e-01, -1.7889e+00,\n",
       "                       -8.7463e-01,  1.0937e-01, -1.4687e+00, -2.0716e+00, -1.2748e+00,\n",
       "                       -1.9340e+00, -1.6457e+00, -1.1691e+00, -2.0023e+00, -1.9666e+00,\n",
       "                       -2.8896e+00, -1.3983e+00, -3.1825e+00, -1.4805e+00, -2.2699e+00,\n",
       "                       -2.2839e+00, -1.5624e+00, -2.8402e+00, -1.6765e+00, -1.1336e+00,\n",
       "                       -9.5358e-01, -1.8081e+00, -4.5977e-01, -2.0111e+00, -1.9063e+00,\n",
       "                       -2.0535e+00, -2.4010e+00, -1.5897e+00, -1.1610e+00, -1.9508e+00,\n",
       "                       -2.6665e+00, -1.3356e+00, -1.8026e+00, -1.6458e+00, -1.0911e+00,\n",
       "                       -1.3228e+00, -1.9282e+00, -1.7995e+00, -1.4001e+00, -1.0983e+00,\n",
       "                       -2.9399e+00, -1.7738e+00, -2.6162e+00, -8.8648e-01, -2.1341e+00,\n",
       "                       -2.1658e+00, -1.7190e+00, -1.6935e+00, -2.8314e+00, -1.4481e+00,\n",
       "                       -1.8467e+00, -1.6918e+00, -1.0212e+00, -1.8590e+00, -8.0593e-01,\n",
       "                       -6.5804e-01, -3.1164e+00, -2.1803e+00, -1.9846e+00, -2.2588e+00,\n",
       "                        3.7882e+00, -1.9243e+00, -2.2270e+00, -1.2335e+00, -2.5988e+00,\n",
       "                       -1.3960e+00, -1.5887e+00,  5.1535e-01, -1.8769e+00, -2.0383e+00,\n",
       "                       -2.5965e+00, -3.2438e+00, -1.8084e+00, -3.2083e-01, -1.8497e+00,\n",
       "                       -1.7505e+00, -8.8763e-01, -1.8268e+00, -2.8845e+00, -2.3486e+00,\n",
       "                       -1.2552e+00,  8.0462e-01, -8.6751e-01, -2.7549e+00, -1.8652e+00,\n",
       "                       -2.6028e+00, -7.8143e-01,  4.2934e+00, -2.0761e+00, -1.6641e+00,\n",
       "                       -1.6062e+00, -1.3879e+00, -2.1302e+00, -2.4362e+00, -1.8412e+00,\n",
       "                       -1.1085e+00, -2.2323e+00, -1.8149e+00, -1.1962e+00, -1.3682e+00,\n",
       "                       -1.7713e+00, -1.0201e+00, -2.0240e+00, -1.8503e+00, -1.6082e+00,\n",
       "                       -1.6920e+00, -1.9711e+00, -1.8041e+00, -1.5496e+00, -1.1891e+00,\n",
       "                       -1.5829e+00, -2.0584e+00, -2.1160e+00, -1.7828e+00, -1.3485e+00,\n",
       "                       -1.3087e+00, -1.9912e+00, -2.2452e+00, -1.9960e+00, -1.4923e+00,\n",
       "                       -2.0937e+00, -1.2081e+00, -2.0561e+00, -1.7565e+00, -9.7059e-01,\n",
       "                       -2.6823e+00, -1.4071e+00, -2.5488e+00, -1.7364e+00, -1.2963e+00,\n",
       "                       -9.2071e-01, -1.5369e+00, -2.0333e+00, -1.7800e+00, -1.0679e+00,\n",
       "                       -1.6710e+00, -2.0699e+00, -1.1171e+00, -1.3411e+00, -2.1404e+00,\n",
       "                       -1.6564e+00, -2.4498e+00, -2.6519e-01, -1.9392e+00, -2.3163e+00,\n",
       "                       -1.5983e+00, -1.1603e+00, -1.8047e+00,  3.1602e+00, -1.9955e+00,\n",
       "                       -1.6536e+00, -1.4976e+00, -6.4653e-01, -1.3856e+00, -1.4417e+00,\n",
       "                       -1.6002e+00, -2.1031e+00, -1.2359e+00,  8.9032e-03, -1.5052e+00,\n",
       "                       -2.2497e+00, -1.3223e+00, -3.9683e-01, -2.6354e+00, -1.9329e+00,\n",
       "                       -1.6739e+00, -3.8639e+00, -1.9763e+00, -2.2280e+00, -1.1564e+00,\n",
       "                       -1.3766e+00, -1.7222e+00, -1.8896e+00, -2.2180e+00, -1.3154e+00,\n",
       "                       -1.1130e+00, -2.1832e+00, -1.2152e+00, -1.3624e+00, -2.1119e+00,\n",
       "                       -1.7127e+00, -1.5627e+00, -9.6426e-01, -1.7858e+00, -1.8146e+00,\n",
       "                       -1.2325e+00, -1.4239e+00, -2.5828e+00, -1.8471e+00, -1.4405e+00,\n",
       "                       -1.2122e+00, -1.9115e+00, -1.5546e+00, -1.8900e+00, -2.0244e+00,\n",
       "                       -1.7920e+00, -2.5770e+00, -1.6525e+00, -1.0231e+00, -1.3083e+00,\n",
       "                       -1.0134e+00, -2.5344e+00, -1.7553e+00, -1.7701e+00, -1.4083e+00,\n",
       "                       -2.1325e+00, -2.2877e+00, -1.1472e+00, -2.2457e-02, -1.3634e-01,\n",
       "                       -2.0179e+00, -6.9723e-01, -1.4495e+00, -1.7150e+00, -1.4396e+00,\n",
       "                       -2.3022e+00, -2.3559e+00, -7.1117e+00, -1.6068e+00, -1.7986e+00,\n",
       "                       -1.0068e+00, -1.6657e+00, -1.2006e+00, -1.9695e+00, -2.0223e+00,\n",
       "                       -2.1576e+00, -9.4891e-01, -1.2384e+00, -1.4584e+00, -1.3840e+00,\n",
       "                        1.3414e+00, -2.1088e+00, -1.9291e+00,  2.0509e+00, -1.4968e+00,\n",
       "                       -1.8274e+00, -5.6966e-02, -1.9942e+00, -1.2633e+00, -1.6611e+00,\n",
       "                       -2.0717e+00, -1.9279e+00, -1.9553e+00, -1.5506e+00, -1.9571e+00,\n",
       "                       -2.1590e+00, -2.1285e+00, -7.3239e-01, -2.2821e+00, -1.9930e+00,\n",
       "                       -1.7453e+00, -1.8576e+00, -1.6279e+00, -8.5366e-01, -1.4886e+00,\n",
       "                       -1.0632e+00, -1.9390e+00, -1.0581e+00, -1.8119e+00, -2.2697e+00,\n",
       "                       -1.8606e+00, -1.2098e+00, -1.6731e+00, -2.0729e+00, -1.7433e+00,\n",
       "                       -1.8509e+00, -1.8241e+00,  4.9277e-01, -2.0256e+00, -1.9728e+00,\n",
       "                       -1.5194e+00, -1.4671e+00, -1.2099e+00, -2.4658e+00, -1.9590e+00,\n",
       "                       -3.1864e+00, -1.5064e+00, -1.8773e+00, -1.1397e+00, -1.6067e+00,\n",
       "                       -1.8666e+00, -1.4481e+00, -1.1218e+00, -1.6133e+00, -2.0226e+00,\n",
       "                       -2.0739e+00, -1.7935e+00, -3.1801e+00, -1.6580e+00, -1.5792e+00,\n",
       "                       -1.9494e+00, -9.9980e-01, -1.9001e+00, -1.3974e+00, -9.4053e-01,\n",
       "                       -1.9277e+00, -1.7773e+00, -2.3832e+00, -3.1432e+00, -1.2411e+00,\n",
       "                       -2.2241e+00, -1.4099e+00, -2.2322e+00, -2.8486e+00, -1.3377e+00,\n",
       "                       -1.9673e+00, -1.3651e+00, -2.4186e+00, -1.6203e+00, -1.2292e+00,\n",
       "                       -1.2877e+00, -1.6520e+00, -1.4596e+00, -1.1217e+00, -1.7900e+00,\n",
       "                       -2.8569e+00, -2.0070e+00, -2.4272e+00, -1.0042e+00, -1.3167e+00,\n",
       "                       -2.2187e+00, -1.8589e+00, -2.4511e+00, -1.7886e+00,  4.1500e-01,\n",
       "                       -1.6287e+00, -2.2198e+00, -1.1514e+00, -5.9958e+00, -1.9365e+00,\n",
       "                       -1.1470e+00, -1.7774e+00, -1.8915e+00,  2.0353e+00, -1.7134e+00,\n",
       "                       -7.7549e-01, -1.6524e+00, -2.2094e+00, -1.5407e+00, -1.7453e+00,\n",
       "                       -2.3431e+00, -1.9325e+00, -2.5071e+00, -1.3088e+00, -1.5527e+00,\n",
       "                       -2.2578e+00, -2.3389e+00, -2.2968e+00, -2.2601e+00, -1.7521e+00,\n",
       "                        3.0166e-01, -2.0241e+00, -1.4969e+00, -1.8865e+00, -1.5819e+00,\n",
       "                       -1.9224e+00, -2.9524e+00, -1.4199e+00, -5.0029e-01, -2.0121e+00,\n",
       "                       -1.6628e+00, -1.3619e+00, -2.1016e+00, -1.8561e+00, -1.4030e+00,\n",
       "                       -1.6218e+00, -2.1515e+00, -1.6725e+00, -2.0048e+00, -1.9779e+00,\n",
       "                       -1.4779e+00, -2.6298e+00, -1.2082e+00, -1.7143e+00, -1.9872e+00,\n",
       "                       -2.0959e+00, -9.6009e-01, -2.1894e+00, -1.8147e+00, -2.2839e-01,\n",
       "                       -1.7034e+00, -1.8214e+00, -3.2441e+00, -1.9557e+00,  2.4667e-01,\n",
       "                       -2.3482e+00, -1.9970e+00, -9.9402e-01,  8.3740e-01, -2.2711e+00,\n",
       "                       -1.3403e+00, -1.8957e+00, -9.4837e-01, -1.9355e+00, -2.9769e+00,\n",
       "                       -3.0019e+00, -2.2735e+00, -2.0974e+00, -1.4803e+00, -2.2814e+00,\n",
       "                       -5.8911e-03, -1.5048e+00, -3.0406e+00, -1.9703e+00, -1.3617e+00,\n",
       "                       -1.7452e+00, -4.8734e+00, -1.3992e+00,  3.8660e+00, -1.3524e+00,\n",
       "                       -1.0290e+00, -1.7320e+00, -1.7695e+00, -2.2543e+00, -2.4620e+00,\n",
       "                       -1.9804e+00, -1.8790e+00, -1.1115e+00, -1.2180e+00, -1.9881e+00,\n",
       "                       -1.2808e+00, -2.0447e+00, -9.8562e-01, -1.9412e+00, -1.8159e+00,\n",
       "                       -1.5648e+00, -1.5345e+00, -1.6630e+00, -1.5177e+00, -1.3381e+00,\n",
       "                       -1.9271e+00, -2.3140e+00, -2.9804e+00, -1.6623e+00, -2.2375e+00,\n",
       "                       -6.1522e-01, -1.9421e+00, -1.8321e+00,  1.5393e+00, -1.2904e+00,\n",
       "                       -2.1302e+00, -1.0472e+00, -2.1835e+00, -1.8158e+00, -6.5528e-01,\n",
       "                       -1.4482e+00, -1.9286e+00, -1.3512e+00, -1.1421e+00, -1.5340e+00,\n",
       "                       -3.4104e+00, -1.3047e+00,  1.2643e-01, -2.3822e+00, -1.6628e+00,\n",
       "                       -1.6882e+00, -1.2337e+00, -3.3224e+00, -2.0262e+00,  5.9320e-01,\n",
       "                       -1.9073e+00, -1.1750e+00, -2.1032e+00, -1.5638e+00, -2.7437e+00,\n",
       "                       -2.3789e+00, -1.6016e+00, -2.1001e+00, -1.2231e+00, -2.8926e+00,\n",
       "                       -2.1301e+00, -1.8992e+00, -1.7151e+00, -7.7970e-01, -1.4128e+00,\n",
       "                       -1.8208e+00, -1.8689e+00, -7.2559e-01, -2.1460e+00, -1.1180e+00,\n",
       "                       -1.2164e+00, -1.1652e+00], device='cuda:0')),\n",
       "              ('module.layer4.1.bn1.running_var',\n",
       "               tensor([ 5.3565,  3.6605,  5.2588,  5.2308,  5.7786,  4.1962,  5.1311,  4.5637,\n",
       "                        5.4345,  5.9540,  4.8060,  4.4056,  4.6959,  5.1725,  4.0316,  7.1690,\n",
       "                        4.5055,  4.9821,  6.2731,  4.1596,  5.5612,  7.7282,  6.0826,  5.7456,\n",
       "                        5.1037,  6.8628,  5.4701,  4.2459,  5.1216,  4.9277,  4.1469, 10.4116,\n",
       "                        5.1634,  5.6931,  4.8225,  5.3728, 13.0311,  4.1096,  5.4076,  5.7337,\n",
       "                        5.6881,  4.6612,  7.0221,  5.6620,  4.9355,  5.2092,  4.4068,  6.6513,\n",
       "                        4.4009,  4.4394,  4.0637,  4.6691,  5.2031,  6.0498,  4.7610,  4.2961,\n",
       "                        5.8449,  4.7652,  4.8798,  5.4164,  9.1210,  6.4000,  4.1330,  5.4585,\n",
       "                        9.9941,  4.3868,  4.8854,  4.3835,  7.2842,  5.7368, 24.9448,  5.8932,\n",
       "                        6.4153,  4.9433,  5.0670,  4.3100,  4.4821,  4.2268,  5.6821,  4.8967,\n",
       "                        5.5227,  5.1305,  4.4144,  7.9038, 11.1856, 15.4953,  7.5163,  4.6101,\n",
       "                        4.6547,  5.3117,  5.4776,  5.1970,  4.7858,  4.6987,  4.2746,  4.5287,\n",
       "                        4.3139,  7.5155,  5.7157,  3.8122,  5.1301,  5.9893,  5.9289,  8.3332,\n",
       "                        8.3308,  4.9312,  4.9600,  5.7601,  5.5508,  5.4134,  5.9208,  5.6546,\n",
       "                        4.8126,  4.7395,  4.7526,  4.5004,  4.6815, 18.2966,  4.2065,  6.6249,\n",
       "                        4.6224,  4.6961,  4.0706,  5.4291,  4.2853,  5.3961,  5.5929,  4.6708,\n",
       "                        3.9399,  4.9736,  4.7241,  4.7433,  5.3888,  4.4676,  4.0457,  5.9455,\n",
       "                        5.9888,  6.5835,  4.9853,  6.2620,  4.6907,  5.0189,  5.3483,  4.9788,\n",
       "                        3.7177,  5.6615,  4.7369,  3.8769,  6.2553,  5.2485,  6.1427,  4.0140,\n",
       "                        4.6693,  5.0911,  4.1753,  4.5895,  5.2198,  6.6320,  5.0708,  4.4174,\n",
       "                        7.2099,  4.4352,  4.7558,  4.8345,  5.7664,  5.0224,  5.9847,  6.8424,\n",
       "                        4.6551,  4.1887,  4.9196,  5.9793, 16.0871,  5.8382,  4.8283,  4.5071,\n",
       "                        6.4603,  5.2689,  8.3521,  4.4526,  4.7931,  4.3123,  5.0923,  5.8515,\n",
       "                        5.1640,  4.8977,  4.9881,  5.5736, 10.5566,  3.7561,  5.5920,  4.3089,\n",
       "                        5.0470,  5.7447,  5.7238,  5.1433, 13.9493,  5.0057,  4.7011,  3.8049,\n",
       "                        4.4501,  5.4840,  4.1812,  5.4175,  4.7792,  4.7214,  6.8025,  4.3499,\n",
       "                        5.2511,  5.4352,  6.2455,  4.9327,  4.9848,  5.4848,  6.0926,  7.4011,\n",
       "                        4.3052,  5.5132,  5.3743,  5.7631,  4.6502,  5.7138,  4.1747,  4.7946,\n",
       "                        4.5851,  5.8438,  4.7075,  4.6609,  6.1048,  4.5374,  4.8664,  5.3084,\n",
       "                        5.3025,  4.7072,  5.2897,  5.3602,  4.8896,  5.0584,  4.4280, 10.5570,\n",
       "                        7.7334,  5.7046,  4.3100,  4.4970,  4.6488, 11.4591,  5.3308,  7.7221,\n",
       "                        3.5786,  5.9909,  5.2099,  6.1062,  4.3121,  5.5862,  6.7963,  3.9787,\n",
       "                        9.8356,  3.9867,  4.2858,  5.5993,  7.0654,  5.1214,  4.6676, 10.5370,\n",
       "                        4.9931,  4.7914,  6.0749,  5.8060,  4.5972,  5.6608,  5.3158,  4.5729,\n",
       "                        4.9821,  5.3470,  4.3394,  4.3820,  6.4151,  4.8693,  4.4622,  4.3489,\n",
       "                        6.0149,  5.1241,  6.7570,  8.4697,  4.5166,  5.3258,  6.5676,  3.4554,\n",
       "                        4.9729,  5.5488,  7.3484, 11.2578,  3.9989,  4.8316,  5.3183,  4.4022,\n",
       "                        5.3464, 16.0576,  5.3833,  5.2258,  5.8219,  4.7970,  5.0804,  5.9818,\n",
       "                        7.3921,  6.2722,  4.9733,  5.0156,  5.5174,  5.8299,  4.3991,  4.9166,\n",
       "                        9.3150,  4.7148,  4.5163,  5.0017, 13.6907,  7.2352,  4.0435,  5.2753,\n",
       "                        5.1696,  5.3541,  4.9300,  4.5820,  4.0265,  4.6578,  4.2632,  4.8043,\n",
       "                        7.0944,  3.5562,  6.2931,  6.4850,  5.3412,  7.8275,  4.6958,  4.4881,\n",
       "                        4.4316,  5.5711,  4.8138,  5.0655,  5.7234,  4.1008,  4.6739,  4.5037,\n",
       "                        4.8405,  6.7889, 11.7758,  5.5477,  4.4896,  6.2217,  4.9632,  5.7322,\n",
       "                        4.6764,  4.9216, 13.0398,  5.7307,  4.7757, 22.4799, 20.2735,  5.4607,\n",
       "                        4.5602,  3.7910,  4.2319, 10.5216,  4.0830,  4.6202,  5.8136,  6.6006,\n",
       "                        5.1905,  6.3577,  4.5735,  4.5465,  4.6929,  5.1092,  4.3996,  4.7407,\n",
       "                        4.6933,  7.0237,  5.8347,  4.9077,  6.0952,  4.7618,  4.9079,  5.4829,\n",
       "                        5.1294,  5.1060,  5.6252,  5.3617,  6.6987,  4.3191,  4.5200,  6.5243,\n",
       "                        4.8361,  3.8839,  6.7215,  4.9723,  3.8062,  5.2965,  4.6960,  4.5785,\n",
       "                        4.6068,  6.3415,  4.1270,  4.6330,  5.1964,  6.6733,  4.5504,  5.2169,\n",
       "                        4.3796, 13.1162,  4.9203,  5.6767,  6.6563,  5.9875, 15.8014,  4.8335,\n",
       "                        6.3393,  5.2616, 14.7711,  4.3390,  4.9430,  5.8915,  5.3980,  4.9107,\n",
       "                        8.0485,  5.8967,  7.0476,  5.3607, 54.2241,  6.0493, 17.1707,  5.0275,\n",
       "                        7.4728,  4.8523,  3.4461,  5.0654,  5.0932,  5.3247, 27.6127,  5.0366,\n",
       "                        8.0655,  5.8057,  4.6425,  6.6841,  5.0325,  4.4833,  4.2549,  5.0558,\n",
       "                       11.8391,  6.7330,  4.4248,  5.1056,  5.2171,  6.0450,  5.2207,  5.4543,\n",
       "                        4.7334,  5.4410,  4.0307,  5.3033,  5.6927,  7.8446, 11.5793,  5.1603,\n",
       "                        4.0782,  4.5480, 11.2666,  4.3966,  6.1001,  5.4837,  4.6497,  4.3368,\n",
       "                        5.0808,  5.8229,  6.3516,  3.8208,  5.5696,  4.9474,  6.1086,  4.5737,\n",
       "                        6.0064,  4.1720,  9.7898,  4.2638,  4.4535,  4.5317,  5.1525,  6.2907,\n",
       "                        5.6334, 13.3012,  5.6882,  4.9861,  3.7478,  5.1790,  4.9915,  5.1795,\n",
       "                        4.3823,  5.0424,  5.0294,  6.1574,  8.7887,  9.5678,  6.2497,  4.8197,\n",
       "                        6.4911,  5.5610,  6.5244, 10.8675,  4.4025,  6.0502,  6.1049,  5.0059],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.1.conv2.weight',\n",
       "               tensor([[[[-1.6323e-02, -1.9465e-02, -1.7348e-02],\n",
       "                         [-9.0352e-03, -1.0522e-02, -1.3044e-02],\n",
       "                         [-1.0589e-03, -2.2480e-02, -1.1429e-02]],\n",
       "               \n",
       "                        [[-5.3956e-04, -3.2918e-04, -1.5862e-02],\n",
       "                         [-4.3950e-03,  2.2628e-02,  4.2467e-03],\n",
       "                         [ 8.1672e-04,  1.9505e-02,  5.7085e-03]],\n",
       "               \n",
       "                        [[ 1.9202e-02,  1.3848e-02,  1.6897e-02],\n",
       "                         [ 1.1530e-02, -2.3023e-05,  1.6662e-03],\n",
       "                         [ 7.7815e-03,  1.4951e-02,  3.5179e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.5679e-02,  2.4558e-03,  2.1274e-03],\n",
       "                         [ 7.4682e-03, -1.6866e-04,  6.6033e-03],\n",
       "                         [ 2.4676e-03,  4.1810e-03,  4.2568e-03]],\n",
       "               \n",
       "                        [[-1.6147e-03,  2.0178e-03,  5.4852e-03],\n",
       "                         [ 1.5928e-03, -2.1478e-03, -1.6457e-04],\n",
       "                         [-4.8993e-03, -8.1566e-03, -1.2713e-02]],\n",
       "               \n",
       "                        [[ 2.2952e-02,  1.0842e-02,  9.2142e-03],\n",
       "                         [ 1.9016e-02,  2.4742e-02,  2.0592e-02],\n",
       "                         [ 4.4251e-03, -5.2363e-04,  6.8706e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.3314e-02,  4.1930e-02,  3.6564e-02],\n",
       "                         [ 3.3293e-02,  4.3129e-02,  4.4257e-02],\n",
       "                         [ 1.9001e-02,  5.3880e-02,  2.9037e-02]],\n",
       "               \n",
       "                        [[ 1.4824e-02,  1.6445e-02,  3.0488e-02],\n",
       "                         [ 2.2651e-02,  1.9609e-02,  7.4374e-03],\n",
       "                         [ 1.6840e-02,  1.1117e-02,  1.3879e-02]],\n",
       "               \n",
       "                        [[-6.5363e-03,  2.2621e-03, -1.2392e-02],\n",
       "                         [ 7.4574e-03, -7.7470e-03, -9.4870e-04],\n",
       "                         [-6.1721e-03,  1.0564e-02, -4.1003e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.6510e-02, -4.6541e-02, -3.3312e-02],\n",
       "                         [-3.8533e-02, -1.6664e-02, -2.7880e-02],\n",
       "                         [-1.8528e-02, -2.7937e-02, -3.2862e-02]],\n",
       "               \n",
       "                        [[-8.2767e-03, -2.3888e-02, -2.4448e-02],\n",
       "                         [-2.6720e-02, -2.6029e-02, -4.0105e-02],\n",
       "                         [-3.4221e-02, -4.1042e-02, -3.6864e-02]],\n",
       "               \n",
       "                        [[-2.1382e-02, -2.6907e-02, -2.5774e-02],\n",
       "                         [-1.9441e-02, -1.6856e-02, -2.3709e-02],\n",
       "                         [-2.2928e-02, -6.8843e-03, -1.1135e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.7680e-02, -2.8609e-02, -2.2084e-02],\n",
       "                         [-2.5072e-02, -1.3764e-02, -1.3788e-02],\n",
       "                         [-1.8809e-02, -3.2421e-02, -2.1897e-02]],\n",
       "               \n",
       "                        [[-1.3798e-02, -6.6121e-03,  2.1193e-03],\n",
       "                         [-9.4649e-03,  6.4214e-03,  1.0100e-03],\n",
       "                         [-1.1483e-02, -6.8539e-03, -3.2100e-03]],\n",
       "               \n",
       "                        [[-7.0036e-03, -1.1943e-03, -4.5351e-03],\n",
       "                         [ 7.9047e-04, -2.0126e-02, -8.3190e-03],\n",
       "                         [ 2.8626e-03, -9.9913e-04,  6.1139e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.2123e-02,  7.0965e-03,  3.0817e-02],\n",
       "                         [ 4.1771e-02,  1.6221e-02,  2.8431e-02],\n",
       "                         [ 2.2399e-02,  2.3574e-02,  2.0203e-02]],\n",
       "               \n",
       "                        [[ 1.4978e-02,  2.1267e-02,  1.4930e-02],\n",
       "                         [ 3.2308e-02,  3.5181e-02,  1.6032e-02],\n",
       "                         [ 1.3083e-02,  2.3400e-02,  2.5677e-02]],\n",
       "               \n",
       "                        [[-1.6203e-02, -4.8543e-03, -8.1736e-03],\n",
       "                         [-1.5752e-02,  2.2058e-02, -9.7580e-03],\n",
       "                         [-2.6766e-03, -5.6073e-03, -2.0594e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 7.3209e-03,  8.9844e-03,  1.0403e-02],\n",
       "                         [ 8.9472e-03,  7.6805e-03,  2.0485e-02],\n",
       "                         [ 4.9633e-03, -3.3325e-03,  8.3867e-03]],\n",
       "               \n",
       "                        [[-9.5516e-03, -4.6433e-03, -2.8052e-04],\n",
       "                         [-5.5324e-03, -4.3313e-03, -2.5736e-03],\n",
       "                         [-1.3094e-02, -2.1578e-02, -1.4769e-02]],\n",
       "               \n",
       "                        [[ 4.1910e-03, -4.9086e-03,  2.1472e-04],\n",
       "                         [-1.4445e-03, -2.0006e-02, -1.8462e-04],\n",
       "                         [-8.1709e-04,  1.5908e-03, -3.1708e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.6415e-03, -1.0355e-02, -6.4443e-03],\n",
       "                         [-1.9338e-02, -3.5409e-03, -2.2853e-02],\n",
       "                         [-2.8083e-02, -3.2499e-02, -2.6440e-02]],\n",
       "               \n",
       "                        [[ 1.6155e-02,  2.9479e-02,  2.6303e-02],\n",
       "                         [ 1.5407e-02,  2.6263e-02,  2.2317e-02],\n",
       "                         [ 1.7167e-02,  1.0573e-02,  5.0642e-03]],\n",
       "               \n",
       "                        [[-4.9582e-03,  4.1218e-03, -1.8532e-02],\n",
       "                         [-1.0661e-02, -5.1746e-03, -5.0781e-03],\n",
       "                         [-1.3828e-02, -2.7393e-02, -2.1771e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4348e-03, -1.2704e-02, -1.2028e-02],\n",
       "                         [-3.8295e-03,  1.6337e-03, -9.2336e-03],\n",
       "                         [-2.0286e-02, -9.6780e-03, -1.4316e-02]],\n",
       "               \n",
       "                        [[-2.0219e-02, -2.8288e-02, -3.3085e-02],\n",
       "                         [-9.7054e-03, -1.5399e-02, -4.1961e-03],\n",
       "                         [-1.0102e-02, -8.1980e-03, -1.6922e-02]],\n",
       "               \n",
       "                        [[ 4.3354e-02,  5.2467e-02,  5.0123e-02],\n",
       "                         [ 2.6987e-02,  2.0612e-02,  3.9470e-02],\n",
       "                         [-7.0432e-03, -3.8725e-03,  1.1477e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.1731e-03,  2.5831e-02,  2.9463e-02],\n",
       "                         [ 2.0063e-02, -1.6853e-03,  1.0338e-02],\n",
       "                         [ 2.1173e-02,  2.0763e-02,  2.5404e-02]],\n",
       "               \n",
       "                        [[ 2.7835e-02,  2.4837e-02,  1.9186e-02],\n",
       "                         [ 2.7640e-02,  2.3166e-02,  9.9374e-03],\n",
       "                         [ 2.1023e-02,  1.4205e-02, -1.4393e-02]],\n",
       "               \n",
       "                        [[ 2.1833e-02,  1.4161e-02,  2.3312e-02],\n",
       "                         [ 9.8976e-03, -1.5530e-02,  3.9874e-03],\n",
       "                         [ 9.5778e-04, -7.0742e-03,  1.0140e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0528e-02,  2.9218e-02,  1.3708e-02],\n",
       "                         [ 3.3658e-02,  3.3596e-02,  3.6840e-02],\n",
       "                         [ 2.9495e-02,  3.4770e-02,  2.9969e-02]],\n",
       "               \n",
       "                        [[-1.8225e-02, -2.8211e-02, -2.8091e-02],\n",
       "                         [-8.3865e-03, -2.0348e-02, -8.5504e-03],\n",
       "                         [-1.5035e-02, -1.6858e-02, -1.3050e-02]],\n",
       "               \n",
       "                        [[-1.5577e-02,  1.0160e-03, -8.4152e-03],\n",
       "                         [-2.2324e-02, -7.0807e-03, -3.7219e-02],\n",
       "                         [-2.6470e-02, -1.5674e-02, -2.4300e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.5101e-02,  4.5224e-02,  3.8372e-02],\n",
       "                         [ 3.7953e-02,  2.7373e-02,  1.7637e-02],\n",
       "                         [ 3.5094e-02,  3.1437e-02,  3.1744e-02]],\n",
       "               \n",
       "                        [[-1.4684e-03,  1.6625e-03, -4.7324e-03],\n",
       "                         [ 1.4037e-02,  4.1625e-03, -1.9885e-04],\n",
       "                         [-4.3877e-04, -1.0425e-02,  1.0106e-03]],\n",
       "               \n",
       "                        [[-5.9329e-03, -7.5479e-03,  6.3794e-03],\n",
       "                         [ 2.8860e-03,  4.7065e-03, -1.2218e-02],\n",
       "                         [-7.0228e-03, -1.7529e-02, -2.6267e-02]]]], device='cuda:0')),\n",
       "              ('module.layer4.1.bn2.weight',\n",
       "               tensor([1.9531, 1.5446, 1.8380, 1.7117, 1.3916, 1.9193, 1.5625, 2.0054, 1.5557,\n",
       "                       2.0977, 1.6567, 1.5660, 1.3385, 1.3617, 1.7712, 1.6440, 1.7948, 1.7433,\n",
       "                       1.9140, 1.4266, 1.7030, 2.2486, 1.4805, 1.6926, 1.3813, 1.8971, 1.9758,\n",
       "                       1.8627, 1.6092, 1.4345, 1.5130, 1.6815, 1.7793, 1.6217, 1.9869, 1.1217,\n",
       "                       1.4430, 1.6409, 1.5746, 1.7563, 1.6808, 1.8892, 1.5393, 1.7238, 1.9817,\n",
       "                       1.8929, 1.8611, 1.5079, 1.8464, 2.1529, 1.6849, 1.5661, 1.6712, 1.6163,\n",
       "                       1.5595, 1.7008, 1.5506, 1.6128, 1.3657, 1.6411, 1.6631, 1.6793, 1.7196,\n",
       "                       1.8841, 2.0551, 1.5884, 2.0710, 3.2034, 1.7045, 1.4799, 1.1338, 1.7726,\n",
       "                       1.1501, 1.6070, 2.3778, 1.9055, 1.6613, 1.5238, 1.7918, 1.5596, 1.6572,\n",
       "                       1.7426, 1.3330, 1.5357, 1.4518, 1.9656, 2.0534, 1.7713, 1.7207, 1.2014,\n",
       "                       1.5877, 1.7536, 1.9492, 1.7873, 1.7231, 1.7421, 1.9258, 1.8124, 1.8954,\n",
       "                       1.9434, 1.7693, 1.3794, 2.1843, 1.9233, 1.4122, 2.0752, 1.6781, 1.8605,\n",
       "                       1.4588, 2.0744, 1.8750, 1.7954, 1.7256, 2.1995, 1.5210, 1.5441, 1.5997,\n",
       "                       1.3686, 2.0966, 1.4725, 1.8525, 1.6922, 2.0283, 1.8997, 1.2951, 1.4935,\n",
       "                       1.5008, 2.3068, 1.3359, 1.6202, 1.8144, 1.5792, 1.7073, 1.6999, 1.6056,\n",
       "                       1.8644, 2.1205, 1.8767, 1.9913, 1.5586, 1.9984, 1.6759, 1.8362, 1.9961,\n",
       "                       2.2764, 1.4789, 2.0767, 1.4848, 1.9865, 1.7601, 2.3870, 1.6574, 1.9281,\n",
       "                       1.6286, 1.4311, 1.8417, 1.4072, 1.7097, 1.4787, 1.7090, 1.6540, 1.5291,\n",
       "                       1.9361, 1.3988, 1.4373, 1.9028, 1.7482, 1.5927, 1.6235, 1.7959, 1.9004,\n",
       "                       1.7904, 1.6979, 1.9126, 1.7635, 1.4945, 1.5589, 1.4389, 1.8619, 2.0591,\n",
       "                       1.9680, 1.3318, 1.4774, 1.7136, 1.9042, 1.7124, 1.9943, 2.0063, 1.9416,\n",
       "                       1.5834, 1.8848, 2.0257, 1.6456, 1.8112, 1.6399, 1.7698, 1.9404, 1.6875,\n",
       "                       1.6980, 1.6347, 1.9253, 1.9553, 1.3223, 1.4669, 1.4259, 1.6152, 1.9419,\n",
       "                       1.4730, 1.6745, 1.8685, 1.7720, 1.9218, 1.5835, 1.7034, 1.5189, 1.7627,\n",
       "                       1.3658, 1.4531, 1.4686, 1.6111, 1.8600, 1.6693, 1.5760, 1.7820, 1.5304,\n",
       "                       1.5900, 1.4609, 1.8283, 1.3323, 2.8986, 1.5880, 1.4273, 1.4073, 1.6362,\n",
       "                       1.6676, 1.8871, 1.3689, 2.0770, 1.3856, 1.6229, 2.0327, 1.6664, 2.0732,\n",
       "                       1.5302, 1.6884, 1.6270, 1.9158, 1.9392, 1.9979, 1.8032, 1.9996, 0.9111,\n",
       "                       1.9917, 1.7390, 1.6701, 1.6379, 1.2871, 1.4350, 1.7616, 1.4871, 1.4769,\n",
       "                       1.6718, 1.6769, 1.7461, 1.8219, 1.7982, 1.6516, 1.6290, 1.8228, 1.3646,\n",
       "                       1.5520, 2.1924, 1.8594, 1.9151, 2.1577, 1.3360, 1.6543, 1.6718, 1.8714,\n",
       "                       2.3236, 1.7862, 1.5719, 2.2189, 1.6862, 2.0686, 1.8895, 1.7980, 1.8872,\n",
       "                       2.1970, 1.2728, 1.6194, 1.3370, 2.3256, 1.4300, 2.1413, 1.7841, 3.4650,\n",
       "                       1.5553, 1.3992, 2.0110, 1.7340, 1.5580, 1.8036, 1.8233, 1.5135, 1.7818,\n",
       "                       1.4733, 1.9287, 1.7077, 1.4895, 1.3695, 1.9850, 1.8539, 1.5916, 1.6414,\n",
       "                       1.5632, 1.9943, 1.5943, 2.4528, 1.9812, 1.5112, 1.7156, 1.7945, 1.4729,\n",
       "                       1.9847, 1.6573, 1.6148, 1.6615, 1.2445, 1.3819, 2.3255, 1.2822, 1.7499,\n",
       "                       1.5645, 1.4514, 1.5823, 1.8787, 1.7300, 1.8725, 1.9715, 1.8180, 2.0514,\n",
       "                       1.2176, 1.6885, 1.4397, 1.6744, 2.0542, 1.3722, 1.6903, 1.9386, 1.4929,\n",
       "                       1.7389, 1.4462, 1.7190, 1.6783, 1.5864, 1.5246, 1.9064, 1.8162, 1.4583,\n",
       "                       2.0466, 1.9372, 1.4347, 1.5167, 2.0756, 1.6883, 1.3464, 1.6870, 1.9113,\n",
       "                       1.8956, 1.9395, 1.7379, 1.7042, 1.7982, 1.9925, 2.2246, 1.8829, 0.9513,\n",
       "                       1.9328, 1.7102, 1.6138, 1.4984, 1.7569, 0.8276, 1.7465, 1.2211, 1.0095,\n",
       "                       2.1115, 1.6572, 1.7572, 2.1317, 1.4985, 1.8721, 1.5216, 1.5181, 1.4402,\n",
       "                       1.5198, 1.7077, 1.7783, 1.3369, 1.7300, 1.5449, 1.7627, 1.6763, 1.6493,\n",
       "                       1.8597, 1.8781, 1.7580, 1.8988, 1.8443, 1.8658, 1.8881, 1.5417, 1.3016,\n",
       "                       2.2350, 1.5153, 1.7758, 1.5467, 2.1092, 1.8246, 1.5130, 1.1641, 2.3433,\n",
       "                       1.7050, 2.0109, 1.5944, 1.7286, 1.5648, 1.1400, 1.4846, 1.6633, 1.6295,\n",
       "                       1.7413, 1.2887, 1.7806, 2.0392, 1.6438, 1.2264, 1.5643, 1.6845, 1.8326,\n",
       "                       1.5574, 1.6167, 1.5232, 1.7811, 1.9311, 1.7203, 1.8956, 1.5372, 1.8634,\n",
       "                       1.8141, 1.6404, 1.2163, 1.7944, 1.8066, 1.3889, 2.0337, 1.6352, 1.9407,\n",
       "                       2.0824, 2.8650, 1.6083, 1.7466, 1.9816, 1.5892, 1.6131, 1.9547, 1.8286,\n",
       "                       1.3362, 1.6377, 1.5636, 2.0598, 1.5241, 1.5145, 1.6542, 1.8289, 1.3901,\n",
       "                       1.5981, 1.6238, 1.6529, 1.5269, 1.3484, 1.5414, 1.4958, 1.7574, 1.7178,\n",
       "                       1.4108, 1.4419, 1.7940, 1.8816, 1.4671, 1.6737, 1.7635, 1.5208, 1.7873,\n",
       "                       1.3879, 1.5777, 1.3975, 1.6399, 1.8446, 1.5886, 1.8580, 1.4831, 1.6310,\n",
       "                       1.6382, 2.1066, 1.9905, 1.6383, 1.5755, 1.7863, 1.5595, 1.5499],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn2.bias',\n",
       "               tensor([-2.4569, -0.8325, -1.6065, -0.5528, -0.2742, -1.6458, -1.1536, -2.2269,\n",
       "                       -0.9582, -3.3729, -1.4780, -0.7851, -0.4547, -0.4861, -1.3103, -1.2357,\n",
       "                       -1.5157, -0.7789, -2.5951, -0.3717, -1.8616, -2.1069, -0.8460, -1.2789,\n",
       "                       -0.1396, -2.2372, -1.5628, -2.1397, -1.2085, -0.1541, -0.7977, -1.0405,\n",
       "                       -1.1481, -0.9326, -1.3655,  0.8269, -0.3973, -1.4923, -0.9567, -0.5969,\n",
       "                       -1.7331, -2.4875, -0.9134, -1.5331, -2.4981, -2.4003, -2.4400, -0.7596,\n",
       "                       -1.7919, -2.2469, -0.6592, -0.4576, -1.1061, -1.2865, -1.0703, -1.3599,\n",
       "                       -1.0646, -1.2386, -0.3487, -1.1604, -1.3695, -1.2317, -1.0282, -1.9934,\n",
       "                       -2.4052, -1.0132, -1.5655, -2.1322, -2.0298, -0.9237,  2.2019, -1.8119,\n",
       "                        0.1544, -1.0460, -1.2135, -1.5631, -1.4345, -0.8198, -0.6591, -1.0221,\n",
       "                       -1.1049, -1.3551,  0.1243, -0.9584, -0.6968, -2.5818, -2.5657, -1.6469,\n",
       "                       -1.8262,  0.0464, -1.4657, -1.8931, -2.1198, -1.6410, -1.9562, -1.6604,\n",
       "                       -2.2383, -2.1459, -2.3443, -1.3001, -1.5946, -0.8035, -3.4759, -2.1524,\n",
       "                       -0.5879, -2.0642, -1.4481, -2.0073, -0.6594, -3.0215, -1.4523, -1.8919,\n",
       "                       -0.9192, -3.4744, -0.7960, -1.0866, -0.4208, -0.6516, -2.8213, -0.8647,\n",
       "                       -0.0686, -1.4438, -2.1451, -2.1101, -0.0632, -0.8623, -0.8633, -2.3232,\n",
       "                       -0.4855, -0.4794, -1.9165, -1.1085, -1.1648, -1.1298, -0.9759, -1.9550,\n",
       "                       -1.6908, -0.7863, -2.6051, -1.0697, -2.3534, -1.0798, -1.6976, -2.6762,\n",
       "                       -1.7109, -0.7411, -2.4866, -0.6482, -2.2620, -1.9881, -3.9671, -1.2751,\n",
       "                       -1.5485, -1.1682, -0.5537, -2.3176, -0.5788, -1.3903, -0.8082, -1.2580,\n",
       "                       -1.1093, -1.1308, -1.9062, -0.6548, -0.5058, -1.6894, -1.6269, -1.2184,\n",
       "                       -1.2010, -1.5964, -1.3727, -1.6326, -1.5478, -1.9356, -0.3048, -0.6833,\n",
       "                       -0.9401, -0.7650, -1.9369, -2.9907, -2.0868, -0.4378, -0.7903, -1.2517,\n",
       "                       -2.1256, -1.5039, -2.5228, -0.3790, -2.2896, -1.1585, -1.8928, -2.7437,\n",
       "                       -1.5557, -1.7381, -0.7138, -1.5267, -3.0457, -1.6521, -1.7047, -1.0963,\n",
       "                       -1.5786, -1.4807, -0.5408, -0.9043, -0.5161, -1.0291, -1.9928, -0.8869,\n",
       "                       -1.4303, -1.5697, -1.8855, -1.7947, -1.1078, -0.6655, -0.7602, -1.5745,\n",
       "                       -0.1434, -0.7086, -0.6736, -1.2311, -1.4012, -0.6168, -1.1829, -1.2427,\n",
       "                       -0.8597, -0.9988, -0.8209, -1.7184,  0.1572, -1.8019, -1.1337, -0.5633,\n",
       "                       -0.6206, -1.3568, -1.7051, -2.0977, -0.6296, -1.2211, -0.5582, -1.2528,\n",
       "                       -2.5636, -1.3900, -2.7715, -1.0479, -1.3202, -1.1112, -1.8822, -2.4615,\n",
       "                       -2.0399, -1.1707, -2.8810,  1.7179, -2.3714, -1.5284, -0.6867, -1.4096,\n",
       "                        0.0348, -0.6800, -1.6620, -0.6976, -0.8582, -1.5708, -1.4756, -1.5686,\n",
       "                       -1.7582, -1.6167, -1.3222, -0.9626, -1.5241, -0.5314, -0.7415, -2.2178,\n",
       "                       -1.7057, -1.7269, -2.2298, -0.2999, -1.1375, -0.9435, -1.8481, -1.4987,\n",
       "                       -1.9640, -1.0930, -1.5122, -1.1680, -3.1026, -2.2236, -1.4797, -1.8542,\n",
       "                       -2.0674, -0.2119, -1.0382,  0.1075, -2.7709, -0.7470, -2.9091, -1.6888,\n",
       "                       -2.9746, -0.5524, -0.6255, -2.6143, -0.8628, -0.9921, -1.2813, -1.9417,\n",
       "                       -0.8120, -1.8771, -0.8215, -2.5393, -1.3256, -0.7915, -0.6657, -1.3885,\n",
       "                       -1.8164, -1.4135, -1.3089, -0.9386, -1.6031, -1.3093, -2.0820, -2.7002,\n",
       "                       -1.0808, -1.6949, -1.5932, -0.4928, -2.3542, -1.2349, -1.0297, -1.0234,\n",
       "                       -0.3750, -0.3669, -2.3547, -0.3321, -1.8908, -0.7959,  0.0996, -0.9141,\n",
       "                       -2.0392, -1.1547, -1.9569, -0.9762, -1.7397, -1.7937, -0.2333, -1.5962,\n",
       "                       -0.6988, -0.9220, -2.3487, -0.4541, -1.6282, -2.3985, -0.7770, -1.3694,\n",
       "                       -0.7913, -1.9368, -0.9198, -0.9479, -0.9844, -2.2601, -1.5983, -0.6270,\n",
       "                       -2.4940, -2.6937, -0.4625, -0.9476, -2.4803, -1.4231, -0.4884, -1.3047,\n",
       "                       -1.6603, -0.1292, -2.5077, -1.7997, -1.4084, -1.3565, -1.9850, -1.7812,\n",
       "                       -1.6243,  2.9833, -2.0051, -1.3121, -1.3541, -0.4328, -1.3401,  2.0776,\n",
       "                       -1.1007,  0.0977,  2.3319, -2.0378, -1.2390, -1.3753, -1.3541, -0.9352,\n",
       "                       -2.0758, -0.8506, -1.3576, -0.9643, -1.0325, -0.6107, -1.4754,  0.0930,\n",
       "                       -1.9381, -1.0586, -1.3662, -1.2865, -1.2583, -1.7714, -1.6109, -1.7298,\n",
       "                       -2.4621, -1.4334, -1.8451, -1.7953, -1.0999, -0.2612, -3.5152,  0.9045,\n",
       "                       -1.3979, -1.0526, -2.2848, -1.7770, -0.6021, -0.0538, -1.7422, -1.0815,\n",
       "                       -2.1574, -1.1923, -1.6662, -1.2141,  0.1678, -0.7125, -1.1966, -1.1261,\n",
       "                       -1.5664, -0.2797, -0.2661, -1.5782, -0.9479,  0.0842, -1.0310, -1.4053,\n",
       "                       -0.0831, -1.0684, -1.0978, -1.1193, -1.4729, -2.6548, -1.2585, -2.1058,\n",
       "                       -1.0427, -2.0446, -1.6341, -1.0631,  0.0256, -1.4193, -1.7399, -0.2348,\n",
       "                       -2.0261, -1.2974, -2.4156, -2.8302, -2.0387, -0.9065, -1.6394, -2.0783,\n",
       "                       -1.2979, -1.2741, -2.4331, -1.3614, -0.3630, -2.0084, -1.4126, -1.8973,\n",
       "                       -0.8028, -0.8991, -1.3602, -0.9098, -0.4311, -1.1336, -1.4250, -0.9106,\n",
       "                       -0.3876, -0.2816, -0.9867, -0.1489, -1.3177, -1.2954, -0.6016, -0.6549,\n",
       "                       -1.5105, -2.0504, -0.7372, -0.8320, -1.2944, -1.1333, -1.5369, -0.6762,\n",
       "                       -0.7593, -0.5584, -1.5444, -2.0067, -1.3105, -2.7055, -0.4660, -0.7397,\n",
       "                       -1.2386, -2.3408, -2.7038, -1.1036, -1.2652, -1.7409, -1.1916, -1.0114],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn2.running_mean',\n",
       "               tensor([-1.2495, -1.4175, -1.2383, -0.5785, -0.9048, -1.5042, -0.3945, -1.2735,\n",
       "                       -1.2334,  0.0634, -1.1260, -1.3326, -1.2038, -1.6082, -0.5272, -0.8456,\n",
       "                       -0.8392,  1.9828, -1.1146, -0.5863,  0.7630, -1.3377, -1.2906, -0.8869,\n",
       "                       -2.4486, -0.7549, -0.6632, -1.3183, -1.0071, -0.7470, -0.7630, -0.6627,\n",
       "                       -1.2870, -0.4180, -0.2184, -1.3261, -1.3863, -1.5193, -1.4134, -0.3235,\n",
       "                       -0.9231, -1.0212, -0.3090, -0.9468, -0.7142, -0.5752, -0.8528, -1.6754,\n",
       "                       -0.9310, -1.0079,  0.0242, -0.2643, -0.8930, -1.2182, -1.3358, -1.4537,\n",
       "                       -1.1106, -0.9139, -1.2334, -1.1470, -1.2885, -1.7084, -0.1229, -0.8534,\n",
       "                       -0.7205, -1.3530, -0.9959, -0.6789, -0.5718, -0.8912,  1.1472, -0.7890,\n",
       "                       -0.6398, -1.1365, -0.4053, -1.3782, -1.0119, -1.1909, -1.1584, -1.4899,\n",
       "                       -1.5284, -0.6102, -2.4521, -0.7816, -0.8213, -0.5950, -0.7881, -1.1624,\n",
       "                       -0.6955, -1.1180, -1.0203, -0.6507, -1.7014, -0.7127, -0.7636, -0.2776,\n",
       "                       -0.9132, -0.5076, -0.8281, -0.7435, -1.1788, -0.9144, -1.0632, -1.3906,\n",
       "                       -1.4297, -1.0756, -0.7731, -1.1376, -1.1268, -0.8768, -0.9739, -1.1050,\n",
       "                        0.3456, -1.4882, -1.0323, -1.0034, -0.2713, -1.1079, -0.6860, -1.4667,\n",
       "                       -0.4782, -1.0761, -1.1137, -1.0010, -1.3922, -1.3308, -1.4791, -1.7374,\n",
       "                       -1.4059, -0.4195, -1.1555, -1.1042, -1.7216, -0.2282, -0.4377, -1.2951,\n",
       "                       -0.8187, -0.4624, -1.1922, -1.2214, -0.9613, -0.1975, -1.3420, -1.0694,\n",
       "                       -0.2935, -1.2359, -1.1825, -1.0639, -1.1251, -1.0376, -1.5368, -1.0279,\n",
       "                       -0.6844, -0.9617, -1.6062, -1.0220, -1.5877, -1.1062, -0.5827, -1.2035,\n",
       "                       -0.7869, -1.0802, -1.4922, -1.8744, -1.1959, -0.7317, -0.6789, -1.2254,\n",
       "                       -0.9523, -1.0201, -1.0497, -0.7339, -1.1916, -0.7985,  0.3362, -0.0773,\n",
       "                       -1.5192, -1.1548, -0.8023, -0.4975, -0.6092, -1.1514, -0.8121, -0.7376,\n",
       "                       -1.2563, -1.1961, -1.2133, -0.4441, -1.3374, -1.2541, -1.5699, -1.4927,\n",
       "                       -1.2702, -1.2077,  0.5084, -1.1862, -0.0734, -0.5626, -1.0756, -0.8182,\n",
       "                       -1.2060, -1.0555, -1.3573, -1.3437, -1.3610, -1.5947, -1.2855, -1.4508,\n",
       "                       -1.2914, -0.9224, -0.9971, -0.6597, -1.3206, -0.5920, -1.6615, -0.9370,\n",
       "                       -2.2519, -1.0364, -1.1949, -0.9475, -1.2167,  0.2530, -1.1167, -0.6878,\n",
       "                       -1.4138, -1.2415, -1.1636, -0.8479, -0.3223, -1.0005, -1.3122, -0.9108,\n",
       "                       -1.2721, -0.6351, -1.3308, -1.3465, -0.7566,  0.0332, -1.1072, -1.5632,\n",
       "                       -0.8822, -0.9387,  1.8416, -0.7014, -1.3480, -1.2053, -0.9251, -0.7782,\n",
       "                       -1.3065, -1.2995, -0.2847,  0.4451, -0.9872, -1.9224, -1.4852, -1.1946,\n",
       "                       -2.1070, -0.9384, -0.8404,  0.4685, -1.1031, -1.1054, -1.0507, -1.2798,\n",
       "                       -0.5365, -1.1787, -0.9772, -0.9313, -1.4521, -0.9223, -1.2524, -1.1921,\n",
       "                       -1.5553, -0.6788, -1.8154, -0.8854, -1.4428, -0.2934, -1.0762, -0.4472,\n",
       "                       -0.4264, -1.6037, -0.2392, -0.5752,  0.0605, -1.2103, -1.2339, -0.9703,\n",
       "                       -1.0731, -1.1059, -1.1712, -2.0131, -1.0602, -1.0235, -1.3165, -1.2179,\n",
       "                       -3.2274,  0.1558, -0.9602, -0.9211, -0.5372, -0.7872, -1.1532, -1.2409,\n",
       "                       -1.0046, -0.4352, -1.3335, -0.7324, -1.1565, -0.7413, -0.9478, -0.3574,\n",
       "                       -1.7391, -1.1569, -1.2696, -1.7291, -1.2587, -0.9533,  0.0574, -1.3445,\n",
       "                       -0.7970, -1.1004, -1.2647, -0.4831, -0.5206, -1.2082, -1.0509, -1.1579,\n",
       "                       -1.7014, -0.7249, -1.1505, -1.0524, -0.9985, -0.7378, -0.6285, -1.3552,\n",
       "                       -1.1682, -0.5690, -0.9782, -0.8037, -0.6427, -0.5836, -1.2738, -0.8328,\n",
       "                       -1.1280, -0.5151, -1.0067, -1.4922, -0.7129, -1.4017, -0.9169, -0.8357,\n",
       "                       -0.9899, -0.8185, -1.4582, -0.9844, -0.9383, -0.7180, -1.6674, -1.2262,\n",
       "                       -0.8149, -0.8817, -1.4115, -1.0956,  3.4662, -1.2581, -0.8844, -1.0211,\n",
       "                       -1.3741, -0.1449, -0.6908, -1.5002, -1.3233, -1.7311, -0.7036, -0.2387,\n",
       "                       -0.7108, -0.2204, -0.7451, -0.9735, -1.5676, -1.9674, -1.3020,  0.2598,\n",
       "                       -1.2107, -1.4595,  2.3873, -0.4370, -0.5551, -1.2104, -0.8325, -0.8943,\n",
       "                       -0.9993, -1.1622,  0.4960, -1.1986, -1.2030, -0.7744, -1.0705, -1.3368,\n",
       "                       -0.7699, -1.2139, -1.1582, -1.0249, -1.2701, -1.1302, -1.1794, -1.0368,\n",
       "                       -0.5533, -0.2115, -1.2104, -0.9901, -1.2159, -1.0978, -1.4840, -2.9385,\n",
       "                       -1.2588, -1.1653, -0.9906, -1.2903, -2.0167, -1.2230, -1.2159, -0.6841,\n",
       "                       -0.8473, -1.0786, -0.9826, -1.4614, -1.1668, -1.2096, -0.6899, -1.2165,\n",
       "                       -1.2120, -0.3842, -2.4030, -0.9182, -0.8687, -1.3808, -0.9810, -0.4916,\n",
       "                       -1.0559, -1.3981, -1.0440, -1.3245, -1.0310, -0.9935, -1.1465, -0.4635,\n",
       "                       -0.9050, -1.2693, -1.4338, -1.0018, -1.4724, -1.0282, -0.7937, -1.3091,\n",
       "                       -0.9420, -1.3208, -0.1106, -0.8150, -2.9539, -0.8777, -0.9017, -0.6974,\n",
       "                       -0.6980, -1.0257, -1.1065, -0.6482, -1.2422, -0.6938, -1.1130, -0.7250,\n",
       "                       -1.5414, -1.5746, -1.2631, -0.4015, -1.3700, -1.1244, -0.7589, -0.7303,\n",
       "                       -0.0121, -1.8895, -0.5991, -1.5135, -1.0355, -1.0572, -1.4292, -1.6345,\n",
       "                       -0.4891, -1.1127, -1.5064,  0.1049, -0.7852, -0.8305, -1.3527, -1.2115,\n",
       "                       -0.8189, -0.8031, -0.9721, -0.8393, -1.2965,  1.8852, -0.7487,  0.6118,\n",
       "                       -1.5544, -1.1348, -0.5475, -1.0624, -1.4468, -1.4640, -0.9082, -0.9595],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn2.running_var',\n",
       "               tensor([1.3394, 1.3275, 1.6043, 1.9834, 2.9712, 1.3753, 0.8818, 1.0296, 1.5962,\n",
       "                       1.0148, 1.4580, 1.8719, 1.6570, 2.0486, 1.5979, 1.3016, 1.5752, 3.1861,\n",
       "                       1.1801, 1.2939, 1.8046, 1.1810, 1.6310, 1.0152, 4.1390, 1.1240, 1.3682,\n",
       "                       1.0858, 1.7781, 3.6945, 1.1612, 1.5242, 1.0020, 1.1235, 1.2102, 3.1869,\n",
       "                       1.5402, 1.4177, 1.6646, 1.9554, 1.2600, 1.0655, 0.9582, 1.4516, 1.2581,\n",
       "                       1.1429, 1.0997, 1.7155, 1.3850, 1.2589, 1.6519, 1.7444, 1.3849, 1.4574,\n",
       "                       1.5285, 1.5014, 1.4100, 0.9859, 1.9232, 1.5961, 1.5263, 1.4510, 0.9963,\n",
       "                       1.1407, 1.2276, 1.7151, 1.2998, 2.3420, 1.0107, 1.3989, 6.7612, 1.1565,\n",
       "                       1.8944, 1.6379, 2.1305, 1.6754, 1.4828, 1.5181, 1.8185, 1.4575, 1.6143,\n",
       "                       1.2274, 3.0408, 1.5689, 1.8026, 1.0492, 1.3023, 1.2527, 1.3018, 2.0886,\n",
       "                       1.3230, 1.0003, 1.2581, 1.1787, 1.2732, 1.3618, 1.2917, 1.0175, 1.1352,\n",
       "                       0.9869, 1.3339, 1.2626, 1.1207, 1.2810, 1.6228, 1.2460, 1.3273, 1.1764,\n",
       "                       1.6465, 1.0006, 1.1695, 1.5514, 2.1383, 0.9449, 1.7328, 1.4695, 1.7554,\n",
       "                       1.4634, 1.2135, 1.4602, 6.9198, 1.3826, 1.1427, 1.2433, 2.5968, 1.6267,\n",
       "                       1.4625, 1.4000, 2.0479, 1.9866, 1.2767, 1.4041, 1.6277, 0.9772, 1.0680,\n",
       "                       1.4831, 1.4766, 1.5346, 1.1261, 1.3773, 0.9845, 1.8611, 1.3325, 1.0357,\n",
       "                       1.3377, 1.6198, 1.2307, 1.4821, 1.1760, 1.1760, 1.0912, 1.2041, 1.1330,\n",
       "                       1.3395, 1.8003, 1.3213, 1.5761, 1.7052, 1.7244, 1.3078, 1.0200, 1.4170,\n",
       "                       1.4108, 1.6387, 1.3237, 1.0556, 1.3268, 1.4250, 1.3830, 1.1024, 1.0299,\n",
       "                       0.9782, 1.1271, 1.3890, 3.3469, 1.1928, 1.6825, 1.6232, 1.2353, 1.1137,\n",
       "                       0.9201, 1.8155, 1.5834, 1.0534, 1.2160, 1.3252, 1.0849, 5.4157, 1.3208,\n",
       "                       1.5656, 1.3315, 1.0653, 1.3077, 1.2403, 1.8567, 1.3318, 1.0781, 1.2326,\n",
       "                       1.2461, 1.5185, 1.4402, 1.5232, 1.5990, 1.5167, 2.1364, 1.7286, 1.2257,\n",
       "                       1.5198, 1.5612, 1.3697, 1.1970, 0.9624, 1.4709, 1.8321, 1.5617, 1.4035,\n",
       "                       2.8986, 1.9164, 1.3146, 1.4207, 1.6679, 1.7461, 1.3754, 0.9515, 1.2551,\n",
       "                       1.7596, 1.6368, 1.1978, 3.0994, 1.8450, 1.4311, 1.7518, 1.6634, 1.3103,\n",
       "                       1.2836, 1.3852, 1.3423, 1.6968, 1.9751, 1.3361, 1.1085, 1.3733, 3.2369,\n",
       "                       1.3874, 1.5727, 1.3798, 1.0921, 1.0397, 1.4908, 1.2861, 1.0964, 2.8243,\n",
       "                       1.0571, 1.5163, 2.3236, 1.3966, 2.8381, 1.3516, 1.1019, 1.1098, 1.3992,\n",
       "                       1.3160, 1.5005, 1.3461, 1.1985, 1.2376, 1.5155, 1.3688, 1.3604, 1.5596,\n",
       "                       1.9811, 1.4843, 1.2225, 0.9460, 1.4853, 2.2536, 1.4768, 0.9870, 1.1785,\n",
       "                       2.1119, 1.1055, 1.7686, 2.1593, 0.9853, 1.2248, 1.1288, 1.4453, 1.1835,\n",
       "                       1.1025, 1.5906, 1.5750, 5.4535, 1.2159, 1.6162, 1.1011, 1.0813, 3.8423,\n",
       "                       1.4455, 1.5826, 1.1290, 1.1117, 1.4292, 1.5953, 1.2434, 1.4166, 1.0720,\n",
       "                       1.6946, 1.3156, 1.5678, 1.0747, 1.6800, 1.1376, 1.3865, 1.3489, 1.2925,\n",
       "                       1.9359, 1.7030, 1.2357, 2.0114, 1.3619, 1.2142, 1.2666, 1.5183, 1.3627,\n",
       "                       1.1389, 0.9872, 1.6267, 1.0723, 1.7778, 1.9022, 1.1417, 1.9419, 1.2010,\n",
       "                       1.3098, 2.5732, 2.0813, 1.2715, 1.1359, 1.4082, 1.4611, 1.3740, 1.0053,\n",
       "                       1.4971, 1.2034, 1.9569, 1.1798, 1.2345, 1.2874, 1.2967, 1.3585, 1.5656,\n",
       "                       1.0857, 1.4945, 0.9853, 1.0634, 1.1484, 1.4360, 1.2859, 1.2991, 1.7281,\n",
       "                       1.0848, 1.2844, 2.4529, 1.4775, 4.4114, 1.1813, 2.1559, 1.4505, 1.5526,\n",
       "                       5.8678, 1.2333, 1.2486, 1.4268, 1.4406, 0.8570, 1.8529, 0.9808, 2.6422,\n",
       "                       1.0644, 1.2364, 1.2886, 2.8698, 1.5690, 1.6751, 1.3796, 2.5322, 3.6516,\n",
       "                       0.9953, 1.5576, 1.1739, 1.7791, 1.3815, 1.1379, 1.4273, 1.4164, 1.3508,\n",
       "                       1.5112, 3.0312, 1.2322, 1.8211, 1.1845, 1.5219, 1.5795, 1.4019, 1.5103,\n",
       "                       1.3513, 1.2834, 1.2743, 1.1051, 0.9851, 1.3929, 1.1256, 1.3670, 2.3559,\n",
       "                       1.0386, 7.7718, 1.0896, 1.4134, 1.3331, 1.3361, 2.3425, 1.9932, 1.6029,\n",
       "                       1.1569, 1.3701, 1.3244, 1.2312, 1.4780, 2.0764, 1.1779, 1.0743, 1.2964,\n",
       "                       1.3770, 1.0578, 4.2198, 1.2256, 1.2388, 2.4476, 1.5956, 0.9886, 5.2380,\n",
       "                       1.6003, 1.7818, 1.4115, 1.3032, 1.1893, 1.3834, 1.5205, 1.5888, 1.5718,\n",
       "                       1.4942, 1.6041, 2.1773, 1.4841, 1.3197, 2.2635, 1.1355, 1.4918, 1.1349,\n",
       "                       1.0735, 4.0595, 1.6197, 1.4239, 0.9857, 1.5157, 1.0919, 1.1770, 1.1415,\n",
       "                       2.1008, 0.8112, 1.2460, 1.3474, 1.6576, 1.7387, 1.5305, 1.4982, 2.2912,\n",
       "                       1.6391, 1.3777, 1.1085, 1.8090, 2.0778, 3.0224, 4.1967, 1.0830, 1.5157,\n",
       "                       1.5681, 1.6781, 1.0243, 1.6637, 1.8572, 2.2299, 1.0958, 1.3413, 1.5956,\n",
       "                       1.4895, 1.1863, 1.8908, 1.2692, 1.1659, 1.3450, 2.1949, 1.1658, 2.3499,\n",
       "                       1.5826, 1.5599, 0.9431, 1.6054, 1.4684, 1.4420, 1.3562, 1.3324],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.1.conv3.weight',\n",
       "               tensor([[[[-0.0806]],\n",
       "               \n",
       "                        [[-0.0315]],\n",
       "               \n",
       "                        [[ 0.0126]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0249]],\n",
       "               \n",
       "                        [[ 0.0559]],\n",
       "               \n",
       "                        [[-0.0684]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0536]],\n",
       "               \n",
       "                        [[-0.0539]],\n",
       "               \n",
       "                        [[-0.0126]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0078]],\n",
       "               \n",
       "                        [[ 0.0021]],\n",
       "               \n",
       "                        [[-0.0215]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0104]],\n",
       "               \n",
       "                        [[-0.0558]],\n",
       "               \n",
       "                        [[-0.0061]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0478]],\n",
       "               \n",
       "                        [[-0.0156]],\n",
       "               \n",
       "                        [[-0.0129]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0061]],\n",
       "               \n",
       "                        [[-0.0301]],\n",
       "               \n",
       "                        [[-0.0165]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0462]],\n",
       "               \n",
       "                        [[ 0.0030]],\n",
       "               \n",
       "                        [[-0.0570]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0112]],\n",
       "               \n",
       "                        [[-0.0263]],\n",
       "               \n",
       "                        [[-0.0350]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0178]],\n",
       "               \n",
       "                        [[-0.0070]],\n",
       "               \n",
       "                        [[-0.0113]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0232]],\n",
       "               \n",
       "                        [[ 0.0234]],\n",
       "               \n",
       "                        [[-0.0209]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0225]],\n",
       "               \n",
       "                        [[-0.0463]],\n",
       "               \n",
       "                        [[ 0.0025]]]], device='cuda:0')),\n",
       "              ('module.layer4.1.bn3.weight',\n",
       "               tensor([1.6713, 1.7900, 1.9186,  ..., 2.0052, 1.8894, 2.1757], device='cuda:0')),\n",
       "              ('module.layer4.1.bn3.bias',\n",
       "               tensor([-2.5959, -2.5213, -3.0587,  ..., -3.3474, -2.8375, -3.2102],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn3.running_mean',\n",
       "               tensor([-0.4821, -0.0430, -0.5416,  ..., -0.1958, -0.8229, -0.2852],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.1.bn3.running_var',\n",
       "               tensor([0.1018, 0.1361, 0.1840,  ..., 0.1703, 0.1930, 0.1410], device='cuda:0')),\n",
       "              ('module.layer4.1.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.2.conv1.weight',\n",
       "               tensor([[[[-0.0212]],\n",
       "               \n",
       "                        [[ 0.0144]],\n",
       "               \n",
       "                        [[ 0.0014]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0343]],\n",
       "               \n",
       "                        [[-0.0123]],\n",
       "               \n",
       "                        [[ 0.0027]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0250]],\n",
       "               \n",
       "                        [[-0.0281]],\n",
       "               \n",
       "                        [[ 0.0426]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0210]],\n",
       "               \n",
       "                        [[-0.0007]],\n",
       "               \n",
       "                        [[-0.0196]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0099]],\n",
       "               \n",
       "                        [[-0.0257]],\n",
       "               \n",
       "                        [[ 0.0105]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0166]],\n",
       "               \n",
       "                        [[-0.0139]],\n",
       "               \n",
       "                        [[ 0.0136]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0100]],\n",
       "               \n",
       "                        [[-0.0319]],\n",
       "               \n",
       "                        [[-0.0068]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0153]],\n",
       "               \n",
       "                        [[ 0.0032]],\n",
       "               \n",
       "                        [[-0.0129]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0148]],\n",
       "               \n",
       "                        [[ 0.0022]],\n",
       "               \n",
       "                        [[-0.0176]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0053]],\n",
       "               \n",
       "                        [[-0.0241]],\n",
       "               \n",
       "                        [[-0.0165]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0339]],\n",
       "               \n",
       "                        [[-0.0201]],\n",
       "               \n",
       "                        [[-0.0102]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0102]],\n",
       "               \n",
       "                        [[-0.0153]],\n",
       "               \n",
       "                        [[-0.0195]]]], device='cuda:0')),\n",
       "              ('module.layer4.2.bn1.weight',\n",
       "               tensor([1.6918, 2.6360, 1.2351, 2.0994, 1.8354, 1.5677, 1.9352, 0.7296, 1.4747,\n",
       "                       2.6344, 1.4226, 1.2482, 2.4016, 0.9641, 1.7058, 2.8721, 1.2646, 1.4945,\n",
       "                       1.6306, 1.0368, 1.6077, 2.0652, 1.2390, 0.4722, 1.7831, 1.6449, 1.1777,\n",
       "                       1.2546, 2.5421, 1.0186, 1.4288, 2.3448, 1.9243, 1.6428, 1.5091, 1.5544,\n",
       "                       2.0286, 2.3673, 0.9276, 2.3566, 1.8177, 2.2042, 2.0778, 0.9767, 2.3170,\n",
       "                       1.1371, 1.8175, 1.0243, 1.4616, 2.0065, 0.8335, 1.3752, 2.4144, 1.4520,\n",
       "                       1.7829, 1.9138, 2.1594, 1.7885, 1.0913, 1.4959, 1.2240, 1.8646, 0.9514,\n",
       "                       0.7992, 2.5283, 1.7299, 1.4553, 0.8674, 1.1769, 0.6932, 2.1008, 1.1855,\n",
       "                       1.8632, 1.6277, 2.0320, 1.5775, 0.7929, 1.0987, 1.6152, 2.0358, 2.1590,\n",
       "                       2.3273, 0.8884, 1.3603, 2.3260, 2.1162, 1.6511, 1.8649, 2.3547, 1.1060,\n",
       "                       2.3128, 2.3231, 1.3612, 1.2157, 2.5990, 2.5110, 1.7546, 2.3032, 0.8933,\n",
       "                       1.4310, 0.5466, 1.9159, 2.0801, 1.5019, 2.3444, 2.0128, 1.1848, 2.5684,\n",
       "                       0.9309, 1.8522, 1.5747, 2.0278, 1.0936, 2.1699, 0.9906, 2.0120, 1.1722,\n",
       "                       1.6688, 1.8350, 1.4128, 1.0935, 1.0866, 1.4957, 1.3593, 1.8409, 0.9266,\n",
       "                       0.9002, 1.9727, 1.4266, 1.2650, 0.7264, 1.7329, 2.4629, 0.7517, 0.9773,\n",
       "                       2.4966, 0.8454, 2.2994, 2.7129, 1.2844, 1.6081, 2.1494, 1.2329, 1.3324,\n",
       "                       1.0543, 2.2488, 1.5028, 2.2897, 0.7052, 0.6336, 2.2433, 1.5277, 2.3747,\n",
       "                       2.1805, 1.7559, 1.6414, 1.7982, 2.3488, 0.9445, 0.9872, 1.5566, 2.5518,\n",
       "                       2.4657, 2.0003, 2.7538, 2.2015, 2.2303, 2.1889, 1.0812, 2.2036, 1.8331,\n",
       "                       1.3302, 1.5792, 1.1989, 1.0524, 2.1661, 0.7190, 2.4771, 1.4132, 2.3933,\n",
       "                       2.0670, 1.4094, 2.5023, 1.7241, 2.1395, 1.0673, 0.7688, 1.2848, 1.7357,\n",
       "                       0.8990, 2.3460, 2.2739, 1.0890, 1.1166, 1.0971, 1.2018, 1.0187, 0.9617,\n",
       "                       2.2014, 2.2570, 1.3895, 1.2491, 1.2985, 0.8122, 1.5067, 1.2378, 1.4638,\n",
       "                       1.7127, 1.0987, 2.2441, 0.7873, 1.8886, 1.4593, 2.6389, 1.6377, 1.5519,\n",
       "                       1.4485, 2.0976, 1.8545, 2.4124, 1.1333, 1.2108, 1.4391, 1.2702, 0.9750,\n",
       "                       1.0233, 1.2821, 0.8844, 1.3940, 1.0995, 2.2384, 0.5937, 1.6563, 2.8020,\n",
       "                       2.4909, 2.1265, 1.1232, 1.8342, 2.2425, 2.5600, 1.7892, 1.3710, 2.2618,\n",
       "                       2.1298, 1.4094, 1.4121, 2.7019, 1.1956, 1.8446, 1.7080, 0.6817, 2.1890,\n",
       "                       2.7073, 1.7289, 2.8666, 2.4369, 1.9223, 1.1802, 1.2891, 1.5522, 1.2251,\n",
       "                       2.7056, 1.9882, 2.1912, 1.8900, 0.6473, 1.1879, 0.9955, 1.2694, 2.0528,\n",
       "                       0.9987, 2.0700, 1.0633, 1.3483, 0.7504, 1.0727, 1.1799, 0.8627, 1.6549,\n",
       "                       1.8861, 1.7287, 0.7419, 1.4140, 0.8572, 0.9354, 0.9957, 2.5295, 1.3025,\n",
       "                       0.9576, 2.3786, 1.0686, 1.2914, 1.9954, 2.2567, 2.1961, 2.4509, 2.1253,\n",
       "                       1.4571, 1.2557, 1.4453, 2.2152, 1.4469, 1.4526, 1.3325, 2.1325, 0.9088,\n",
       "                       1.3123, 1.1695, 1.2373, 0.9364, 2.5010, 1.2822, 1.9040, 2.1742, 1.7993,\n",
       "                       1.1168, 0.9107, 1.8858, 0.9853, 0.8582, 1.2473, 0.6874, 0.5973, 1.3662,\n",
       "                       2.0166, 1.2359, 1.9675, 1.5678, 1.2927, 1.1847, 0.9893, 2.4728, 1.1303,\n",
       "                       2.2718, 2.1562, 1.7685, 1.4135, 1.1705, 2.0808, 1.3132, 1.3429, 0.9787,\n",
       "                       1.9630, 2.4436, 1.6396, 0.9101, 2.1137, 2.0145, 2.2326, 2.2525, 1.8857,\n",
       "                       0.8766, 1.0702, 1.2957, 1.8408, 1.6002, 1.7998, 1.2859, 2.1592, 0.7377,\n",
       "                       2.2008, 2.1376, 1.3028, 1.4715, 1.8570, 0.7047, 1.1630, 1.2815, 2.2641,\n",
       "                       2.1051, 0.7648, 1.4796, 1.4877, 0.9351, 1.9578, 1.9286, 1.1410, 1.8214,\n",
       "                       1.1099, 2.5870, 0.7914, 1.7255, 1.8295, 1.3629, 1.2058, 1.6343, 2.3489,\n",
       "                       1.5913, 2.3238, 1.9310, 0.9855, 0.9481, 0.8576, 2.3487, 0.9700, 1.6353,\n",
       "                       1.7813, 0.8478, 1.8693, 1.8390, 1.6932, 1.3245, 2.6359, 2.0831, 2.1020,\n",
       "                       1.3273, 0.9810, 1.5695, 1.6856, 0.7044, 1.7654, 2.6402, 1.2358, 2.5592,\n",
       "                       2.4537, 2.4352, 1.9254, 1.1874, 1.3330, 2.6053, 0.8059, 2.1970, 1.0724,\n",
       "                       1.3767, 1.1182, 1.4909, 2.6437, 1.0561, 1.9713, 1.3691, 1.3614, 1.8033,\n",
       "                       2.2101, 1.6007, 1.1876, 2.2581, 0.6799, 1.7872, 2.1853, 1.2459, 2.0136,\n",
       "                       1.5364, 2.2759, 3.1630, 2.4170, 0.7643, 1.8931, 0.8789, 1.4352, 2.0504,\n",
       "                       0.7293, 1.4538, 1.5204, 1.0281, 2.2783, 1.0855, 2.4093, 2.3729, 1.5295,\n",
       "                       0.7129, 0.9256, 1.8786, 1.3888, 1.2163, 1.9567, 1.0864, 1.0637, 1.3721,\n",
       "                       0.7771, 0.8016, 1.0185, 1.4708, 0.9632, 1.5638, 0.5140, 1.2970, 2.5070,\n",
       "                       1.8806, 1.5392, 1.6770, 1.2791, 2.0729, 1.1730, 1.8074, 0.8105, 1.5606,\n",
       "                       1.3611, 0.7579, 1.2544, 1.5086, 1.2023, 1.4739, 1.0294, 1.9573, 0.9156,\n",
       "                       1.4402, 1.4384, 1.2260, 1.0750, 1.1269, 2.3248, 0.9444, 1.7176, 1.0568,\n",
       "                       0.9279, 2.3878, 1.5531, 1.4985, 2.2061, 1.6592, 2.1754, 1.3076],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.2.bn1.bias',\n",
       "               tensor([-1.3314, -2.9020, -1.0269, -1.9394, -1.6849, -1.4151, -1.8369, -0.2397,\n",
       "                       -0.9736, -2.6774, -1.3741, -1.1053, -2.5193, -0.8372, -1.4640, -2.9833,\n",
       "                       -0.9495, -0.9938, -1.2516,  0.4205, -1.2708, -1.9015, -1.1371,  0.2060,\n",
       "                       -1.2548, -1.2978, -0.7233, -0.8481, -2.7017, -0.7881, -1.1258, -3.1600,\n",
       "                       -1.9234, -1.4657, -1.0252, -1.2733, -2.2424, -2.6186, -0.3934, -2.2427,\n",
       "                       -2.2673, -2.2088, -1.9390, -0.7369, -2.5485, -0.6152, -1.6105, -0.6295,\n",
       "                       -1.4330, -1.6633,  0.2500, -1.3380, -2.4809, -1.5586, -1.5765, -1.9780,\n",
       "                       -2.4459, -0.8498, -0.6087, -1.5456, -0.8269, -1.7421, -0.6821, -0.2279,\n",
       "                       -2.7786, -1.4131, -1.1973, -0.2297, -1.4899, -0.0335, -1.6250, -0.1522,\n",
       "                       -1.6855, -1.1311, -2.0632, -1.5281,  0.6114, -0.6705, -1.2300, -2.1738,\n",
       "                       -2.2963, -2.1777, -0.4795, -0.8914, -2.2542, -2.0694, -1.9330, -1.8219,\n",
       "                       -2.4719, -0.9921, -2.4395, -2.1937, -0.8666, -0.7287, -2.8312, -2.6706,\n",
       "                       -1.8966, -2.0278, -0.0722, -1.1928,  0.1631, -1.5569, -1.9985, -1.3561,\n",
       "                       -2.5445, -1.9756, -1.0068, -2.7643, -0.5575, -1.5077, -1.1695, -1.7918,\n",
       "                       -0.4907, -2.0124, -0.4454, -0.9623, -0.3677, -1.7569, -1.8240, -1.0332,\n",
       "                       -0.8406,  0.2695, -1.4020, -1.2481, -1.8016, -0.3120, -0.5461, -1.6963,\n",
       "                       -1.1074, -0.6982,  0.7426, -1.5188, -2.6276, -0.1191, -0.6190, -3.1426,\n",
       "                       -0.2669, -2.2365, -2.9826, -0.8665, -1.6110, -2.1778, -0.7528, -0.7106,\n",
       "                        0.0899, -2.3307, -1.2132, -2.1559,  0.0572,  0.0880, -2.3244, -1.3146,\n",
       "                       -2.6154, -2.2419, -1.8144, -1.3799, -1.6038, -2.6303, -0.7442, -0.3474,\n",
       "                       -1.5616, -2.5425, -2.4317, -1.9620, -2.7620, -2.2652, -2.0601, -1.8221,\n",
       "                       -1.1326, -2.2480, -1.9249, -1.5005, -1.3931, -0.7429, -0.7584, -2.3185,\n",
       "                        0.3433, -2.3616, -1.7665, -2.6679, -1.9668, -1.0647, -2.5767, -1.8758,\n",
       "                       -1.9806, -1.4120,  0.2779, -1.1972, -1.5729, -0.3786, -2.4218, -2.3120,\n",
       "                       -0.0887, -0.8805, -0.7634, -0.4831, -0.7703, -0.5668, -2.2507, -2.1564,\n",
       "                       -1.3231, -0.8995, -1.3710, -0.1016, -1.1848, -0.7834, -0.8106, -0.9350,\n",
       "                       -0.8346, -2.3997, -0.1777, -1.9624, -1.3448, -2.8118, -1.4047, -1.4987,\n",
       "                       -1.2188, -2.0005, -2.0350, -2.4934,  0.0523, -1.1755, -1.4827, -0.7659,\n",
       "                       -0.6862, -0.8857, -0.6434, -0.4621, -0.9885, -0.3979, -2.3704,  0.6141,\n",
       "                       -1.8377, -2.9189, -2.6798, -2.2712, -0.7450, -1.5824, -2.1502, -2.4942,\n",
       "                       -1.6482, -0.9535, -2.3252, -2.2754, -0.9501, -1.3206, -2.8206, -0.7925,\n",
       "                       -1.9601, -1.2092,  0.4930, -1.2329, -3.0567, -1.5633, -3.0923, -2.4130,\n",
       "                       -1.5407, -0.9333, -0.8282, -1.4832, -0.8857, -3.0305, -1.8107, -2.2863,\n",
       "                       -1.7796, -0.0496, -0.6059, -0.5693, -0.7617, -1.8123, -0.5237, -1.6186,\n",
       "                       -0.8406, -1.2940, -0.1644, -0.7510, -0.8083, -0.1843, -1.7426, -1.7136,\n",
       "                       -1.7968, -0.2106, -0.9626, -0.2212, -0.2357, -0.5766, -2.7559, -1.0879,\n",
       "                       -0.6677, -2.8070, -0.8346, -0.9684, -1.6385, -2.4669, -2.1830, -2.4059,\n",
       "                       -2.2632, -0.8031, -1.1804, -0.8260, -2.2373, -1.3290, -1.2932, -0.9086,\n",
       "                       -1.7733, -0.4717, -0.8596, -1.2617, -0.9307, -0.3472, -2.2551, -1.1090,\n",
       "                       -1.6397, -2.0700, -1.5663, -0.7488, -0.5722, -1.8454, -0.4388, -0.4276,\n",
       "                       -0.9539,  0.1723,  0.0153, -1.1331, -1.7753, -0.7167, -1.8717, -1.4049,\n",
       "                       -1.3332, -0.8734, -0.5807, -2.5010, -1.0910, -2.3616, -2.0803, -1.7806,\n",
       "                       -1.2752, -0.7539, -1.6947, -0.8202, -0.6867, -0.5532, -2.2597, -2.8721,\n",
       "                       -1.4595, -0.5243, -1.6452, -1.9146, -2.6148, -2.3329, -1.9265, -0.3259,\n",
       "                       -0.5342, -1.1532, -1.7361, -1.4477, -1.5858, -0.5597, -2.4785, -0.2260,\n",
       "                       -2.2728, -1.9270, -1.0139, -1.0562, -2.0010, -0.0470, -0.6235, -0.7081,\n",
       "                       -2.4709, -2.3081, -0.3004, -1.1337, -1.0616, -0.3966, -2.1552, -1.8232,\n",
       "                        0.2461, -1.6290, -0.6515, -2.5455, -0.1753, -1.7713, -1.4988, -1.4081,\n",
       "                       -0.7393, -1.5473, -2.4880, -1.0637, -2.6015, -1.6945, -0.8423, -0.3831,\n",
       "                       -0.0919, -2.1910, -0.3020, -1.6860, -0.7629, -0.2013, -1.6795, -1.9235,\n",
       "                       -1.3991, -0.9125, -2.6555, -2.0627, -2.0181, -0.7776, -0.4636, -1.0225,\n",
       "                       -1.2242,  0.2340, -1.5319, -2.7365, -0.3387, -2.7864, -3.1041, -2.6573,\n",
       "                       -1.8724, -0.7794, -0.6427, -2.5254, -0.2698, -2.1046, -1.0340, -1.1991,\n",
       "                       -0.6163, -1.4140, -2.5942, -0.8373, -1.9322, -0.9680, -0.8779, -1.4562,\n",
       "                       -2.0970, -1.7495, -0.8770, -2.2736,  0.2345, -1.6893, -2.3693, -1.4942,\n",
       "                       -1.9620, -1.1390, -2.3270, -4.7096, -2.9462, -0.0806, -1.8673, -0.2112,\n",
       "                       -1.1497, -2.2027, -0.0396, -1.4565, -1.6890, -0.7804, -2.4010, -0.5814,\n",
       "                       -2.4832, -2.5089, -2.0640, -0.1195, -0.4375, -1.5093, -1.2631, -1.0978,\n",
       "                       -1.5913, -0.6759, -0.5408, -0.9253, -0.3519,  0.1409, -0.5925, -1.0772,\n",
       "                       -0.2457, -1.5878, -0.1384, -1.2476, -2.8344, -0.9824, -1.2014, -1.3749,\n",
       "                       -1.0429, -1.5451, -1.3514, -1.6926,  0.3435, -1.3368, -1.1987, -0.3137,\n",
       "                       -1.1946, -1.7222, -0.8339, -0.6118, -0.7206, -1.7290, -0.1948, -1.0475,\n",
       "                       -1.1911, -0.8335, -0.4622, -0.5581, -2.3366, -0.3845, -1.3930, -0.5279,\n",
       "                       -0.3026, -2.4994, -1.8809, -1.1471, -2.2859, -1.7109, -1.9356, -1.0837],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.2.bn1.running_mean',\n",
       "               tensor([-1.8769, -2.1513, -2.2488, -1.7998, -2.0396, -1.7238, -1.9943, -1.0559,\n",
       "                       -2.2941, -2.4776, -1.5682, -0.8658, -2.3610, -0.4429, -1.7065, -2.1176,\n",
       "                       -3.7058, -1.8469, -2.0777, -2.4811, -1.8855, -2.4402,  0.8586, -0.9068,\n",
       "                       -2.1857, -1.7288, -2.0239, -1.0244, -2.0247, -0.7792, -1.5427, -1.8415,\n",
       "                       -1.8000, -1.2237, -2.0016, -1.0452, -1.5902, -2.1666, -1.9312, -2.3208,\n",
       "                       -1.3759, -2.0352, -2.1007, -0.5795, -2.0004, -1.5031, -1.9231, -0.8312,\n",
       "                       -0.8998, -1.9832, -1.6616, -1.5284, -2.5641, -1.1753, -1.3796, -1.7444,\n",
       "                       -1.8958, -1.3402, -1.6154, -1.5171, -0.9218, -1.6538, -0.2233, -0.6928,\n",
       "                       -2.2658, -2.1547, -1.7874, -1.6700,  0.0311, -1.5043, -2.3216, -2.0557,\n",
       "                       -1.6099, -2.0929, -2.1615, -0.9605,  5.7315, -2.2540, -1.7711, -1.7191,\n",
       "                       -1.3790, -2.0474, -0.8279, -1.8480, -1.6505, -2.0547, -1.3652, -1.9196,\n",
       "                       -2.0458, -2.7985, -2.0081, -2.2417, -2.1814, -1.5195, -1.8255, -2.1261,\n",
       "                       -1.9070, -2.1086, -0.7555, -1.6911,  0.7991, -1.8835, -2.1852, -1.5943,\n",
       "                       -1.8424, -1.8810, -1.0546, -2.1654, -1.0975, -1.9765, -1.4234, -1.8381,\n",
       "                       -1.1352, -2.0212, -2.1659, -4.5398, -0.4316, -1.3381, -1.5286, -2.9339,\n",
       "                       -0.9538, -1.7260, -1.4687, -0.5989, -1.7833, -1.8557, -0.7791, -1.9991,\n",
       "                       -2.0803, -0.7780, -0.4574, -1.5111, -2.1915, -1.5392, -1.2419, -1.7757,\n",
       "                       -1.3366, -1.7325, -1.9819, -1.7354, -1.4010, -2.0663, -1.1455, -2.1187,\n",
       "                        1.9000, -1.7636, -2.2856, -1.5741, -0.6703, -0.3489, -1.5716, -1.5549,\n",
       "                       -1.6170, -1.9329, -1.5795, -1.4981, -1.6216, -2.3952, -0.9799, -1.6014,\n",
       "                       -1.4305, -2.3789, -2.1197, -1.8492, -2.4254, -2.1232, -2.2419, -0.3551,\n",
       "                       -0.3339, -1.5585, -2.0522, -0.7979, -1.4190, -1.1420, -0.8752, -1.4779,\n",
       "                       -2.5275, -2.1005, -1.1815, -1.7406, -2.1562, -1.3882, -2.5395, -1.6770,\n",
       "                       -2.0646, -0.2924,  0.8413,  1.8012, -2.4446, -2.0050, -1.9764, -1.6612,\n",
       "                       -0.1709, -1.5842, -1.0311, -1.9123, -0.8309, -1.1983, -1.9196, -1.5639,\n",
       "                       -1.7405, -1.9767, -0.5711, -0.4559, -1.9881, -1.9575, -2.9791, -1.6770,\n",
       "                       -0.6548, -1.5490, -1.6219, -1.3664, -0.9092, -2.5422, -1.8274, -1.8825,\n",
       "                       -1.6863, -1.9176, -1.3860, -2.1479, -2.3539, -1.5113, -0.8489, -3.0175,\n",
       "                       -1.0093, -0.6227, -1.5770, -1.6824, -3.1652, -1.8608, -1.9588, -4.3887,\n",
       "                       -1.9548, -2.2309, -1.9328, -1.6761, -0.7757, -1.8668, -2.0499, -2.6417,\n",
       "                       -1.3764, -1.0469, -2.1791, -1.8392, -1.9942, -1.3437, -2.3973, -1.1329,\n",
       "                       -1.2545, -1.7394, -1.4828,  1.5325, -2.5230, -1.5030, -2.2524, -2.1473,\n",
       "                       -4.1428, -0.6707, -2.3840, -1.6137, -0.8049, -2.1880, -2.0976, -1.7479,\n",
       "                       -1.9630, -1.4827, -1.8162, -1.4121, -2.1282, -1.8674, -1.1899, -1.7009,\n",
       "                       -1.3490, -1.0445, -1.6037,  1.3772, -1.5627, -1.1185, -0.7656, -1.8004,\n",
       "                       -1.2711, -0.4020, -2.4555, -1.4753, -2.1145, -0.9720, -2.1733, -1.1465,\n",
       "                       -1.9540, -1.6169, -1.0691, -0.6455, -2.2034, -1.7710, -1.8366, -2.7266,\n",
       "                       -1.9081, -2.1113, -1.7452, -2.0885, -1.9627, -0.9745, -0.9114, -1.7279,\n",
       "                       -2.1804, -1.5976, -1.5147, -0.7348, -2.1173, -1.6256, -2.6553, -1.6352,\n",
       "                       -2.2193, -1.6429,  1.1205, -1.2779, -1.2566, -1.5415, -0.4577, -1.8869,\n",
       "                       -1.5196, -0.4131, -0.9322, -1.5456, -2.3215, -2.1540, -2.0006, -0.9486,\n",
       "                       -0.9013, -1.3139, -0.7903, -1.9663, -0.2895, -1.7436, -2.1001, -1.4424,\n",
       "                       -1.2714, -2.1758, -2.1145, -3.7900, -1.9271, -2.2966, -2.5482, -1.8983,\n",
       "                       -1.5868, -0.2124, -1.9524, -1.9149, -1.8425, -1.6981, -1.8650, -0.9746,\n",
       "                       -1.0438, -1.0530, -1.8294,  3.4624, -1.7356, -1.4550, -1.5558, -1.4066,\n",
       "                       -1.9433, -2.0878, -0.8045, -2.1928, -2.1514, -1.3966, -1.6816, -0.4354,\n",
       "                       -1.8769, -1.7998, -0.6484, -1.6690, -1.3502, -1.2737, -1.9689, -1.7137,\n",
       "                        0.9359, -1.9436, -1.9277, -2.3200, -2.0604, -1.8225, -2.1517, -1.0646,\n",
       "                       -2.9631, -1.9445, -2.0074, -2.0805, -2.3349, -1.7493, -0.1092, -1.5737,\n",
       "                       -5.5535, -1.9236, -1.5388, -1.2155, -1.5518, -1.5444, -2.0795, -1.9738,\n",
       "                       -1.5300, -1.7072, -2.2070, -2.0894, -1.8215, -2.8287,  0.0118, -2.0069,\n",
       "                       -1.5999,  0.0963, -1.5607, -2.4700, -0.4017, -2.1293, -2.1572, -1.9540,\n",
       "                       -2.0004, -1.8424, -1.2895, -2.4082, -2.1784, -1.9932, -1.0443, -1.2413,\n",
       "                       -1.7272,  0.7351, -2.7038, -1.3123, -1.5059, -1.7193, -2.4543, -1.8586,\n",
       "                       -1.9249, -1.7235, -0.6253, -1.8591, -1.5108, -1.6085, -1.6620, -0.5122,\n",
       "                       -1.7431, -1.6326, -1.9565,  1.2445, -1.6475, -2.3836, -1.6822, -1.5778,\n",
       "                       -2.0275, -2.1065, -2.1642, -1.3044, -1.2651, -1.2518, -2.3528, -0.9939,\n",
       "                       -2.0367, -1.9244, -0.7880, -1.5361, -1.9834, -2.0419, -1.7181, -1.1915,\n",
       "                       -1.9477, -2.2076, -1.4795, -1.7795, -1.2573,  0.2939, -0.8428, -1.2917,\n",
       "                       -1.4043, -1.3076, -0.0657, -0.3692, -1.9168, -3.6977, -1.5389, -1.7209,\n",
       "                       -1.8886, -1.9849, -0.2842, -1.6144,  0.7195, -1.4234, -1.2531, -1.5095,\n",
       "                       -1.5105, -0.8901, -1.5759, -3.9244, -1.7249, -2.0376, -1.5896, -1.5696,\n",
       "                       -0.2399, -2.2107, -1.7370, -2.1111, -2.0672, -2.1228, -2.0837, -1.4254,\n",
       "                       -1.9308, -2.0997, -1.3817, -2.1551, -1.9652, -1.6443, -1.8290, -1.0733],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.2.bn1.running_var',\n",
       "               tensor([  7.0924,   8.3644,   6.8938,   9.0419,   8.4534,   4.6576,   7.3616,\n",
       "                         5.0779,  11.3326,  10.8184,  10.2795,   3.2163,  10.9065,   5.1754,\n",
       "                        10.8864,  11.9660,   6.2258,  10.4036,   8.5601,  38.1243,   8.1851,\n",
       "                         9.0955,   8.5484,   4.3581,  13.2020,   8.3138,   7.1564,   6.3009,\n",
       "                         9.4018,   4.4887,   5.9983,   5.3622,   4.9739,   7.4996,   9.2274,\n",
       "                         8.1708,   6.2616,   7.2979,   5.9822,   8.8486,   5.1861,   8.0020,\n",
       "                         9.7398,   6.4366,   7.0333,   7.8530,   7.3000,   4.8858,   4.6107,\n",
       "                        10.6979,  15.4917,   4.7493,   9.9796,   4.0555,   7.7915,   6.2732,\n",
       "                         7.0069,  14.8663,   7.6641,   3.6915,   4.5569,   7.3824,   3.8711,\n",
       "                         6.3355,   8.4791,   6.7629,   6.8095,   8.7417,   3.8468,  10.0857,\n",
       "                        12.4774,  16.5003,   6.8908,  10.6063,   9.0413,   5.2355, 117.1492,\n",
       "                         6.4753,   7.5375,   6.0980,   8.5872,   8.3861,  11.8876,   5.9729,\n",
       "                         8.6039,   8.3397,   3.3049,   6.1083,   6.8346,   4.8472,   7.3443,\n",
       "                        10.4185,   8.5723,   8.1899,   8.8243,   9.6127,   5.8409,  12.0483,\n",
       "                        14.5362,   5.6073,  12.0275,   8.3896,   8.6454,   5.2963,   8.1503,\n",
       "                         7.2613,   3.4848,   9.3781,   6.0257,   8.5221,   7.7502,   9.4218,\n",
       "                         9.0016,   7.9862,  14.9309,  27.6685,  10.9047,   6.4342,   5.8900,\n",
       "                         9.1818,   3.9424,  22.9599,   4.8499,   4.0569,   5.6106,  10.6451,\n",
       "                         4.1314,   8.8805,   6.3123,   6.6200,  12.1191,   5.7827,  10.4391,\n",
       "                         7.3371,   5.6648,   7.1193,   5.8101,   9.6143,  11.6045,  12.2037,\n",
       "                         3.8768,   7.9770,   6.4759,  12.1295,  28.3449,   6.7741,   7.0530,\n",
       "                         9.2632,  10.6113,   3.2848,   8.3903,   4.7191,   6.6011,   7.5648,\n",
       "                         4.2924,   5.8467,   6.6854,   7.8891,   3.4241,   9.0807,   4.7202,\n",
       "                        12.4743,   9.6843,   7.6809,  10.6561,   7.8742,   8.9192,  10.0977,\n",
       "                         3.7300,   5.9310,   5.6532,   3.4231,   5.8177,   6.7090,   3.6739,\n",
       "                         8.5648,   6.9360,   8.6677,   4.3020,   6.5202,   8.6384,   8.8761,\n",
       "                         9.5691,   5.2823,   6.8123,   2.5640,  16.1084,   9.0492,   5.5666,\n",
       "                         5.4515,   9.5612,   7.9868,  20.3389,   4.8881,   4.7097,  16.4142,\n",
       "                         3.7445,   3.8454,   7.3871,   9.5771,   6.6494,   4.8667,   3.3441,\n",
       "                         7.7804,   4.9681,   7.2168,   7.2845,  16.1481,   4.6838,   5.9254,\n",
       "                        20.0120,   6.3557,   5.1279,  12.0139,   6.5762,   6.4145,   5.6257,\n",
       "                         9.2523,   5.2052,   8.0974,  37.6237,   4.7759,   2.5711,   6.7548,\n",
       "                         3.5592,   6.4243,  11.4903,   6.8644,   7.0308,  11.7087,   7.3483,\n",
       "                        23.4740,   6.3087,  11.9282,   7.9398,   5.6628,   9.4723,   8.6121,\n",
       "                         8.4776,  12.5734,   7.5694,   6.8593,   7.5797,   6.5586,   6.9034,\n",
       "                         4.1146,  10.1087,   5.8104,   4.6552,   8.5863,   8.1600,  25.7776,\n",
       "                         9.5876,   6.2211,  11.7720,  10.4541,   4.8696,   4.2818,   6.1631,\n",
       "                         4.6922,   5.4600,   9.0083,   9.9425,   8.3656,   6.8125,   5.1717,\n",
       "                         8.9645,   6.0792,   9.1514,   9.0078,   6.7484,  12.1305,   4.0170,\n",
       "                         5.4388,   5.9753,   5.5606,  10.4609,  12.2660,   4.7518,   6.2349,\n",
       "                         5.3920,   6.8249,   5.8868,   7.3077,  12.7540,   8.4044,   8.8886,\n",
       "                         4.5030,   5.0966,   6.2832,   4.1333,   5.0420,  11.3999,   6.5010,\n",
       "                         8.2437,  11.9952,   7.5945,  13.8990,   4.2459,  14.4094,  11.4551,\n",
       "                         4.7683,   5.4194,   8.1123,  10.5205,   5.3339,   5.9663,   3.1375,\n",
       "                         3.9467,   7.9188,  14.5485,   5.1993,   9.6467,   6.5709,   6.0963,\n",
       "                         5.3052,   5.5157,   8.5530,   9.5540,   5.3163,   7.1108,   7.4933,\n",
       "                         6.7391,   4.7738,  10.1932,   8.4150,   6.6293,   6.3036,   4.1881,\n",
       "                         8.5871,   6.6355,   8.8031,   5.6064,   9.3700,   7.4950,   5.2346,\n",
       "                         4.0237,   8.7582,  10.8386,   8.1919,   9.4115,   7.3321,   4.6654,\n",
       "                         7.3235,   5.3260,   3.7573,  14.9335,   7.0182,   7.8994,   7.8594,\n",
       "                         7.2208,   5.0452,   8.6984,   3.8251,   7.2746,   9.7001,   8.8381,\n",
       "                        13.5277,   5.4073,   5.0013,   7.4819,  11.1008,   6.0281,   5.5783,\n",
       "                         6.8546,   9.7693,   7.8075,  10.4781,   7.1786,   6.0513,   4.4431,\n",
       "                         5.8772,   6.3273,   8.5056,   6.5409,   6.8173,  19.1949,   7.2343,\n",
       "                         5.0599,  10.3652,  11.1166,   5.2383,  10.5918,   5.2396,   8.3923,\n",
       "                         5.5475,   9.2494,  10.1282,   8.4076,   7.5341,   3.6429,   5.9712,\n",
       "                         9.2278,   9.5199,  13.8118,   4.9333,  11.0837,   9.3877,   7.7022,\n",
       "                         4.7554,   7.7318,   7.1342,  11.0674,   6.8807,   8.2774,   9.2349,\n",
       "                         4.8580,   9.5044,   8.5660,   7.2068,   8.8923,   9.6538,  14.6089,\n",
       "                        10.1580,   7.2434,   8.1429,   8.0150,   8.2256,   9.8519,  10.5444,\n",
       "                         5.4249,   9.2664,   3.7588,   5.7914,   7.9616,   9.9477,  13.0277,\n",
       "                         4.1530,   7.7618,   6.3400,   9.4118,   7.6992,  10.3907,   4.5755,\n",
       "                         4.7591,   9.7457,   7.2599,   6.2634,   7.7602,   2.8508,   9.0726,\n",
       "                         7.6445,  10.8603,   8.8891,   6.5611,  10.4828,   6.2667,  10.4960,\n",
       "                        12.0230,   6.1884,   6.5488,   4.1625,   5.4620,   3.5006,   8.0565,\n",
       "                         6.6219,   8.6405,   7.7903,   3.6525,   6.1528,   6.7778,   8.5180,\n",
       "                         5.1066,   5.2632,  10.8568,   6.1874,   8.8968,   6.7231,   3.9085,\n",
       "                        15.1246,   6.2903,   7.1972,  14.0561,   5.3648,   4.7203,   3.8641,\n",
       "                         7.8886,  17.2074,   7.0446,   7.1184,   5.6138,  11.6853,   3.0002,\n",
       "                         5.8816,  17.7838,   4.7648,   5.1251,   3.8854,   4.4900,   3.8231,\n",
       "                         7.1547,  17.3292,   7.6643,   8.5408,  15.9694,  10.2999,   6.3820,\n",
       "                         6.0434,   8.7716,   7.5604,   8.2220,  10.7665,   8.5017,  10.8208,\n",
       "                        12.8755,   9.1890,   4.1688,   9.6854,   8.0795,   4.7102,   7.9956,\n",
       "                         4.4343], device='cuda:0')),\n",
       "              ('module.layer4.2.bn1.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.2.conv2.weight',\n",
       "               tensor([[[[-1.2447e-02, -5.8915e-03, -1.4033e-02],\n",
       "                         [-2.0829e-03, -6.8178e-03, -6.5417e-03],\n",
       "                         [-1.4179e-02, -3.0464e-03, -1.4520e-02]],\n",
       "               \n",
       "                        [[ 1.5563e-02,  1.1779e-02,  1.2707e-02],\n",
       "                         [ 1.2675e-02,  4.5336e-04,  8.9366e-03],\n",
       "                         [ 1.3712e-02,  5.4529e-03,  1.3053e-02]],\n",
       "               \n",
       "                        [[ 7.3496e-03, -2.5151e-03,  1.3295e-02],\n",
       "                         [ 1.0576e-02, -5.6874e-03,  2.6279e-03],\n",
       "                         [ 2.5373e-02,  3.9710e-03,  1.4217e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.4125e-03, -1.4956e-03, -2.0862e-03],\n",
       "                         [ 6.0166e-05, -3.5185e-03,  2.1310e-03],\n",
       "                         [-3.1017e-03, -5.3756e-04, -5.7703e-03]],\n",
       "               \n",
       "                        [[-1.5708e-03,  3.8001e-03, -9.0456e-04],\n",
       "                         [ 6.4389e-03, -2.7354e-03, -3.2250e-03],\n",
       "                         [ 1.8491e-03,  1.0710e-03,  2.3012e-03]],\n",
       "               \n",
       "                        [[ 3.9788e-04,  1.8101e-03,  1.7355e-03],\n",
       "                         [ 7.5776e-04, -1.3067e-03,  4.3118e-03],\n",
       "                         [-8.6253e-04,  3.7950e-03, -4.6757e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2952e-03,  1.6975e-02,  2.3790e-03],\n",
       "                         [ 1.7282e-02,  3.8865e-02,  1.6777e-02],\n",
       "                         [ 1.7126e-02,  3.7647e-02,  2.9415e-03]],\n",
       "               \n",
       "                        [[ 1.3605e-02,  1.5398e-02,  4.5532e-03],\n",
       "                         [-5.4814e-03,  5.4429e-03, -7.3311e-03],\n",
       "                         [-7.8826e-03, -6.5649e-04, -5.5421e-03]],\n",
       "               \n",
       "                        [[-1.2306e-02, -1.9830e-03, -1.2591e-02],\n",
       "                         [ 5.4715e-04,  1.9642e-02,  6.7360e-03],\n",
       "                         [ 4.8132e-03, -4.3116e-04, -1.4192e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.2021e-03,  4.4096e-03, -6.9810e-03],\n",
       "                         [ 2.2387e-03,  4.6421e-03, -3.3329e-04],\n",
       "                         [ 3.9374e-03, -4.6327e-04, -1.4436e-03]],\n",
       "               \n",
       "                        [[ 5.2397e-03, -4.1650e-03, -3.4114e-03],\n",
       "                         [-8.7928e-03, -1.0636e-02, -1.1431e-02],\n",
       "                         [-6.4845e-03, -1.7584e-02, -2.1822e-02]],\n",
       "               \n",
       "                        [[-5.5437e-03,  5.4329e-02,  6.5852e-03],\n",
       "                         [ 4.9699e-02,  7.7403e-02,  4.8613e-02],\n",
       "                         [ 4.3998e-03,  3.8761e-02,  9.3020e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.5159e-03, -1.3188e-02, -5.0409e-03],\n",
       "                         [ 3.5402e-03, -6.9286e-03,  6.3824e-03],\n",
       "                         [ 3.4316e-03, -3.0064e-03,  2.5749e-03]],\n",
       "               \n",
       "                        [[-6.6030e-03, -4.2498e-03, -8.0348e-04],\n",
       "                         [-7.6672e-03, -1.1534e-02, -3.3386e-04],\n",
       "                         [ 5.8989e-03,  4.3110e-03,  5.7541e-03]],\n",
       "               \n",
       "                        [[-7.4195e-02, -2.7750e-02, -7.9400e-02],\n",
       "                         [-3.9150e-02,  7.8380e-03, -3.5227e-02],\n",
       "                         [-5.2771e-02, -1.5758e-02, -5.6659e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.4989e-03, -1.0514e-03,  3.4820e-03],\n",
       "                         [ 9.9738e-03, -1.9127e-02, -3.4542e-03],\n",
       "                         [ 6.1946e-03, -7.3062e-03,  1.6377e-02]],\n",
       "               \n",
       "                        [[-1.0207e-02,  4.1152e-04, -1.7208e-02],\n",
       "                         [ 7.1018e-03,  1.0324e-03, -1.4966e-02],\n",
       "                         [-1.1360e-02, -7.6636e-03, -2.2172e-02]],\n",
       "               \n",
       "                        [[-4.8769e-03, -1.5528e-02, -1.5015e-02],\n",
       "                         [ 5.0255e-04, -1.0595e-02,  2.2777e-03],\n",
       "                         [ 7.6406e-04, -4.6319e-03, -2.3700e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-1.5594e-02, -6.8937e-03, -1.3647e-02],\n",
       "                         [-1.2932e-02,  7.7696e-05, -9.0804e-03],\n",
       "                         [-9.4926e-03,  6.6008e-03, -6.2859e-03]],\n",
       "               \n",
       "                        [[-3.2367e-03, -1.2174e-02, -5.9592e-03],\n",
       "                         [-6.1658e-03, -5.8545e-03, -1.1640e-02],\n",
       "                         [-3.7289e-03, -6.4897e-03, -1.7164e-03]],\n",
       "               \n",
       "                        [[ 5.0438e-04,  3.4714e-03,  3.7538e-03],\n",
       "                         [-6.3289e-03, -2.8775e-02,  4.3072e-03],\n",
       "                         [-2.0911e-03,  3.9146e-03,  6.3932e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.6284e-02, -6.7238e-03, -1.4683e-02],\n",
       "                         [-2.6035e-02, -1.5809e-02, -2.2504e-02],\n",
       "                         [-1.9839e-02, -1.9779e-02, -1.8617e-02]],\n",
       "               \n",
       "                        [[-1.4715e-02, -1.3353e-02, -4.5785e-03],\n",
       "                         [-1.1648e-02, -1.2289e-02, -1.0095e-02],\n",
       "                         [-1.3190e-02, -1.6983e-02, -1.3328e-02]],\n",
       "               \n",
       "                        [[-3.4627e-03, -5.4692e-03, -1.1569e-02],\n",
       "                         [-4.6911e-03, -1.3451e-02, -8.3153e-03],\n",
       "                         [-1.3290e-02, -1.3305e-02, -1.5204e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.7196e-03,  2.5217e-03, -8.6791e-03],\n",
       "                         [ 8.0661e-04, -5.9587e-03, -3.2813e-03],\n",
       "                         [-2.1065e-03,  3.4706e-03, -2.2490e-03]],\n",
       "               \n",
       "                        [[-9.1012e-03, -8.5566e-03, -1.1519e-02],\n",
       "                         [-5.4761e-03, -8.7812e-03, -5.5329e-03],\n",
       "                         [ 7.1724e-04, -3.6180e-03, -4.8969e-03]],\n",
       "               \n",
       "                        [[-5.8928e-03,  2.0550e-03, -2.5322e-04],\n",
       "                         [ 5.4688e-05,  2.3828e-03,  9.9440e-03],\n",
       "                         [-8.9196e-03, -2.2380e-03,  1.1259e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.8999e-03, -1.0365e-02,  4.2011e-03],\n",
       "                         [ 8.9471e-03,  1.0457e-02,  2.8644e-03],\n",
       "                         [ 7.6998e-03,  4.9751e-03,  1.4014e-02]],\n",
       "               \n",
       "                        [[ 1.7629e-02,  2.4327e-02,  1.9637e-02],\n",
       "                         [ 1.8564e-02,  2.6523e-02,  2.1849e-02],\n",
       "                         [ 1.3856e-02,  9.1683e-03,  9.6526e-03]],\n",
       "               \n",
       "                        [[-3.8482e-04,  4.1028e-04, -1.3890e-03],\n",
       "                         [-8.0372e-03,  3.0351e-03,  2.3732e-03],\n",
       "                         [ 2.0748e-03,  2.9381e-03, -3.1043e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3390e-02,  6.5431e-03,  8.4621e-03],\n",
       "                         [ 1.9296e-03, -1.7565e-02, -7.2957e-03],\n",
       "                         [-5.7140e-03, -1.5486e-02, -2.1385e-03]],\n",
       "               \n",
       "                        [[ 1.2346e-02,  1.9734e-02,  1.1286e-02],\n",
       "                         [ 2.0617e-02,  1.7835e-02,  2.0093e-02],\n",
       "                         [ 1.7242e-02,  1.5357e-02,  1.6825e-02]],\n",
       "               \n",
       "                        [[-9.2604e-03, -1.2894e-02, -2.1011e-03],\n",
       "                         [-9.4927e-03, -3.1803e-02, -4.6777e-04],\n",
       "                         [ 3.0496e-03, -2.6302e-04,  5.0821e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.2416e-02, -1.8212e-02, -1.4405e-02],\n",
       "                         [-1.8113e-02, -3.0017e-02, -2.3080e-02],\n",
       "                         [-7.2645e-03, -1.0617e-02, -3.6711e-03]],\n",
       "               \n",
       "                        [[ 1.2219e-02,  8.7581e-03,  4.7380e-03],\n",
       "                         [ 2.3089e-04, -6.3424e-03,  1.6057e-03],\n",
       "                         [ 2.0724e-03,  2.1676e-03, -8.0122e-04]],\n",
       "               \n",
       "                        [[-1.7629e-02, -3.6670e-02, -2.2947e-02],\n",
       "                         [-2.9876e-02, -2.8635e-02, -2.7716e-02],\n",
       "                         [-1.1318e-02, -1.1253e-02, -1.5531e-02]]]], device='cuda:0')),\n",
       "              ('module.layer4.2.bn2.weight',\n",
       "               tensor([1.2473, 1.2419, 2.6032, 1.4842, 0.8484, 0.9403, 0.9156, 0.7925, 1.6691,\n",
       "                       1.5519, 0.8092, 0.8072, 0.9345, 1.8608, 0.8669, 2.2404, 0.8719, 0.8952,\n",
       "                       1.9965, 1.9659, 1.6442, 0.9105, 2.1118, 0.8344, 1.9988, 0.9025, 0.9226,\n",
       "                       1.8498, 1.9859, 1.7501, 2.2098, 1.5800, 1.8631, 0.9163, 0.8057, 2.0653,\n",
       "                       0.8734, 0.9336, 0.9174, 2.1663, 1.6857, 1.1521, 2.1588, 0.8001, 0.9247,\n",
       "                       0.9729, 1.7325, 1.9736, 0.8582, 1.1847, 0.9597, 0.9401, 2.0141, 0.8225,\n",
       "                       1.5338, 0.8240, 1.5562, 0.9892, 1.6472, 2.3067, 0.8524, 1.4498, 1.0309,\n",
       "                       1.8404, 0.8200, 1.7377, 1.6639, 0.9579, 0.8777, 0.9182, 0.8460, 0.8699,\n",
       "                       1.7416, 0.8352, 1.0529, 2.0958, 1.1188, 0.8430, 1.8738, 1.7506, 1.9786,\n",
       "                       1.1914, 3.1506, 2.7343, 1.0979, 1.2387, 1.7730, 1.6668, 0.8718, 1.8029,\n",
       "                       0.8411, 1.6840, 1.0168, 1.2782, 2.2437, 0.8718, 1.4815, 2.0731, 1.7855,\n",
       "                       1.5461, 0.9396, 1.4869, 1.4846, 1.5785, 1.7596, 0.9035, 0.9055, 1.0284,\n",
       "                       1.4973, 1.5379, 1.4928, 1.1415, 0.8394, 0.8809, 1.6445, 0.9380, 0.7883,\n",
       "                       2.4104, 2.1641, 0.9120, 1.1139, 1.5033, 1.5380, 0.8161, 2.0878, 1.5014,\n",
       "                       1.4190, 1.0199, 1.6948, 1.4355, 1.6308, 0.8595, 1.5349, 1.6458, 1.5565,\n",
       "                       2.2336, 1.8078, 1.4643, 1.6897, 1.8416, 1.7296, 0.8727, 0.8876, 2.2767,\n",
       "                       0.8952, 2.4689, 2.1630, 1.7350, 1.5622, 0.8433, 1.5427, 0.8693, 1.3630,\n",
       "                       1.6828, 0.7955, 1.6821, 1.7619, 1.0299, 1.7483, 0.8344, 1.0002, 1.4140,\n",
       "                       1.1927, 0.8479, 1.6033, 1.6106, 1.9122, 1.9788, 0.8700, 0.9838, 0.8741,\n",
       "                       0.8492, 1.5691, 1.2610, 0.9766, 0.8709, 0.9200, 0.8857, 1.8521, 0.8682,\n",
       "                       1.6506, 1.8080, 0.8381, 0.9647, 1.4188, 1.6507, 0.9028, 1.3901, 0.9896,\n",
       "                       1.0023, 0.9970, 1.2393, 1.7798, 1.8562, 2.0922, 1.6396, 0.8918, 1.1721,\n",
       "                       2.2389, 0.8394, 1.6671, 0.8385, 0.9908, 0.9421, 1.8065, 0.8775, 1.7164,\n",
       "                       2.1754, 1.4461, 1.1764, 1.4392, 0.8350, 1.5460, 1.4969, 1.7332, 0.9411,\n",
       "                       0.9061, 0.8130, 1.5922, 1.7709, 1.4332, 1.2911, 3.5439, 0.9124, 0.8786,\n",
       "                       1.7395, 0.8332, 1.3569, 1.2701, 0.8922, 2.4781, 1.1054, 3.0214, 1.9352,\n",
       "                       0.8216, 1.7742, 0.9363, 0.9475, 2.3821, 0.7954, 2.1606, 0.8983, 1.5679,\n",
       "                       1.7222, 1.2140, 1.5050, 2.1475, 0.9176, 0.9403, 0.9375, 2.4960, 0.7896,\n",
       "                       2.2743, 0.9607, 0.9411, 0.8999, 1.1662, 2.5985, 1.9576, 1.4355, 2.2470,\n",
       "                       0.8199, 1.5810, 0.8607, 2.0369, 1.2809, 0.8856, 1.8582, 2.5267, 1.0621,\n",
       "                       0.8896, 0.8986, 0.7795, 1.6756, 1.9398, 2.3530, 2.1438, 2.0874, 1.7956,\n",
       "                       1.4744, 1.6956, 1.7159, 2.1646, 0.9834, 2.3605, 1.2018, 2.3828, 1.8841,\n",
       "                       0.9170, 1.7486, 1.5237, 1.6175, 1.5393, 1.1016, 0.8484, 1.6157, 1.3302,\n",
       "                       2.1441, 1.6490, 1.4615, 1.6198, 1.2620, 1.7906, 0.8664, 1.6593, 1.7420,\n",
       "                       1.8001, 1.4748, 2.4384, 2.3104, 1.4577, 1.5757, 1.8111, 1.3876, 3.6042,\n",
       "                       3.0814, 0.9961, 1.6590, 1.4635, 1.5502, 1.4785, 1.4581, 2.0928, 1.0687,\n",
       "                       1.6928, 1.1149, 0.8301, 0.8480, 2.8463, 1.7512, 1.7612, 1.2211, 2.0220,\n",
       "                       1.7372, 1.2608, 0.9078, 1.8582, 1.6392, 0.7999, 1.6994, 0.9836, 0.9965,\n",
       "                       1.7880, 1.1561, 1.6419, 1.0100, 1.6554, 1.5612, 1.4015, 0.8332, 1.3051,\n",
       "                       1.6074, 1.2296, 0.8675, 1.1860, 1.0056, 1.0543, 1.7066, 2.1775, 2.1716,\n",
       "                       1.0863, 2.2073, 1.5649, 2.0664, 1.6779, 1.1103, 0.8980, 1.7751, 1.0004,\n",
       "                       1.4812, 1.3572, 2.1453, 1.7328, 1.5470, 1.4519, 1.2665, 0.9596, 2.1862,\n",
       "                       1.7699, 0.8898, 1.0528, 1.3265, 1.6760, 1.7922, 1.7558, 1.6422, 1.5395,\n",
       "                       1.5956, 0.8747, 2.0190, 2.2659, 1.5970, 1.4123, 1.3438, 1.0570, 1.8114,\n",
       "                       0.8344, 1.4554, 2.4888, 1.5686, 1.7996, 0.8100, 1.4726, 2.0074, 1.9621,\n",
       "                       1.3120, 1.1923, 2.0384, 0.7853, 2.0866, 0.8518, 2.2203, 1.9082, 2.1949,\n",
       "                       1.0043, 1.7555, 0.9754, 0.8392, 1.0098, 0.8895, 1.8647, 1.0148, 0.8620,\n",
       "                       1.4361, 0.9443, 0.8685, 1.6121, 1.6700, 2.0226, 1.8048, 1.1400, 0.9021,\n",
       "                       2.0996, 1.6573, 1.6278, 0.8601, 1.6501, 2.1026, 0.8556, 1.9512, 1.2024,\n",
       "                       1.7928, 1.1019, 1.1577, 1.5513, 1.0278, 0.7217, 2.4370, 1.5649, 1.9448,\n",
       "                       0.8594, 1.4716, 1.3581, 0.8805, 1.7882, 1.7687, 2.1669, 1.3600, 1.0643,\n",
       "                       0.8433, 1.2098, 0.8464, 1.4842, 1.0616, 2.1805, 2.5123, 1.6175, 1.4884,\n",
       "                       1.7869, 0.9666, 0.8697, 1.5463, 1.7672, 1.8163, 1.1506, 0.9492, 1.0056,\n",
       "                       0.9969, 1.9454, 1.0444, 0.8655, 0.8971, 2.3071, 0.8555, 0.8628, 1.5062,\n",
       "                       1.3669, 1.8404, 2.2579, 1.0576, 0.9517, 1.6575, 1.0135, 1.8885, 1.7104,\n",
       "                       1.0865, 3.1521, 0.9678, 0.8503, 2.5429, 1.0589, 1.2186, 2.8641, 1.3507,\n",
       "                       2.8085, 0.8155, 2.1068, 1.2923, 1.4590, 1.6840, 1.8711, 0.8138],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.2.bn2.bias',\n",
       "               tensor([-7.5950e-01, -7.7219e-01, -2.7696e+00, -1.8317e+00,  4.0913e-02,\n",
       "                        3.4692e-01,  1.1918e-02,  1.2858e-01, -1.6176e+00, -1.1137e+00,\n",
       "                        6.3027e-02,  1.5804e-01, -2.6554e-01, -1.6020e+00, -3.0377e-02,\n",
       "                       -1.5602e+00,  2.4542e-02, -1.0229e-01, -1.1690e+00, -2.3074e+00,\n",
       "                       -1.3678e+00, -1.2234e-01, -2.1601e+00,  5.0525e-02, -1.5978e+00,\n",
       "                       -4.1876e-02, -1.5274e-01, -1.6464e+00, -1.5163e+00, -1.6715e+00,\n",
       "                       -2.1301e+00, -1.2260e+00, -1.4331e+00, -3.4097e-02,  1.6933e-01,\n",
       "                       -1.2683e+00,  1.8405e-02, -2.6501e-01,  1.0203e-01, -2.1090e+00,\n",
       "                       -1.3932e+00, -5.3227e-01, -2.4997e+00,  1.4419e-01, -4.2487e-02,\n",
       "                       -1.9062e-01, -1.7552e+00, -1.6563e+00,  3.7910e-02, -6.6902e-01,\n",
       "                       -2.0513e-01, -2.5651e-01, -1.8043e+00,  1.4585e-01, -1.2132e+00,\n",
       "                        1.0639e-01, -1.3667e+00, -3.4250e-01, -1.5829e+00, -1.9641e+00,\n",
       "                        6.8609e-02, -1.1980e+00, -2.1448e-01, -2.0550e+00,  6.1329e-02,\n",
       "                       -1.2945e+00, -1.2638e+00, -2.7309e-01, -3.3066e-02, -9.4726e-02,\n",
       "                       -4.3343e-02, -1.0626e-01, -1.5188e+00, -7.7631e-02, -3.4656e-01,\n",
       "                       -1.9795e+00, -6.7909e-01,  1.7448e-01, -1.2784e+00, -2.0180e+00,\n",
       "                       -2.0532e+00, -7.3919e-01, -2.2367e+00, -2.8819e+00, -6.4610e-01,\n",
       "                       -7.5452e-01, -1.6788e+00, -9.2444e-01,  5.6629e-02, -1.9290e+00,\n",
       "                        9.8007e-02, -1.4469e+00, -4.5899e-01, -6.3833e-01, -2.4088e+00,\n",
       "                       -1.0125e-01, -1.2064e+00, -1.5992e+00, -1.4894e+00, -1.2038e+00,\n",
       "                       -1.7918e-01,  2.0279e-01, -1.0599e+00, -1.4175e+00, -1.4171e+00,\n",
       "                       -1.5157e-01, -1.8862e-02, -2.5166e-01, -1.5749e+00, -1.0850e+00,\n",
       "                       -1.1736e+00, -7.9876e-01,  2.2347e-01, -1.6231e-01, -1.3609e+00,\n",
       "                       -1.1943e-01,  1.2275e-01, -2.7025e+00, -2.2857e+00, -1.2066e-01,\n",
       "                       -3.6613e-01, -1.5418e+00, -1.1798e+00,  1.1755e-01, -2.1424e+00,\n",
       "                       -1.2823e+00, -1.0555e+00, -3.4650e-01, -1.1045e+00, -2.3342e+00,\n",
       "                       -1.2128e+00,  4.9445e-02, -2.4552e+00, -1.1409e+00, -1.0417e+00,\n",
       "                       -1.0436e+00, -9.6826e-01, -9.0398e-01, -1.2438e+00, -1.9857e+00,\n",
       "                       -1.3908e+00, -5.2658e-02, -1.4508e-01, -1.9450e+00, -6.9793e-02,\n",
       "                       -1.7646e+00, -2.3896e+00, -1.8122e+00, -1.2112e+00,  5.8640e-02,\n",
       "                       -2.4230e+00,  3.1831e-01, -7.7210e-01, -1.2000e+00,  4.6063e-02,\n",
       "                       -1.6329e+00, -1.2356e+00, -2.8012e-01, -1.0013e+00,  8.6178e-02,\n",
       "                       -3.7470e-01, -1.0285e+00,  5.6190e-01,  1.2189e-02, -9.7400e-01,\n",
       "                       -1.3749e+00, -1.8712e+00, -1.6691e+00,  4.4441e-02, -3.2022e-01,\n",
       "                        3.8897e-03,  1.0118e-01, -1.0930e+00, -1.1891e+00, -2.6525e-01,\n",
       "                       -1.5294e-02, -2.7328e-01,  4.0411e-02, -2.1190e+00, -5.1889e-02,\n",
       "                       -1.2768e+00, -1.9202e+00, -2.2556e-02, -1.8939e-01, -9.1141e-01,\n",
       "                       -1.2224e+00, -1.0930e-01,  8.2431e-01, -2.3517e-01, -4.1549e-01,\n",
       "                       -3.8059e-01, -7.1794e-01, -1.4233e+00, -2.5856e+00, -1.7045e+00,\n",
       "                       -1.2560e+00, -6.0605e-02,  1.9082e+00, -1.9126e+00,  6.3337e-02,\n",
       "                       -1.3818e+00,  4.8381e-02, -2.2502e-01, -1.2805e-01, -1.7528e+00,\n",
       "                       -1.0652e-01, -1.4674e+00, -1.9518e+00,  1.0852e+00, -2.4275e-01,\n",
       "                       -1.7705e+00,  1.2845e-01, -1.3637e+00, -1.2397e+00, -1.4518e+00,\n",
       "                       -1.3279e-01, -3.0516e-02,  1.8344e-01, -1.3608e+00, -1.5190e+00,\n",
       "                       -1.5779e+00, -1.1162e+00, -5.4182e+00, -8.3774e-02, -2.0804e-02,\n",
       "                       -1.8778e+00,  2.8292e-01, -1.1564e+00, -9.9547e-01, -8.6282e-02,\n",
       "                       -2.3743e+00, -7.3402e-01, -3.3420e+00, -1.7400e+00,  1.0637e-01,\n",
       "                       -8.9852e-01, -2.1891e-01,  2.9794e-01, -2.0922e+00,  2.3475e-01,\n",
       "                       -1.1532e+00, -1.4636e-01, -2.0591e+00, -1.5239e+00, -3.8111e-01,\n",
       "                       -1.2174e+00, -1.6517e+00, -2.6584e-01, -1.9540e-01, -1.5012e-01,\n",
       "                       -3.0186e+00,  2.2128e-01, -1.7281e+00, -8.2863e-02, -1.3896e-01,\n",
       "                       -2.6236e-01, -7.4669e-01, -2.7039e+00, -1.6709e+00, -2.1405e+00,\n",
       "                       -2.0599e+00,  4.0636e-02, -5.1816e-01,  7.3085e-02, -1.4722e+00,\n",
       "                       -9.7055e-01, -4.4053e-02, -1.2448e+00, -2.1420e+00, -5.6057e-01,\n",
       "                       -2.8253e-02, -4.3794e-02,  1.9065e-01, -1.2522e+00, -1.8360e+00,\n",
       "                       -2.6171e+00, -2.1458e+00, -1.8846e+00, -1.7250e+00, -1.1218e+00,\n",
       "                       -1.4600e+00, -1.2187e+00, -2.2319e+00, -1.4486e-01, -1.2093e+00,\n",
       "                       -7.2199e-01, -1.2011e+00, -1.6307e+00, -7.0971e-02, -1.3489e+00,\n",
       "                       -1.9617e+00, -2.0514e+00, -1.3465e+00, -5.7637e-01,  9.6300e-02,\n",
       "                       -1.6121e+00, -6.3533e-01, -2.2053e+00, -1.3371e+00, -1.0688e+00,\n",
       "                       -1.2294e+00, -8.0600e-01, -2.0104e+00,  3.0727e-02, -1.6145e+00,\n",
       "                       -1.3979e+00, -1.4890e+00, -9.5359e-01, -2.9216e+00,  5.8596e+00,\n",
       "                       -9.9848e-01, -2.5092e+00, -1.4411e+00, -8.2256e-01, -3.6207e+00,\n",
       "                       -2.4257e+00, -2.8751e-01, -1.3491e+00, -1.1479e+00, -3.9578e-01,\n",
       "                       -1.1742e+00, -1.3079e+00, -1.7883e+00, -4.3159e-01, -9.8031e-01,\n",
       "                       -5.9665e-01,  6.5818e-02,  5.8993e-02, -1.9960e+00, -1.4390e+00,\n",
       "                       -2.0632e+00, -7.6896e-01, -2.0695e+00, -1.7554e+00, -9.3498e-01,\n",
       "                       -1.0871e-01, -1.7314e+00, -1.3416e+00,  1.7642e-01, -1.2646e+00,\n",
       "                        1.1961e-01, -2.1079e-01, -1.6299e+00, -5.1582e-01, -1.1170e+00,\n",
       "                       -2.6229e-01, -1.4735e+00, -1.4396e+00, -9.4824e-01, -2.6004e-02,\n",
       "                       -9.3586e-01, -9.6439e-01, -3.2598e-01, -6.7171e-03, -5.7191e-01,\n",
       "                       -3.5102e-01, -4.7497e-01, -1.2346e+00, -2.1297e+00, -1.5475e+00,\n",
       "                       -6.8892e-01, -2.1855e+00, -1.0951e+00, -1.9930e+00, -1.7725e+00,\n",
       "                       -5.9656e-01, -1.6997e-02, -1.8933e+00, -3.5088e-01, -1.8946e+00,\n",
       "                       -8.2365e-01, -1.9885e+00, -1.6710e+00, -9.5963e-01, -1.4255e+00,\n",
       "                       -8.7402e-01, -1.2639e-01, -1.9500e+00, -1.4999e+00, -2.8080e-02,\n",
       "                       -2.5863e-01, -1.6508e+00, -1.3183e+00, -1.2132e+00, -1.3332e+00,\n",
       "                       -1.5104e+00, -1.4321e+00, -2.0158e+00,  3.7599e-02, -1.5734e+00,\n",
       "                       -2.7253e+00, -1.4005e+00, -1.3382e+00, -7.7596e-01, -3.9167e-01,\n",
       "                       -1.4578e+00,  1.1161e-01, -9.3215e-01, -2.6735e+00, -1.9284e+00,\n",
       "                       -1.7940e+00,  1.2432e-01, -1.2050e+00, -1.1102e+00, -2.0595e+00,\n",
       "                       -6.8262e-01,  5.9789e-01, -1.8384e+00,  1.4157e-01, -2.1118e+00,\n",
       "                       -9.9842e-02, -1.6707e+00, -1.4117e+00, -2.1295e+00, -2.7436e-01,\n",
       "                       -1.3781e+00, -2.3332e-01,  7.6485e-02, -2.1149e-01, -3.7018e-02,\n",
       "                       -1.4571e+00, -2.8605e-01,  1.4651e-02, -1.2088e+00, -1.8916e-01,\n",
       "                        4.9544e-02, -1.4616e+00, -1.1057e+00, -1.7889e+00, -1.6408e+00,\n",
       "                       -6.0143e-01, -3.0659e-02, -1.4001e+00, -1.6434e+00, -1.1456e+00,\n",
       "                        3.1459e-02, -1.4942e+00, -1.7309e+00, -4.1111e-02, -1.4021e+00,\n",
       "                       -1.0886e+00, -2.0819e+00, -5.1026e-01, -8.3206e-01, -1.1820e+00,\n",
       "                       -3.5283e-01,  1.8643e+00, -4.6071e-01, -1.7805e+00, -2.0604e+00,\n",
       "                        1.1596e-01, -1.1739e+00, -7.8922e-01, -1.5422e-01, -1.7011e+00,\n",
       "                       -1.4617e+00, -1.8187e+00, -1.1152e+00, -3.2922e-01,  6.8587e-02,\n",
       "                       -7.4784e-01,  3.1254e-02, -1.1610e+00, -4.1885e-01, -1.7808e+00,\n",
       "                       -2.9536e+00, -1.1028e+00, -1.2644e+00, -1.7171e+00, -2.8291e-01,\n",
       "                       -1.2926e-02, -1.0630e+00, -1.4562e+00, -1.6374e+00, -6.8043e-01,\n",
       "                       -2.3569e-01, -3.3202e-01, -3.8086e-01, -1.9375e+00, -4.1077e-01,\n",
       "                       -3.5380e-03, -5.3087e-03, -2.2511e+00,  5.8041e-03, -3.4701e-02,\n",
       "                       -8.9005e-01, -1.0227e+00, -1.4615e+00, -1.9763e+00, -4.5708e-01,\n",
       "                       -1.7439e-01, -1.1635e+00, -3.7811e-01, -1.2423e+00, -1.0571e+00,\n",
       "                       -4.7556e-01, -2.3423e+00, -2.9759e-01,  2.2655e-02, -1.4443e+00,\n",
       "                       -4.4100e-01, -8.6654e-01, -2.5726e+00, -6.3329e-01, -3.0044e+00,\n",
       "                        9.6283e-02, -1.9630e+00, -9.4020e-01, -9.6250e-01, -1.5837e+00,\n",
       "                       -1.6624e+00,  9.5870e-02], device='cuda:0')),\n",
       "              ('module.layer4.2.bn2.running_mean',\n",
       "               tensor([-0.4424, -0.5819, -0.4850, -0.5936, -0.3292, -0.5045, -0.4374, -0.2655,\n",
       "                       -0.4784, -0.4369, -0.5308, -0.3790, -0.3734, -0.4643, -0.2307, -0.3976,\n",
       "                       -0.5551, -0.4787, -0.3122, -0.4633, -0.5906, -0.5705, -0.3233, -0.4768,\n",
       "                       -0.6312, -0.6084, -0.4063, -0.2770, -0.4387, -0.6338, -0.4735, -0.4536,\n",
       "                       -0.4742, -0.4691, -0.3552, -1.0806, -0.3954, -0.5550, -0.5003, -0.2957,\n",
       "                       -0.2903, -0.5009, -0.0881, -0.4080, -0.5554, -0.4576, -0.4331, -0.5057,\n",
       "                       -0.5163, -0.5734, -0.5460, -0.3883, -0.7977, -0.4211, -0.8011, -0.4390,\n",
       "                       -0.5516, -0.5721, -0.2639, -0.4588, -0.5295, -0.5767, -0.5436,  0.0747,\n",
       "                       -0.1486, -0.4640, -0.0389, -0.5365, -0.3978, -0.3199, -0.3731, -0.4057,\n",
       "                       -0.5610, -0.2046, -0.4964, -0.4271, -0.6636, -0.5270, -0.2727, -0.2602,\n",
       "                       -0.4030, -0.1988, -0.8454, -0.4306, -0.3582, -0.2402, -0.2538, -0.3445,\n",
       "                       -0.3249, -0.3290, -0.5854, -0.6551, -0.3390, -0.3281, -0.2716, -0.4917,\n",
       "                       -0.6136, -0.5161, -0.2565, -0.2952, -0.4164, -0.4257, -0.4514, -0.5487,\n",
       "                       -0.3984, -0.5136, -0.3522, -0.6303, -0.2352, -0.3285, -0.6225, -0.5643,\n",
       "                       -0.4929, -0.5108, -0.7651, -0.4195, -0.3887, -0.4755, -0.2960, -0.5546,\n",
       "                       -0.6533, -0.4824, -0.4881, -0.7174, -0.3389, -0.3757, -0.5406, -0.5396,\n",
       "                       -0.6256, -0.4522, -0.4435, -0.4373, -0.3998, -0.3561, -0.3798, -0.7345,\n",
       "                       -0.5948, -0.4507, -0.2101, -0.5934, -0.4133, -0.3211, -0.4314, -0.2146,\n",
       "                       -0.5363, -0.0990, -0.4494, -0.2919, -0.4820, -0.6438, -0.4092, -0.6182,\n",
       "                       -0.5248, -0.3444, -0.4618, -0.1348, -0.4000, -0.5982, -1.0746, -0.3676,\n",
       "                       -0.4659, -0.6644, -0.2957, -0.2727, -0.5806, -0.3818, -0.1947, -0.4478,\n",
       "                       -0.3826, -0.4199, -0.5200, -0.4148, -0.3654, -0.5381, -0.5179, -0.3856,\n",
       "                       -0.4772, -0.5206, -0.2427, -0.4805, -0.6750, -0.3577, -0.5277, -0.4703,\n",
       "                       -0.7454, -0.4605, -0.5148, -0.2812, -0.2953, -0.3592, -0.3903, -0.7301,\n",
       "                       -0.2676, -0.5073, -0.3049, -0.3267, -0.1880,  0.2909, -0.4213, -0.3538,\n",
       "                       -0.4486, -0.2944, -0.4877, -0.6978, -0.3507, -0.3620, -0.7153, -0.1264,\n",
       "                       -0.8809, -0.3560, -0.4021, -0.6806, -0.5104, -0.3886, -0.4416, -0.3536,\n",
       "                       -0.5047, -0.6679, -0.2359, -0.2109, -0.5366, -0.5265,  0.4772, -0.4106,\n",
       "                       -0.3772, -0.6607, -0.4300, -0.5956, -0.5025, -0.4865, -0.3565, -0.6400,\n",
       "                       -0.2695, -0.3343, -0.4875, -0.2698, -0.3802, -0.5304, -0.2571, -0.3101,\n",
       "                       -1.2365, -0.4752, -0.3481, -0.1840, -0.1450, -0.3415, -0.3599, -0.4787,\n",
       "                       -0.2009, -0.3992, -0.3607, -0.3412, -0.3399, -0.4283, -0.4143, -0.6043,\n",
       "                       -0.5233, -0.3907, -0.3337, -0.3555, -0.4297, -0.6885, -0.2250, -0.4484,\n",
       "                       -0.4372, -0.3242, -0.1691, -0.3183, -0.4159, -0.3708, -0.4614, -0.1690,\n",
       "                       -0.4771, -0.2830, -0.5245, -0.3413, -0.3030, -0.3024, -0.3495, -0.5232,\n",
       "                       -0.5536, -0.4991, -0.3100, -0.4560,  0.2320, -0.4942, -0.1884, -0.2874,\n",
       "                       -0.5871, -0.6862, -0.6992, -0.2879, -0.3200, -0.4863, -0.4743, -0.1605,\n",
       "                       -0.6467, -0.4919, -0.3030, -0.2324, -0.4496, -0.5411, -0.4888, -0.4594,\n",
       "                       -0.4149, -0.2637, -0.6563, -0.3499, -0.0916, -1.9413, -0.4081, -0.1751,\n",
       "                       -0.8570, -0.4737, -0.1797, -0.9796, -0.4514, -0.5673, -0.5398, -0.3085,\n",
       "                       -0.7655, -0.3959, -0.3515, -0.5343, -0.5077, -0.4521, -0.4190, -0.4605,\n",
       "                       -0.5373, -0.5601, -0.2428, -0.4410, -0.2391, -0.4447, -0.4608, -0.5387,\n",
       "                       -0.5269, -0.5108, -0.3085, -0.3928, -0.6964, -0.3955, -0.2088, -0.5026,\n",
       "                       -0.3606, -0.4207, -0.4990, -0.4496, -0.2076, -0.5453, -0.4407, -0.4692,\n",
       "                       -0.6924, -0.6074, -0.6548, -0.3858, -0.6385, -0.1937, -0.7705, -1.6525,\n",
       "                       -0.6192, -0.4091, -0.2698, -0.5171, -0.2201, -0.4102, -0.6495, -0.5371,\n",
       "                       -0.6207, -0.4372, -0.6157, -0.4418, -0.5699, -0.5286, -0.3541, -0.4934,\n",
       "                       -0.4097, -0.2319, -0.5797, -0.6417, -0.4569, -0.2936, -0.2154, -0.4643,\n",
       "                       -0.5058, -0.3524, -0.7519, -0.4842, -0.3766, -0.2867, -0.2550, -0.4736,\n",
       "                       -0.2722, -0.5958, -0.5424, -0.2875, -0.6043, -0.3389, -0.1837, -0.3461,\n",
       "                       -0.5385, -0.1832, -0.6027,  0.0324, -0.3822, -0.5247,  0.0305, -0.4743,\n",
       "                       -0.5215, -0.3564, -0.5339, -0.2851, -0.1706, -0.4678, -0.1759, -0.4355,\n",
       "                       -0.4676, -0.5142, -0.5903, -0.4736, -0.2880, -0.6756, -0.5834, -0.4013,\n",
       "                       -0.3687, -0.2759, -0.8779, -0.1188, -0.4371, -0.4894, -0.2803, -0.6169,\n",
       "                       -0.2970, -0.2067, -0.6774, -0.5779, -0.6711, -0.4181, -0.3236, -0.4934,\n",
       "                       -0.4969, -0.3583, -0.2622, -0.0991, -0.5427, -0.3341,  1.0867, -1.2122,\n",
       "                       -0.7226, -0.2905, -0.3349, -0.5347, -0.3483, -0.3637, -0.4339, -0.1543,\n",
       "                       -0.4739, -0.4449, -0.5992, -0.4711, -0.5909, -0.4115, -0.6274, -0.6001,\n",
       "                       -0.5271, -0.5737, -0.3321, -0.2638, -0.4371, -0.3352, -0.5101, -0.4925,\n",
       "                       -0.7105, -0.3702, -0.5705, -0.3248, -0.4543, -0.5582, -0.4521, -0.5630,\n",
       "                       -0.4006, -0.4828, -0.2768, -0.6110, -0.3662, -0.5247, -0.6265, -0.4675,\n",
       "                       -0.5572, -0.4335, -0.5385, -0.0776, -0.5338, -0.5296, -0.2541, -0.4945,\n",
       "                       -0.7226, -0.2722, -0.3684, -0.2809, -0.3874, -0.7705, -0.6201, -0.5760,\n",
       "                       -0.9596, -0.3072, -0.4183, -0.3098, -0.1764, -0.3942, -0.2944, -0.3947],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.2.bn2.running_var',\n",
       "               tensor([ 0.4873,  0.2941,  1.3229,  0.3405,  0.3251,  1.0617,  0.4253,  0.2922,\n",
       "                        0.8416,  0.2862,  0.4339,  0.3746,  0.2869,  1.3803,  0.3051,  1.8627,\n",
       "                        0.3899,  0.2777,  0.7826,  1.1515,  0.2783,  0.3346,  1.6958,  0.4186,\n",
       "                        1.7917,  0.3743,  0.3561,  1.0256,  1.4541,  1.1980,  1.8732,  0.3204,\n",
       "                        1.5850,  0.3578,  0.3283,  0.5257,  0.3455,  0.3544,  0.4521,  1.2115,\n",
       "                        0.2320,  0.4111,  1.1232,  0.3264,  0.3574,  0.3103,  1.2385,  1.2679,\n",
       "                        0.3048,  0.4075,  0.3329,  0.2730,  2.2530,  0.3457,  0.2449,  0.4282,\n",
       "                        0.4296,  0.3097,  0.7094,  0.8975,  0.3891,  0.6187,  0.3941,  0.7180,\n",
       "                        0.3463,  1.2780,  0.2938,  0.3464,  0.3519,  0.4856,  0.3377,  0.3522,\n",
       "                        0.2261,  0.3032,  0.3331,  1.2671,  0.4270,  0.3573,  0.3238,  0.5394,\n",
       "                        1.3127,  0.2800,  1.1295,  1.0661,  0.3352,  0.3235,  1.0550,  1.0195,\n",
       "                        0.4030,  0.7250,  0.3665,  0.9339,  0.3506,  0.5881,  0.8960,  0.3460,\n",
       "                        0.2739,  1.6755,  1.6966,  0.7232,  0.3733,  3.5897,  0.9746,  1.3136,\n",
       "                        1.2885,  0.3066,  0.3556,  0.3342,  0.4847,  1.0532,  0.2318,  0.2562,\n",
       "                        0.6929,  0.3617,  0.3331,  0.3843,  0.4770,  1.2658,  1.2742,  0.2925,\n",
       "                        0.3675,  0.4107,  0.4352,  0.4056,  1.3955,  1.0339,  0.4265,  0.3102,\n",
       "                        1.4774,  0.1356,  0.2951,  0.3520,  0.1804,  1.3995,  1.2512,  0.6384,\n",
       "                        0.8152,  1.2861,  0.2901,  1.0142,  1.6475,  0.3540,  0.3096,  1.2629,\n",
       "                        0.3401,  1.0734,  1.4022,  0.9344,  0.2386,  0.3299,  0.3061,  0.6728,\n",
       "                        0.4442,  0.3489,  0.3390,  0.7711,  1.1565,  0.3449,  0.5149,  0.3422,\n",
       "                        0.2824,  0.9036,  2.3839,  0.3733,  0.7389,  0.5803,  1.1138,  1.4808,\n",
       "                        0.4257,  0.2737,  0.3226,  0.4820,  0.2427,  0.4182,  0.3105,  0.4155,\n",
       "                        0.2636,  0.4026,  0.9773,  0.2972,  1.2002,  0.8053,  0.3449,  0.3238,\n",
       "                        0.2910,  1.1320,  0.3119,  1.8525,  0.3191,  0.3422,  0.2998,  0.2924,\n",
       "                        1.0971,  0.1891,  1.3309,  1.1611,  0.3257,  1.9963,  1.2068,  0.3366,\n",
       "                        0.2572,  0.3846,  0.3168,  0.2881,  1.2378,  0.2718,  0.7031,  1.3623,\n",
       "                        3.0245,  1.1414,  0.2032,  0.3189,  0.5466,  0.9133,  1.1607,  0.3218,\n",
       "                        0.3238,  0.5054,  0.7115,  0.6940,  0.3071,  0.2426,  0.6840,  0.3285,\n",
       "                        0.3321,  0.6432,  0.7270,  0.3068,  0.8213,  0.3687,  1.3428,  0.3157,\n",
       "                        1.2008,  0.8680,  0.4025,  1.9241,  0.3480,  0.8812,  1.1751,  0.3733,\n",
       "                        1.5713,  0.3618,  0.3018,  0.7892,  0.5538,  0.8390,  1.5004,  0.2888,\n",
       "                        0.3010,  0.3221,  1.4630,  0.4104,  2.0883,  0.3405,  0.3801,  0.2873,\n",
       "                        0.3076,  1.2053,  1.3392,  0.1973,  1.2934,  0.3675,  1.2985,  0.5592,\n",
       "                        1.3084,  0.2499,  0.3180,  0.4703,  1.9407,  0.3445,  0.3078,  0.3248,\n",
       "                        0.3768,  0.5375,  1.0949,  1.4150,  1.1402,  1.3417,  0.7280,  0.2576,\n",
       "                        0.9918,  1.5463,  1.6723,  0.3289,  1.1434,  0.3289,  1.8815,  1.5319,\n",
       "                        0.3378,  1.4439,  0.7772,  0.3310,  0.5300,  0.3320,  0.3280,  0.6071,\n",
       "                        0.3971,  1.3585,  1.0768,  0.6593,  1.0358,  0.2483,  0.4387,  0.4626,\n",
       "                        0.5581,  0.2877,  1.4878,  0.3452,  1.3030, 14.6334,  0.3755,  0.2325,\n",
       "                        1.0068,  0.8988,  1.0935,  1.5071,  0.2868,  0.3683,  0.2069,  2.7764,\n",
       "                        0.6233,  0.2789,  1.3032,  0.2711,  1.4716,  0.2954,  0.3567,  0.3607,\n",
       "                        1.7698,  1.0357,  0.6696,  0.3304,  1.5398,  1.0042,  0.2830,  0.3110,\n",
       "                        1.1237,  0.2965,  0.4211,  1.3086,  0.7422,  0.3189,  0.9764,  0.2944,\n",
       "                        0.3025,  0.3138,  1.2904,  0.2412,  0.2852,  0.3470,  0.5843,  0.2089,\n",
       "                        0.8811,  0.3589,  0.2622,  0.3375,  0.2587,  0.3158,  1.4602,  0.8779,\n",
       "                        0.3061,  1.4767,  1.2272,  1.5382,  0.5008,  0.2542,  0.3274,  0.7196,\n",
       "                        0.2731,  0.1600,  0.2186,  1.5835,  0.4017,  0.3026,  0.3540,  0.3623,\n",
       "                        0.3283,  1.2760,  0.7291,  0.3425,  0.3830,  0.2072,  0.8420,  1.6552,\n",
       "                        0.2617,  0.4744,  0.2702,  0.3812,  0.3313,  0.3978,  1.5040,  0.3805,\n",
       "                        0.3804,  0.5391,  0.2803,  0.8362,  0.3908,  1.1070,  0.8454,  0.3040,\n",
       "                        1.0555,  0.3721,  1.0695,  1.3599,  1.0812,  0.9426,  1.8518,  1.2881,\n",
       "                        0.3456,  1.3071,  0.3099,  2.0267,  0.7989,  1.5858,  0.3646,  1.0801,\n",
       "                        0.3181,  0.4896,  0.3159,  0.3361,  0.2576,  0.3120,  0.3920,  0.4515,\n",
       "                        0.3233,  0.3970,  0.3093,  1.0478,  1.2762,  0.2368,  0.3932,  0.3526,\n",
       "                        1.1729,  0.7928,  0.4093,  0.3512,  0.2438,  1.8495,  0.3943,  0.5809,\n",
       "                        0.2586,  0.6420,  0.2857,  0.3699,  0.2386,  0.3490,  0.7814,  2.5616,\n",
       "                        0.2419,  0.9468,  0.4125,  0.4845,  0.2965,  0.2936,  0.5789,  0.3626,\n",
       "                        1.9229,  0.3357,  0.3498,  0.3425,  0.4164,  0.3115,  0.4102,  0.2849,\n",
       "                        1.8655,  1.8952,  1.2982,  0.5027,  0.7332,  0.4235,  0.3023,  0.9454,\n",
       "                        1.5407,  1.1081,  0.3374,  0.2859,  0.2519,  0.2870,  1.0999,  0.2535,\n",
       "                        0.2826,  0.3334,  1.0881,  0.3238,  0.3062,  0.5499,  0.6585,  1.1832,\n",
       "                        1.8205,  0.3463,  0.3522,  0.7512,  0.3724,  1.1236,  0.2837,  0.3222,\n",
       "                        1.4562,  0.2965,  0.3965,  3.3297,  0.2956,  0.3821,  1.0146,  0.5979,\n",
       "                        0.5276,  0.4759,  1.4949,  0.3790,  0.3132,  1.0819,  1.0213,  0.3035],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.2.bn2.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.layer4.2.conv3.weight',\n",
       "               tensor([[[[-0.0263]],\n",
       "               \n",
       "                        [[-0.0078]],\n",
       "               \n",
       "                        [[-0.0002]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0268]],\n",
       "               \n",
       "                        [[ 0.0085]],\n",
       "               \n",
       "                        [[ 0.0104]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0293]],\n",
       "               \n",
       "                        [[ 0.0110]],\n",
       "               \n",
       "                        [[ 0.0232]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0140]],\n",
       "               \n",
       "                        [[ 0.0032]],\n",
       "               \n",
       "                        [[ 0.0231]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0179]],\n",
       "               \n",
       "                        [[-0.0151]],\n",
       "               \n",
       "                        [[ 0.0106]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0399]],\n",
       "               \n",
       "                        [[-0.0120]],\n",
       "               \n",
       "                        [[ 0.0329]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0476]],\n",
       "               \n",
       "                        [[-0.0449]],\n",
       "               \n",
       "                        [[ 0.0068]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0234]],\n",
       "               \n",
       "                        [[ 0.0019]],\n",
       "               \n",
       "                        [[ 0.0147]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0061]],\n",
       "               \n",
       "                        [[ 0.0173]],\n",
       "               \n",
       "                        [[ 0.0627]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0048]],\n",
       "               \n",
       "                        [[ 0.0195]],\n",
       "               \n",
       "                        [[-0.0862]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0162]],\n",
       "               \n",
       "                        [[-0.0017]],\n",
       "               \n",
       "                        [[ 0.0175]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0313]],\n",
       "               \n",
       "                        [[-0.0353]],\n",
       "               \n",
       "                        [[-0.0369]]]], device='cuda:0')),\n",
       "              ('module.layer4.2.bn3.weight',\n",
       "               tensor([1.7197, 2.6174, 2.0817,  ..., 1.9607, 2.8499, 2.6272], device='cuda:0')),\n",
       "              ('module.layer4.2.bn3.bias',\n",
       "               tensor([-2.8027, -3.8884, -3.0699,  ..., -2.9416, -4.4088, -4.0962],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.2.bn3.running_mean',\n",
       "               tensor([-0.2864,  0.0308, -0.1629,  ..., -0.1777, -0.2921, -0.1147],\n",
       "                      device='cuda:0')),\n",
       "              ('module.layer4.2.bn3.running_var',\n",
       "               tensor([0.0444, 0.0618, 0.0647,  ..., 0.0607, 0.1012, 0.0552], device='cuda:0')),\n",
       "              ('module.layer4.2.bn3.num_batches_tracked',\n",
       "               tensor(682678, device='cuda:0')),\n",
       "              ('module.fc.weight',\n",
       "               tensor([[ 0.0141,  0.0306, -0.0238,  ..., -0.0117, -0.0094,  0.0432],\n",
       "                       [ 0.0008,  0.0654, -0.0040,  ...,  0.0098, -0.0260,  0.0144],\n",
       "                       [ 0.0420, -0.0107,  0.0188,  ..., -0.0017, -0.0170,  0.0106],\n",
       "                       ...,\n",
       "                       [-0.0120,  0.1063,  0.0104,  ...,  0.0052,  0.0194, -0.0109],\n",
       "                       [ 0.0626, -0.0981,  0.0086,  ..., -0.0082, -0.0450, -0.0278],\n",
       "                       [ 0.0258,  0.0071, -0.0262,  ..., -0.0426, -0.0106,  0.0084]],\n",
       "                      device='cuda:0')),\n",
       "              ('module.fc.bias',\n",
       "               tensor([ 8.9938e-03, -9.8953e-03,  1.4524e-02,  1.0448e-02,  1.8654e-02,\n",
       "                       -5.4018e-03, -9.6241e-03, -4.5321e-02,  5.3551e-03, -5.1089e-03,\n",
       "                        1.9312e-02,  2.9452e-02,  5.3901e-03, -5.8800e-03,  1.0908e-02,\n",
       "                       -9.8112e-03, -1.3040e-02, -6.5587e-05,  5.8799e-03,  1.7572e-02,\n",
       "                        4.0410e-02,  4.5889e-02,  2.0033e-02,  1.1289e-02, -1.2961e-02,\n",
       "                       -9.1181e-04, -1.1441e-02,  2.6909e-02, -1.6762e-02, -1.1471e-03,\n",
       "                       -2.2845e-02, -5.5599e-03, -1.7944e-02,  2.5752e-03,  3.2724e-03,\n",
       "                       -2.2987e-02, -2.1946e-02, -7.1071e-03,  3.7462e-03, -2.0298e-02,\n",
       "                        3.3497e-02,  1.0426e-02,  5.3305e-03, -3.5608e-02, -2.2773e-03,\n",
       "                       -8.6115e-03,  5.5900e-02, -4.1784e-02, -1.0925e-02, -1.9340e-02,\n",
       "                       -2.4687e-02, -6.2809e-02,  2.8214e-02,  2.0011e-02, -9.4355e-03,\n",
       "                        3.1564e-02,  3.8158e-03, -1.0677e-02, -6.4308e-03,  4.0925e-02,\n",
       "                        6.0986e-03,  2.1947e-02, -1.8888e-02, -4.7809e-03,  1.8025e-02,\n",
       "                        8.1997e-03,  4.7354e-02, -2.3125e-02,  9.4984e-03, -5.7544e-03,\n",
       "                       -4.6437e-03, -1.8669e-02,  2.1721e-02,  2.3595e-02,  2.6867e-02,\n",
       "                        3.2179e-02, -1.4333e-02,  6.2118e-02,  3.3839e-02,  3.3002e-03,\n",
       "                        6.6477e-03,  3.0506e-02,  2.2587e-02,  9.0445e-03, -2.0553e-02,\n",
       "                        1.3240e-02, -3.5815e-02,  2.5290e-02, -3.5707e-03,  1.2355e-02,\n",
       "                        1.4037e-02, -3.5149e-02,  2.8774e-02, -1.7347e-02,  1.7639e-02,\n",
       "                        4.3665e-02,  1.2591e-02,  3.5972e-03, -1.6768e-02, -2.6134e-03,\n",
       "                        4.9664e-03, -4.0427e-02,  4.3775e-03,  3.1429e-02, -2.5579e-02,\n",
       "                        1.8792e-02, -2.0715e-04, -1.2347e-02, -3.0086e-02, -4.4263e-02,\n",
       "                       -1.7822e-02,  2.5549e-02, -1.6700e-02, -1.8094e-02, -1.7160e-02,\n",
       "                       -4.2538e-02, -1.4800e-02, -2.5409e-02, -1.6333e-02, -3.5362e-02,\n",
       "                       -1.8857e-02,  2.0298e-02,  3.0835e-03, -6.5826e-02, -1.7863e-02,\n",
       "                        8.6592e-03,  4.2985e-02,  3.6887e-02, -2.9174e-02,  3.2047e-02,\n",
       "                        8.5458e-03,  1.3132e-02,  1.5069e-02, -2.4224e-02,  9.2307e-03,\n",
       "                       -1.6492e-02,  4.9974e-03, -1.1026e-02, -1.3324e-02,  2.4799e-02,\n",
       "                        2.2205e-02,  4.1421e-02,  1.0514e-02,  1.9038e-02, -9.8930e-03,\n",
       "                       -1.0464e-02,  7.1428e-03,  4.2773e-02,  1.1951e-02,  1.8191e-02,\n",
       "                       -1.4405e-02, -1.2775e-02, -1.3334e-02,  3.4276e-02,  2.4409e-02,\n",
       "                        3.7892e-02,  4.5197e-02,  1.1025e-02, -2.6941e-02, -3.5620e-03,\n",
       "                        2.4020e-02,  2.1715e-02,  4.4210e-02,  2.6452e-02, -1.2035e-03,\n",
       "                       -2.1405e-02, -3.5458e-02, -9.9117e-03, -3.2853e-02,  2.6275e-02,\n",
       "                        4.0268e-02,  4.1414e-02,  1.9605e-02,  1.2195e-02,  3.0099e-03,\n",
       "                       -1.0737e-02, -2.1802e-02, -4.6976e-02, -1.3891e-02,  9.0675e-03,\n",
       "                       -4.6513e-02,  7.7426e-03,  2.2529e-02, -7.4204e-03,  3.5319e-02,\n",
       "                        3.9250e-03,  6.9939e-03,  6.2453e-03, -9.2726e-03,  2.1489e-02,\n",
       "                       -7.6825e-03,  2.6289e-02,  4.9076e-02, -5.0067e-02,  2.4936e-02,\n",
       "                        4.8607e-02,  3.7093e-02,  4.0478e-02, -2.5402e-02, -1.6136e-02,\n",
       "                        1.6648e-02,  1.2471e-02,  2.1177e-02,  3.9694e-02,  5.2851e-02,\n",
       "                        2.0141e-03,  8.7662e-04, -1.6072e-02, -1.0643e-02,  3.7710e-02,\n",
       "                       -2.8359e-03, -1.6671e-02,  1.3963e-02, -1.6245e-03, -2.6829e-02,\n",
       "                       -8.2443e-03,  2.6081e-02,  3.9836e-02,  4.7175e-02,  2.6858e-02,\n",
       "                        2.7088e-02, -3.5249e-02,  2.5768e-02,  4.4465e-02, -1.0538e-02,\n",
       "                        3.7143e-02, -5.9329e-03,  2.4039e-02, -2.1223e-02,  2.9436e-02,\n",
       "                        4.6503e-02,  1.0975e-02, -7.6905e-03, -8.7835e-03,  4.3024e-02,\n",
       "                       -2.7483e-02,  1.1155e-02,  1.9919e-02,  9.6216e-03,  7.0932e-02,\n",
       "                        7.4461e-03, -1.4117e-02, -1.3641e-04, -4.5563e-03,  2.6042e-02,\n",
       "                        4.4563e-02, -4.2262e-02,  1.7480e-02,  3.8268e-02,  2.1352e-02,\n",
       "                        2.9682e-02,  1.6460e-02,  2.4851e-02,  5.6799e-02,  8.1287e-03,\n",
       "                        3.3095e-02,  3.4995e-02,  1.1648e-02,  4.6047e-02,  3.7594e-02,\n",
       "                       -4.7037e-03,  2.3805e-02, -3.5082e-02,  1.2051e-02, -3.1385e-03,\n",
       "                        4.4920e-02,  1.9797e-02, -2.6167e-02, -7.7005e-02, -9.3728e-03,\n",
       "                        2.8623e-02, -1.8734e-02,  2.6914e-02,  3.3401e-02,  3.2995e-04,\n",
       "                        5.9388e-03,  9.7389e-03,  1.6651e-02, -2.0250e-02,  1.1932e-02,\n",
       "                        6.7898e-03,  5.5144e-02,  1.9472e-02,  3.4067e-02,  3.4584e-02,\n",
       "                        1.1107e-02,  1.2840e-03,  1.6998e-02,  1.5717e-02, -7.9767e-03,\n",
       "                        4.2596e-03, -4.7973e-05, -2.4625e-02,  9.1699e-03,  1.0197e-03,\n",
       "                       -2.4330e-03,  1.7379e-02,  3.5574e-02,  7.3061e-03,  5.8923e-04,\n",
       "                       -1.1919e-02,  3.6447e-02,  3.3928e-02, -9.4837e-03,  8.7636e-03,\n",
       "                       -9.7030e-03, -1.1629e-02,  1.2925e-02,  1.7046e-02,  1.2522e-03,\n",
       "                       -1.2495e-02, -2.5914e-02, -1.2590e-02,  2.3857e-03,  2.2596e-02,\n",
       "                        1.7724e-02,  2.2814e-02,  3.7186e-02,  4.1287e-02, -8.5564e-03,\n",
       "                        3.3131e-02,  1.9763e-02, -1.0146e-02, -9.8027e-03,  4.0678e-02,\n",
       "                        1.4311e-02,  9.0408e-03, -3.2872e-02, -1.6107e-02, -2.2091e-02,\n",
       "                        2.4148e-02, -4.0899e-02,  2.4791e-02,  4.0343e-02, -1.9870e-03,\n",
       "                       -2.1719e-02, -7.9226e-03, -1.3905e-02,  3.0695e-03, -5.6289e-03,\n",
       "                       -1.8887e-02, -1.4247e-02, -1.9377e-02, -8.6046e-03, -7.1915e-03,\n",
       "                       -6.1123e-03,  2.9556e-02,  2.0622e-02,  9.0842e-03,  1.7669e-02,\n",
       "                       -4.5758e-02,  5.9002e-03,  4.8906e-03, -1.0178e-02, -7.5181e-04,\n",
       "                       -2.3316e-02,  2.4107e-02, -1.3909e-02,  5.6671e-02,  2.0767e-02,\n",
       "                       -2.3595e-02,  4.5039e-03, -4.1683e-03, -1.9941e-02, -1.6817e-02,\n",
       "                        1.8781e-03, -1.1285e-02,  2.5872e-02, -1.2798e-02,  2.3312e-02,\n",
       "                        4.0118e-02,  7.2427e-04,  2.3172e-02, -1.8712e-02,  1.2040e-02,\n",
       "                        1.1812e-02, -5.1289e-03, -4.4094e-03,  1.9007e-02,  5.7097e-02,\n",
       "                        1.2797e-02,  1.8161e-02, -3.3840e-04,  2.8458e-02, -1.1938e-02,\n",
       "                        1.2209e-03,  3.1583e-02, -2.7188e-03,  1.9513e-02, -9.7560e-03,\n",
       "                       -7.6809e-02, -2.8873e-02, -1.9250e-02,  2.8755e-02,  5.7073e-03,\n",
       "                       -5.4397e-03,  1.2930e-02, -6.8442e-03, -5.6795e-03,  1.2862e-02,\n",
       "                        3.9601e-02, -8.5280e-03,  3.4234e-02,  2.2039e-02, -1.1033e-02,\n",
       "                        1.4837e-02,  1.3412e-02, -2.1986e-03, -2.0279e-02, -3.7325e-02,\n",
       "                       -2.0048e-02, -2.1931e-02, -1.1562e-02, -1.5430e-02, -4.7261e-02,\n",
       "                       -1.2250e-02,  1.2531e-02,  5.8025e-03, -2.7158e-03, -1.1446e-02,\n",
       "                        8.3442e-04, -1.8776e-02,  1.4653e-02,  8.5640e-05,  2.8130e-02,\n",
       "                       -9.8339e-03,  1.5831e-02, -2.2491e-02, -3.7768e-02,  2.2789e-02,\n",
       "                        1.3344e-02,  5.2063e-02,  4.6696e-02, -5.3395e-03,  2.6867e-02,\n",
       "                       -2.0200e-02, -2.2215e-02,  1.9271e-02, -1.0037e-02, -3.5185e-02,\n",
       "                       -1.8279e-02,  3.4823e-02,  9.3981e-03,  1.7931e-02,  9.1501e-03,\n",
       "                        5.0640e-02,  2.7314e-02, -8.3078e-03, -1.1116e-02, -2.1844e-02,\n",
       "                       -2.9907e-02,  2.5346e-04, -1.1744e-02,  1.6476e-02, -2.2631e-02,\n",
       "                        2.2858e-02, -4.5997e-02,  8.8300e-03,  1.7320e-02, -2.3319e-02,\n",
       "                        4.0585e-02,  1.2155e-02, -2.2219e-02,  6.2592e-04, -4.2072e-03,\n",
       "                        1.0639e-02, -1.5428e-02,  1.0321e-02,  1.7434e-02, -1.8724e-02,\n",
       "                        1.3148e-02, -2.7259e-02,  5.2151e-03,  1.2839e-02, -5.1800e-03,\n",
       "                        1.4797e-02, -1.6576e-02, -1.6720e-02, -1.7658e-02, -3.3953e-02,\n",
       "                        8.0723e-03, -2.0128e-02,  2.5401e-02,  7.6416e-03, -1.1586e-04,\n",
       "                       -2.5816e-02,  1.9167e-02,  6.5044e-03, -1.7486e-02, -3.3045e-02,\n",
       "                       -2.2093e-02, -3.5218e-02,  3.0924e-03,  6.8044e-02,  1.0148e-02,\n",
       "                        2.4777e-02, -7.9908e-03, -5.5800e-03, -3.7921e-02, -9.5383e-03,\n",
       "                        3.5959e-02, -4.5207e-02, -3.4424e-02, -1.2391e-02, -8.0744e-03,\n",
       "                       -1.8930e-03, -3.6948e-02, -1.0367e-02,  1.7510e-02, -6.4314e-03,\n",
       "                        1.1416e-02,  1.6444e-02,  2.1093e-02,  1.5064e-02, -4.1034e-02,\n",
       "                       -1.0843e-02, -3.0128e-02, -3.4906e-02, -2.7675e-02, -2.9289e-02,\n",
       "                        2.5840e-02, -3.5468e-02, -2.2002e-02,  3.0729e-02, -5.0627e-02,\n",
       "                       -1.5006e-02, -3.3184e-02,  1.4886e-02, -1.8585e-02, -3.1370e-03,\n",
       "                        9.3988e-03, -5.4770e-02, -1.5064e-02,  1.3007e-02,  1.6373e-02,\n",
       "                        4.8205e-03,  4.8237e-02,  3.6135e-02, -6.2421e-03, -1.7302e-02,\n",
       "                        6.1235e-03, -1.2100e-02,  2.2830e-02, -1.0320e-02, -1.8074e-02,\n",
       "                       -4.3972e-02,  3.4868e-03,  2.1901e-03,  2.5615e-02, -8.4765e-03,\n",
       "                       -7.8351e-04,  3.6126e-03,  1.6204e-02,  2.3018e-02,  6.1755e-02,\n",
       "                       -2.4182e-02, -1.3145e-02,  4.0094e-02,  1.6410e-02, -1.1820e-02,\n",
       "                       -2.4340e-02, -3.4376e-02, -5.9172e-02,  1.9112e-02, -5.2861e-03,\n",
       "                       -2.1065e-02, -2.9174e-02, -3.2113e-02,  1.1488e-03, -1.5762e-02,\n",
       "                       -6.6586e-03, -1.0312e-02,  1.0378e-02,  1.3579e-02,  7.3254e-03,\n",
       "                        3.9611e-03, -6.8207e-03, -4.6891e-02, -2.0774e-02,  5.9728e-03,\n",
       "                       -2.7828e-02, -3.0335e-02,  2.8372e-02, -1.2738e-02, -2.9601e-02,\n",
       "                       -2.4865e-02, -2.9180e-02,  2.3796e-02, -3.7545e-02, -1.1255e-02,\n",
       "                       -4.6677e-02, -1.1871e-02,  7.5307e-03,  2.3052e-02, -5.6040e-03,\n",
       "                        2.4520e-02, -3.2682e-02, -3.3971e-02,  1.8301e-02, -4.0200e-02,\n",
       "                       -1.1301e-03,  1.6443e-02,  8.3757e-03,  1.1622e-02, -1.2915e-02,\n",
       "                        2.7918e-02, -2.2445e-02,  3.7169e-02, -2.8901e-03, -1.8651e-02,\n",
       "                       -4.3545e-02, -4.5771e-02,  9.6220e-03,  1.3343e-02, -1.4690e-02,\n",
       "                        1.2753e-02, -4.3457e-02,  2.8816e-02, -2.0869e-02, -2.4346e-02,\n",
       "                        9.0557e-03,  2.7678e-03,  4.8823e-02,  8.6303e-03, -3.9329e-02,\n",
       "                        2.0627e-02,  3.3120e-02,  1.3490e-02,  1.3748e-02,  2.3253e-02,\n",
       "                       -2.3735e-02, -3.8934e-03,  2.4329e-02,  2.4027e-02, -4.2359e-02,\n",
       "                       -1.4013e-02, -4.9428e-02, -4.3973e-02,  3.4548e-02, -1.8833e-03,\n",
       "                       -2.7614e-02, -1.2492e-02,  4.7830e-03, -5.1847e-02,  3.6699e-02,\n",
       "                       -1.6353e-02, -4.8559e-02, -8.4724e-03,  1.7643e-02,  3.1179e-02,\n",
       "                        3.1722e-02,  2.5820e-02,  2.4396e-02, -1.5109e-02, -6.3643e-03,\n",
       "                        7.1011e-02, -1.2200e-03, -9.5898e-03,  6.6454e-03,  2.9884e-02,\n",
       "                        5.7923e-04, -1.1566e-02, -4.8761e-02, -1.5659e-02,  1.5817e-02,\n",
       "                        2.1200e-02, -1.2633e-02, -3.9220e-03,  2.6087e-02, -3.8715e-03,\n",
       "                       -4.7180e-02, -1.6462e-02, -5.3075e-03,  6.1818e-02, -3.8044e-02,\n",
       "                       -1.9471e-02, -1.1396e-03, -3.3238e-02, -2.8495e-03, -7.7761e-03,\n",
       "                        2.0855e-02,  7.6359e-02,  3.8570e-02,  5.3469e-02, -4.4646e-03,\n",
       "                       -4.3942e-04, -7.4186e-03, -2.5810e-02, -1.2937e-02, -4.8772e-02,\n",
       "                       -1.5834e-02, -5.1068e-03, -1.9276e-02, -5.7250e-02,  8.0736e-04,\n",
       "                        1.9244e-02, -3.5977e-03,  1.2182e-02, -4.6578e-03, -7.1572e-03,\n",
       "                        2.0658e-02,  3.6316e-02,  2.3208e-02, -5.8043e-02, -7.7133e-03,\n",
       "                        1.4108e-02, -6.1098e-03, -1.5490e-02,  1.0318e-02, -9.4961e-03,\n",
       "                        6.3304e-04, -9.9150e-03, -4.6810e-02,  1.8332e-04, -2.8010e-03,\n",
       "                       -1.5535e-02, -1.1253e-02, -1.3542e-02, -1.8574e-03, -1.1444e-02,\n",
       "                        1.3621e-02,  1.3705e-02, -3.7128e-03, -6.5425e-02, -1.8641e-02,\n",
       "                       -1.3926e-02,  1.3072e-02, -2.1439e-02, -1.0489e-01, -4.2816e-02,\n",
       "                       -3.2102e-02,  8.2833e-03, -4.3264e-03,  7.6944e-03,  2.6963e-02,\n",
       "                       -5.0123e-03,  2.6332e-03, -1.8304e-02, -4.3201e-02, -2.4968e-03,\n",
       "                       -3.4811e-02, -2.5312e-02,  1.3875e-02, -1.2231e-02,  2.6226e-03,\n",
       "                       -2.2053e-03,  5.9859e-04, -3.0636e-02, -3.3350e-02, -2.2793e-02,\n",
       "                       -3.3243e-02, -2.9143e-02, -4.0967e-02, -7.2663e-03,  9.9694e-03,\n",
       "                        1.9542e-02, -3.6234e-02, -5.2956e-03, -2.1390e-02, -2.2353e-02,\n",
       "                        2.2393e-03,  3.2672e-02, -3.0724e-02,  2.0962e-02,  1.7416e-02,\n",
       "                       -1.6218e-02, -2.0139e-02,  1.9606e-03, -1.3203e-02,  1.7135e-02,\n",
       "                       -3.1435e-02, -3.6217e-02, -9.0683e-03, -3.0453e-03, -3.7964e-02,\n",
       "                       -1.2132e-02,  5.3034e-03, -3.1366e-02, -1.3411e-02, -2.0224e-02,\n",
       "                        3.3009e-02, -2.5576e-02,  2.2070e-02,  1.9797e-02,  7.2423e-03,\n",
       "                        1.7688e-02, -4.1692e-02, -6.2587e-02,  6.5071e-03,  8.4216e-03,\n",
       "                       -4.7789e-02, -2.0768e-02,  4.1296e-04, -5.7326e-03, -3.1118e-02,\n",
       "                       -2.9275e-02, -3.8622e-03, -2.3923e-02,  1.9629e-02,  5.4649e-02,\n",
       "                       -4.4899e-02, -1.2001e-02, -8.6726e-03,  5.1299e-03,  1.2118e-02,\n",
       "                        3.3765e-02, -2.5822e-03, -5.0896e-02, -2.4850e-02, -7.9134e-03,\n",
       "                       -1.7508e-02, -4.2799e-02,  2.6408e-02,  2.2265e-02, -2.5359e-02,\n",
       "                       -1.8667e-02, -1.5375e-02, -1.8201e-02, -4.0496e-02,  2.5590e-02,\n",
       "                        1.0657e-04, -2.2786e-02, -3.0793e-05, -3.6958e-03, -5.8775e-02,\n",
       "                       -6.5621e-03,  4.8888e-04, -2.4343e-02,  2.3235e-02, -2.4766e-02,\n",
       "                       -2.8396e-02,  2.6370e-03,  2.1662e-03,  2.2481e-02,  3.6591e-02,\n",
       "                       -3.0120e-02, -2.6799e-03,  4.6467e-02,  1.8373e-02,  1.1224e-02,\n",
       "                       -2.3193e-02, -5.3812e-02, -3.5068e-02, -2.3517e-02, -1.7087e-02,\n",
       "                        1.1809e-02,  2.0036e-02,  1.1258e-02,  4.1013e-02,  5.7591e-03,\n",
       "                       -1.3172e-02, -5.2991e-02,  3.8220e-02, -3.8073e-02, -4.6898e-03,\n",
       "                       -1.2809e-02, -4.5258e-02, -5.8042e-02, -2.7698e-02, -1.3795e-02,\n",
       "                       -2.3077e-02, -2.7870e-02,  7.0254e-03, -1.0127e-02, -1.8297e-02,\n",
       "                       -1.7585e-02, -3.5073e-03,  1.3697e-02, -3.1522e-02, -2.9492e-02,\n",
       "                       -1.8352e-02,  3.3486e-02, -9.6711e-03,  3.4329e-03,  1.3386e-03,\n",
       "                        2.7264e-02,  2.9615e-02, -2.9957e-02,  1.8289e-02, -3.9236e-02,\n",
       "                        2.8524e-02,  2.5228e-02,  9.6937e-03, -4.4857e-02,  1.9251e-02,\n",
       "                       -2.5921e-02, -2.8364e-02, -1.7320e-02,  1.6850e-02,  2.6162e-02,\n",
       "                        7.7821e-03, -4.9116e-02,  1.9156e-02, -3.7071e-02, -1.9057e-02,\n",
       "                        3.0594e-02, -3.1072e-03,  7.2718e-03, -2.2320e-02,  4.7234e-02,\n",
       "                        1.2431e-02, -1.5742e-02,  2.8635e-02,  2.0722e-02,  1.3937e-02,\n",
       "                       -8.1199e-03,  2.7693e-03, -7.4593e-03,  7.8917e-02, -1.6010e-02,\n",
       "                        2.6258e-02,  1.9853e-02, -1.6704e-02,  3.0206e-02,  2.5340e-02,\n",
       "                       -3.4568e-02, -1.9614e-02, -2.8019e-02,  1.1369e-02, -1.4688e-02,\n",
       "                        1.2603e-02, -5.6260e-02,  2.6938e-02, -2.3312e-02,  2.6160e-02,\n",
       "                        9.1630e-03, -7.5113e-02, -2.0272e-02,  1.0274e-02,  3.3902e-02,\n",
       "                        2.8368e-02,  1.7864e-02, -2.9826e-02,  3.9247e-02,  1.5467e-02,\n",
       "                        3.8891e-02, -5.1793e-02, -8.8381e-04,  7.3826e-03, -1.0816e-02,\n",
       "                       -3.5932e-02, -1.1370e-02,  6.9369e-03, -2.7401e-02, -2.1592e-02,\n",
       "                       -4.5875e-02, -1.8572e-02, -4.6063e-02,  2.5761e-03,  3.3578e-02,\n",
       "                        2.7102e-02,  1.9731e-02, -1.5793e-02, -3.5222e-02, -1.4348e-02,\n",
       "                        1.2306e-02, -2.0355e-02,  6.3553e-03,  3.0360e-02,  2.4119e-02,\n",
       "                       -2.2016e-02,  5.0849e-02, -1.4128e-03,  6.2328e-03,  3.0154e-03,\n",
       "                        1.3670e-02,  2.8407e-02,  5.1516e-02,  1.8557e-02, -1.2661e-02,\n",
       "                        3.2378e-02,  8.3599e-03, -4.4410e-03,  2.2332e-02,  4.9005e-02,\n",
       "                        1.2167e-03,  7.7832e-02,  1.0305e-01,  1.8995e-02,  2.7548e-02,\n",
       "                        3.5120e-02, -1.1488e-02,  2.3218e-02,  2.8407e-02,  4.5906e-02,\n",
       "                        1.8134e-02,  1.1551e-02,  3.3121e-02, -4.4800e-02, -1.3734e-02,\n",
       "                       -3.4892e-02, -3.9044e-03,  6.3056e-03, -3.7721e-02, -1.6081e-02,\n",
       "                        4.5246e-03,  4.1110e-03, -3.6129e-02, -1.8843e-02, -1.3130e-02],\n",
       "                      device='cuda:0'))]),\n",
       " 'best_prec1': tensor(0.7876),\n",
       " 'optimizer': {'state': {0: {'momentum_buffer': tensor([[[[-1.1859e-03, -5.2268e-04, -3.3941e-04,  ...,  1.7728e-04,\n",
       "                3.6953e-04,  8.6423e-04],\n",
       "              [-7.9618e-04, -2.3419e-04,  1.3559e-04,  ...,  1.2850e-03,\n",
       "                1.3664e-03,  1.7683e-03],\n",
       "              [-5.5091e-04, -4.5468e-04,  5.3037e-04,  ...,  1.4838e-03,\n",
       "                1.7848e-03,  1.3805e-03],\n",
       "              ...,\n",
       "              [-1.5183e-04,  7.7097e-04, -6.9925e-04,  ...,  8.5356e-04,\n",
       "                4.3959e-04,  1.6314e-03],\n",
       "              [-2.9303e-04, -9.2087e-05, -1.2837e-05,  ...,  4.5999e-05,\n",
       "               -2.6152e-05,  8.7224e-04],\n",
       "              [ 2.5822e-04,  4.4812e-04, -2.7830e-05,  ..., -6.8764e-04,\n",
       "                2.4655e-04,  5.7311e-04]],\n",
       "    \n",
       "             [[-2.0703e-03, -1.3828e-03, -1.3263e-03,  ..., -6.5880e-04,\n",
       "               -6.0631e-04, -1.0139e-04],\n",
       "              [-1.7573e-03, -1.2675e-03, -8.9199e-04,  ...,  3.1031e-04,\n",
       "                1.9984e-04,  6.1731e-04],\n",
       "              [-1.6521e-03, -1.5327e-03, -5.0272e-04,  ...,  3.4253e-04,\n",
       "                7.0331e-04,  1.5960e-04],\n",
       "              ...,\n",
       "              [-1.1470e-03, -2.6931e-05, -1.9339e-03,  ...,  2.0909e-04,\n",
       "               -7.3686e-04,  6.7773e-04],\n",
       "              [-1.3048e-03, -9.4919e-04, -8.7033e-04,  ..., -6.2968e-04,\n",
       "               -9.7475e-04, -7.2773e-05],\n",
       "              [-6.0564e-04, -3.8561e-04, -7.8686e-04,  ..., -1.4979e-03,\n",
       "               -5.8566e-04, -3.2890e-04]],\n",
       "    \n",
       "             [[-2.1746e-03, -1.4032e-03, -1.3781e-03,  ..., -7.1959e-04,\n",
       "               -5.9491e-04, -1.2089e-04],\n",
       "              [-1.8777e-03, -1.4202e-03, -1.2220e-03,  ...,  1.2381e-04,\n",
       "                3.7707e-05,  5.2539e-04],\n",
       "              [-1.7009e-03, -1.4563e-03, -7.6414e-04,  ...,  3.5749e-04,\n",
       "                3.4441e-04,  5.9906e-05],\n",
       "              ...,\n",
       "              [-1.5467e-03, -7.5924e-04, -1.9211e-03,  ..., -7.4681e-04,\n",
       "               -9.0843e-04,  1.8348e-04],\n",
       "              [-1.6773e-03, -1.4861e-03, -1.5803e-03,  ..., -1.4044e-03,\n",
       "               -1.3931e-03, -4.4412e-04],\n",
       "              [-9.8897e-04, -6.1782e-04, -1.1864e-03,  ..., -1.7080e-03,\n",
       "               -1.0048e-03, -6.4301e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-5.8479e-04, -4.4159e-04, -5.3908e-04,  ..., -2.4033e-04,\n",
       "                5.9963e-04,  3.1288e-04],\n",
       "              [-1.4243e-03, -1.4440e-03, -1.3892e-03,  ..., -1.0593e-03,\n",
       "               -1.5909e-04, -1.5132e-05],\n",
       "              [-1.5554e-03, -1.8482e-03, -1.7102e-03,  ..., -1.3462e-03,\n",
       "               -7.5559e-04, -2.0554e-04],\n",
       "              ...,\n",
       "              [-2.8156e-04, -4.1770e-04, -2.0093e-04,  ..., -6.4204e-04,\n",
       "               -7.1210e-04, -4.9585e-04],\n",
       "              [-6.4230e-04, -8.2662e-04, -1.0872e-03,  ..., -1.6349e-03,\n",
       "               -1.5058e-03, -8.9966e-04],\n",
       "              [-2.2624e-04,  3.0814e-04,  7.3674e-04,  ..., -1.3306e-04,\n",
       "               -5.0038e-04, -4.3263e-04]],\n",
       "    \n",
       "             [[-1.8033e-04, -1.2366e-04, -1.9408e-04,  ...,  3.8755e-05,\n",
       "                8.7150e-04,  5.6532e-04],\n",
       "              [-1.0761e-03, -1.1574e-03, -1.0397e-03,  ..., -7.9685e-04,\n",
       "                7.3346e-05,  2.8053e-04],\n",
       "              [-1.2952e-03, -1.6542e-03, -1.4514e-03,  ..., -1.1117e-03,\n",
       "               -5.3395e-04,  9.7876e-05],\n",
       "              ...,\n",
       "              [ 3.6767e-05, -8.4937e-05,  2.2255e-04,  ..., -1.3527e-04,\n",
       "               -1.5198e-04,  5.5310e-05],\n",
       "              [-4.4550e-04, -6.2389e-04, -8.1798e-04,  ..., -1.3128e-03,\n",
       "               -1.1375e-03, -4.6960e-04],\n",
       "              [ 5.8582e-05,  6.2215e-04,  1.0892e-03,  ...,  2.3804e-04,\n",
       "               -8.2552e-05, -4.8518e-06]],\n",
       "    \n",
       "             [[-5.2009e-04, -5.1767e-04, -6.1704e-04,  ..., -3.3779e-04,\n",
       "                4.3458e-04,  1.7026e-04],\n",
       "              [-1.3906e-03, -1.4697e-03, -1.4088e-03,  ..., -1.0956e-03,\n",
       "               -2.6804e-04, -6.4917e-05],\n",
       "              [-1.5929e-03, -1.9270e-03, -1.6120e-03,  ..., -1.1680e-03,\n",
       "               -7.0353e-04, -1.2507e-04],\n",
       "              ...,\n",
       "              [-5.2827e-04, -7.6628e-04, -5.2630e-04,  ..., -8.2257e-04,\n",
       "               -6.7472e-04, -3.6486e-04],\n",
       "              [-7.9244e-04, -7.8431e-04, -7.9010e-04,  ..., -1.3027e-03,\n",
       "               -1.2458e-03, -6.6848e-04],\n",
       "              [-4.8167e-04,  9.4912e-05,  6.7207e-04,  ..., -1.2844e-04,\n",
       "               -4.5896e-04, -3.6454e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.3696e-04, -1.9720e-03, -2.3752e-04,  ...,  1.6519e-03,\n",
       "                2.0334e-03,  2.1354e-03],\n",
       "              [ 1.8425e-04, -8.3348e-05, -1.5023e-04,  ...,  5.1713e-04,\n",
       "                1.9490e-03,  1.6710e-03],\n",
       "              [ 2.1395e-03,  2.3386e-03,  9.1437e-04,  ..., -1.1942e-04,\n",
       "                1.7318e-03,  1.4619e-03],\n",
       "              ...,\n",
       "              [ 5.3587e-04, -1.9428e-04, -1.9338e-03,  ...,  1.2670e-03,\n",
       "                2.1771e-03,  2.1339e-03],\n",
       "              [ 1.0413e-03,  1.7718e-03, -2.6442e-04,  ...,  2.5086e-03,\n",
       "                1.8610e-03,  1.4601e-03],\n",
       "              [-6.2244e-04,  1.0997e-03,  5.3475e-04,  ...,  1.8831e-03,\n",
       "                2.0221e-03,  1.6070e-03]],\n",
       "    \n",
       "             [[-1.3691e-04, -1.9192e-03, -2.1289e-04,  ...,  1.4533e-03,\n",
       "                1.8423e-03,  2.0368e-03],\n",
       "              [ 1.5487e-04, -5.9309e-05, -1.4374e-04,  ...,  2.7818e-04,\n",
       "                1.7298e-03,  1.4256e-03],\n",
       "              [ 2.0441e-03,  2.2665e-03,  9.0378e-04,  ..., -1.9141e-04,\n",
       "                1.5009e-03,  1.1817e-03],\n",
       "              ...,\n",
       "              [ 4.6072e-04, -1.0976e-04, -1.7129e-03,  ...,  1.6522e-03,\n",
       "                2.3160e-03,  2.0352e-03],\n",
       "              [ 1.0452e-03,  1.8872e-03, -1.0207e-04,  ...,  2.8279e-03,\n",
       "                1.8636e-03,  1.3465e-03],\n",
       "              [-7.9400e-04,  1.1951e-03,  5.7797e-04,  ...,  2.0426e-03,\n",
       "                2.0638e-03,  1.6265e-03]],\n",
       "    \n",
       "             [[ 1.3710e-04, -1.5889e-03,  2.8573e-04,  ...,  2.0015e-03,\n",
       "                2.4082e-03,  2.5993e-03],\n",
       "              [ 4.3065e-04,  9.7675e-05,  1.8766e-04,  ...,  5.6696e-04,\n",
       "                2.0716e-03,  1.7591e-03],\n",
       "              [ 2.2688e-03,  2.4018e-03,  9.5414e-04,  ..., -6.3298e-04,\n",
       "                1.4579e-03,  1.3435e-03],\n",
       "              ...,\n",
       "              [ 6.2970e-04, -1.1594e-04, -2.2990e-03,  ..., -7.6032e-05,\n",
       "                1.4005e-03,  1.9704e-03],\n",
       "              [ 1.0276e-03,  1.9116e-03, -4.0920e-04,  ...,  1.9668e-03,\n",
       "                1.5700e-03,  1.5077e-03],\n",
       "              [-7.4939e-04,  1.1173e-03,  4.6325e-04,  ...,  1.9906e-03,\n",
       "                2.1935e-03,  1.8610e-03]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.8305e-03,  1.4345e-03,  1.4686e-03,  ...,  1.6788e-03,\n",
       "                2.2803e-03,  1.3358e-03],\n",
       "              [ 1.4653e-03,  9.3846e-04,  1.1578e-03,  ...,  1.7465e-03,\n",
       "                1.9233e-03,  1.0618e-03],\n",
       "              [ 1.5494e-03,  4.5463e-04,  8.5766e-04,  ...,  3.8483e-04,\n",
       "                1.0218e-03,  6.1917e-04],\n",
       "              ...,\n",
       "              [ 5.5749e-04, -6.8805e-04, -6.2808e-04,  ..., -6.0296e-04,\n",
       "               -1.1513e-03, -1.3787e-03],\n",
       "              [-4.1817e-04, -1.5625e-03, -8.1199e-04,  ..., -1.4250e-03,\n",
       "               -2.5569e-03, -2.3398e-03],\n",
       "              [ 3.1344e-05, -1.6367e-03, -1.3138e-03,  ..., -1.3927e-03,\n",
       "               -3.2480e-03, -2.0254e-03]],\n",
       "    \n",
       "             [[ 2.0868e-03,  1.5428e-03,  1.5043e-03,  ...,  1.7236e-03,\n",
       "                2.4590e-03,  1.5255e-03],\n",
       "              [ 1.5832e-03,  8.8070e-04,  8.6062e-04,  ...,  1.2727e-03,\n",
       "                1.6068e-03,  8.7136e-04],\n",
       "              [ 1.6766e-03,  4.4958e-04,  5.4131e-04,  ..., -2.0213e-04,\n",
       "                6.3610e-04,  4.8919e-04],\n",
       "              ...,\n",
       "              [ 8.0322e-04, -5.3527e-04, -4.1658e-04,  ...,  7.8819e-06,\n",
       "               -5.8424e-04, -9.7437e-04],\n",
       "              [-2.6338e-04, -1.3380e-03, -3.6735e-04,  ..., -5.3141e-04,\n",
       "               -1.7912e-03, -1.8907e-03],\n",
       "              [ 2.3442e-04, -1.4004e-03, -8.4706e-04,  ..., -4.2198e-04,\n",
       "               -2.3637e-03, -1.4761e-03]],\n",
       "    \n",
       "             [[ 2.0019e-03,  1.4583e-03,  1.4859e-03,  ...,  1.6747e-03,\n",
       "                2.4030e-03,  1.4205e-03],\n",
       "              [ 1.3777e-03,  5.6096e-04,  6.1131e-04,  ...,  8.3887e-04,\n",
       "                1.2550e-03,  6.1024e-04],\n",
       "              [ 1.7212e-03,  3.6621e-04,  2.7843e-04,  ..., -6.5570e-04,\n",
       "                3.8674e-04,  3.8296e-04],\n",
       "              ...,\n",
       "              [ 8.6044e-04, -4.5569e-04, -2.6327e-04,  ...,  2.8048e-04,\n",
       "               -2.3251e-04, -7.3749e-04],\n",
       "              [-1.5514e-04, -1.2050e-03, -1.1077e-04,  ..., -4.8697e-05,\n",
       "               -1.2486e-03, -1.5882e-03],\n",
       "              [ 4.3659e-04, -1.2428e-03, -5.9398e-04,  ..., -7.0010e-06,\n",
       "               -1.9650e-03, -1.2482e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.7344e-04,  1.4676e-03,  2.4668e-03,  ...,  9.2527e-04,\n",
       "                1.6878e-03,  2.3023e-03],\n",
       "              [-2.8992e-04,  1.1642e-03,  2.5283e-03,  ...,  1.2136e-03,\n",
       "                1.8212e-03,  2.5470e-03],\n",
       "              [-1.1656e-04,  1.1497e-03,  2.1713e-03,  ...,  1.1913e-03,\n",
       "                1.8986e-03,  1.3984e-03],\n",
       "              ...,\n",
       "              [ 7.8357e-04,  1.5820e-03,  9.8864e-04,  ...,  1.9476e-03,\n",
       "                5.9671e-04,  5.4618e-04],\n",
       "              [ 3.0060e-04,  8.5235e-04,  5.2159e-04,  ...,  7.9573e-04,\n",
       "                2.4828e-04,  1.9596e-03],\n",
       "              [ 1.5057e-03,  1.8230e-03,  1.7267e-03,  ...,  1.1377e-03,\n",
       "                1.4935e-03,  2.8406e-03]],\n",
       "    \n",
       "             [[-8.6211e-05,  1.0821e-03,  1.9712e-03,  ...,  4.4838e-04,\n",
       "                1.2054e-03,  1.7480e-03],\n",
       "              [-7.0093e-04,  5.8346e-04,  1.9910e-03,  ...,  8.6919e-04,\n",
       "                1.1949e-03,  2.0060e-03],\n",
       "              [-7.8633e-04,  3.9953e-04,  2.1610e-03,  ...,  8.7693e-04,\n",
       "                1.0165e-03,  7.6757e-04],\n",
       "              ...,\n",
       "              [ 3.8039e-04,  1.2930e-03,  9.2367e-04,  ..., -9.8305e-04,\n",
       "               -5.7220e-04,  4.1811e-04],\n",
       "              [-2.2231e-05,  3.4408e-04,  6.0902e-05,  ..., -2.2513e-04,\n",
       "                7.2555e-04,  2.1742e-03],\n",
       "              [ 1.3374e-03,  1.5629e-03,  1.4812e-03,  ...,  1.0932e-03,\n",
       "                1.8933e-03,  2.4740e-03]],\n",
       "    \n",
       "             [[-1.3210e-03, -4.2779e-05,  7.1679e-04,  ..., -6.7799e-04,\n",
       "                2.0211e-05,  4.6368e-04],\n",
       "              [-1.7654e-03, -5.7816e-04,  5.3806e-04,  ..., -2.7478e-04,\n",
       "               -7.3386e-05,  7.0841e-04],\n",
       "              [-1.9384e-03, -9.1327e-04,  7.1572e-04,  ..., -3.5336e-04,\n",
       "               -5.4103e-04, -5.9761e-04],\n",
       "              ...,\n",
       "              [-5.8872e-04,  3.5283e-04, -1.0221e-04,  ..., -2.8092e-03,\n",
       "               -1.8464e-03, -4.6271e-04],\n",
       "              [-1.1354e-03, -7.6477e-04, -1.2256e-03,  ..., -1.4487e-03,\n",
       "               -1.6513e-05,  1.2769e-03],\n",
       "              [ 1.3390e-04,  4.1046e-04,  2.5979e-04,  ...,  4.3696e-04,\n",
       "                1.1915e-03,  1.3142e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.7398e-04,  9.3525e-04,  9.1102e-04,  ...,  8.6278e-04,\n",
       "                1.5132e-03,  1.6199e-03],\n",
       "              [ 6.4894e-04,  5.2138e-04,  1.6858e-04,  ...,  5.8432e-04,\n",
       "                9.3999e-04,  8.7488e-04],\n",
       "              [ 1.9775e-04,  2.1226e-04, -2.0786e-04,  ...,  1.3850e-04,\n",
       "                6.6486e-04,  3.6329e-04],\n",
       "              ...,\n",
       "              [-9.0935e-04, -3.3809e-04, -2.0478e-04,  ..., -5.9996e-04,\n",
       "               -5.1794e-04, -3.8809e-05],\n",
       "              [-7.6010e-04, -1.3244e-04, -3.1791e-04,  ..., -9.9261e-04,\n",
       "               -9.1581e-04, -7.5169e-04],\n",
       "              [-1.2458e-03, -4.8874e-04, -5.1048e-04,  ..., -5.3141e-04,\n",
       "               -8.3513e-04, -2.2508e-04]],\n",
       "    \n",
       "             [[ 7.1325e-04,  1.5038e-03,  1.5804e-03,  ...,  1.4788e-03,\n",
       "                2.1618e-03,  2.2943e-03],\n",
       "              [ 1.0296e-03,  9.3995e-04,  6.7296e-04,  ...,  1.6150e-03,\n",
       "                1.8199e-03,  1.5997e-03],\n",
       "              [ 6.0764e-04,  6.2178e-04, -7.2249e-05,  ...,  7.7032e-04,\n",
       "                1.7121e-03,  1.4164e-03],\n",
       "              ...,\n",
       "              [-4.6697e-04,  2.4313e-04,  6.4615e-04,  ...,  1.7374e-04,\n",
       "               -2.3451e-04,  2.9579e-04],\n",
       "              [-3.6587e-04,  3.0733e-04,  1.5700e-04,  ..., -6.6027e-05,\n",
       "               -5.0045e-05, -1.3722e-04],\n",
       "              [-8.1776e-04,  2.9715e-05,  6.2978e-06,  ...,  5.5853e-05,\n",
       "               -1.1053e-04,  5.1149e-04]],\n",
       "    \n",
       "             [[ 9.7985e-04,  1.9165e-03,  2.0193e-03,  ...,  2.0483e-03,\n",
       "                2.8618e-03,  3.1015e-03],\n",
       "              [ 1.3970e-03,  1.4751e-03,  1.1990e-03,  ...,  2.0575e-03,\n",
       "                2.4055e-03,  2.4208e-03],\n",
       "              [ 1.1277e-03,  1.3444e-03,  6.8304e-04,  ...,  1.3965e-03,\n",
       "                2.3270e-03,  2.0728e-03],\n",
       "              ...,\n",
       "              [ 2.0121e-04,  9.9876e-04,  1.2576e-03,  ...,  8.8556e-04,\n",
       "                5.9240e-04,  1.0625e-03],\n",
       "              [ 3.5278e-04,  1.1369e-03,  9.5320e-04,  ...,  6.5984e-04,\n",
       "                7.6638e-04,  6.3011e-04],\n",
       "              [-1.4731e-04,  8.1697e-04,  8.7343e-04,  ...,  8.2533e-04,\n",
       "                6.5885e-04,  1.3057e-03]]]], device='cuda:0')},\n",
       "   1: {'momentum_buffer': tensor([ 0.0021,  0.0010,  0.0025,  0.0012,  0.0048,  0.0013,  0.0012,  0.0014,\n",
       "             0.0039,  0.0044,  0.0016,  0.0024,  0.0063,  0.0023,  0.0017,  0.0018,\n",
       "             0.0016,  0.0020,  0.0027,  0.0066,  0.0025,  0.0004,  0.0026,  0.0019,\n",
       "             0.0055,  0.0035,  0.0025,  0.0014,  0.0018,  0.0093,  0.0008,  0.0004,\n",
       "             0.0058,  0.0028,  0.0018,  0.0013,  0.0022,  0.0007,  0.0009,  0.0075,\n",
       "             0.0023,  0.0044,  0.0030,  0.0012,  0.0023,  0.0022, -0.0001,  0.0003,\n",
       "             0.0013,  0.0020,  0.0023,  0.0019,  0.0041,  0.0004,  0.0019,  0.0021,\n",
       "             0.0029,  0.0020,  0.0025,  0.0013,  0.0025,  0.0014,  0.0013,  0.0018],\n",
       "           device='cuda:0')},\n",
       "   2: {'momentum_buffer': tensor([ 0.0029,  0.0021,  0.0038,  0.0013, -0.0039,  0.0024,  0.0025,  0.0023,\n",
       "             0.0014,  0.0019,  0.0025,  0.0060, -0.0061,  0.0012,  0.0024,  0.0051,\n",
       "             0.0045,  0.0094,  0.0027,  0.0141,  0.0024,  0.0025,  0.0022,  0.0020,\n",
       "            -0.0082,  0.0020,  0.0040,  0.0016,  0.0030,  0.0221,  0.0022,  0.0025,\n",
       "            -0.0093,  0.0018,  0.0024,  0.0025,  0.0024,  0.0022,  0.0025,  0.0150,\n",
       "             0.0017, -0.0029,  0.0025,  0.0027,  0.0025,  0.0025,  0.0022,  0.0024,\n",
       "             0.0030,  0.0026,  0.0027,  0.0028, -0.0040,  0.0025,  0.0012,  0.0021,\n",
       "             0.0021,  0.0037,  0.0045,  0.0025,  0.0025,  0.0019,  0.0027,  0.0026],\n",
       "           device='cuda:0')},\n",
       "   3: {'momentum_buffer': tensor([[[[ 2.5705e-04]],\n",
       "    \n",
       "             [[ 1.1910e-03]],\n",
       "    \n",
       "             [[ 4.1650e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.9352e-04]],\n",
       "    \n",
       "             [[-3.2071e-04]],\n",
       "    \n",
       "             [[-6.2960e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.9310e-04]],\n",
       "    \n",
       "             [[-2.2938e-04]],\n",
       "    \n",
       "             [[ 1.2194e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.6555e-04]],\n",
       "    \n",
       "             [[ 2.3028e-06]],\n",
       "    \n",
       "             [[ 8.8902e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.4312e-05]],\n",
       "    \n",
       "             [[ 1.4444e-03]],\n",
       "    \n",
       "             [[ 6.8268e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.3384e-06]],\n",
       "    \n",
       "             [[ 2.9965e-04]],\n",
       "    \n",
       "             [[ 2.6411e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-1.3754e-06]],\n",
       "    \n",
       "             [[ 8.1791e-04]],\n",
       "    \n",
       "             [[ 1.2138e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.4462e-04]],\n",
       "    \n",
       "             [[-7.9333e-05]],\n",
       "    \n",
       "             [[ 6.0289e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.2781e-04]],\n",
       "    \n",
       "             [[ 1.6692e-04]],\n",
       "    \n",
       "             [[ 3.0799e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.7119e-04]],\n",
       "    \n",
       "             [[ 7.3034e-05]],\n",
       "    \n",
       "             [[ 4.2210e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-4.0834e-04]],\n",
       "    \n",
       "             [[-4.6265e-04]],\n",
       "    \n",
       "             [[-6.0626e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.4558e-04]],\n",
       "    \n",
       "             [[ 1.4405e-04]],\n",
       "    \n",
       "             [[-3.6787e-04]]]], device='cuda:0')},\n",
       "   4: {'momentum_buffer': tensor([0.0030, 0.0032, 0.0015, 0.0030, 0.0012, 0.0010, 0.0024, 0.0028, 0.0013,\n",
       "            0.0013, 0.0028, 0.0022, 0.0012, 0.0035, 0.0017, 0.0007, 0.0017, 0.0032,\n",
       "            0.0032, 0.0034, 0.0012, 0.0026, 0.0011, 0.0022, 0.0013, 0.0036, 0.0036,\n",
       "            0.0004, 0.0029, 0.0041, 0.0028, 0.0020, 0.0040, 0.0051, 0.0028, 0.0028,\n",
       "            0.0029, 0.0028, 0.0015, 0.0025, 0.0021, 0.0022, 0.0012, 0.0045, 0.0012,\n",
       "            0.0009, 0.0035, 0.0020, 0.0031, 0.0009, 0.0008, 0.0002, 0.0044, 0.0012,\n",
       "            0.0019, 0.0043, 0.0010, 0.0015, 0.0011, 0.0013, 0.0034, 0.0017, 0.0013,\n",
       "            0.0038], device='cuda:0')},\n",
       "   5: {'momentum_buffer': tensor([-1.3252e-04, -1.4121e-03, -8.9159e-04, -1.3971e-03, -9.6986e-04,\n",
       "             6.8980e-04, -1.4524e-03,  2.4659e-04,  1.2917e-03,  9.0212e-04,\n",
       "            -9.3867e-06,  1.1926e-03,  1.3569e-03, -2.4816e-03,  1.6359e-03,\n",
       "             1.7181e-03,  3.9959e-05, -8.5804e-04, -2.3581e-04, -1.9906e-03,\n",
       "             1.3707e-03,  5.4475e-04,  9.8106e-04,  9.9840e-04,  1.6509e-03,\n",
       "             2.7607e-03, -8.7680e-04,  1.6844e-03, -1.4883e-03, -3.9142e-03,\n",
       "             7.4798e-03, -1.6419e-03, -1.1681e-03, -7.0122e-03, -3.5929e-04,\n",
       "             6.6474e-04, -7.5021e-04, -1.7195e-03,  5.2395e-04, -2.7791e-03,\n",
       "            -1.2351e-04, -1.5016e-03,  9.4468e-04, -3.0579e-03,  9.9172e-04,\n",
       "             7.6275e-04, -1.6924e-03, -1.6672e-03,  6.7757e-03,  3.8926e-04,\n",
       "             3.0226e-04,  9.7733e-04, -2.7977e-03,  1.8124e-03, -2.3494e-03,\n",
       "            -5.3221e-03,  8.9220e-04,  9.0998e-05,  1.3008e-03,  1.8386e-03,\n",
       "             3.2463e-03, -1.7423e-03,  1.3550e-03, -1.1224e-03], device='cuda:0')},\n",
       "   6: {'momentum_buffer': tensor([[[[-3.1546e-05,  5.2088e-05, -1.8837e-05],\n",
       "              [ 3.6369e-05,  1.3425e-04,  6.2724e-05],\n",
       "              [-8.5451e-06,  1.0555e-04,  4.2336e-05]],\n",
       "    \n",
       "             [[-5.1737e-05, -3.6788e-05, -3.3089e-05],\n",
       "              [-3.1155e-05,  7.4748e-06, -1.2101e-05],\n",
       "              [-3.4710e-05, -3.6390e-05, -5.1054e-05]],\n",
       "    \n",
       "             [[ 3.7462e-05,  1.2106e-04,  1.3097e-04],\n",
       "              [ 3.6342e-05,  1.3140e-05, -1.0630e-05],\n",
       "              [-5.5374e-06,  4.0968e-06, -5.6709e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.2866e-05, -3.3933e-05, -3.3934e-05],\n",
       "              [-3.0674e-05, -8.2739e-06, -2.8390e-05],\n",
       "              [-1.0397e-05, -6.5232e-06, -2.9442e-05]],\n",
       "    \n",
       "             [[-9.3161e-05, -1.6692e-04, -1.0144e-04],\n",
       "              [-1.5616e-04, -2.7539e-04, -1.7709e-04],\n",
       "              [-9.1290e-05, -1.6162e-04, -1.0848e-04]],\n",
       "    \n",
       "             [[-5.4346e-05, -3.8604e-05, -5.7793e-05],\n",
       "              [-3.3221e-05,  8.2537e-05,  3.6375e-06],\n",
       "              [-5.5995e-05,  1.9789e-05,  2.2285e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.2785e-04,  2.5696e-04,  2.0534e-04],\n",
       "              [ 9.4950e-05,  1.5304e-04,  3.4069e-05],\n",
       "              [ 1.2084e-04,  1.9585e-04,  7.9819e-05]],\n",
       "    \n",
       "             [[ 5.5884e-05,  6.8888e-05,  5.1133e-05],\n",
       "              [ 5.8708e-05,  1.7396e-04,  5.1865e-05],\n",
       "              [-5.0134e-05, -7.4659e-06, -5.9090e-05]],\n",
       "    \n",
       "             [[ 2.5662e-04, -1.6155e-04, -1.5338e-04],\n",
       "              [-2.7163e-04, -5.6161e-04, -5.9412e-04],\n",
       "              [ 7.4291e-05,  5.9898e-05,  3.9089e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.5583e-08,  4.0632e-06, -1.9619e-06],\n",
       "              [ 6.1438e-06,  2.7936e-05,  9.5028e-06],\n",
       "              [-1.8034e-06,  2.9046e-06, -5.1101e-06]],\n",
       "    \n",
       "             [[ 6.8719e-04,  4.3060e-04,  4.2720e-04],\n",
       "              [ 1.9525e-04, -6.9941e-05, -1.1800e-04],\n",
       "              [-1.4692e-05, -2.9673e-04, -3.1574e-04]],\n",
       "    \n",
       "             [[ 1.4640e-04,  2.2297e-04,  1.5568e-04],\n",
       "              [ 1.8821e-04,  3.7409e-04,  2.1013e-04],\n",
       "              [ 8.9098e-05,  1.4658e-04,  1.1267e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 6.3190e-04, -1.4948e-05,  4.1071e-04],\n",
       "              [ 6.6538e-04, -1.4983e-04,  2.1088e-04],\n",
       "              [ 7.7253e-04,  4.2883e-04,  2.0849e-04]],\n",
       "    \n",
       "             [[ 1.7472e-04,  3.4555e-05,  1.8587e-04],\n",
       "              [ 4.9471e-05, -1.5440e-05, -3.4167e-04],\n",
       "              [ 1.7802e-04,  1.4859e-04,  9.3625e-05]],\n",
       "    \n",
       "             [[ 1.1801e-04,  4.3419e-04, -3.6393e-04],\n",
       "              [-6.7833e-04, -4.7074e-04, -1.3021e-04],\n",
       "              [ 3.7132e-04, -8.2570e-05,  4.4855e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.0130e-04,  2.0031e-04,  3.1470e-04],\n",
       "              [ 2.9148e-04,  1.6091e-04,  3.4983e-04],\n",
       "              [ 3.9747e-04,  4.5959e-04,  2.2071e-04]],\n",
       "    \n",
       "             [[ 1.2718e-04, -1.0045e-04, -7.1707e-04],\n",
       "              [-2.8981e-04, -4.0431e-04, -8.1375e-04],\n",
       "              [-1.4846e-04, -8.0185e-04, -6.7190e-04]],\n",
       "    \n",
       "             [[ 1.0942e-04,  3.4325e-04, -1.1428e-05],\n",
       "              [ 3.3104e-05,  3.3322e-04,  9.7438e-05],\n",
       "              [ 1.5540e-04,  3.0970e-04,  3.0559e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-2.0675e-04,  2.0170e-04,  1.3428e-04],\n",
       "              [-1.5515e-04,  9.2090e-05,  8.4016e-05],\n",
       "              [-3.8695e-05,  1.8080e-04,  1.1111e-04]],\n",
       "    \n",
       "             [[-1.6031e-04, -2.8936e-04, -1.9649e-04],\n",
       "              [-5.7180e-05,  1.8252e-04,  8.6445e-05],\n",
       "              [-9.4373e-05,  1.1583e-05, -9.4639e-05]],\n",
       "    \n",
       "             [[-6.5645e-05, -1.1279e-04,  4.4765e-05],\n",
       "              [-1.0116e-04, -1.9960e-04, -2.4912e-04],\n",
       "              [ 9.3726e-05, -9.5578e-05, -2.8747e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.6996e-04, -1.2525e-04,  1.9842e-05],\n",
       "              [-1.7841e-04, -1.1821e-04,  7.6945e-06],\n",
       "              [-1.3543e-04,  3.0222e-05,  1.0586e-04]],\n",
       "    \n",
       "             [[ 9.8648e-04,  8.5330e-04,  6.7747e-04],\n",
       "              [ 8.6830e-04,  8.1446e-04,  5.7996e-04],\n",
       "              [ 9.1444e-04,  7.2047e-04,  3.8587e-04]],\n",
       "    \n",
       "             [[-4.5614e-05,  1.7657e-06, -1.2830e-04],\n",
       "              [-3.4153e-05,  1.0729e-04,  2.5233e-05],\n",
       "              [-1.3447e-04, -2.8444e-05,  2.7259e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.6486e-04,  1.3031e-04, -4.5503e-05],\n",
       "              [ 1.2505e-04,  6.2198e-05, -5.0329e-06],\n",
       "              [-1.5486e-05, -1.5471e-05, -8.3280e-05]],\n",
       "    \n",
       "             [[-1.9359e-04, -9.5801e-05,  1.8539e-05],\n",
       "              [-1.4283e-04, -8.3738e-05, -3.3026e-05],\n",
       "              [-2.1302e-04, -1.6806e-04, -1.5938e-04]],\n",
       "    \n",
       "             [[-7.3555e-05, -2.5913e-04, -2.9076e-04],\n",
       "              [ 2.2508e-04,  1.6416e-04,  2.3759e-04],\n",
       "              [ 1.1647e-05, -1.7666e-05,  4.0702e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.8325e-04, -1.7892e-04,  8.9844e-06],\n",
       "              [-2.4347e-04, -1.4607e-04, -1.2560e-05],\n",
       "              [-2.2114e-04, -1.3146e-04,  1.9727e-05]],\n",
       "    \n",
       "             [[ 6.5401e-04,  2.4133e-04,  2.9009e-04],\n",
       "              [ 4.7098e-04,  3.8890e-04,  4.9486e-04],\n",
       "              [ 3.3796e-04,  3.9850e-04,  2.7465e-04]],\n",
       "    \n",
       "             [[-2.9322e-04, -6.2530e-05, -3.6501e-05],\n",
       "              [-2.1381e-04, -5.6566e-05,  9.3553e-06],\n",
       "              [-2.4380e-04, -1.2751e-04,  6.0200e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 6.9572e-05, -2.2952e-04, -1.3151e-04],\n",
       "              [ 3.2252e-04,  1.4173e-05, -2.9247e-04],\n",
       "              [ 1.4693e-04, -1.1608e-04, -2.0557e-04]],\n",
       "    \n",
       "             [[ 4.2712e-05,  1.6027e-04,  6.0520e-05],\n",
       "              [-9.8708e-05, -1.0730e-04, -1.1375e-04],\n",
       "              [-2.8827e-04, -1.0554e-04, -1.9226e-04]],\n",
       "    \n",
       "             [[-1.9039e-04, -1.8882e-04, -1.9137e-04],\n",
       "              [ 1.5756e-04, -2.0801e-04, -1.0613e-04],\n",
       "              [-3.2839e-04, -1.7455e-04,  6.8068e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.5986e-04,  1.0594e-04,  4.0261e-06],\n",
       "              [-1.1665e-06,  5.8698e-06, -1.9874e-06],\n",
       "              [-1.7632e-04, -1.5142e-04, -1.8917e-05]],\n",
       "    \n",
       "             [[ 3.2909e-04,  2.5001e-04,  1.9267e-04],\n",
       "              [ 3.5135e-04,  2.7551e-04,  1.7031e-05],\n",
       "              [ 3.0432e-04,  4.0124e-04,  1.6365e-04]],\n",
       "    \n",
       "             [[ 1.2427e-04,  3.3505e-05, -4.7187e-05],\n",
       "              [ 1.6834e-04,  1.4190e-04,  1.0438e-05],\n",
       "              [ 2.4452e-05, -3.1088e-05, -6.4005e-05]]]], device='cuda:0')},\n",
       "   7: {'momentum_buffer': tensor([ 1.3712e-03,  3.8375e-03,  4.6963e-03,  2.5959e-03, -6.7722e-05,\n",
       "             1.0275e-04,  1.3894e-03,  1.6538e-03,  4.2420e-03,  2.9745e-03,\n",
       "             1.4550e-03,  2.4239e-03,  3.1027e-03,  1.8486e-03,  7.8941e-04,\n",
       "             1.6167e-03,  1.1151e-03,  2.8214e-03,  1.3063e-03,  1.2111e-03,\n",
       "             5.8675e-04,  1.0274e-03,  7.8099e-04,  3.2076e-04,  1.4356e-03,\n",
       "             1.4271e-03,  1.9063e-03,  1.9892e-03,  1.7895e-03, -4.7786e-04,\n",
       "             2.3275e-03,  2.8117e-03,  1.0512e-03,  2.5615e-03,  7.1112e-05,\n",
       "             9.3961e-05,  2.0354e-03, -2.1578e-03,  2.6009e-03,  1.0700e-03,\n",
       "             2.9467e-03,  3.0506e-03,  3.7029e-03,  1.7435e-03,  1.6189e-03,\n",
       "             1.0452e-03,  1.0866e-03, -4.3938e-05,  1.4660e-03,  5.4770e-04,\n",
       "             1.0141e-04,  2.1599e-03,  2.8897e-04,  2.7615e-03,  1.5270e-03,\n",
       "             8.6528e-04,  7.3445e-04,  2.1124e-03,  1.0129e-03,  3.8239e-03,\n",
       "             9.3311e-04,  3.4259e-04,  1.1736e-03,  1.2705e-03], device='cuda:0')},\n",
       "   8: {'momentum_buffer': tensor([-1.5462e-04, -8.5224e-03,  9.7133e-03,  7.7943e-04,  1.8417e-03,\n",
       "             1.1423e-03, -1.9501e-03, -1.4166e-03,  1.1027e-02,  1.0103e-02,\n",
       "             1.1112e-03, -3.4617e-03,  3.1022e-03,  4.9139e-03,  2.3413e-03,\n",
       "            -5.8978e-04, -1.8015e-03, -2.5336e-03,  6.3539e-04,  4.4911e-04,\n",
       "             1.2288e-03, -4.8328e-04, -8.9466e-04,  5.5371e-04,  3.2967e-04,\n",
       "            -2.1488e-03, -2.2989e-03, -6.0902e-04, -9.7693e-04,  6.4782e-04,\n",
       "            -1.2995e-03,  6.6846e-03,  1.5526e-03, -3.7988e-03,  1.8713e-03,\n",
       "             8.1566e-04, -2.8905e-03,  2.7178e-03,  3.1181e-03, -8.4650e-05,\n",
       "             7.2184e-03, -1.4293e-02,  1.0119e-02,  7.4446e-04,  2.6541e-04,\n",
       "             4.7073e-04, -4.5998e-04,  1.2418e-03, -1.4639e-03,  3.0079e-03,\n",
       "             1.0187e-03,  2.8515e-04,  8.2585e-04,  4.6550e-03,  2.6427e-03,\n",
       "            -3.9288e-04, -1.9193e-03,  5.2410e-04,  1.6987e-03,  2.5440e-03,\n",
       "             3.4604e-03, -1.2508e-03,  9.8661e-04,  3.5344e-04], device='cuda:0')},\n",
       "   9: {'momentum_buffer': tensor([[[[-3.6409e-04]],\n",
       "    \n",
       "             [[-2.0709e-04]],\n",
       "    \n",
       "             [[ 1.6640e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.4238e-04]],\n",
       "    \n",
       "             [[-2.2623e-05]],\n",
       "    \n",
       "             [[-5.7852e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.7920e-05]],\n",
       "    \n",
       "             [[-2.8715e-04]],\n",
       "    \n",
       "             [[-6.4145e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.2075e-04]],\n",
       "    \n",
       "             [[-5.7254e-04]],\n",
       "    \n",
       "             [[-9.6890e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.1276e-04]],\n",
       "    \n",
       "             [[-1.5040e-04]],\n",
       "    \n",
       "             [[ 7.7371e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.7633e-04]],\n",
       "    \n",
       "             [[-4.6641e-04]],\n",
       "    \n",
       "             [[-3.0572e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 2.7059e-04]],\n",
       "    \n",
       "             [[ 7.9676e-04]],\n",
       "    \n",
       "             [[-2.8425e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.9005e-04]],\n",
       "    \n",
       "             [[ 1.0198e-03]],\n",
       "    \n",
       "             [[ 2.0702e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.4932e-05]],\n",
       "    \n",
       "             [[ 2.0600e-04]],\n",
       "    \n",
       "             [[ 1.0014e-03]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.5393e-04]],\n",
       "    \n",
       "             [[ 2.5721e-06]],\n",
       "    \n",
       "             [[ 3.0058e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.2702e-04]],\n",
       "    \n",
       "             [[-4.2045e-05]],\n",
       "    \n",
       "             [[ 8.1511e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.3502e-05]],\n",
       "    \n",
       "             [[-6.5032e-05]],\n",
       "    \n",
       "             [[-2.8878e-05]]]], device='cuda:0')},\n",
       "   10: {'momentum_buffer': tensor([ 6.2376e-03,  3.4894e-03,  1.5934e-03,  1.6075e-03,  2.7766e-03,\n",
       "             6.1034e-03,  2.1085e-03,  5.9056e-03,  2.4494e-03,  4.1862e-03,\n",
       "             2.5278e-03,  3.9119e-03,  1.3677e-03,  2.9280e-03,  2.6297e-03,\n",
       "             2.9168e-03,  2.8199e-03,  5.8008e-03,  2.8812e-03,  2.7024e-03,\n",
       "             2.9044e-03,  5.7551e-03,  3.5646e-03,  3.1995e-03,  2.9338e-03,\n",
       "             4.7738e-03,  3.1296e-03,  1.3881e-03,  4.4499e-03,  5.0421e-03,\n",
       "             3.6291e-03,  2.6140e-03,  2.2486e-03,  4.4313e-03,  1.6428e-03,\n",
       "             3.0965e-03,  3.0541e-03,  1.9122e-03,  1.4981e-03,  1.9669e-03,\n",
       "             4.3655e-03,  2.0847e-03,  1.4363e-03,  4.5680e-03,  2.1181e-03,\n",
       "             7.2417e-04,  7.7750e-04,  7.5571e-04,  3.2611e-03,  4.8644e-04,\n",
       "             3.7192e-03,  1.7057e-03,  4.3055e-03,  5.4702e-03,  5.7604e-03,\n",
       "             2.3772e-03,  2.3765e-03,  1.9028e-03,  1.7255e-03,  5.0180e-03,\n",
       "             1.0793e-03,  4.0505e-03,  5.2727e-03,  2.3817e-03,  4.1397e-03,\n",
       "             5.9649e-03,  2.8642e-03,  1.6809e-03,  2.3301e-03,  3.4106e-03,\n",
       "             6.7467e-04,  4.0622e-03,  1.2594e-03,  2.1385e-03,  2.7556e-03,\n",
       "             9.1211e-04,  2.4871e-03,  4.8563e-03,  4.6426e-04,  3.7913e-03,\n",
       "             4.0670e-03,  6.1192e-04,  5.4699e-04,  3.0512e-03,  2.0831e-03,\n",
       "             5.0102e-03,  2.0607e-03,  2.8720e-03,  4.4164e-03,  6.6504e-03,\n",
       "             9.2438e-04,  4.3149e-03,  1.2118e-03,  2.4601e-03,  2.8703e-03,\n",
       "             2.5128e-03,  2.3724e-03,  1.1925e-03,  1.9001e-03,  3.2368e-03,\n",
       "             5.4305e-04, -1.7637e-03,  2.9010e-03,  3.5314e-03,  2.5689e-03,\n",
       "             5.0086e-03,  2.3840e-03,  1.9907e-03,  1.2880e-03,  2.2834e-03,\n",
       "             5.6794e-03,  3.9589e-03,  2.2057e-03,  5.9014e-03,  2.2211e-03,\n",
       "             2.3509e-03,  6.1626e-03,  2.9741e-03,  2.1114e-03,  4.0657e-04,\n",
       "             2.4078e-03,  2.3548e-03,  2.9959e-03,  3.6260e-03,  6.2049e-03,\n",
       "             6.4667e-03,  5.4397e-03,  3.3441e-04,  1.6617e-03,  4.0923e-03,\n",
       "             2.1800e-03,  3.0909e-03,  5.9030e-03,  2.6866e-03,  9.3647e-03,\n",
       "             2.0372e-03,  2.5408e-03,  3.3679e-03,  5.9773e-03,  2.7717e-03,\n",
       "             2.4994e-03,  3.7491e-03,  4.3882e-03,  1.3798e-03,  2.6128e-03,\n",
       "             2.3323e-03,  5.4816e-03,  5.5769e-03,  3.4670e-03,  2.7776e-03,\n",
       "             4.4717e-03,  4.0304e-03,  1.5548e-03,  3.9244e-03,  5.0350e-03,\n",
       "             2.1444e-03,  7.3976e-04,  5.6032e-04,  3.2367e-03,  3.0448e-03,\n",
       "             2.1393e-03,  6.7109e-03,  3.8383e-03,  3.9556e-03,  1.1150e-03,\n",
       "             1.4231e-03,  4.6587e-03,  7.7411e-04,  4.1955e-03,  5.9684e-03,\n",
       "             7.6749e-04,  4.3390e-03,  4.4030e-03,  1.6060e-03,  1.3189e-03,\n",
       "             3.5244e-03,  3.2737e-03,  1.5192e-04,  2.0276e-03,  3.1167e-04,\n",
       "             4.2930e-03,  1.4290e-03,  3.0532e-03,  2.1187e-03,  1.5330e-03,\n",
       "             4.7408e-03,  4.2798e-03,  1.8314e-03,  5.4451e-03,  2.9073e-03,\n",
       "             1.6199e-03,  5.9604e-03,  2.0646e-03,  3.2758e-03,  3.4305e-03,\n",
       "             1.6440e-03,  8.6368e-04,  5.6958e-03,  6.3179e-03,  5.5295e-03,\n",
       "             2.6068e-03,  3.9514e-03,  6.8490e-03,  2.3237e-03,  2.5856e-03,\n",
       "             6.1221e-03,  5.8308e-05,  2.1144e-03,  3.0166e-03,  2.7728e-03,\n",
       "             2.8050e-03,  3.5615e-03,  5.1853e-03,  4.2020e-03,  3.2927e-03,\n",
       "             2.4303e-03,  3.8565e-03,  5.9982e-03,  1.0861e-04,  3.2223e-03,\n",
       "             2.7616e-03,  3.7526e-03,  1.1283e-03,  4.4325e-03,  1.5017e-03,\n",
       "             3.3128e-03,  5.3300e-03,  4.6822e-03,  3.0899e-03,  3.7194e-03,\n",
       "             5.5746e-03,  2.8404e-03,  8.2523e-04,  4.2672e-03,  5.0954e-03,\n",
       "             1.9488e-03,  2.8854e-03,  1.3599e-03,  3.9566e-03,  1.8795e-03,\n",
       "             2.7378e-03,  1.5707e-03,  1.9216e-03,  4.7663e-03,  3.5536e-03,\n",
       "             3.6828e-03,  3.2318e-03,  1.6010e-03,  4.6232e-03,  7.0542e-03,\n",
       "             8.2675e-04,  2.3709e-03,  3.5640e-03,  7.0259e-03,  4.0269e-03,\n",
       "             3.2944e-03], device='cuda:0')},\n",
       "   11: {'momentum_buffer': tensor([-2.2167e-04, -6.0863e-04,  2.8204e-04, -3.2920e-05, -2.8799e-04,\n",
       "             3.4548e-04, -8.3701e-04,  9.7839e-04,  4.1856e-04, -6.3200e-04,\n",
       "            -3.4029e-04,  5.2203e-04,  5.7248e-04, -1.4196e-03,  6.1664e-04,\n",
       "            -2.6752e-05,  1.9658e-04,  4.5992e-04,  1.0582e-04, -9.7486e-04,\n",
       "            -1.0031e-04, -8.2894e-04, -1.7148e-04,  5.9712e-04,  8.6411e-06,\n",
       "             5.8925e-05,  7.0672e-06,  1.2620e-04,  2.7848e-04,  1.0744e-03,\n",
       "            -5.9237e-04,  3.7872e-04, -3.9214e-04,  1.2383e-03,  2.8899e-04,\n",
       "             9.8120e-04,  8.6391e-04,  1.4037e-04,  3.1487e-05, -4.0812e-06,\n",
       "             5.8413e-04, -2.3178e-04, -3.2555e-04, -8.5811e-04,  1.1981e-03,\n",
       "            -1.8844e-03, -1.4590e-03, -2.5505e-04, -1.4190e-04, -3.1018e-04,\n",
       "             4.3535e-05, -3.9045e-04, -7.5085e-04, -6.8047e-05, -3.3008e-04,\n",
       "             1.7770e-04,  1.7419e-05,  6.1888e-04,  4.8540e-04, -4.2982e-04,\n",
       "            -9.1500e-04,  2.8741e-03, -2.7549e-04, -2.6192e-04,  4.2963e-04,\n",
       "            -4.7922e-05, -6.1439e-04,  1.9015e-04, -3.7842e-05,  4.0015e-04,\n",
       "            -1.3141e-03,  1.4775e-04, -2.8373e-04,  2.9203e-05, -2.9321e-04,\n",
       "             3.9513e-04, -1.5012e-04,  1.8522e-04, -2.4517e-03,  1.5913e-03,\n",
       "            -8.0616e-05, -1.3850e-04,  1.2615e-03,  2.6302e-04,  6.8090e-05,\n",
       "            -2.7625e-04,  1.8195e-04,  2.0063e-04, -1.8917e-04,  7.5925e-04,\n",
       "            -7.3137e-05,  5.5781e-04, -5.6802e-04, -4.5582e-04,  7.7132e-05,\n",
       "            -4.9559e-04, -5.6475e-04, -1.4079e-03,  5.2267e-06, -4.6492e-04,\n",
       "             1.9810e-04,  1.6915e-04, -3.1778e-04,  1.7523e-04, -2.4292e-04,\n",
       "             6.8303e-04,  3.1465e-04,  6.3889e-04,  2.0588e-04,  8.4162e-04,\n",
       "             1.6209e-04,  3.8047e-04,  2.7524e-04,  7.4033e-04, -6.0466e-04,\n",
       "            -4.3832e-04, -8.5695e-04, -8.1707e-04, -7.2258e-04, -1.7293e-03,\n",
       "            -7.1212e-04,  1.3704e-05,  1.9121e-04, -1.0064e-03, -7.3157e-04,\n",
       "             9.5723e-04, -6.2955e-04, -6.2150e-05, -3.1101e-04, -3.4210e-04,\n",
       "             3.9645e-05, -1.5228e-03, -4.6556e-04, -4.7185e-04, -6.1462e-04,\n",
       "            -8.7204e-05,  5.5928e-04, -6.6431e-04, -2.0683e-04,  2.8746e-04,\n",
       "             6.0797e-05,  2.8250e-03, -3.3328e-04, -8.2255e-04, -3.1460e-03,\n",
       "            -4.8637e-05,  8.7942e-05, -9.2671e-04, -7.1534e-04, -7.3279e-05,\n",
       "             4.5798e-04,  4.0555e-04,  3.9506e-04, -1.5828e-04,  4.1465e-04,\n",
       "             6.4618e-04, -5.6716e-04, -8.3702e-04, -1.2147e-04, -3.8993e-04,\n",
       "             1.0452e-05, -5.0142e-04,  2.6454e-05,  4.4131e-04, -1.1643e-03,\n",
       "             3.7592e-04,  5.9286e-04, -9.7917e-04,  1.2024e-03, -2.5461e-04,\n",
       "            -1.1954e-03, -2.4317e-04, -6.1052e-04,  5.7978e-04, -1.0438e-04,\n",
       "            -1.5972e-04, -1.5144e-04, -5.6367e-04, -1.5172e-04, -5.6891e-04,\n",
       "            -3.0393e-04, -2.2803e-03,  8.5342e-04,  7.7246e-04,  2.5220e-04,\n",
       "             7.3965e-04, -3.5668e-04,  2.2446e-04,  7.4255e-05,  2.0290e-04,\n",
       "             8.3032e-04,  9.2717e-04,  5.8874e-04,  5.2371e-04, -1.0397e-03,\n",
       "            -3.2920e-04, -8.5509e-04, -5.2612e-04,  6.3686e-04, -9.1533e-04,\n",
       "            -6.6296e-04, -2.2519e-04, -6.2354e-04,  2.2553e-04,  9.5744e-04,\n",
       "            -1.2305e-03, -4.1620e-04,  7.2243e-04,  1.1911e-03, -5.5040e-04,\n",
       "             6.8528e-05,  4.8604e-04, -9.5195e-04, -1.3694e-04,  9.5810e-04,\n",
       "             1.2647e-03, -1.5240e-04,  1.4580e-04, -6.0454e-04, -4.8719e-05,\n",
       "             1.1990e-04, -4.3022e-04, -1.2752e-03, -3.1317e-04,  5.8400e-04,\n",
       "             4.1360e-04, -2.3559e-04,  2.4664e-04, -1.1712e-04,  9.1176e-05,\n",
       "            -1.6984e-05,  5.4251e-04, -6.8761e-04, -1.0298e-03,  8.2506e-04,\n",
       "            -7.4594e-04,  2.3807e-04,  1.3180e-03,  5.1516e-04, -3.2965e-03,\n",
       "             5.4144e-04,  1.6944e-03, -1.4481e-04, -2.3404e-04, -5.8463e-05,\n",
       "             7.9236e-04, -1.2330e-04, -5.4250e-04, -6.2165e-04,  4.3061e-04,\n",
       "             7.8216e-04,  1.7460e-04,  1.0270e-04, -7.8246e-04,  1.2738e-03,\n",
       "            -2.2305e-03], device='cuda:0')},\n",
       "   12: {'momentum_buffer': tensor([[[[ 8.7192e-04]],\n",
       "    \n",
       "             [[ 8.5058e-04]],\n",
       "    \n",
       "             [[-1.8488e-03]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-9.8332e-06]],\n",
       "    \n",
       "             [[ 1.4203e-04]],\n",
       "    \n",
       "             [[ 1.6848e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-4.3706e-04]],\n",
       "    \n",
       "             [[-1.6710e-04]],\n",
       "    \n",
       "             [[ 2.7084e-07]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.4564e-04]],\n",
       "    \n",
       "             [[-1.1634e-04]],\n",
       "    \n",
       "             [[ 9.4101e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.8636e-04]],\n",
       "    \n",
       "             [[-2.9727e-05]],\n",
       "    \n",
       "             [[ 7.4330e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.1740e-05]],\n",
       "    \n",
       "             [[ 8.6997e-05]],\n",
       "    \n",
       "             [[ 2.4225e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-3.8987e-04]],\n",
       "    \n",
       "             [[-8.0468e-04]],\n",
       "    \n",
       "             [[-1.2392e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.2627e-03]],\n",
       "    \n",
       "             [[-1.9777e-04]],\n",
       "    \n",
       "             [[-9.4475e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.0249e-05]],\n",
       "    \n",
       "             [[-7.0449e-04]],\n",
       "    \n",
       "             [[-1.0388e-03]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.1639e-03]],\n",
       "    \n",
       "             [[-3.8701e-04]],\n",
       "    \n",
       "             [[-7.3581e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.5556e-04]],\n",
       "    \n",
       "             [[ 1.8344e-05]],\n",
       "    \n",
       "             [[-1.4136e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.8446e-05]],\n",
       "    \n",
       "             [[ 9.2713e-05]],\n",
       "    \n",
       "             [[-5.2024e-05]]]], device='cuda:0')},\n",
       "   13: {'momentum_buffer': tensor([ 6.5312e-03,  3.7428e-03,  1.2899e-03,  2.2870e-03,  2.5300e-03,\n",
       "             5.4066e-03,  3.9124e-03,  5.6416e-03,  3.2198e-03,  2.9749e-03,\n",
       "             2.6505e-03,  4.2879e-03,  3.5061e-03,  3.4500e-03,  4.9618e-03,\n",
       "             2.7069e-03,  2.3754e-03,  4.3124e-03,  2.3549e-03,  2.1854e-03,\n",
       "             3.0702e-03,  5.1149e-03,  2.9535e-03,  5.1247e-03,  4.8686e-03,\n",
       "             3.4730e-03,  2.2758e-03,  1.3763e-03,  3.3046e-03,  4.7124e-03,\n",
       "             3.1082e-03,  2.8248e-03,  2.6393e-03,  4.1548e-03,  1.7348e-03,\n",
       "             2.9272e-03,  2.9586e-03,  1.9681e-03,  2.0974e-03,  3.2810e-03,\n",
       "             5.3090e-03,  2.3811e-03,  1.4424e-03,  5.3935e-03,  1.4074e-03,\n",
       "             2.2191e-03,  2.5685e-03,  2.0754e-03,  4.0597e-03,  6.8452e-04,\n",
       "             3.4729e-03,  2.0862e-03,  4.4965e-03,  4.3308e-03,  5.9661e-03,\n",
       "             1.2887e-03,  3.3530e-03,  1.3749e-03,  8.3896e-04,  5.4154e-03,\n",
       "             1.0553e-03,  4.7182e-03,  7.5400e-03,  3.4474e-03,  4.1551e-03,\n",
       "             5.9981e-03,  3.9893e-03,  2.7326e-03,  2.8703e-03,  6.0939e-03,\n",
       "             2.1450e-03,  3.1232e-03,  2.2740e-03,  2.1520e-03,  3.6244e-03,\n",
       "             4.3884e-03,  9.8815e-04,  6.1129e-03,  6.5573e-04,  4.5604e-03,\n",
       "             5.6020e-03,  4.7756e-04,  2.6362e-03,  3.2889e-03,  1.7705e-03,\n",
       "             6.0049e-03,  2.8037e-03,  3.6256e-03,  2.3585e-03,  5.1164e-03,\n",
       "             1.1020e-03,  3.5538e-03,  1.1997e-03,  1.6836e-03,  2.3442e-03,\n",
       "             2.6455e-03,  2.5772e-03,  1.0084e-03,  2.5299e-03,  3.0570e-03,\n",
       "             2.2656e-03,  2.1770e-03,  2.9648e-03,  3.6094e-03,  2.4920e-03,\n",
       "             5.9978e-03,  3.3324e-03,  2.5448e-03,  2.4134e-03,  1.0258e-03,\n",
       "             5.5819e-03,  4.2258e-03,  1.3702e-03,  6.6553e-03,  3.5013e-03,\n",
       "             2.5798e-03,  6.9924e-03,  5.0882e-03,  3.0676e-03,  1.5898e-03,\n",
       "             3.9511e-03,  2.6270e-03,  3.7060e-03,  1.6018e-03,  6.6129e-03,\n",
       "             3.7498e-03,  5.5511e-03,  5.9226e-05,  2.7440e-03,  3.6961e-03,\n",
       "             5.1933e-03,  4.7472e-03,  5.4309e-03,  2.7389e-03,  6.0810e-03,\n",
       "             1.8669e-03,  3.0942e-03,  5.2275e-03,  7.5824e-03,  3.1653e-03,\n",
       "             1.7033e-03,  4.6943e-03,  2.8077e-03,  4.0855e-03,  4.4793e-03,\n",
       "             2.4966e-03,  6.0796e-03,  6.1846e-03,  4.0469e-03,  2.6722e-03,\n",
       "             4.3833e-03,  3.5862e-03,  1.9715e-03,  4.2157e-03,  6.2599e-03,\n",
       "             3.3748e-03,  1.0361e-03,  2.9956e-04,  2.6364e-03,  2.8148e-03,\n",
       "             2.8327e-03,  7.3951e-03,  4.2048e-03,  5.2806e-03,  1.1884e-03,\n",
       "             7.8317e-04,  6.9563e-03, -3.6965e-04,  2.9720e-03,  7.2635e-03,\n",
       "             5.9636e-04,  4.9821e-03,  3.7746e-03,  3.5639e-04,  2.9861e-03,\n",
       "             3.2377e-03,  2.4739e-03,  2.6800e-04,  1.8217e-03,  2.3915e-04,\n",
       "             6.1925e-03,  6.4554e-04,  3.1688e-03,  2.8185e-03,  2.4708e-04,\n",
       "             3.5491e-03,  4.4297e-03,  2.1239e-03,  6.1193e-03,  3.7218e-03,\n",
       "             3.3171e-03,  4.7712e-03,  2.3256e-03,  4.5390e-03,  5.4711e-04,\n",
       "             2.1291e-03,  8.9308e-04,  7.0278e-03,  5.0020e-03,  6.0748e-03,\n",
       "             3.2689e-03,  2.4825e-03,  7.9839e-03,  2.2780e-03,  3.7830e-03,\n",
       "             5.6250e-03,  3.1316e-04,  4.3848e-03,  4.2392e-03,  5.0411e-03,\n",
       "             3.2232e-03,  3.0217e-03,  5.0393e-03,  4.8524e-03,  3.6167e-03,\n",
       "             2.2014e-03,  2.8235e-03,  6.0257e-03,  1.0881e-03,  3.4495e-03,\n",
       "             3.3637e-03,  4.6769e-03,  6.5994e-04,  3.6449e-03,  2.1073e-03,\n",
       "             1.7415e-03,  7.0094e-03,  6.4805e-03,  3.0446e-03,  3.4729e-03,\n",
       "             5.8613e-03,  3.3066e-03,  4.1243e-04,  4.5855e-03,  7.7551e-03,\n",
       "             2.9416e-03,  1.5687e-03,  2.3624e-03,  7.2454e-03,  2.7902e-03,\n",
       "             3.7689e-03,  6.5353e-04,  1.9621e-03,  5.1241e-03,  2.6735e-03,\n",
       "             2.3678e-03,  3.4737e-03,  2.6337e-03,  5.4641e-03,  6.9179e-03,\n",
       "             1.2197e-04,  2.6660e-03,  3.9200e-03,  5.3722e-03,  5.2173e-03,\n",
       "             1.9716e-03], device='cuda:0')},\n",
       "   14: {'momentum_buffer': tensor([-2.2167e-04, -6.0863e-04,  2.8204e-04, -3.2920e-05, -2.8799e-04,\n",
       "             3.4548e-04, -8.3701e-04,  9.7839e-04,  4.1856e-04, -6.3200e-04,\n",
       "            -3.4029e-04,  5.2203e-04,  5.7248e-04, -1.4196e-03,  6.1664e-04,\n",
       "            -2.6752e-05,  1.9658e-04,  4.5992e-04,  1.0582e-04, -9.7486e-04,\n",
       "            -1.0031e-04, -8.2894e-04, -1.7148e-04,  5.9712e-04,  8.6411e-06,\n",
       "             5.8925e-05,  7.0672e-06,  1.2620e-04,  2.7848e-04,  1.0744e-03,\n",
       "            -5.9237e-04,  3.7872e-04, -3.9214e-04,  1.2383e-03,  2.8899e-04,\n",
       "             9.8120e-04,  8.6391e-04,  1.4037e-04,  3.1487e-05, -4.0812e-06,\n",
       "             5.8413e-04, -2.3178e-04, -3.2555e-04, -8.5811e-04,  1.1981e-03,\n",
       "            -1.8844e-03, -1.4590e-03, -2.5505e-04, -1.4190e-04, -3.1018e-04,\n",
       "             4.3535e-05, -3.9045e-04, -7.5085e-04, -6.8047e-05, -3.3008e-04,\n",
       "             1.7770e-04,  1.7419e-05,  6.1888e-04,  4.8540e-04, -4.2982e-04,\n",
       "            -9.1500e-04,  2.8741e-03, -2.7549e-04, -2.6192e-04,  4.2963e-04,\n",
       "            -4.7922e-05, -6.1439e-04,  1.9015e-04, -3.7842e-05,  4.0015e-04,\n",
       "            -1.3141e-03,  1.4775e-04, -2.8373e-04,  2.9203e-05, -2.9321e-04,\n",
       "             3.9513e-04, -1.5012e-04,  1.8522e-04, -2.4517e-03,  1.5913e-03,\n",
       "            -8.0616e-05, -1.3850e-04,  1.2615e-03,  2.6302e-04,  6.8090e-05,\n",
       "            -2.7625e-04,  1.8195e-04,  2.0063e-04, -1.8917e-04,  7.5925e-04,\n",
       "            -7.3137e-05,  5.5781e-04, -5.6802e-04, -4.5582e-04,  7.7132e-05,\n",
       "            -4.9559e-04, -5.6475e-04, -1.4079e-03,  5.2267e-06, -4.6492e-04,\n",
       "             1.9810e-04,  1.6915e-04, -3.1778e-04,  1.7523e-04, -2.4292e-04,\n",
       "             6.8303e-04,  3.1465e-04,  6.3889e-04,  2.0588e-04,  8.4162e-04,\n",
       "             1.6209e-04,  3.8047e-04,  2.7524e-04,  7.4033e-04, -6.0466e-04,\n",
       "            -4.3832e-04, -8.5695e-04, -8.1707e-04, -7.2258e-04, -1.7293e-03,\n",
       "            -7.1212e-04,  1.3704e-05,  1.9121e-04, -1.0064e-03, -7.3157e-04,\n",
       "             9.5723e-04, -6.2955e-04, -6.2150e-05, -3.1101e-04, -3.4210e-04,\n",
       "             3.9645e-05, -1.5228e-03, -4.6556e-04, -4.7185e-04, -6.1462e-04,\n",
       "            -8.7204e-05,  5.5928e-04, -6.6431e-04, -2.0683e-04,  2.8746e-04,\n",
       "             6.0797e-05,  2.8250e-03, -3.3328e-04, -8.2255e-04, -3.1460e-03,\n",
       "            -4.8637e-05,  8.7942e-05, -9.2671e-04, -7.1534e-04, -7.3279e-05,\n",
       "             4.5798e-04,  4.0555e-04,  3.9506e-04, -1.5828e-04,  4.1465e-04,\n",
       "             6.4618e-04, -5.6716e-04, -8.3702e-04, -1.2147e-04, -3.8993e-04,\n",
       "             1.0452e-05, -5.0142e-04,  2.6454e-05,  4.4131e-04, -1.1643e-03,\n",
       "             3.7592e-04,  5.9286e-04, -9.7917e-04,  1.2024e-03, -2.5461e-04,\n",
       "            -1.1954e-03, -2.4317e-04, -6.1052e-04,  5.7978e-04, -1.0438e-04,\n",
       "            -1.5972e-04, -1.5144e-04, -5.6367e-04, -1.5172e-04, -5.6891e-04,\n",
       "            -3.0393e-04, -2.2803e-03,  8.5342e-04,  7.7246e-04,  2.5220e-04,\n",
       "             7.3965e-04, -3.5668e-04,  2.2446e-04,  7.4255e-05,  2.0290e-04,\n",
       "             8.3032e-04,  9.2717e-04,  5.8874e-04,  5.2371e-04, -1.0397e-03,\n",
       "            -3.2920e-04, -8.5509e-04, -5.2612e-04,  6.3686e-04, -9.1533e-04,\n",
       "            -6.6296e-04, -2.2519e-04, -6.2354e-04,  2.2553e-04,  9.5744e-04,\n",
       "            -1.2305e-03, -4.1620e-04,  7.2243e-04,  1.1911e-03, -5.5040e-04,\n",
       "             6.8528e-05,  4.8604e-04, -9.5195e-04, -1.3694e-04,  9.5810e-04,\n",
       "             1.2647e-03, -1.5240e-04,  1.4580e-04, -6.0454e-04, -4.8719e-05,\n",
       "             1.1990e-04, -4.3022e-04, -1.2752e-03, -3.1317e-04,  5.8400e-04,\n",
       "             4.1360e-04, -2.3559e-04,  2.4664e-04, -1.1712e-04,  9.1176e-05,\n",
       "            -1.6984e-05,  5.4251e-04, -6.8761e-04, -1.0298e-03,  8.2506e-04,\n",
       "            -7.4594e-04,  2.3807e-04,  1.3180e-03,  5.1516e-04, -3.2965e-03,\n",
       "             5.4144e-04,  1.6944e-03, -1.4481e-04, -2.3404e-04, -5.8463e-05,\n",
       "             7.9236e-04, -1.2330e-04, -5.4250e-04, -6.2165e-04,  4.3061e-04,\n",
       "             7.8216e-04,  1.7460e-04,  1.0270e-04, -7.8246e-04,  1.2738e-03,\n",
       "            -2.2305e-03], device='cuda:0')},\n",
       "   15: {'momentum_buffer': tensor([[[[-2.3859e-04]],\n",
       "    \n",
       "             [[ 2.9882e-04]],\n",
       "    \n",
       "             [[ 7.0138e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.0173e-04]],\n",
       "    \n",
       "             [[ 5.6457e-05]],\n",
       "    \n",
       "             [[ 4.8378e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.7761e-04]],\n",
       "    \n",
       "             [[-1.7970e-05]],\n",
       "    \n",
       "             [[-5.8115e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.8206e-04]],\n",
       "    \n",
       "             [[ 2.3989e-04]],\n",
       "    \n",
       "             [[ 4.0903e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.3888e-14]],\n",
       "    \n",
       "             [[-1.2669e-14]],\n",
       "    \n",
       "             [[-2.8827e-14]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.3380e-14]],\n",
       "    \n",
       "             [[ 6.8638e-15]],\n",
       "    \n",
       "             [[ 6.0158e-15]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 8.9671e-04]],\n",
       "    \n",
       "             [[-3.0816e-05]],\n",
       "    \n",
       "             [[-3.6656e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.2676e-04]],\n",
       "    \n",
       "             [[ 5.1470e-04]],\n",
       "    \n",
       "             [[ 1.1530e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.2075e-03]],\n",
       "    \n",
       "             [[ 6.9895e-05]],\n",
       "    \n",
       "             [[-6.8213e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.7740e-04]],\n",
       "    \n",
       "             [[-1.4411e-04]],\n",
       "    \n",
       "             [[-9.1189e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.5584e-04]],\n",
       "    \n",
       "             [[-1.8074e-04]],\n",
       "    \n",
       "             [[ 6.6362e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.3672e-05]],\n",
       "    \n",
       "             [[ 2.3697e-04]],\n",
       "    \n",
       "             [[-8.8085e-05]]]], device='cuda:0')},\n",
       "   16: {'momentum_buffer': tensor([0.0025, 0.0012, 0.0019, 0.0024, 0.0020, 0.0020, 0.0038, 0.0008, 0.0018,\n",
       "            0.0010, 0.0027, 0.0011, 0.0015, 0.0014, 0.0021, 0.0024, 0.0010, 0.0032,\n",
       "            0.0011, 0.0029, 0.0017, 0.0040, 0.0022, 0.0023, 0.0024, 0.0022, 0.0022,\n",
       "            0.0021, 0.0020, 0.0021, 0.0019, 0.0028, 0.0023, 0.0016, 0.0025, 0.0017,\n",
       "            0.0017, 0.0069, 0.0012, 0.0009, 0.0016, 0.0009, 0.0022, 0.0026, 0.0022,\n",
       "            0.0014, 0.0017, 0.0028, 0.0014, 0.0011, 0.0023, 0.0014, 0.0023, 0.0025,\n",
       "            0.0033, 0.0028, 0.0035, 0.0010, 0.0027, 0.0024, 0.0020, 0.0005, 0.0012,\n",
       "            0.0024], device='cuda:0')},\n",
       "   17: {'momentum_buffer': tensor([-3.4413e-04,  9.8085e-04, -4.6143e-03, -4.5214e-04,  1.8443e-03,\n",
       "            -1.8235e-03, -5.9962e-03, -8.9257e-06, -1.6202e-04,  3.5276e-04,\n",
       "             2.6429e-03,  1.5334e-03,  1.8861e-03,  1.9191e-03, -8.3910e-05,\n",
       "            -2.0561e-03,  8.7751e-04, -1.1206e-03,  3.7159e-04, -1.9238e-03,\n",
       "            -1.1080e-03, -2.9113e-03, -2.0697e-03,  3.6373e-04, -1.9440e-03,\n",
       "            -3.1052e-04,  6.4775e-04, -1.0630e-03,  4.8591e-04, -2.6837e-04,\n",
       "            -1.0582e-03, -1.8762e-05,  2.8369e-04, -9.6749e-04,  2.5349e-03,\n",
       "            -1.2794e-03, -4.2822e-04, -9.6719e-03,  1.5333e-03, -2.0837e-04,\n",
       "             6.6004e-04,  1.4130e-03,  2.5849e-04,  1.8499e-04,  9.7668e-04,\n",
       "            -1.1732e-03, -8.0538e-04, -2.7144e-03,  1.6570e-03,  7.4549e-04,\n",
       "            -3.8597e-05,  7.6391e-05,  3.0540e-04, -6.4739e-04,  2.7619e-03,\n",
       "            -1.6316e-03, -1.7106e-03,  5.4433e-04,  1.5453e-03, -1.3996e-03,\n",
       "            -4.2886e-05,  3.1872e-03,  9.0146e-04, -3.1191e-03], device='cuda:0')},\n",
       "   18: {'momentum_buffer': tensor([[[[ 2.2198e-05, -1.1902e-04, -1.2132e-04],\n",
       "              [ 1.4581e-04,  7.6594e-05, -2.2885e-04],\n",
       "              [-1.4282e-04,  2.4524e-05,  1.8372e-04]],\n",
       "    \n",
       "             [[ 5.1316e-04, -2.4685e-05, -5.0490e-06],\n",
       "              [ 6.6753e-04,  2.7897e-04,  1.1762e-04],\n",
       "              [ 5.1858e-04,  3.4057e-04, -7.1889e-05]],\n",
       "    \n",
       "             [[ 1.6096e-16,  5.6165e-15,  2.2871e-15],\n",
       "              [-6.6580e-15, -2.4524e-15, -2.7622e-15],\n",
       "              [-7.5980e-15, -8.7581e-15, -5.8375e-15]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.6740e-04, -2.9261e-04, -3.8913e-04],\n",
       "              [ 1.4757e-04, -3.8540e-04, -4.0744e-04],\n",
       "              [ 2.4813e-04, -3.4643e-05, -1.4708e-04]],\n",
       "    \n",
       "             [[-6.7758e-05, -1.7130e-04,  1.2572e-04],\n",
       "              [-2.3358e-05, -3.3098e-04, -2.4458e-04],\n",
       "              [-1.8827e-04, -2.6735e-05, -2.7956e-04]],\n",
       "    \n",
       "             [[ 1.5626e-04,  1.0156e-04,  6.0615e-05],\n",
       "              [ 7.6173e-06,  4.6353e-05, -1.9238e-05],\n",
       "              [ 1.0052e-05,  1.5326e-05,  2.5081e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.5289e-04,  6.3597e-04,  5.5965e-04],\n",
       "              [-3.8292e-04, -9.7402e-05,  2.9291e-04],\n",
       "              [ 4.9671e-04,  2.1119e-04,  3.8891e-04]],\n",
       "    \n",
       "             [[-1.1027e-04, -2.7744e-04, -2.1122e-04],\n",
       "              [-4.2454e-04, -2.6741e-04, -1.9508e-04],\n",
       "              [-9.8625e-04, -6.7317e-04, -7.1131e-04]],\n",
       "    \n",
       "             [[-5.8641e-15, -2.3936e-15,  1.0719e-14],\n",
       "              [-2.6478e-15,  6.7506e-17,  6.9574e-15],\n",
       "              [ 7.2031e-16, -1.4645e-15, -5.7006e-15]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.5590e-04,  6.0549e-04, -2.0522e-04],\n",
       "              [ 8.7073e-04,  5.7271e-04, -1.0607e-04],\n",
       "              [ 1.0386e-03,  5.8528e-04, -1.0731e-04]],\n",
       "    \n",
       "             [[ 7.7617e-05,  8.7303e-06, -1.7722e-04],\n",
       "              [ 3.4013e-04,  5.0274e-04,  1.0364e-04],\n",
       "              [ 1.3806e-04,  1.7703e-04, -9.7720e-05]],\n",
       "    \n",
       "             [[-9.2537e-05, -2.0273e-04, -1.5247e-04],\n",
       "              [-9.7800e-05, -2.5800e-04,  7.7484e-06],\n",
       "              [-3.5863e-05, -3.7062e-04, -1.4631e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.7371e-04, -3.2894e-04,  1.6912e-04],\n",
       "              [-4.2693e-05, -1.5359e-06, -3.0648e-05],\n",
       "              [ 5.7383e-05,  1.6705e-05, -4.6021e-05]],\n",
       "    \n",
       "             [[-6.8284e-04, -6.3275e-04, -7.1459e-04],\n",
       "              [-6.6045e-04, -5.9899e-04, -6.4772e-04],\n",
       "              [-6.8598e-04, -5.9367e-04, -6.6934e-04]],\n",
       "    \n",
       "             [[ 6.4232e-14,  7.0469e-14,  6.5508e-14],\n",
       "              [ 7.6424e-14,  8.8349e-14,  7.2634e-14],\n",
       "              [ 7.1705e-14,  7.6879e-14,  7.5939e-14]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.4259e-04,  2.7465e-04,  1.2588e-04],\n",
       "              [ 3.0935e-04, -1.6406e-04,  1.7909e-04],\n",
       "              [ 2.5647e-04,  2.8498e-05, -1.5148e-04]],\n",
       "    \n",
       "             [[ 5.5507e-04,  3.7490e-04,  1.6755e-04],\n",
       "              [ 4.2294e-04,  4.0900e-04,  1.7160e-04],\n",
       "              [ 7.0756e-04,  3.4246e-04,  1.4290e-04]],\n",
       "    \n",
       "             [[ 5.4793e-05, -2.9344e-04, -3.0803e-04],\n",
       "              [-9.9276e-05, -2.3315e-04, -6.7995e-05],\n",
       "              [-9.8314e-05, -2.4325e-04, -1.0787e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.5558e-04,  3.6064e-04,  4.8161e-04],\n",
       "              [-3.4553e-04, -2.1966e-04, -3.8414e-04],\n",
       "              [-1.1619e-05, -3.5352e-05,  2.7766e-04]],\n",
       "    \n",
       "             [[-3.1679e-04, -6.6096e-04, -9.5950e-04],\n",
       "              [-2.3917e-05, -1.1133e-03, -9.5886e-04],\n",
       "              [-4.4007e-05, -1.0253e-03, -1.1512e-03]],\n",
       "    \n",
       "             [[ 1.0122e-14,  1.6450e-15,  5.9217e-15],\n",
       "              [ 7.2775e-15,  6.9515e-15,  5.5724e-15],\n",
       "              [ 6.2719e-15,  1.0720e-14,  6.3198e-15]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-7.0856e-05,  1.3811e-04, -3.5283e-05],\n",
       "              [-1.2180e-05, -2.9842e-04, -2.4814e-04],\n",
       "              [ 3.5165e-04,  1.8718e-05, -1.1912e-04]],\n",
       "    \n",
       "             [[ 2.1125e-04,  1.4828e-04,  1.1683e-04],\n",
       "              [ 4.1786e-04,  4.2807e-04,  5.1073e-04],\n",
       "              [ 4.3641e-04,  7.2687e-04,  4.2139e-04]],\n",
       "    \n",
       "             [[-1.0949e-04, -1.5054e-04, -1.9966e-04],\n",
       "              [-2.6043e-04, -1.1806e-04, -3.2161e-04],\n",
       "              [-3.3096e-04, -3.1544e-04, -4.2644e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.9901e-05, -6.5196e-04, -7.5078e-05],\n",
       "              [ 3.9004e-05, -8.3081e-05, -9.8074e-05],\n",
       "              [-5.6964e-05, -1.9436e-04, -1.7544e-04]],\n",
       "    \n",
       "             [[-2.7726e-04,  5.8685e-04,  1.1565e-04],\n",
       "              [-1.3725e-04,  4.3643e-04,  1.3523e-04],\n",
       "              [ 1.2227e-05,  6.4925e-05,  1.0501e-04]],\n",
       "    \n",
       "             [[ 2.2144e-15, -4.1810e-15,  4.4565e-15],\n",
       "              [-1.5657e-15, -1.0188e-15, -3.0319e-15],\n",
       "              [ 2.0780e-15, -2.6121e-16,  1.1438e-15]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.5458e-04,  2.8600e-04, -3.9088e-04],\n",
       "              [ 6.8693e-04,  4.3948e-04, -2.9675e-04],\n",
       "              [ 8.3816e-04,  2.4033e-04, -6.7217e-04]],\n",
       "    \n",
       "             [[ 5.5635e-04,  3.0865e-04, -1.0150e-04],\n",
       "              [ 4.7893e-04,  2.9277e-04, -1.8842e-04],\n",
       "              [ 6.9528e-04,  3.1025e-04, -2.1625e-04]],\n",
       "    \n",
       "             [[ 5.3678e-05, -6.0808e-04, -4.5195e-04],\n",
       "              [ 5.3838e-05, -9.5806e-05, -1.3345e-05],\n",
       "              [ 2.4236e-05, -1.7925e-04, -9.1228e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.9366e-05,  7.6238e-04,  2.3168e-04],\n",
       "              [ 2.0586e-04,  5.2715e-05, -5.9448e-04],\n",
       "              [-1.0820e-04, -7.1449e-06, -2.0249e-04]],\n",
       "    \n",
       "             [[ 1.4790e-04, -2.2763e-04, -3.7259e-04],\n",
       "              [-1.7808e-05, -6.1384e-04, -2.4221e-04],\n",
       "              [-2.5270e-04, -7.7026e-04, -5.4090e-04]],\n",
       "    \n",
       "             [[-3.7889e-15, -7.0997e-15, -3.0787e-15],\n",
       "              [-7.1683e-15, -6.2458e-15, -8.7570e-15],\n",
       "              [-1.2208e-14, -1.4818e-14, -1.0655e-14]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.7403e-04, -3.2660e-04, -2.8251e-04],\n",
       "              [-7.4295e-05,  9.1571e-05, -7.8444e-05],\n",
       "              [-3.8040e-04, -7.8250e-04, -6.3063e-04]],\n",
       "    \n",
       "             [[-2.1829e-05,  1.5802e-04,  5.7652e-05],\n",
       "              [-2.8952e-05, -2.2347e-04,  7.0928e-05],\n",
       "              [-2.1811e-04, -1.8273e-04, -4.6378e-05]],\n",
       "    \n",
       "             [[-7.6927e-05, -1.0532e-04, -9.1818e-06],\n",
       "              [ 5.1481e-05, -1.1507e-05,  9.2404e-06],\n",
       "              [ 3.5622e-05, -8.1992e-06,  6.0278e-05]]]], device='cuda:0')},\n",
       "   19: {'momentum_buffer': tensor([ 2.0169e-03,  1.1075e-03,  2.3183e-03,  9.2180e-04,  2.4355e-03,\n",
       "             1.0528e-03,  3.0557e-03,  1.1580e-03,  2.2353e-03,  1.9407e-03,\n",
       "             1.5966e-03,  1.2162e-03,  4.1179e-04,  1.2722e-03,  1.4903e-03,\n",
       "             1.4181e-03,  2.5019e-04,  2.1277e-03,  2.0343e-03,  1.6878e-03,\n",
       "             1.4316e-03,  2.1218e-03,  2.4698e-03,  2.2419e-03,  2.1060e-03,\n",
       "             2.5810e-03,  2.5903e-03,  2.0235e-03,  2.7495e-03,  2.1701e-03,\n",
       "            -5.9743e-04,  1.9234e-03,  1.9720e-03,  1.8616e-03,  1.5985e-05,\n",
       "             2.7233e-03,  2.4919e-03,  4.1667e-04,  1.9289e-03,  9.2059e-04,\n",
       "             2.0798e-03,  1.9496e-03,  1.4843e-03,  1.9749e-03,  2.0690e-03,\n",
       "             2.6269e-03,  1.7656e-03,  1.6652e-03,  1.6060e-03,  3.0563e-03,\n",
       "             1.3656e-03,  1.7932e-03,  1.9478e-03,  1.8765e-03,  2.2825e-03,\n",
       "             2.4566e-03,  2.2667e-03,  1.5771e-03,  3.2942e-03,  1.3577e-03,\n",
       "             1.2080e-03,  1.4092e-03,  3.9275e-03,  3.7008e-03], device='cuda:0')},\n",
       "   20: {'momentum_buffer': tensor([-7.7099e-04,  1.2641e-03, -1.2025e-03,  3.2039e-03,  3.6140e-03,\n",
       "             3.5450e-03, -3.8282e-03,  1.1231e-03, -5.2544e-04,  1.0432e-03,\n",
       "            -1.0174e-03,  7.5766e-04,  3.9529e-03,  1.8976e-04,  1.4617e-03,\n",
       "             2.2011e-03,  2.8706e-03,  3.7725e-04,  3.5721e-03, -1.2258e-04,\n",
       "             1.6686e-03, -3.4148e-04,  3.3905e-03, -6.5273e-04, -6.9527e-04,\n",
       "            -1.7503e-03,  3.4255e-04, -6.2515e-04, -2.0495e-03,  1.2610e-03,\n",
       "             3.3653e-03,  1.1020e-03, -4.9090e-04,  2.9685e-03,  4.6259e-03,\n",
       "            -6.8091e-04,  6.8128e-04,  3.3754e-03, -1.3916e-04,  3.3495e-03,\n",
       "            -2.2606e-04,  1.3523e-03,  1.1338e-03, -4.5096e-04,  2.6619e-03,\n",
       "            -2.8917e-03,  4.2362e-03,  3.3225e-04,  4.0509e-04,  3.6346e-03,\n",
       "             1.8956e-03,  7.2845e-04,  1.6445e-04,  9.4241e-04,  2.0983e-03,\n",
       "            -1.4592e-03, -9.1459e-04,  2.6418e-03, -4.3044e-03,  5.5151e-04,\n",
       "             2.0473e-06, -4.0968e-04, -4.4613e-03, -4.7513e-03], device='cuda:0')},\n",
       "   21: {'momentum_buffer': tensor([[[[-9.5825e-05]],\n",
       "    \n",
       "             [[-2.0140e-04]],\n",
       "    \n",
       "             [[-5.0808e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.8792e-04]],\n",
       "    \n",
       "             [[-6.1647e-04]],\n",
       "    \n",
       "             [[-7.1270e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.2921e-04]],\n",
       "    \n",
       "             [[ 5.2825e-06]],\n",
       "    \n",
       "             [[ 3.9835e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.0905e-04]],\n",
       "    \n",
       "             [[ 1.4454e-04]],\n",
       "    \n",
       "             [[ 2.7254e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.9880e-04]],\n",
       "    \n",
       "             [[ 5.8924e-04]],\n",
       "    \n",
       "             [[ 1.2548e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-7.6611e-05]],\n",
       "    \n",
       "             [[-7.8350e-04]],\n",
       "    \n",
       "             [[-2.8848e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-8.0520e-05]],\n",
       "    \n",
       "             [[ 4.3730e-04]],\n",
       "    \n",
       "             [[ 4.6569e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.3044e-04]],\n",
       "    \n",
       "             [[ 1.1865e-05]],\n",
       "    \n",
       "             [[-3.7998e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[-9.0413e-05]],\n",
       "    \n",
       "             [[-7.1734e-05]],\n",
       "    \n",
       "             [[ 9.9112e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.2681e-04]],\n",
       "    \n",
       "             [[ 2.5940e-04]],\n",
       "    \n",
       "             [[ 1.9178e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.7387e-04]],\n",
       "    \n",
       "             [[ 8.1182e-05]],\n",
       "    \n",
       "             [[-3.9671e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.1292e-04]],\n",
       "    \n",
       "             [[ 2.9644e-06]],\n",
       "    \n",
       "             [[-2.4153e-04]]]], device='cuda:0')},\n",
       "   22: {'momentum_buffer': tensor([ 1.6341e-03,  1.5791e-03,  1.3060e-03,  2.3955e-03, -4.2010e-04,\n",
       "             1.9433e-04, -1.4007e-04, -6.7422e-04,  2.4879e-05,  2.1665e-03,\n",
       "             2.0882e-03,  4.0976e-04,  8.6603e-04,  2.1635e-03,  5.2237e-04,\n",
       "             8.7332e-04,  1.0935e-03,  3.2717e-05,  1.2854e-03,  1.0152e-03,\n",
       "             6.7199e-04,  1.2338e-03,  2.0264e-04,  1.8699e-05,  1.0097e-03,\n",
       "             1.2443e-03,  1.2225e-03,  2.1064e-03,  1.3964e-03, -5.2249e-04,\n",
       "             1.8675e-03,  1.4591e-03,  1.9431e-03,  6.1726e-04,  2.3437e-03,\n",
       "             3.4296e-04,  1.8697e-03,  1.3676e-03,  2.4577e-03,  1.6655e-03,\n",
       "            -9.9865e-04,  1.2755e-03,  2.6408e-03,  6.7592e-04,  1.3274e-03,\n",
       "             5.0042e-04,  6.9890e-03,  1.1138e-03,  8.1009e-04,  2.1167e-03,\n",
       "             3.4151e-04,  2.5009e-03,  1.9907e-03, -1.9505e-04, -1.0211e-03,\n",
       "             2.0189e-03,  2.6508e-03,  2.6511e-03, -1.1974e-03,  3.7156e-04,\n",
       "             2.7139e-03,  4.5484e-04,  4.7437e-04,  2.1307e-03,  1.3449e-03,\n",
       "            -3.3763e-04,  1.6648e-03,  1.2242e-03,  9.6671e-04,  1.5505e-03,\n",
       "             2.8224e-03,  1.8522e-04,  1.2532e-03,  1.3953e-03,  1.4931e-03,\n",
       "            -6.1146e-05,  2.8292e-03,  6.0420e-04,  2.2492e-03,  3.5184e-04,\n",
       "             2.1770e-03,  1.6528e-03,  4.5081e-05,  1.0716e-03,  1.0434e-03,\n",
       "             1.3749e-03,  9.5240e-04,  1.3991e-03,  1.3652e-03,  1.2058e-03,\n",
       "             2.0763e-03,  1.0953e-03,  2.6854e-03,  2.7632e-03,  7.2799e-04,\n",
       "             7.8178e-04,  1.7439e-03,  2.8547e-03,  1.0052e-03,  5.1584e-04,\n",
       "             1.0549e-03, -4.9432e-04,  1.7296e-03,  1.8420e-03,  5.6144e-04,\n",
       "             6.9967e-04,  1.2262e-04,  3.2559e-04,  1.1045e-03,  1.9187e-03,\n",
       "             9.2611e-04,  1.4592e-03,  1.7164e-03,  4.9634e-05,  1.6127e-03,\n",
       "             1.6090e-03,  9.1508e-04,  1.7489e-03,  2.1950e-03,  1.4901e-03,\n",
       "             3.3324e-03,  1.9466e-03, -7.1029e-04,  1.2610e-03,  5.6834e-03,\n",
       "             7.3430e-05,  1.1115e-03,  1.1564e-03,  2.8916e-03,  9.8089e-04,\n",
       "             4.7775e-04,  2.1780e-03,  4.5814e-04,  1.6624e-03,  5.4565e-04,\n",
       "             7.4728e-04,  2.0605e-03,  2.4945e-03,  9.6690e-04,  2.4978e-04,\n",
       "            -2.5036e-05, -2.7599e-04, -4.2710e-04,  3.1137e-04,  1.9721e-03,\n",
       "             1.3860e-03,  2.7632e-04,  5.0975e-04,  1.3089e-03,  5.9911e-04,\n",
       "             8.8509e-04,  1.0365e-03,  2.2564e-03,  1.2168e-03,  4.2593e-04,\n",
       "             9.6730e-06,  1.2542e-03,  2.2021e-03,  1.2290e-03,  9.8475e-04,\n",
       "             1.4514e-03,  9.4287e-04,  7.0532e-04,  1.0298e-03,  1.1775e-03,\n",
       "             2.2097e-03, -2.5741e-06,  1.0633e-03,  9.3300e-04,  4.8643e-04,\n",
       "             1.3365e-03,  1.8868e-03,  2.2693e-03, -1.1772e-04,  3.6977e-04,\n",
       "             1.6875e-03,  1.3565e-03,  1.5047e-03,  8.6123e-04,  1.8817e-03,\n",
       "             9.4259e-04,  2.3450e-03,  3.9659e-04,  1.9336e-03,  2.2109e-03,\n",
       "             4.4265e-04,  1.4923e-03,  1.1336e-03,  5.1245e-04,  3.6866e-05,\n",
       "             2.3538e-04,  4.0951e-04,  9.8852e-04,  2.7115e-03,  1.7414e-03,\n",
       "             2.0555e-03,  2.0125e-03,  1.3158e-04,  1.7462e-03, -2.6750e-05,\n",
       "             1.8038e-03,  1.0570e-03,  1.2316e-03,  3.2088e-03,  1.6459e-03,\n",
       "             7.1342e-04,  2.3307e-03, -1.5569e-04,  1.2282e-03,  1.4025e-04,\n",
       "             4.1697e-04,  1.2055e-03,  7.6541e-04,  7.0706e-04,  7.2990e-04,\n",
       "             1.7077e-03,  1.4475e-03, -1.8654e-04,  9.4722e-04,  1.4466e-03,\n",
       "             1.4189e-03,  3.1274e-04,  1.2543e-03,  9.9137e-04,  1.5748e-03,\n",
       "             1.4388e-03,  8.9342e-04,  4.6633e-04,  1.7123e-03,  1.4112e-03,\n",
       "             7.5276e-04,  1.5024e-03,  1.5099e-03,  1.9475e-03,  4.4083e-05,\n",
       "             1.0521e-03,  1.5532e-03, -1.2614e-03, -8.6444e-05,  4.3867e-04,\n",
       "             1.1871e-03,  1.0636e-03,  3.2154e-03,  8.0706e-04,  3.2703e-04,\n",
       "             1.3509e-03,  9.1233e-04,  2.6192e-03,  6.6807e-04,  5.5012e-04,\n",
       "             3.0548e-03,  4.4815e-04,  9.3239e-04,  1.6695e-04,  1.7388e-03,\n",
       "             1.1250e-03], device='cuda:0')},\n",
       "   23: {'momentum_buffer': tensor([-7.0131e-04, -1.3443e-03,  2.0239e-04, -1.0086e-03,  3.0322e-04,\n",
       "            -1.3333e-04,  9.0701e-05, -6.6008e-04,  8.3942e-05, -3.3758e-04,\n",
       "            -6.6175e-04,  4.9830e-05, -1.1762e-03, -8.5782e-04, -1.1840e-04,\n",
       "            -1.1415e-03, -1.3553e-03, -1.6073e-03,  1.4916e-03, -8.3766e-04,\n",
       "            -7.3130e-06,  5.2231e-04,  9.4780e-04,  1.0087e-04,  6.8875e-04,\n",
       "            -2.5137e-04, -3.5910e-04, -7.0390e-04, -8.5724e-04, -3.5715e-05,\n",
       "            -9.0840e-04, -8.5439e-04, -1.3556e-03,  2.6520e-04, -1.2825e-03,\n",
       "             2.2051e-03, -1.1340e-03,  2.8150e-05, -6.3187e-04, -1.0017e-03,\n",
       "             1.3845e-04, -1.6045e-03, -1.6667e-04,  1.3918e-04, -1.2718e-03,\n",
       "             1.2617e-03, -5.2467e-03, -3.7876e-04, -1.5358e-03,  3.1755e-03,\n",
       "             6.7204e-05, -2.9173e-04, -2.0326e-03,  6.6273e-04,  3.9524e-04,\n",
       "            -1.8723e-04, -1.1965e-03, -1.1508e-04,  4.3703e-05, -6.2797e-05,\n",
       "            -9.4847e-04, -1.3668e-03, -2.3637e-04,  8.9903e-05, -7.5624e-04,\n",
       "            -1.9363e-04, -3.1001e-03,  2.3688e-03, -8.5722e-04, -3.3351e-04,\n",
       "            -1.2517e-03, -5.6914e-04, -7.6019e-04, -7.9636e-04,  4.3797e-04,\n",
       "             2.4620e-04, -8.8152e-04, -1.7713e-04, -7.6349e-04, -1.7747e-03,\n",
       "             8.1394e-04, -5.6184e-04,  4.3642e-05, -1.7317e-03, -4.6473e-04,\n",
       "            -1.1707e-04, -1.2574e-03, -9.2771e-04, -2.3518e-04,  3.1361e-04,\n",
       "            -1.3483e-03,  6.8168e-05, -8.8391e-04, -5.6686e-04,  1.3995e-04,\n",
       "             5.8350e-04, -1.2178e-04, -2.0963e-03,  1.2105e-05,  9.4070e-05,\n",
       "             7.6004e-05,  1.8235e-05, -5.6938e-04,  4.1907e-04, -1.1214e-03,\n",
       "             1.2735e-04,  1.4371e-05,  1.2616e-05, -7.6731e-04, -7.4762e-04,\n",
       "             5.2679e-04, -9.8310e-04, -1.9563e-04, -2.2979e-04, -1.1692e-03,\n",
       "            -6.1561e-04, -1.3492e-04, -1.2352e-05, -5.1027e-04, -5.1856e-04,\n",
       "            -3.2231e-03, -1.4673e-03, -3.6110e-07,  3.8431e-04, -4.8607e-03,\n",
       "             5.4000e-04, -1.1887e-03,  1.4329e-04, -2.2333e-03,  1.0694e-04,\n",
       "             1.2018e-03, -2.1917e-03,  9.7437e-04, -7.3660e-04,  4.4421e-04,\n",
       "            -9.5246e-04, -1.6898e-05, -9.7128e-04,  2.8911e-04,  2.1773e-04,\n",
       "            -5.4801e-05, -8.3674e-04, -1.1824e-03, -7.1799e-05, -9.8989e-04,\n",
       "            -9.4216e-04, -2.0560e-04,  2.0137e-04, -1.4958e-03,  9.4088e-05,\n",
       "             8.8753e-05,  2.6958e-05, -9.9866e-04, -1.3256e-03, -3.4056e-04,\n",
       "             8.7186e-04, -7.3590e-04, -9.8208e-04,  1.3425e-04, -1.1195e-03,\n",
       "            -1.4663e-04, -2.6917e-04, -8.0347e-04,  3.5967e-04,  2.5569e-03,\n",
       "            -6.3688e-04, -6.0613e-04,  1.4082e-04,  7.6035e-04, -1.1861e-04,\n",
       "            -1.6856e-03, -3.0922e-04,  1.9674e-06,  4.8559e-04, -1.0532e-03,\n",
       "            -1.4514e-03, -1.1450e-03,  9.0449e-05, -7.3209e-04, -5.9007e-04,\n",
       "             2.2220e-04, -3.9921e-03, -9.3204e-04, -1.2358e-03,  4.2959e-03,\n",
       "            -2.3487e-05,  2.7189e-04,  3.5649e-04, -1.0918e-03, -3.3718e-04,\n",
       "            -6.8416e-06,  7.0549e-04, -1.2132e-03,  7.2696e-04, -5.9974e-04,\n",
       "            -2.3082e-03, -1.7213e-03, -5.6108e-04, -5.1135e-05, -1.5376e-04,\n",
       "            -1.2350e-03, -1.1085e-03, -2.0098e-04, -7.7931e-04, -2.0467e-03,\n",
       "            -1.3885e-05,  3.5431e-04,  1.5784e-05,  3.3483e-04,  6.3236e-04,\n",
       "             5.2143e-06,  5.0432e-04, -3.3184e-04, -2.7601e-04, -3.2365e-04,\n",
       "            -7.3314e-05, -6.6018e-04, -1.9447e-04, -8.7862e-04,  2.8464e-05,\n",
       "             2.6843e-04, -7.4561e-04, -8.9981e-04, -6.4206e-04,  3.1283e-03,\n",
       "            -1.2960e-03, -7.9733e-05, -1.9536e-05, -4.3419e-04, -7.1601e-05,\n",
       "             4.7703e-04, -1.2743e-03, -1.4436e-03, -2.2321e-03,  2.0395e-04,\n",
       "             3.3983e-03, -1.2472e-03,  7.9350e-05,  3.1039e-04,  1.4289e-03,\n",
       "            -3.6927e-04,  1.4375e-05, -7.9767e-04,  3.3938e-04,  1.9276e-05,\n",
       "            -6.5512e-04, -5.1578e-05,  3.6490e-04,  1.6282e-04,  2.7211e-04,\n",
       "            -1.2710e-03, -6.7679e-04, -8.2892e-04, -5.4835e-04,  6.6059e-04,\n",
       "            -6.2919e-04], device='cuda:0')},\n",
       "   24: {'momentum_buffer': tensor([[[[-1.9331e-04]],\n",
       "    \n",
       "             [[-2.6836e-04]],\n",
       "    \n",
       "             [[ 4.3847e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.7507e-04]],\n",
       "    \n",
       "             [[-5.8828e-04]],\n",
       "    \n",
       "             [[-1.3117e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.5092e-04]],\n",
       "    \n",
       "             [[ 3.2943e-04]],\n",
       "    \n",
       "             [[ 5.2705e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.2739e-04]],\n",
       "    \n",
       "             [[-9.3567e-06]],\n",
       "    \n",
       "             [[ 1.5169e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.0153e-04]],\n",
       "    \n",
       "             [[ 4.4423e-04]],\n",
       "    \n",
       "             [[ 3.1516e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.2141e-05]],\n",
       "    \n",
       "             [[-5.4359e-04]],\n",
       "    \n",
       "             [[ 2.1009e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-2.6635e-05]],\n",
       "    \n",
       "             [[ 1.9286e-04]],\n",
       "    \n",
       "             [[-2.2315e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.1889e-05]],\n",
       "    \n",
       "             [[ 2.1772e-04]],\n",
       "    \n",
       "             [[ 4.1105e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-8.1556e-07]],\n",
       "    \n",
       "             [[ 7.4177e-04]],\n",
       "    \n",
       "             [[ 6.1925e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.1012e-04]],\n",
       "    \n",
       "             [[ 5.3629e-05]],\n",
       "    \n",
       "             [[ 2.8128e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.9838e-04]],\n",
       "    \n",
       "             [[ 2.1649e-04]],\n",
       "    \n",
       "             [[-7.6429e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.2721e-04]],\n",
       "    \n",
       "             [[-4.8821e-05]],\n",
       "    \n",
       "             [[-4.6396e-05]]]], device='cuda:0')},\n",
       "   25: {'momentum_buffer': tensor([0.0019, 0.0014, 0.0017, 0.0019, 0.0020, 0.0014, 0.0015, 0.0013, 0.0018,\n",
       "            0.0017, 0.0015, 0.0016, 0.0004, 0.0017, 0.0029, 0.0017, 0.0019, 0.0020,\n",
       "            0.0028, 0.0012, 0.0010, 0.0024, 0.0022, 0.0022, 0.0028, 0.0012, 0.0032,\n",
       "            0.0010, 0.0019, 0.0019, 0.0019, 0.0035, 0.0007, 0.0011, 0.0014, 0.0014,\n",
       "            0.0015, 0.0017, 0.0020, 0.0022, 0.0020, 0.0021, 0.0010, 0.0020, 0.0016,\n",
       "            0.0021, 0.0008, 0.0018, 0.0019, 0.0018, 0.0014, 0.0012, 0.0015, 0.0022,\n",
       "            0.0044, 0.0026, 0.0019, 0.0016, 0.0019, 0.0026, 0.0023, 0.0016, 0.0018,\n",
       "            0.0016], device='cuda:0')},\n",
       "   26: {'momentum_buffer': tensor([ 7.0809e-04, -9.1505e-04,  3.1877e-04,  5.7094e-04,  9.9105e-04,\n",
       "             1.0969e-03, -1.6810e-04, -8.3934e-04,  1.1623e-03,  8.4664e-04,\n",
       "             1.5682e-04,  1.2018e-03,  1.8570e-03,  4.1332e-04, -3.2622e-03,\n",
       "             3.9565e-04, -9.1426e-05,  3.4797e-04, -2.8997e-03,  1.2731e-03,\n",
       "             1.6668e-03, -1.1647e-03,  3.2030e-04,  5.7425e-04, -1.5942e-03,\n",
       "             7.7780e-04, -1.8908e-03, -3.6222e-04,  5.0345e-04, -3.9709e-04,\n",
       "             1.0211e-03, -7.7121e-03,  1.5424e-03,  1.1806e-03,  3.7457e-03,\n",
       "             9.3017e-04,  4.2044e-04, -1.6093e-03,  1.1806e-03,  1.1543e-03,\n",
       "            -2.3368e-04, -3.6944e-04, -7.0076e-04, -1.1040e-03,  2.4092e-03,\n",
       "             5.6796e-04,  2.0169e-04, -1.6420e-05, -8.5544e-04, -6.7148e-04,\n",
       "             5.8111e-04, -3.1192e-05,  9.7181e-04, -1.4742e-03, -8.7004e-03,\n",
       "            -3.3622e-03, -1.1601e-03, -1.0511e-03, -8.0619e-04, -7.1047e-04,\n",
       "            -1.0206e-03, -1.7847e-04,  7.9758e-04,  1.8377e-04], device='cuda:0')},\n",
       "   27: {'momentum_buffer': tensor([[[[ 5.9045e-06, -3.3735e-05, -3.1343e-04],\n",
       "              [ 1.3855e-04, -1.8933e-05, -4.9390e-04],\n",
       "              [-1.1699e-04, -5.0639e-04, -6.8013e-04]],\n",
       "    \n",
       "             [[ 1.2502e-04, -1.7677e-04,  1.3969e-04],\n",
       "              [-1.5833e-04,  1.0972e-04,  3.0600e-04],\n",
       "              [ 9.5617e-05, -1.5542e-04,  5.9987e-05]],\n",
       "    \n",
       "             [[ 2.1006e-04,  6.4205e-04,  6.0527e-04],\n",
       "              [ 5.8540e-05,  3.1081e-04,  3.9440e-04],\n",
       "              [-3.0596e-04, -1.5086e-04,  2.5299e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.3229e-05, -9.1297e-05, -1.2546e-04],\n",
       "              [ 2.6690e-04, -3.1758e-05,  4.1304e-06],\n",
       "              [-8.7927e-05, -1.1472e-05,  5.8951e-05]],\n",
       "    \n",
       "             [[-3.3623e-04, -1.5418e-04, -3.5429e-04],\n",
       "              [-3.8703e-04, -3.1758e-04, -6.2601e-06],\n",
       "              [-3.4857e-04, -5.6755e-04, -1.8548e-04]],\n",
       "    \n",
       "             [[-1.0060e-05,  8.1607e-05, -7.6126e-05],\n",
       "              [ 4.0956e-04,  2.4295e-04,  1.7538e-04],\n",
       "              [ 6.9930e-05, -1.3947e-04,  2.8320e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.5049e-04,  2.5154e-04,  2.8999e-04],\n",
       "              [-2.8304e-04, -1.2497e-04,  5.9624e-05],\n",
       "              [-3.2088e-04, -4.6378e-04,  9.3476e-05]],\n",
       "    \n",
       "             [[-1.1213e-04, -1.9990e-04, -4.9714e-04],\n",
       "              [ 1.3927e-05, -5.2494e-04, -5.5769e-04],\n",
       "              [-7.5019e-05, -6.1647e-04, -1.6192e-04]],\n",
       "    \n",
       "             [[-2.0739e-04, -6.3706e-04, -2.6300e-04],\n",
       "              [ 4.8545e-04, -7.9128e-04, -4.1092e-04],\n",
       "              [ 6.7480e-04, -6.2178e-05,  9.4679e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.4777e-04, -6.7010e-05, -6.7163e-04],\n",
       "              [-4.8808e-04, -1.5010e-04, -5.4708e-04],\n",
       "              [-3.3428e-04, -5.4825e-04, -4.0323e-04]],\n",
       "    \n",
       "             [[ 7.3114e-04,  5.2045e-04, -2.3472e-04],\n",
       "              [-8.7415e-05, -3.7819e-04,  4.2907e-04],\n",
       "              [ 1.4511e-04,  7.0199e-05,  2.9352e-04]],\n",
       "    \n",
       "             [[-2.6701e-04, -3.5946e-04, -3.9433e-04],\n",
       "              [ 3.5973e-04, -4.7732e-05, -3.7896e-04],\n",
       "              [ 7.4508e-05, -2.0925e-04,  3.5599e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.0487e-04, -4.9304e-06, -1.6525e-04],\n",
       "              [ 5.3778e-04,  6.0514e-04, -3.5799e-04],\n",
       "              [ 5.8328e-04,  8.7273e-05,  2.6650e-04]],\n",
       "    \n",
       "             [[ 1.3489e-04,  3.5062e-05, -1.1322e-04],\n",
       "              [-2.2980e-04,  8.6201e-05, -3.8734e-05],\n",
       "              [-4.0578e-05,  1.6830e-05, -2.8728e-04]],\n",
       "    \n",
       "             [[-2.4706e-04, -1.1649e-04, -1.8589e-04],\n",
       "              [ 8.2199e-05,  9.4649e-05,  5.4846e-04],\n",
       "              [-2.6602e-04,  2.3750e-04,  5.6339e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.1133e-05,  1.4528e-04,  1.6473e-04],\n",
       "              [-1.0107e-04, -2.6613e-04, -4.7471e-05],\n",
       "              [-6.2321e-05,  1.2874e-04, -7.2274e-05]],\n",
       "    \n",
       "             [[-1.7515e-04,  6.8449e-05, -4.3155e-05],\n",
       "              [-1.2478e-04, -5.2648e-04, -6.2876e-04],\n",
       "              [-1.1112e-04, -6.2472e-04, -4.7288e-04]],\n",
       "    \n",
       "             [[ 6.1276e-04,  3.2333e-04,  1.2432e-04],\n",
       "              [ 2.6404e-05,  3.8828e-04,  1.9412e-04],\n",
       "              [ 4.0700e-04, -6.2642e-05, -2.9651e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-4.8421e-04, -4.7883e-04, -3.3458e-04],\n",
       "              [-4.9107e-04, -5.1457e-05, -2.7062e-04],\n",
       "              [-3.7274e-04, -3.8504e-04, -1.9325e-04]],\n",
       "    \n",
       "             [[ 1.2783e-04, -3.6952e-04, -7.4245e-04],\n",
       "              [-3.2800e-04, -6.3991e-04, -5.9527e-04],\n",
       "              [-1.6337e-04, -6.6679e-06,  1.5651e-04]],\n",
       "    \n",
       "             [[-1.0261e-04,  4.5127e-04,  6.6310e-04],\n",
       "              [-8.2616e-05,  9.4761e-05,  6.9436e-04],\n",
       "              [ 4.0033e-04,  8.5148e-05,  3.5453e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.7530e-05,  1.7974e-04, -2.2267e-04],\n",
       "              [-9.5488e-05,  3.3854e-04,  3.8431e-04],\n",
       "              [-2.9896e-04, -7.9059e-05,  2.9390e-04]],\n",
       "    \n",
       "             [[ 4.5988e-04,  4.3850e-04, -2.1132e-04],\n",
       "              [ 1.8125e-04,  6.7380e-04,  4.7451e-04],\n",
       "              [ 5.2189e-04,  4.6410e-04,  9.0181e-04]],\n",
       "    \n",
       "             [[-5.2982e-05,  4.2784e-05, -1.2731e-04],\n",
       "              [ 8.7456e-05, -2.4671e-04, -6.2581e-04],\n",
       "              [-2.0399e-04,  7.4860e-05,  2.7397e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.7556e-04,  1.7160e-04,  6.1465e-04],\n",
       "              [-1.7481e-04,  1.5679e-05,  3.2881e-04],\n",
       "              [ 1.5014e-04,  3.1976e-05,  3.2252e-04]],\n",
       "    \n",
       "             [[ 4.8381e-04,  4.2142e-04,  2.7331e-04],\n",
       "              [ 5.2197e-05,  2.0633e-05,  2.5835e-04],\n",
       "              [ 2.2795e-04,  2.1546e-05, -2.8601e-04]],\n",
       "    \n",
       "             [[-3.6522e-04, -5.4966e-04, -6.1450e-04],\n",
       "              [-5.1765e-04, -5.6763e-05, -4.5391e-04],\n",
       "              [-3.3063e-04, -1.6175e-04,  1.4336e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.7399e-05,  1.8783e-04,  3.6616e-04],\n",
       "              [ 4.4541e-04,  4.6841e-04,  5.3270e-05],\n",
       "              [-5.4600e-06,  2.5565e-04,  1.3752e-04]],\n",
       "    \n",
       "             [[-2.0338e-04, -4.2230e-06,  4.3623e-04],\n",
       "              [-1.9028e-04, -4.6577e-04, -6.4980e-04],\n",
       "              [-4.2942e-05,  9.6713e-05, -1.1236e-04]],\n",
       "    \n",
       "             [[ 3.0998e-04,  5.0694e-04,  1.6168e-04],\n",
       "              [ 1.9435e-04, -7.1538e-05,  3.1472e-04],\n",
       "              [ 4.0647e-04,  2.5221e-04, -1.1540e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.5267e-05,  4.8761e-04, -2.4161e-04],\n",
       "              [-2.5643e-04,  1.2041e-04, -3.9069e-04],\n",
       "              [-2.8451e-04, -1.6596e-04,  1.0648e-04]],\n",
       "    \n",
       "             [[ 1.2356e-04,  4.9271e-04, -1.8412e-04],\n",
       "              [ 2.3841e-05, -4.6973e-04, -6.0050e-04],\n",
       "              [-9.2672e-04, -7.6297e-04, -1.7987e-04]],\n",
       "    \n",
       "             [[ 2.7850e-04,  9.7782e-04,  1.2167e-03],\n",
       "              [ 3.4107e-04,  5.2160e-04,  1.5732e-03],\n",
       "              [ 3.8262e-04,  1.9931e-04,  5.2553e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.4146e-04, -1.5780e-04, -9.1900e-05],\n",
       "              [ 2.8243e-04,  5.9841e-04,  5.4348e-04],\n",
       "              [ 1.8307e-04,  3.5524e-04,  5.6990e-04]],\n",
       "    \n",
       "             [[ 2.3679e-04, -5.8330e-04, -1.4088e-04],\n",
       "              [ 2.1952e-05, -7.4010e-05,  1.3981e-04],\n",
       "              [-7.0884e-04,  2.2976e-04, -1.4738e-04]],\n",
       "    \n",
       "             [[-1.6024e-06,  4.2721e-04,  2.5560e-04],\n",
       "              [ 8.0061e-04,  1.1807e-04, -4.5613e-04],\n",
       "              [ 4.9939e-06, -2.0457e-04, -1.5371e-04]]]], device='cuda:0')},\n",
       "   28: {'momentum_buffer': tensor([ 0.0015,  0.0009,  0.0019,  0.0023,  0.0021,  0.0013,  0.0038,  0.0010,\n",
       "             0.0009,  0.0014,  0.0011,  0.0034,  0.0016,  0.0014,  0.0026,  0.0023,\n",
       "             0.0021,  0.0019,  0.0017,  0.0017,  0.0016,  0.0007,  0.0013,  0.0017,\n",
       "             0.0016,  0.0017,  0.0009,  0.0011,  0.0015,  0.0012,  0.0015,  0.0010,\n",
       "             0.0015,  0.0033,  0.0014,  0.0025,  0.0008,  0.0019,  0.0021,  0.0015,\n",
       "             0.0025,  0.0009,  0.0019,  0.0017,  0.0013,  0.0018,  0.0014, -0.0006,\n",
       "             0.0010,  0.0018,  0.0015,  0.0017,  0.0014,  0.0018,  0.0017,  0.0013,\n",
       "            -0.0001,  0.0018,  0.0029,  0.0013,  0.0011,  0.0022,  0.0017,  0.0003],\n",
       "           device='cuda:0')},\n",
       "   29: {'momentum_buffer': tensor([-3.1386e-04, -3.1165e-04, -6.5209e-04, -9.6410e-05,  4.6445e-03,\n",
       "             1.5224e-04, -5.1978e-03,  2.2788e-03,  2.6849e-03,  8.1979e-04,\n",
       "             3.0902e-03, -1.3241e-02,  4.3469e-03,  2.5910e-04,  2.0014e-04,\n",
       "            -1.4460e-04,  3.6320e-03, -6.6782e-04, -1.4261e-04, -1.9341e-04,\n",
       "            -9.9973e-04,  2.5759e-03,  9.4310e-04, -1.0097e-03, -7.4416e-04,\n",
       "            -3.8196e-04, -6.6404e-04,  7.3673e-04, -9.2913e-04,  5.3747e-04,\n",
       "            -5.5911e-04,  1.1262e-04, -8.0403e-04, -3.7164e-03, -1.0721e-03,\n",
       "            -3.5559e-04, -2.3449e-04, -4.4270e-04,  7.7198e-04, -8.9334e-04,\n",
       "            -1.0843e-04,  2.9787e-03, -7.9868e-04,  6.5954e-04, -4.1724e-04,\n",
       "             3.1181e-05, -1.0362e-03,  4.2139e-03,  2.7003e-03, -6.6138e-05,\n",
       "             4.0984e-03, -2.6885e-04, -8.5033e-04,  6.7551e-04, -7.9430e-04,\n",
       "            -2.7443e-04,  3.0667e-03, -2.7625e-04,  3.8903e-03, -1.0301e-03,\n",
       "             4.5463e-05,  6.2980e-04, -9.1805e-04,  4.1616e-03], device='cuda:0')},\n",
       "   30: {'momentum_buffer': tensor([[[[-1.5591e-04]],\n",
       "    \n",
       "             [[-3.7384e-04]],\n",
       "    \n",
       "             [[-4.1021e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.2483e-04]],\n",
       "    \n",
       "             [[-3.4837e-04]],\n",
       "    \n",
       "             [[ 1.7947e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.6779e-05]],\n",
       "    \n",
       "             [[ 6.7634e-05]],\n",
       "    \n",
       "             [[ 4.2945e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.0057e-04]],\n",
       "    \n",
       "             [[ 2.7311e-04]],\n",
       "    \n",
       "             [[-1.4933e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-5.8082e-05]],\n",
       "    \n",
       "             [[ 4.2371e-04]],\n",
       "    \n",
       "             [[ 1.4538e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.2740e-04]],\n",
       "    \n",
       "             [[ 3.9022e-04]],\n",
       "    \n",
       "             [[-1.1616e-03]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-5.2603e-04]],\n",
       "    \n",
       "             [[ 9.0798e-05]],\n",
       "    \n",
       "             [[-2.0145e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.5696e-05]],\n",
       "    \n",
       "             [[ 4.3558e-04]],\n",
       "    \n",
       "             [[ 3.9076e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-8.4395e-05]],\n",
       "    \n",
       "             [[-2.5545e-05]],\n",
       "    \n",
       "             [[-9.8845e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.5884e-05]],\n",
       "    \n",
       "             [[ 1.1576e-04]],\n",
       "    \n",
       "             [[ 8.4740e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.0332e-05]],\n",
       "    \n",
       "             [[ 5.0509e-06]],\n",
       "    \n",
       "             [[ 2.1451e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.2983e-04]],\n",
       "    \n",
       "             [[ 1.1333e-04]],\n",
       "    \n",
       "             [[ 2.6493e-05]]]], device='cuda:0')},\n",
       "   31: {'momentum_buffer': tensor([ 3.3363e-05,  8.5656e-04,  1.6449e-03,  1.3706e-03,  6.9760e-04,\n",
       "             5.3872e-04, -9.1934e-06,  1.9343e-06,  2.8302e-04,  1.4154e-03,\n",
       "             2.5232e-03,  9.6934e-05,  3.1602e-04,  2.1879e-03,  3.9821e-04,\n",
       "             5.4309e-04,  3.6140e-03,  2.6856e-04,  5.1379e-04,  1.0666e-03,\n",
       "             2.1516e-03, -1.0769e-05, -2.6105e-04, -1.5567e-04,  1.8362e-03,\n",
       "             3.5065e-05,  2.3404e-04,  2.0938e-03,  2.1736e-03,  1.4461e-03,\n",
       "             2.4880e-03,  2.1557e-03,  3.3652e-03,  1.4819e-04,  2.3344e-03,\n",
       "             2.4769e-05,  2.2036e-03,  9.3142e-04,  1.6470e-03,  1.5798e-03,\n",
       "             4.2615e-05,  1.8930e-03,  4.0938e-04,  1.2735e-04,  1.7923e-03,\n",
       "            -7.3391e-04,  5.2271e-03,  2.0876e-03,  1.0054e-03,  1.2200e-03,\n",
       "             5.2434e-04,  1.1103e-03,  9.2724e-04, -2.2004e-04,  5.6728e-04,\n",
       "             2.5494e-03,  1.9421e-03,  2.2188e-03, -3.6485e-04,  1.0045e-03,\n",
       "             2.4397e-03,  5.5694e-04,  2.4251e-04,  2.5882e-03,  1.9873e-03,\n",
       "             5.1749e-04,  2.9595e-03,  5.3836e-04,  2.7176e-03,  9.7653e-04,\n",
       "             8.7838e-04,  2.1235e-04,  1.4858e-03,  3.3701e-03,  2.1496e-03,\n",
       "             6.3800e-04,  6.6992e-04, -2.1569e-04,  3.0579e-03, -9.8752e-04,\n",
       "             1.3459e-04,  2.0473e-03, -9.5732e-04,  1.4087e-03,  2.0765e-03,\n",
       "            -1.7868e-04,  2.8607e-03,  2.2210e-03,  8.9848e-04, -4.8887e-04,\n",
       "             1.7542e-03,  1.0403e-03,  8.3492e-04,  5.5324e-04,  1.9022e-03,\n",
       "             2.7496e-03,  2.0378e-03,  8.3184e-04,  2.1236e-03,  6.1655e-04,\n",
       "             2.1916e-03,  2.8225e-04,  3.9084e-03,  1.9624e-03,  1.7915e-03,\n",
       "            -1.0828e-04, -5.1453e-04,  5.3768e-05,  1.6741e-03,  1.6690e-03,\n",
       "             4.6539e-04,  4.1553e-04,  2.0074e-03, -1.7960e-04,  2.6151e-03,\n",
       "             2.8945e-03,  6.9076e-04,  1.1950e-03,  1.0694e-03,  3.4745e-03,\n",
       "             1.9490e-03,  2.2333e-03, -1.9262e-04,  2.2769e-03,  2.9228e-03,\n",
       "             1.8110e-04,  1.8779e-03,  2.1238e-03,  3.3681e-03,  1.8557e-03,\n",
       "             1.1971e-03,  1.6058e-03,  4.4072e-04,  3.4438e-03,  2.2297e-04,\n",
       "             1.9486e-03,  1.2146e-03,  1.6128e-03,  3.3203e-04,  2.9721e-04,\n",
       "            -1.7677e-04,  1.1201e-04,  1.4462e-03, -1.4731e-04,  1.6907e-03,\n",
       "             2.6660e-03, -7.4057e-05,  5.1786e-05,  1.7843e-03,  1.8932e-03,\n",
       "             3.5353e-04,  1.9045e-03,  2.9514e-03,  2.0391e-03, -9.4545e-05,\n",
       "             9.7853e-04,  4.2547e-04,  8.8734e-04,  2.4776e-03,  2.0553e-03,\n",
       "             2.2316e-03,  3.4896e-04,  8.3044e-04,  8.0785e-04,  2.7599e-03,\n",
       "             1.8874e-03, -4.3029e-04,  2.3538e-03,  1.8522e-04,  2.3776e-04,\n",
       "             2.8032e-03,  3.8662e-04,  1.4448e-03, -8.9565e-05,  1.5664e-03,\n",
       "             3.1473e-04, -1.4585e-04,  2.1532e-03,  1.7451e-03,  3.5836e-03,\n",
       "             7.1705e-04,  2.5741e-03,  1.0752e-03,  1.1941e-03,  2.3412e-04,\n",
       "            -1.3620e-04,  1.9882e-03,  1.9910e-03,  1.8826e-04, -9.5623e-05,\n",
       "            -2.9518e-04,  4.4772e-04,  4.3753e-03,  1.7883e-03,  6.9306e-04,\n",
       "             3.5632e-03,  1.3738e-03,  1.1543e-03,  5.9151e-04,  4.0585e-04,\n",
       "             2.3325e-03,  6.5934e-04,  3.9940e-04,  1.2547e-03,  1.0038e-03,\n",
       "            -1.4049e-04,  9.0017e-04, -3.0203e-05,  7.2091e-04,  2.5258e-03,\n",
       "            -8.4305e-06,  2.2809e-04,  2.7197e-03,  9.0272e-04,  3.3603e-04,\n",
       "             2.4364e-03,  2.8295e-03, -3.5981e-04,  2.3172e-03,  1.3316e-03,\n",
       "             1.6951e-03,  1.5662e-03,  2.3553e-03,  6.4848e-04,  1.2987e-03,\n",
       "             2.1383e-03,  4.2461e-04, -1.9177e-04,  1.0892e-03,  1.3147e-03,\n",
       "             2.7710e-03,  1.1551e-03,  2.7283e-03,  1.3395e-03,  1.1192e-04,\n",
       "             1.7448e-04,  2.5489e-03,  2.2852e-04,  1.0645e-03,  4.6742e-05,\n",
       "             2.4926e-03,  1.4127e-03,  1.1202e-03, -1.3953e-04, -1.6480e-04,\n",
       "             1.8661e-03,  2.2651e-03,  1.4683e-03, -1.9486e-05,  5.5901e-04,\n",
       "             1.4248e-03,  1.7591e-03,  6.6160e-04,  3.0231e-04,  7.4272e-04,\n",
       "             1.2325e-03], device='cuda:0')},\n",
       "   32: {'momentum_buffer': tensor([-7.1120e-04,  9.3155e-04, -1.0822e-03, -8.2092e-04,  4.2303e-04,\n",
       "            -5.1062e-04, -6.1452e-05,  2.2653e-04, -1.8521e-05, -1.9687e-03,\n",
       "            -2.1022e-03,  1.8325e-05,  1.2118e-03, -3.7345e-04,  8.2022e-04,\n",
       "             1.9704e-03, -2.6334e-03, -6.8696e-04, -2.1514e-03, -1.7365e-03,\n",
       "            -2.2245e-03, -1.6510e-05,  2.3314e-04,  1.1533e-04, -1.3459e-03,\n",
       "             9.7440e-05,  3.7467e-04, -8.8401e-04, -1.9015e-03,  2.5538e-04,\n",
       "            -1.0507e-03, -6.8598e-04, -1.9880e-03,  4.5130e-04, -1.6319e-03,\n",
       "             1.5645e-04, -1.1590e-03, -1.1617e-03, -5.0064e-04, -2.1065e-03,\n",
       "            -2.2791e-04, -1.2614e-03, -1.8309e-03, -3.1887e-04, -1.3055e-03,\n",
       "             2.1403e-04, -6.0410e-03, -1.2995e-03, -7.3963e-04,  1.1152e-03,\n",
       "            -1.6186e-05, -3.6829e-04, -6.8937e-04,  2.9447e-04,  2.4194e-04,\n",
       "            -2.1004e-03, -1.7109e-03, -1.8775e-03,  8.6837e-06, -1.1430e-04,\n",
       "            -1.6109e-03, -5.2852e-04, -5.7460e-04, -1.2589e-03, -2.0910e-03,\n",
       "            -3.2008e-04, -4.4384e-04,  6.0308e-04, -2.1012e-03, -2.0927e-04,\n",
       "            -4.9105e-04, -9.1622e-04, -1.5162e-03, -3.3176e-03, -1.5814e-03,\n",
       "             1.1298e-04, -1.3438e-03, -2.4054e-04, -1.5477e-03, -3.7757e-04,\n",
       "             1.2454e-04, -1.5327e-03,  2.4509e-05, -1.0849e-03, -3.9192e-04,\n",
       "             6.6013e-04, -1.7014e-03, -7.2749e-04, -7.7956e-04,  2.0821e-04,\n",
       "            -9.3950e-04, -7.0190e-04, -2.1282e-03, -4.6881e-04, -1.3549e-03,\n",
       "            -2.3234e-03, -1.3387e-03, -5.1600e-04, -1.1534e-03, -2.7357e-05,\n",
       "            -1.7030e-03,  1.3672e-05, -3.4600e-03, -1.6771e-03, -2.2431e-03,\n",
       "            -2.5925e-04,  2.6466e-05,  2.2732e-04, -2.3973e-03, -6.5242e-04,\n",
       "             3.5682e-04,  6.2612e-04, -1.1838e-03, -2.6868e-04, -1.9376e-03,\n",
       "            -2.8917e-03, -6.8579e-05, -6.3628e-04, -4.9564e-04, -2.7967e-03,\n",
       "            -1.5873e-03, -1.7533e-03,  1.4581e-05, -1.9784e-03, -2.2304e-03,\n",
       "             1.7806e-04, -8.3337e-05, -7.7248e-04, -1.5675e-03, -6.7950e-04,\n",
       "             1.0462e-03, -6.9896e-04,  2.1992e-04, -3.4291e-03,  3.1083e-04,\n",
       "            -1.8071e-03,  1.1817e-04, -2.0260e-03,  1.0699e-04,  3.4526e-04,\n",
       "             5.7285e-04, -4.7636e-04, -1.0797e-03,  9.1496e-05, -2.2305e-04,\n",
       "            -1.5768e-03, -8.2296e-04,  3.5808e-04, -1.2128e-04, -2.0618e-03,\n",
       "            -3.4935e-05, -6.6275e-04, -2.1048e-03, -7.2945e-05,  2.8415e-04,\n",
       "             1.8341e-03,  9.5798e-04, -1.0053e-04, -2.1215e-03, -2.5977e-03,\n",
       "            -1.8667e-03,  3.0172e-04, -5.7316e-04, -2.8271e-04,  2.6697e-03,\n",
       "            -1.0117e-03,  5.1088e-04, -1.0381e-03, -4.0020e-05, -2.2861e-04,\n",
       "            -1.3308e-03,  1.8433e-03, -1.0722e-03,  7.2080e-05, -9.3853e-04,\n",
       "             7.5325e-04, -5.4425e-04, -1.4156e-03, -1.5208e-03, -2.1236e-03,\n",
       "             3.0501e-04, -6.3282e-04,  1.6653e-05,  1.6566e-04,  2.8216e-04,\n",
       "             1.6581e-03, -2.8577e-03, -2.4928e-03, -4.4506e-04,  1.7973e-05,\n",
       "            -4.6955e-06,  5.4299e-04, -3.7101e-03, -2.1810e-03,  3.2291e-03,\n",
       "            -2.5413e-03,  1.2508e-03, -7.8127e-04,  2.1865e-04, -4.6943e-04,\n",
       "            -1.0860e-03,  1.1766e-03,  1.7525e-05, -8.8115e-04, -1.1368e-03,\n",
       "            -2.6947e-04, -1.5546e-03, -2.8705e-07, -3.0128e-04, -2.3613e-03,\n",
       "            -3.9671e-06,  1.2123e-04, -2.7440e-03, -8.1803e-04, -6.6796e-04,\n",
       "            -7.6328e-04, -1.7086e-03,  1.9516e-04, -1.0528e-03, -1.0946e-03,\n",
       "            -2.8064e-03, -4.5551e-04, -3.5703e-04,  7.6779e-04,  1.6344e-03,\n",
       "            -1.2561e-03,  1.7166e-04,  2.1443e-04, -2.1530e-04,  8.2987e-04,\n",
       "            -2.0346e-03,  6.2808e-04,  1.9427e-05,  6.2055e-04,  1.7837e-04,\n",
       "             7.9452e-04, -1.6010e-03,  6.6426e-05,  2.0060e-04,  3.7142e-04,\n",
       "            -3.9660e-03, -4.6346e-03, -1.7852e-03, -1.6417e-05,  1.9530e-04,\n",
       "             5.6275e-04, -1.4979e-03, -8.6728e-04, -3.4450e-04,  5.4262e-04,\n",
       "            -1.1582e-03, -2.1074e-03,  1.6535e-03, -5.2758e-04,  1.4297e-04,\n",
       "            -1.0858e-03], device='cuda:0')},\n",
       "   33: {'momentum_buffer': tensor([[[[-3.7010e-04]],\n",
       "    \n",
       "             [[-6.2003e-05]],\n",
       "    \n",
       "             [[ 6.8071e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.8863e-04]],\n",
       "    \n",
       "             [[ 4.6950e-04]],\n",
       "    \n",
       "             [[-1.0497e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.5052e-04]],\n",
       "    \n",
       "             [[-1.9030e-04]],\n",
       "    \n",
       "             [[-7.3718e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.1980e-04]],\n",
       "    \n",
       "             [[-2.8185e-04]],\n",
       "    \n",
       "             [[-4.1573e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.2501e-04]],\n",
       "    \n",
       "             [[-1.4015e-04]],\n",
       "    \n",
       "             [[-6.8758e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.2438e-04]],\n",
       "    \n",
       "             [[-3.0731e-04]],\n",
       "    \n",
       "             [[ 1.7343e-06]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 7.8479e-06]],\n",
       "    \n",
       "             [[ 1.2951e-03]],\n",
       "    \n",
       "             [[ 1.7825e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.4791e-04]],\n",
       "    \n",
       "             [[ 3.0767e-04]],\n",
       "    \n",
       "             [[ 3.9732e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.8274e-04]],\n",
       "    \n",
       "             [[ 4.4658e-04]],\n",
       "    \n",
       "             [[ 3.4500e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.4110e-04]],\n",
       "    \n",
       "             [[-4.4209e-04]],\n",
       "    \n",
       "             [[-1.2474e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-9.9419e-04]],\n",
       "    \n",
       "             [[-2.7829e-05]],\n",
       "    \n",
       "             [[ 1.8195e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.0704e-04]],\n",
       "    \n",
       "             [[-3.8484e-04]],\n",
       "    \n",
       "             [[-9.8223e-05]]]], device='cuda:0')},\n",
       "   34: {'momentum_buffer': tensor([0.0026, 0.0021, 0.0030, 0.0020, 0.0030, 0.0025, 0.0023, 0.0040, 0.0041,\n",
       "            0.0036, 0.0027, 0.0037, 0.0031, 0.0027, 0.0014, 0.0024, 0.0023, 0.0029,\n",
       "            0.0017, 0.0036, 0.0024, 0.0023, 0.0033, 0.0042, 0.0037, 0.0023, 0.0011,\n",
       "            0.0025, 0.0022, 0.0045, 0.0025, 0.0031, 0.0024, 0.0029, 0.0039, 0.0025,\n",
       "            0.0023, 0.0029, 0.0016, 0.0027, 0.0019, 0.0026, 0.0042, 0.0025, 0.0019,\n",
       "            0.0040, 0.0037, 0.0032, 0.0041, 0.0032, 0.0028, 0.0019, 0.0038, 0.0032,\n",
       "            0.0021, 0.0018, 0.0015, 0.0024, 0.0036, 0.0013, 0.0025, 0.0023, 0.0026,\n",
       "            0.0026, 0.0023, 0.0034, 0.0029, 0.0020, 0.0027, 0.0020, 0.0026, 0.0030,\n",
       "            0.0025, 0.0022, 0.0017, 0.0026, 0.0021, 0.0026, 0.0027, 0.0020, 0.0040,\n",
       "            0.0027, 0.0023, 0.0028, 0.0021, 0.0010, 0.0037, 0.0038, 0.0022, 0.0034,\n",
       "            0.0042, 0.0025, 0.0030, 0.0045, 0.0013, 0.0022, 0.0031, 0.0017, 0.0013,\n",
       "            0.0002, 0.0019, 0.0017, 0.0032, 0.0017, 0.0026, 0.0022, 0.0027, 0.0027,\n",
       "            0.0026, 0.0034, 0.0025, 0.0015, 0.0027, 0.0027, 0.0027, 0.0029, 0.0037,\n",
       "            0.0032, 0.0030, 0.0019, 0.0015, 0.0017, 0.0025, 0.0028, 0.0027, 0.0026,\n",
       "            0.0031, 0.0021], device='cuda:0')},\n",
       "   35: {'momentum_buffer': tensor([-1.6857e-03, -4.1874e-04, -1.2384e-03,  6.1968e-04, -1.6574e-03,\n",
       "            -9.5981e-04, -4.6590e-04, -2.7130e-03, -3.1580e-03, -1.6114e-03,\n",
       "            -2.6964e-03, -3.0210e-03, -2.0212e-03, -1.0804e-03, -1.4980e-03,\n",
       "             9.3153e-04,  1.1554e-04, -2.5526e-03, -9.9474e-04, -1.0941e-03,\n",
       "            -8.3577e-04, -1.6865e-03, -2.8616e-03, -3.4608e-03, -2.4091e-03,\n",
       "            -1.2355e-03,  6.4114e-04, -5.2966e-04, -1.1074e-03, -4.3661e-03,\n",
       "            -1.7306e-03, -1.9817e-03, -1.0182e-03, -1.6675e-03, -2.5050e-03,\n",
       "            -1.3101e-03, -1.3028e-03, -1.7609e-03, -7.5261e-05, -1.2625e-03,\n",
       "             9.3411e-04, -8.7889e-04, -4.2324e-03, -1.9722e-03, -2.0820e-03,\n",
       "            -3.3706e-03, -4.5711e-04, -9.1720e-04, -2.7599e-03, -1.6969e-03,\n",
       "            -1.0636e-03, -8.6592e-04, -4.4687e-03, -2.4859e-03, -2.4670e-04,\n",
       "            -8.4577e-04, -9.9543e-05, -4.6085e-04, -1.5285e-03, -9.4429e-04,\n",
       "            -1.5124e-03, -5.6161e-05,  2.1786e-05, -1.6922e-03, -1.1797e-04,\n",
       "            -1.5688e-03, -1.8866e-03, -1.4085e-03, -1.2331e-03, -1.6599e-03,\n",
       "            -1.3417e-03, -2.8516e-03, -3.1111e-03, -1.3998e-03, -1.0399e-03,\n",
       "            -7.4805e-04, -1.6266e-03, -9.0558e-04, -1.3810e-03, -6.9623e-04,\n",
       "            -3.9078e-03, -8.6948e-04, -6.5945e-04, -1.2453e-03, -1.7456e-03,\n",
       "             7.6029e-04, -2.2074e-03, -1.9720e-03, -5.7941e-04, -2.6738e-03,\n",
       "            -3.4938e-03, -9.7366e-04, -1.7417e-03, -7.9698e-04, -1.1749e-03,\n",
       "            -1.4528e-03, -2.0882e-04,  1.6551e-04, -1.6897e-03,  4.3090e-04,\n",
       "             1.5138e-03, -2.1277e-05, -2.0021e-03, -1.0644e-03, -7.1847e-04,\n",
       "            -1.7803e-03, -2.4002e-03, -1.0505e-04, -2.6389e-03, -1.7269e-03,\n",
       "            -2.4470e-03, -4.5941e-04, -1.4432e-03,  3.4344e-04, -1.1242e-03,\n",
       "            -1.1680e-03, -3.2035e-04, -6.6159e-04, -2.6183e-03, -2.6851e-04,\n",
       "            -1.2889e-03, -1.2293e-03, -1.4821e-03, -1.2158e-03, -1.3716e-03,\n",
       "            -1.4829e-03, -2.6175e-03, -1.5151e-04], device='cuda:0')},\n",
       "   36: {'momentum_buffer': tensor([[[[ 3.1362e-04,  2.8377e-04,  1.0667e-04],\n",
       "              [ 5.7334e-04,  5.0299e-04,  1.6076e-04],\n",
       "              [-2.1473e-04, -4.8909e-05,  1.3008e-05]],\n",
       "    \n",
       "             [[ 2.3411e-04,  3.5674e-04,  2.2593e-04],\n",
       "              [-3.4320e-04, -2.5484e-04, -1.5119e-04],\n",
       "              [-3.3342e-04, -3.8534e-05,  1.6810e-04]],\n",
       "    \n",
       "             [[-5.6242e-05,  1.1369e-04,  1.5389e-04],\n",
       "              [ 6.9996e-04,  3.7530e-04,  6.3533e-04],\n",
       "              [-6.5539e-04, -4.3803e-04,  5.9112e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.8628e-05, -2.8276e-05,  2.4656e-04],\n",
       "              [-6.0168e-05, -7.4006e-05,  2.4042e-04],\n",
       "              [ 9.6086e-05,  7.1475e-05, -1.2196e-04]],\n",
       "    \n",
       "             [[ 2.3730e-04,  1.3336e-04, -3.3194e-05],\n",
       "              [ 5.2397e-04,  2.4989e-04,  6.1554e-04],\n",
       "              [ 6.6927e-05,  1.1176e-04, -6.4403e-04]],\n",
       "    \n",
       "             [[ 4.7932e-04,  2.7280e-04,  6.3263e-04],\n",
       "              [ 1.1156e-03,  9.4471e-04,  6.8367e-04],\n",
       "              [ 3.7838e-04,  1.4350e-04,  4.5327e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.7882e-04,  3.5007e-04,  4.5139e-05],\n",
       "              [ 2.2620e-04,  4.4994e-04, -3.7220e-05],\n",
       "              [-6.6970e-06, -8.4294e-05,  3.5528e-04]],\n",
       "    \n",
       "             [[ 1.4344e-04,  1.2340e-04,  3.7750e-05],\n",
       "              [ 3.5938e-04, -4.4134e-06, -2.9563e-04],\n",
       "              [ 9.3829e-05,  1.9155e-04, -2.5391e-04]],\n",
       "    \n",
       "             [[-4.8144e-04, -1.8683e-04, -4.5955e-04],\n",
       "              [-3.7068e-04, -1.1649e-04, -3.1175e-04],\n",
       "              [-1.4932e-04, -3.4272e-04, -1.1355e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.9520e-05,  9.3017e-05, -2.2749e-05],\n",
       "              [ 1.3080e-04,  7.9367e-05,  4.2060e-04],\n",
       "              [ 1.8946e-04,  2.6297e-04, -3.0552e-05]],\n",
       "    \n",
       "             [[-1.3898e-04,  3.9189e-04,  7.4863e-04],\n",
       "              [-4.9333e-04,  1.7554e-04, -1.3395e-04],\n",
       "              [ 1.4357e-04, -2.3354e-05,  3.1630e-04]],\n",
       "    \n",
       "             [[ 2.3450e-05,  9.6091e-05, -4.1951e-04],\n",
       "              [ 2.9535e-04,  1.6900e-04,  3.2124e-04],\n",
       "              [-2.3491e-04,  7.3579e-06, -9.3041e-07]]],\n",
       "    \n",
       "    \n",
       "            [[[-8.2776e-05, -3.4483e-04, -2.9878e-04],\n",
       "              [ 8.1484e-06, -5.1191e-04,  1.9001e-04],\n",
       "              [-6.5933e-05, -1.4488e-04,  1.3583e-04]],\n",
       "    \n",
       "             [[ 2.9436e-05,  2.7784e-04, -1.6371e-05],\n",
       "              [ 3.1129e-04, -4.1757e-05,  1.4637e-04],\n",
       "              [-2.2791e-04, -2.5330e-04,  4.7466e-06]],\n",
       "    \n",
       "             [[-1.5111e-04,  1.6265e-04, -5.1903e-05],\n",
       "              [-4.4007e-04, -3.8153e-04,  2.5968e-04],\n",
       "              [ 5.2791e-05,  1.2441e-04,  9.8992e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.3095e-04,  1.5434e-04, -7.4493e-05],\n",
       "              [-1.6394e-04,  1.1962e-04, -2.0253e-04],\n",
       "              [-3.8563e-04, -1.5970e-04,  7.2909e-05]],\n",
       "    \n",
       "             [[ 2.0488e-04, -1.2794e-04, -2.3590e-04],\n",
       "              [ 1.2504e-04,  4.4483e-07, -9.1461e-05],\n",
       "              [ 3.1611e-04,  1.8169e-04,  3.3685e-04]],\n",
       "    \n",
       "             [[-2.9184e-04,  9.3895e-05,  2.0234e-04],\n",
       "              [ 2.7733e-04,  2.6025e-04,  5.7247e-04],\n",
       "              [-6.8272e-05, -2.4318e-05,  4.3894e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-4.3004e-04,  1.4877e-04,  3.5521e-05],\n",
       "              [ 6.7110e-05, -7.6543e-05,  8.7165e-05],\n",
       "              [-3.2418e-06, -3.6278e-04,  4.3868e-05]],\n",
       "    \n",
       "             [[-3.0145e-04, -1.8674e-04,  1.4999e-05],\n",
       "              [ 1.7828e-04,  4.1651e-04,  8.0188e-04],\n",
       "              [-3.0167e-04,  2.3963e-04,  1.3429e-04]],\n",
       "    \n",
       "             [[-2.6317e-04, -3.9970e-04, -2.3326e-04],\n",
       "              [-2.7201e-04,  5.7252e-05,  1.4479e-04],\n",
       "              [ 3.4100e-04,  4.2520e-05,  8.6202e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.6707e-04,  5.1133e-05, -3.2145e-05],\n",
       "              [ 2.5244e-04,  1.5231e-05, -2.7677e-05],\n",
       "              [ 1.0653e-04, -1.1788e-05, -1.0215e-04]],\n",
       "    \n",
       "             [[ 2.9340e-04, -7.1850e-05, -2.6421e-04],\n",
       "              [-1.4772e-04, -3.3989e-04, -3.7286e-04],\n",
       "              [-4.0711e-04, -3.1996e-04, -3.7533e-04]],\n",
       "    \n",
       "             [[-1.4241e-04, -2.1497e-04, -4.9454e-05],\n",
       "              [-4.0413e-04, -5.4603e-04, -4.7348e-04],\n",
       "              [-8.8823e-05,  1.9571e-04, -1.5275e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.3992e-04,  5.3078e-04,  1.7434e-04],\n",
       "              [ 1.9679e-04,  3.0203e-04,  8.8579e-05],\n",
       "              [ 2.0979e-04,  3.8130e-04, -2.1887e-04]],\n",
       "    \n",
       "             [[ 2.1682e-04,  4.3107e-05,  2.9765e-04],\n",
       "              [ 2.0308e-04, -1.2424e-04, -3.1622e-04],\n",
       "              [-1.0353e-06, -4.1087e-04, -3.2561e-04]],\n",
       "    \n",
       "             [[ 1.7418e-04,  3.2313e-04, -1.1590e-04],\n",
       "              [-2.4487e-04,  1.5071e-04, -1.2678e-04],\n",
       "              [-4.6926e-04,  4.9949e-06, -4.1278e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.8010e-05, -2.4879e-05,  9.3641e-05],\n",
       "              [-2.6684e-04, -2.9708e-04,  5.5069e-05],\n",
       "              [-5.1042e-04, -4.7092e-04,  1.7687e-04]],\n",
       "    \n",
       "             [[-1.9823e-04, -1.2074e-04, -2.4389e-04],\n",
       "              [-1.1328e-04, -7.6361e-05,  3.5906e-04],\n",
       "              [-2.7767e-04, -6.4556e-04, -4.8394e-04]],\n",
       "    \n",
       "             [[ 1.7683e-04,  4.5519e-04,  3.6881e-04],\n",
       "              [-7.6546e-06,  4.4921e-04,  5.5488e-05],\n",
       "              [ 2.5314e-04,  3.9787e-04,  8.5069e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.5161e-04,  3.9891e-04, -1.3433e-04],\n",
       "              [-1.8048e-04,  4.0693e-04, -2.1521e-04],\n",
       "              [-1.5910e-04, -3.5171e-05, -7.9163e-04]],\n",
       "    \n",
       "             [[-3.1555e-04, -2.7543e-04, -3.9796e-05],\n",
       "              [-1.6672e-04,  3.1935e-05,  9.6372e-05],\n",
       "              [-1.7920e-04, -2.6832e-04,  5.2699e-05]],\n",
       "    \n",
       "             [[-2.8205e-05,  5.0402e-04,  3.0509e-04],\n",
       "              [ 3.2283e-04,  5.5033e-04,  3.2095e-04],\n",
       "              [-3.4462e-04, -5.0381e-04, -1.1235e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-7.0815e-06,  1.2669e-04,  5.0563e-04],\n",
       "              [ 9.1817e-05,  5.0440e-05,  1.9542e-04],\n",
       "              [-1.0117e-04, -3.5039e-04, -1.0674e-04]],\n",
       "    \n",
       "             [[-1.8521e-04,  8.1267e-05,  4.9242e-04],\n",
       "              [ 2.0196e-04,  7.7390e-05,  2.9855e-04],\n",
       "              [-1.5090e-04,  1.3611e-04, -2.3315e-04]],\n",
       "    \n",
       "             [[-9.3794e-04, -3.5449e-04, -6.7864e-04],\n",
       "              [-6.6737e-04, -2.0768e-05, -7.5890e-04],\n",
       "              [-4.7462e-05,  1.7040e-04, -3.9178e-04]]]], device='cuda:0')},\n",
       "   37: {'momentum_buffer': tensor([ 1.6622e-03,  1.0300e-03,  1.6685e-03,  1.4026e-03,  1.2555e-03,\n",
       "             2.3719e-03,  1.7008e-03,  2.0027e-03,  1.5087e-03,  1.9807e-03,\n",
       "             1.6908e-03,  1.5395e-03,  2.3653e-03,  1.3694e-03,  4.1870e-03,\n",
       "             2.1522e-03,  2.6312e-03,  2.3685e-03,  1.6752e-03,  2.0269e-03,\n",
       "             2.3997e-04,  7.3688e-04,  1.1272e-03,  2.3029e-03,  1.0893e-03,\n",
       "             9.9188e-04, -6.1516e-05,  1.4289e-03,  2.7305e-03,  2.0614e-03,\n",
       "             2.1689e-03,  7.5172e-04,  1.7943e-03,  8.8791e-04,  3.5958e-04,\n",
       "             2.2160e-03,  1.5332e-03,  1.8828e-03,  1.6004e-03,  1.1876e-03,\n",
       "             1.6106e-03,  2.1690e-03,  2.1387e-03,  1.2341e-03,  2.0365e-03,\n",
       "             1.5092e-03,  2.0558e-03,  1.4220e-03,  2.8646e-03,  1.6522e-03,\n",
       "             1.7285e-03,  1.6132e-03,  2.4070e-03,  1.8357e-03,  1.2993e-03,\n",
       "             4.9852e-04,  2.3567e-03,  2.7428e-03,  1.6030e-03,  1.7131e-03,\n",
       "             1.7054e-03,  1.0375e-03,  2.0015e-03,  3.0183e-03,  1.3862e-03,\n",
       "             1.4251e-03,  1.2783e-03,  2.3072e-03,  9.7130e-04,  2.7615e-03,\n",
       "             3.2181e-03,  1.8137e-03,  2.5089e-03,  1.7813e-03,  2.3100e-03,\n",
       "             2.1167e-03,  2.3202e-03,  8.1072e-04,  1.3016e-03,  2.2558e-03,\n",
       "             1.4746e-03,  2.0081e-03,  2.1029e-03,  2.0670e-03,  1.6371e-03,\n",
       "             1.9165e-03,  2.7201e-03,  2.2534e-03,  3.4278e-03,  1.2113e-03,\n",
       "             1.8499e-03,  1.5316e-03,  2.1130e-03,  1.4662e-03,  5.1830e-04,\n",
       "             8.2545e-04,  2.2454e-03,  2.3949e-03, -5.8696e-04,  1.7737e-03,\n",
       "             1.9265e-03,  1.9569e-03,  1.3494e-03,  2.2830e-03,  2.7293e-04,\n",
       "             2.0519e-03,  1.6755e-03,  2.3272e-03,  1.6293e-03,  1.7761e-03,\n",
       "             8.8655e-04,  2.0209e-03,  2.7385e-03,  1.2753e-03,  2.4459e-03,\n",
       "             1.1613e-03,  2.0363e-03,  2.3422e-03,  1.9205e-03,  1.9505e-03,\n",
       "             2.1534e-03,  3.1908e-03,  8.1107e-04,  9.0411e-04,  1.9628e-03,\n",
       "             1.6221e-03,  1.0685e-03,  1.9799e-03], device='cuda:0')},\n",
       "   38: {'momentum_buffer': tensor([-2.4070e-06,  2.5210e-03,  5.6985e-06,  3.4595e-03, -5.5751e-04,\n",
       "             3.4992e-03,  4.0044e-03,  2.6482e-03,  1.3476e-03, -4.2870e-04,\n",
       "            -3.1251e-04, -5.1259e-04, -2.4831e-04,  5.3659e-05, -3.7615e-03,\n",
       "            -9.6019e-05, -4.7538e-04, -1.1356e-03,  8.6744e-04, -9.5557e-04,\n",
       "             3.5114e-03,  3.1290e-03,  3.7155e-03,  3.2704e-04,  2.1820e-03,\n",
       "             3.5893e-03,  3.5808e-03,  2.3509e-03, -8.1285e-04,  6.4489e-04,\n",
       "             3.2731e-04, -8.0964e-04,  8.2606e-05,  1.0804e-03,  3.6415e-03,\n",
       "             1.6608e-03,  2.0985e-03,  1.9209e-04,  2.5840e-03,  1.3749e-03,\n",
       "             3.5405e-03,  1.2184e-03, -3.7657e-04, -8.7161e-04, -7.0091e-04,\n",
       "            -1.3489e-04, -9.8111e-05,  2.9851e-03, -6.1940e-04, -3.0789e-04,\n",
       "             1.5830e-03,  3.4742e-04, -6.9551e-04,  3.1505e-03,  3.5207e-03,\n",
       "             2.6733e-03, -1.0137e-03, -5.5962e-04, -3.7774e-04,  5.0767e-04,\n",
       "             6.1893e-04,  1.0533e-03,  2.5693e-03, -6.0335e-04, -1.0936e-03,\n",
       "             3.0616e-03,  3.3509e-03, -1.3641e-03, -1.4065e-03, -1.5154e-04,\n",
       "            -1.7306e-03, -5.6815e-04, -2.3159e-03, -2.9783e-04, -6.7594e-04,\n",
       "            -6.1202e-04, -2.3025e-04,  3.6041e-03, -3.1074e-04, -1.7544e-04,\n",
       "             6.4596e-05,  1.0601e-04, -9.2782e-04, -3.9660e-04,  5.2316e-04,\n",
       "            -2.0390e-04, -1.2274e-03, -8.8290e-05, -1.0119e-03,  3.0679e-03,\n",
       "             1.2757e-03,  9.8484e-04,  6.5619e-05,  2.2895e-03,  2.6435e-03,\n",
       "             3.2233e-03,  1.4124e-03, -1.0079e-03,  1.9962e-03,  3.7875e-04,\n",
       "            -9.8463e-04, -2.6885e-04,  3.5203e-03,  9.8129e-04,  1.8410e-03,\n",
       "            -5.5737e-04,  2.3653e-03,  2.8874e-05,  1.6386e-03,  1.8087e-03,\n",
       "             2.7948e-03, -6.0777e-04, -1.4523e-03,  1.7114e-03, -7.2852e-04,\n",
       "            -5.4566e-05, -5.6633e-04, -8.5405e-04,  3.0654e-04,  5.5111e-04,\n",
       "            -7.3761e-04, -1.0729e-03,  3.5883e-03,  4.0503e-03,  2.0030e-03,\n",
       "             4.1613e-06,  3.2309e-03,  3.3776e-03], device='cuda:0')},\n",
       "   39: {'momentum_buffer': tensor([[[[-2.1077e-04]],\n",
       "    \n",
       "             [[ 3.1517e-04]],\n",
       "    \n",
       "             [[-1.9693e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.0774e-04]],\n",
       "    \n",
       "             [[ 7.6716e-05]],\n",
       "    \n",
       "             [[-3.2227e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.3837e-05]],\n",
       "    \n",
       "             [[-3.2968e-04]],\n",
       "    \n",
       "             [[-1.4410e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.9828e-05]],\n",
       "    \n",
       "             [[-2.2047e-04]],\n",
       "    \n",
       "             [[ 1.7149e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.0493e-04]],\n",
       "    \n",
       "             [[-2.8720e-04]],\n",
       "    \n",
       "             [[-7.2641e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.7071e-05]],\n",
       "    \n",
       "             [[ 1.3090e-04]],\n",
       "    \n",
       "             [[-1.0929e-06]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-6.8628e-05]],\n",
       "    \n",
       "             [[-7.5216e-05]],\n",
       "    \n",
       "             [[ 3.2593e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.3189e-04]],\n",
       "    \n",
       "             [[-8.4646e-05]],\n",
       "    \n",
       "             [[ 1.9568e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.1172e-04]],\n",
       "    \n",
       "             [[ 3.2795e-04]],\n",
       "    \n",
       "             [[ 2.9627e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.3790e-04]],\n",
       "    \n",
       "             [[ 3.7116e-05]],\n",
       "    \n",
       "             [[ 3.0649e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.9351e-04]],\n",
       "    \n",
       "             [[ 2.6807e-04]],\n",
       "    \n",
       "             [[ 6.0994e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.2011e-04]],\n",
       "    \n",
       "             [[ 3.8560e-05]],\n",
       "    \n",
       "             [[-2.5571e-04]]]], device='cuda:0')},\n",
       "   40: {'momentum_buffer': tensor([ 4.9092e-04,  1.1456e-04,  5.9308e-04,  9.4402e-04,  6.2317e-04,\n",
       "             1.6121e-03,  1.9909e-03,  3.1292e-05, -1.9172e-04,  1.5518e-03,\n",
       "             1.2305e-03,  2.9004e-03,  1.3836e-03,  6.8149e-04,  4.8122e-04,\n",
       "             1.2980e-03,  2.0728e-03,  1.8992e-03,  2.7964e-03,  1.6574e-03,\n",
       "             4.6528e-04,  1.1450e-03,  3.3647e-04,  1.9907e-03,  1.2819e-03,\n",
       "             2.4687e-03,  2.9812e-03,  1.7535e-03,  8.3335e-04, -1.2042e-06,\n",
       "             2.2657e-03, -2.4435e-05,  1.6307e-03,  1.1200e-03,  1.4783e-03,\n",
       "             2.1278e-05,  7.6512e-04,  1.0695e-03,  2.4885e-03,  1.3041e-03,\n",
       "             1.3645e-03, -3.4303e-04,  9.9233e-04,  2.3155e-03,  8.6776e-04,\n",
       "             1.0290e-03,  1.8066e-03,  1.5341e-03,  3.1309e-04,  1.3718e-03,\n",
       "             8.7494e-04,  1.5346e-03,  6.5860e-04,  1.8262e-03,  3.6621e-03,\n",
       "             1.3636e-03,  1.3439e-03,  1.0769e-03,  1.2806e-03,  9.1387e-04,\n",
       "             9.9640e-04,  2.8530e-04,  7.8919e-04,  4.2930e-04,  1.3456e-03,\n",
       "            -2.9398e-05,  1.7515e-03,  8.8802e-04,  1.2634e-03,  5.4018e-04,\n",
       "             1.4562e-03,  1.7350e-03,  6.6134e-04,  1.5972e-03,  1.6386e-03,\n",
       "             1.7152e-03,  8.2028e-04,  2.2578e-03,  8.1468e-04,  1.5531e-03,\n",
       "             1.7822e-03,  1.2626e-03,  1.0101e-03,  3.6330e-05,  1.0049e-03,\n",
       "             1.3478e-03,  1.0064e-03,  3.3907e-04,  2.1269e-03,  1.1316e-03,\n",
       "             7.8089e-04,  8.2950e-04,  1.8831e-03,  8.5775e-04, -1.0553e-04,\n",
       "             1.8980e-03,  2.0497e-03,  1.3950e-03,  3.0247e-04,  2.8561e-03,\n",
       "             2.0263e-03,  1.6000e-03,  1.8596e-03,  5.4790e-04,  1.8913e-03,\n",
       "             1.5031e-03,  2.0269e-03,  9.7058e-04,  7.3494e-04,  1.2232e-03,\n",
       "             1.8936e-03,  6.7637e-06,  1.9864e-03,  1.6087e-03,  8.8471e-04,\n",
       "             1.9560e-03,  9.1330e-04,  2.6092e-03,  1.5972e-03,  1.7187e-03,\n",
       "             1.1316e-03,  1.7594e-03,  1.5035e-03,  7.3603e-04,  2.3647e-03,\n",
       "             1.2203e-03,  4.8413e-04,  1.5618e-03,  9.3931e-04,  4.0951e-04,\n",
       "             2.1466e-03,  9.1168e-04,  3.0067e-03, -1.6178e-04,  1.3829e-04,\n",
       "             2.8420e-03,  7.8608e-04,  7.7701e-04,  2.5141e-03,  1.4458e-03,\n",
       "             8.6726e-04,  1.0921e-03,  1.9193e-06,  1.6924e-03,  1.5486e-03,\n",
       "             5.9717e-04,  3.2847e-03,  1.4185e-03,  3.1959e-04,  3.7219e-04,\n",
       "             7.0413e-04, -8.1845e-06,  2.4858e-03,  1.1061e-03,  1.8590e-03,\n",
       "             2.0033e-03,  2.0342e-03, -4.8240e-04,  1.6304e-03,  1.0511e-03,\n",
       "             2.5035e-03,  1.4396e-03,  1.8138e-03,  6.1750e-04,  1.0680e-03,\n",
       "             1.2092e-03,  1.5147e-03,  1.9081e-03,  5.1331e-04, -3.2009e-05,\n",
       "             7.2241e-04,  2.6076e-03,  1.9040e-03,  5.2200e-05,  2.6056e-04,\n",
       "             1.3570e-03,  1.1189e-03,  1.5562e-03,  4.9960e-05,  1.0847e-03,\n",
       "             3.2516e-04,  2.4198e-03,  7.3869e-04,  5.2112e-04,  9.9428e-04,\n",
       "             1.3741e-03,  3.2550e-04,  5.1494e-04,  4.8339e-04,  1.0132e-03,\n",
       "             3.2519e-03,  1.3581e-03,  1.8047e-03,  1.2362e-03,  8.9545e-04,\n",
       "             5.9938e-04,  2.2114e-04,  2.2736e-03,  5.8095e-04,  2.7095e-03,\n",
       "             2.1621e-03,  1.9959e-03,  1.1991e-03,  2.3636e-03,  1.2940e-03,\n",
       "             1.2810e-03,  7.4916e-04,  1.5223e-03,  7.7690e-04,  1.7712e-04,\n",
       "             9.2372e-04,  7.4663e-04,  1.7188e-03,  2.8071e-03,  2.1758e-03,\n",
       "             1.1404e-03,  4.5993e-04,  1.3126e-03,  2.0909e-03,  1.8817e-03,\n",
       "             1.6931e-03, -1.5582e-04,  1.2194e-03, -6.3435e-05,  9.2309e-04,\n",
       "             1.1078e-03,  3.0318e-03,  9.8448e-04,  4.6173e-04,  1.7497e-03,\n",
       "             1.1058e-03,  9.5075e-05,  6.8912e-04,  7.3622e-04,  2.6658e-03,\n",
       "             3.1609e-04,  8.2449e-04,  2.0211e-03,  1.6824e-03,  2.4757e-03,\n",
       "             4.2609e-04,  5.2296e-04, -4.2654e-05,  1.5927e-03,  2.9879e-03,\n",
       "             4.8467e-03,  5.7368e-04,  2.3351e-03,  1.4690e-03,  1.3709e-03,\n",
       "             2.2674e-03,  7.5386e-04,  1.8452e-03,  1.8277e-03, -4.6376e-04,\n",
       "             1.4902e-03,  2.0564e-03,  2.0147e-03,  1.0969e-03, -3.4008e-06,\n",
       "             9.0338e-04,  1.2457e-03,  1.6520e-03,  8.9663e-04,  1.8957e-03,\n",
       "             2.4532e-04,  1.4284e-03,  1.3858e-03,  2.5883e-03,  2.7577e-03,\n",
       "             1.9271e-03,  1.9644e-03,  7.3071e-04,  1.9060e-03,  1.3421e-03,\n",
       "             1.4328e-03,  1.6379e-03,  1.4314e-03,  2.4469e-03,  1.8438e-03,\n",
       "             2.8759e-03,  1.2034e-03,  3.1509e-03,  2.4494e-03,  1.8925e-03,\n",
       "            -3.2953e-04,  1.8042e-03,  1.0753e-03,  1.3041e-03,  1.3472e-03,\n",
       "             9.4704e-04,  1.8736e-03,  1.3830e-03,  6.2205e-04,  8.5991e-04,\n",
       "             9.4808e-04,  1.5835e-03,  2.6386e-03,  1.8348e-03,  1.2927e-04,\n",
       "             7.6481e-04,  1.0867e-03,  1.5040e-03,  1.6194e-03,  1.9407e-03,\n",
       "             9.6913e-04,  5.5108e-04,  2.8009e-03,  2.9866e-03, -1.2794e-04,\n",
       "             1.0609e-03,  1.3927e-03,  2.1084e-03,  1.3300e-03,  1.5962e-03,\n",
       "             4.3695e-04,  1.5589e-03,  1.3311e-03,  3.0859e-03,  2.6948e-03,\n",
       "             1.3656e-03,  1.9144e-03,  8.2553e-04,  1.5504e-03,  9.4252e-04,\n",
       "             2.0820e-03,  7.0110e-04,  1.2136e-03,  6.7321e-04,  2.3390e-03,\n",
       "             1.6367e-03,  2.3609e-03,  2.9139e-03,  3.0059e-04,  2.0027e-03,\n",
       "             1.6044e-04,  1.5739e-03,  1.9902e-03,  1.8064e-04,  1.8074e-03,\n",
       "             2.0008e-03,  9.1399e-04,  6.5213e-05,  1.6035e-03,  2.7838e-03,\n",
       "             1.3976e-03,  1.1866e-03,  1.3597e-03,  1.0928e-05,  1.9688e-04,\n",
       "             2.7939e-03,  2.8332e-04,  1.9845e-03,  5.2071e-04,  1.4824e-03,\n",
       "             6.4087e-04,  1.2925e-03,  1.9839e-03,  1.7745e-03,  9.4696e-04,\n",
       "             8.7703e-04,  8.2109e-04,  1.1636e-03,  8.0767e-04,  1.2117e-03,\n",
       "             1.8378e-03,  5.7171e-04,  8.6991e-04,  1.2432e-03,  1.9142e-03,\n",
       "             2.0072e-03,  7.8650e-04,  1.2851e-03,  1.4436e-03,  6.0433e-04,\n",
       "             1.7896e-03,  3.8365e-03,  1.4418e-03,  2.5368e-03,  8.6278e-04,\n",
       "             2.1493e-03,  1.4354e-03,  1.9311e-03,  1.4707e-03,  1.6302e-03,\n",
       "             1.5127e-03,  4.9073e-03,  2.1297e-03,  2.5688e-03,  1.5479e-04,\n",
       "             1.9233e-03,  1.4409e-03,  1.0398e-03,  1.9039e-03,  1.6372e-04,\n",
       "             5.0898e-04,  2.4575e-04,  2.0934e-03,  1.7038e-03,  2.7327e-03,\n",
       "             2.1738e-03,  1.4113e-03,  1.6843e-04,  1.8288e-03,  8.3152e-04,\n",
       "             1.8302e-03,  1.8275e-03,  1.8708e-03,  2.5253e-03,  1.0785e-03,\n",
       "             2.3393e-03,  1.7355e-04,  1.0466e-03,  9.4426e-04,  1.0405e-03,\n",
       "            -4.3170e-05,  7.6752e-04,  1.8912e-03,  1.0925e-03,  1.7279e-03,\n",
       "             5.5219e-04,  1.6072e-03,  1.6738e-03,  8.6407e-04,  2.4123e-04,\n",
       "             2.3950e-04,  2.4665e-03,  1.4719e-03,  9.0089e-04,  1.4841e-03,\n",
       "             1.0449e-04,  2.1170e-03,  1.9845e-03,  2.2129e-03,  1.9739e-03,\n",
       "             8.3439e-04,  9.1882e-05,  1.4865e-03,  1.8006e-03,  1.7443e-03,\n",
       "             1.0206e-03,  5.7527e-04,  7.2817e-04,  2.1177e-03,  1.5572e-03,\n",
       "             1.1354e-03,  4.3999e-04, -1.9944e-04,  1.4354e-03,  1.2539e-03,\n",
       "             4.8453e-04,  6.9323e-04,  1.0174e-03,  4.0472e-04,  1.2512e-03,\n",
       "             1.8574e-03, -9.5032e-05,  6.1684e-04,  1.5347e-03,  2.9032e-05,\n",
       "             3.6385e-03,  1.5799e-03,  2.2356e-03,  1.1091e-03,  1.8312e-03,\n",
       "             2.3151e-03,  1.6346e-03,  2.0925e-03,  9.1818e-04, -9.7115e-05,\n",
       "             1.9169e-03, -6.6398e-05,  2.3328e-03,  1.2137e-03, -5.7762e-05,\n",
       "             1.6241e-03,  8.8497e-04,  1.5628e-03,  6.0790e-04,  6.6145e-04,\n",
       "             4.2016e-04,  1.1640e-03,  1.9259e-03,  2.0189e-04,  1.0875e-03,\n",
       "             1.0441e-03,  1.7685e-03,  1.3220e-03,  1.5481e-03,  1.6683e-03,\n",
       "             1.0373e-03,  1.6750e-03,  3.5186e-04,  2.6244e-03,  7.9077e-05,\n",
       "             2.4876e-03,  1.8150e-04,  1.2274e-03,  2.2030e-03,  2.3008e-03,\n",
       "             1.0065e-03,  2.9167e-03,  3.6684e-04,  1.2627e-03,  8.0013e-04,\n",
       "             2.3099e-03,  1.5042e-03,  8.5188e-04,  8.9489e-04,  7.3598e-04,\n",
       "             8.5820e-04,  1.7068e-03], device='cuda:0')},\n",
       "   41: {'momentum_buffer': tensor([ 1.1782e-03, -3.3405e-04,  5.4301e-04,  1.5001e-03,  3.8334e-04,\n",
       "            -1.8404e-03, -9.6256e-04,  6.3639e-04,  1.2845e-05, -9.9974e-04,\n",
       "            -3.4458e-04,  7.8349e-04, -1.8852e-04,  1.1004e-03, -2.3809e-04,\n",
       "            -1.3900e-04,  1.7357e-04, -1.6473e-04, -5.1546e-04, -1.2422e-04,\n",
       "             4.3800e-04,  8.2999e-04,  7.1768e-04,  1.0346e-04,  3.2549e-04,\n",
       "            -9.9090e-04, -2.8792e-03, -2.2693e-04,  7.3995e-04,  9.5823e-05,\n",
       "            -2.9600e-05,  5.9991e-04, -3.3560e-04, -9.0093e-04, -2.0931e-04,\n",
       "             2.5369e-07, -1.1130e-04, -2.6033e-04,  3.9656e-05,  3.1868e-04,\n",
       "            -1.5351e-04,  9.1845e-04, -7.9126e-05, -1.2761e-04,  4.6199e-04,\n",
       "            -1.9280e-04,  1.7909e-04, -4.5754e-04, -3.9205e-04,  8.7688e-04,\n",
       "            -1.1531e-04, -4.0741e-04,  1.3550e-04, -8.5117e-05, -1.0524e-03,\n",
       "             5.4341e-04,  8.4541e-05, -1.8622e-04,  1.9728e-03,  5.8704e-04,\n",
       "             1.8949e-04,  1.6831e-03,  8.3032e-04, -8.8719e-05,  1.3556e-03,\n",
       "             3.5343e-04,  1.9432e-04,  5.4796e-04, -3.7480e-04, -2.3964e-05,\n",
       "             9.2708e-04,  4.2782e-04, -5.7694e-04,  3.4828e-04,  3.4358e-04,\n",
       "             3.6808e-04,  4.4546e-04,  7.2054e-06, -3.2532e-04,  1.5771e-04,\n",
       "            -2.2152e-04, -1.3902e-03,  6.3260e-05,  9.6097e-04, -2.3403e-04,\n",
       "            -2.4961e-04,  1.0114e-03, -2.8529e-05,  1.2406e-04, -2.4702e-04,\n",
       "             9.4177e-04,  5.8357e-04, -4.1453e-04,  1.1398e-05,  8.9892e-04,\n",
       "            -2.2751e-04, -1.1322e-03, -8.5563e-04,  7.9762e-04, -7.8936e-04,\n",
       "             3.0297e-04,  3.2900e-05, -1.0346e-03,  1.8313e-03,  9.8982e-04,\n",
       "             7.6769e-04, -5.3474e-04, -1.0561e-04,  6.7204e-04,  5.1636e-04,\n",
       "             7.7812e-04,  6.2686e-04, -2.0897e-04, -2.1517e-03,  2.4179e-04,\n",
       "             1.2307e-04,  1.2718e-04, -2.7017e-04,  4.5584e-04,  1.4892e-04,\n",
       "             6.3968e-04, -5.1168e-04, -4.1205e-04,  3.0068e-04,  7.8851e-05,\n",
       "            -7.7627e-05, -9.5015e-05, -4.7011e-04, -1.7204e-04,  5.1845e-04,\n",
       "            -1.9824e-03,  8.2835e-04, -2.0769e-03,  1.5035e-04,  1.6223e-03,\n",
       "            -1.1375e-03,  1.2653e-04, -3.9663e-04, -4.1974e-06,  6.0373e-05,\n",
       "            -2.3741e-05, -3.0274e-04,  4.3107e-04,  3.4339e-04, -7.5569e-05,\n",
       "            -9.6317e-04,  7.1144e-04, -2.2234e-04,  1.1761e-03, -1.2076e-04,\n",
       "             3.0879e-04,  1.4562e-03, -3.1609e-04, -5.0632e-04,  6.9691e-04,\n",
       "             6.4472e-04, -2.9916e-04,  2.5691e-04,  1.1117e-04,  7.0468e-04,\n",
       "             1.9515e-03,  2.8301e-04, -2.1192e-04,  4.3152e-04, -1.0245e-03,\n",
       "             5.3346e-04,  2.0374e-03, -1.9370e-04, -1.6618e-04,  1.3911e-03,\n",
       "             1.3890e-03, -1.0362e-03, -7.8898e-04,  8.1831e-05,  6.0029e-05,\n",
       "            -4.7434e-04,  7.3114e-04, -2.0171e-05,  3.7572e-04, -1.7725e-04,\n",
       "            -1.0295e-03, -2.0381e-03,  3.0413e-04,  5.6122e-05,  1.9859e-04,\n",
       "            -3.3627e-04,  3.9271e-05,  8.1843e-04,  4.5426e-04,  7.2906e-04,\n",
       "            -1.2830e-04,  1.7907e-04,  4.0185e-04, -8.3564e-04, -1.6076e-04,\n",
       "             4.6791e-05, -3.4230e-04,  7.6963e-04, -2.1118e-05, -2.5243e-03,\n",
       "             1.7528e-04,  5.6650e-04, -1.4558e-04,  1.3281e-03,  1.1935e-03,\n",
       "            -5.8364e-04, -2.0377e-04,  4.2591e-04, -5.1174e-05,  9.9499e-04,\n",
       "             9.9495e-04,  1.1218e-04, -9.2043e-05, -2.9933e-03, -1.0758e-03,\n",
       "            -1.0533e-04,  6.1845e-05,  4.7922e-04,  1.6941e-04, -8.3582e-04,\n",
       "            -4.2696e-05,  1.1743e-03,  1.0645e-03,  7.3313e-04,  1.1184e-04,\n",
       "             5.5331e-04, -1.3540e-03,  6.2653e-05, -9.4055e-05,  6.5023e-05,\n",
       "            -6.4147e-04, -1.6000e-04, -1.9904e-04,  6.2115e-04, -3.8936e-04,\n",
       "            -2.4826e-04, -8.2388e-04,  8.9739e-04, -5.5478e-04,  2.8694e-04,\n",
       "            -6.7483e-04, -3.0114e-04,  8.2339e-04,  4.0463e-04, -4.8205e-05,\n",
       "            -2.0872e-04,  7.9757e-04,  8.1706e-04,  3.0749e-04, -2.0949e-04,\n",
       "             3.6307e-05,  2.0233e-03, -3.4179e-04, -6.3239e-05,  5.1769e-04,\n",
       "            -4.8936e-04, -6.6052e-05,  5.3710e-05,  5.6899e-05,  1.5615e-03,\n",
       "             3.7094e-04,  2.8030e-04, -5.2268e-04,  8.5216e-05,  1.9402e-04,\n",
       "            -2.9807e-04,  3.7405e-04, -3.5794e-06, -1.3015e-03, -1.0064e-03,\n",
       "             7.7990e-04, -3.2311e-04, -8.5503e-05, -9.5214e-04, -6.9985e-04,\n",
       "             4.4334e-04,  4.3208e-04, -4.3028e-04,  2.4754e-04,  4.3594e-04,\n",
       "             5.8974e-04,  6.6892e-04, -6.3400e-04, -4.8018e-04,  1.9150e-03,\n",
       "             1.2547e-03,  2.2884e-04,  7.8635e-04, -6.6408e-05, -4.2405e-04,\n",
       "             5.2388e-04, -1.5993e-03, -3.4190e-04,  1.2552e-04, -3.2585e-04,\n",
       "             1.6386e-04,  2.9227e-04,  2.7894e-04,  2.9928e-04, -1.9874e-04,\n",
       "             3.4897e-04,  1.8772e-04,  2.5646e-04,  4.7453e-04, -4.7264e-04,\n",
       "             6.1121e-05,  2.3620e-04,  9.8806e-05, -3.5614e-04,  7.6350e-04,\n",
       "            -1.3144e-05,  3.1146e-06, -8.0317e-05,  6.8700e-04, -4.0112e-04,\n",
       "             3.4648e-04,  8.0193e-04,  2.1494e-04, -1.4971e-03, -1.1037e-04,\n",
       "             1.8535e-03,  1.1779e-04,  1.2020e-03,  2.7379e-04,  3.8031e-04,\n",
       "             5.3928e-04, -1.7141e-04, -3.0030e-04,  4.8560e-04, -1.1850e-03,\n",
       "            -4.3427e-04, -3.1968e-04, -1.0805e-03, -1.6357e-04,  1.6038e-04,\n",
       "             3.2892e-04,  2.7131e-04, -1.9565e-04,  4.4382e-04,  7.4695e-04,\n",
       "            -5.3264e-04, -1.0529e-03, -2.1943e-04,  1.8487e-04, -2.2931e-04,\n",
       "             2.6920e-04,  7.3024e-04,  1.1289e-03, -2.8960e-04, -3.4877e-04,\n",
       "            -2.2637e-03,  1.2189e-03, -1.1822e-04,  1.1836e-04,  2.1597e-04,\n",
       "             1.1060e-03,  4.6267e-04,  3.3052e-05, -6.0112e-04, -3.6205e-04,\n",
       "            -5.4479e-05,  1.2352e-04, -3.6802e-04,  4.4923e-04, -8.9407e-04,\n",
       "             7.9178e-05,  3.2501e-04, -1.1085e-04,  3.6455e-05, -2.1648e-04,\n",
       "             5.7419e-04,  4.6362e-04, -3.3219e-04,  4.9989e-04,  5.7574e-04,\n",
       "             2.9803e-04, -9.8476e-04,  8.5201e-04,  4.4921e-04, -1.7017e-03,\n",
       "            -7.9102e-04, -2.1964e-06, -4.8429e-04,  7.7591e-04,  6.2475e-04,\n",
       "             4.6748e-04, -2.8070e-03,  2.5702e-04, -3.1798e-04, -1.7766e-04,\n",
       "             1.5909e-04, -3.3764e-04, -1.3904e-04,  3.2947e-04, -4.0590e-04,\n",
       "             9.4626e-04, -1.3081e-04, -2.0332e-03,  5.0799e-04,  2.1002e-03,\n",
       "             6.9448e-05,  3.4369e-05, -3.6314e-04, -9.1961e-04,  1.0324e-03,\n",
       "            -6.0691e-04, -2.3021e-04,  5.0413e-04,  7.2641e-04, -5.0673e-04,\n",
       "             4.0333e-04, -7.3848e-04, -2.2362e-05,  7.2046e-04,  9.2443e-04,\n",
       "            -1.7599e-05,  6.7645e-04, -1.1714e-03,  2.7755e-04,  4.7906e-04,\n",
       "             7.3308e-05, -1.3985e-03,  6.4143e-04,  2.5794e-04,  6.0416e-05,\n",
       "             3.7099e-04, -2.2060e-03, -1.0130e-04,  8.2566e-04,  5.9591e-05,\n",
       "            -7.2407e-04, -9.1160e-04,  9.7891e-05,  2.1998e-04,  4.3624e-04,\n",
       "             1.0781e-04,  7.3305e-04, -1.3934e-04, -7.0180e-04, -1.4262e-03,\n",
       "            -2.1085e-04,  1.7939e-04,  8.3464e-05, -1.0947e-03,  1.5355e-03,\n",
       "             5.2962e-04,  2.6803e-04,  1.2328e-03,  8.7416e-04,  6.1712e-04,\n",
       "             8.4886e-04,  1.9363e-03, -3.5310e-04, -2.1960e-04,  5.9417e-04,\n",
       "             2.3006e-04,  2.0660e-03, -4.6511e-05,  9.2459e-04,  2.0473e-03,\n",
       "            -4.8074e-04,  1.0805e-04, -3.9554e-04, -4.3197e-04,  8.6806e-04,\n",
       "            -9.8426e-04, -6.7856e-04, -5.4341e-04,  4.0480e-04,  1.2500e-03,\n",
       "            -1.4439e-06,  1.4410e-03, -1.9135e-04, -3.3276e-04,  1.4823e-03,\n",
       "            -3.8324e-04, -3.1044e-04, -3.4134e-04,  7.0883e-04,  5.6044e-04,\n",
       "            -3.0492e-04,  1.5783e-03, -7.7322e-05, -9.0786e-04, -2.6800e-04,\n",
       "             6.9819e-05, -1.1879e-03,  4.3528e-05,  6.3881e-05,  5.5383e-04,\n",
       "            -2.8593e-04,  1.0862e-03,  3.7394e-04,  8.5315e-04,  1.1789e-03,\n",
       "            -3.2860e-03, -9.5821e-05, -6.5652e-04, -1.4339e-03, -3.4558e-04,\n",
       "            -7.1522e-07, -2.0051e-03,  2.7048e-04, -1.6597e-04, -5.3263e-04,\n",
       "             2.6628e-04, -3.0365e-04, -1.5455e-04,  6.7108e-04,  1.1495e-03,\n",
       "             7.2574e-05, -9.8582e-05], device='cuda:0')},\n",
       "   42: {'momentum_buffer': tensor([[[[ 9.7180e-05]],\n",
       "    \n",
       "             [[ 6.2192e-05]],\n",
       "    \n",
       "             [[ 2.6264e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.7604e-04]],\n",
       "    \n",
       "             [[-6.1313e-05]],\n",
       "    \n",
       "             [[-6.7629e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 6.3571e-05]],\n",
       "    \n",
       "             [[-7.6739e-05]],\n",
       "    \n",
       "             [[ 9.4901e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-9.7121e-05]],\n",
       "    \n",
       "             [[-2.8200e-05]],\n",
       "    \n",
       "             [[-8.6497e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.1742e-04]],\n",
       "    \n",
       "             [[ 1.3369e-04]],\n",
       "    \n",
       "             [[-5.5166e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.1995e-04]],\n",
       "    \n",
       "             [[-4.6289e-06]],\n",
       "    \n",
       "             [[ 3.0594e-08]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-3.3680e-06]],\n",
       "    \n",
       "             [[ 3.6291e-04]],\n",
       "    \n",
       "             [[-9.0332e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.7883e-06]],\n",
       "    \n",
       "             [[ 1.7463e-04]],\n",
       "    \n",
       "             [[ 3.1854e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.2680e-05]],\n",
       "    \n",
       "             [[-2.8554e-05]],\n",
       "    \n",
       "             [[-1.5916e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.5539e-04]],\n",
       "    \n",
       "             [[ 1.0408e-04]],\n",
       "    \n",
       "             [[-9.5233e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.2310e-05]],\n",
       "    \n",
       "             [[-2.6075e-05]],\n",
       "    \n",
       "             [[ 4.7294e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.6730e-04]],\n",
       "    \n",
       "             [[-1.2970e-04]],\n",
       "    \n",
       "             [[-4.6031e-05]]]], device='cuda:0')},\n",
       "   43: {'momentum_buffer': tensor([ 1.8347e-03,  5.3682e-04,  1.0764e-03,  2.3382e-03,  1.5401e-03,\n",
       "             1.0224e-03,  2.8194e-03,  8.7990e-04,  2.9360e-03,  7.3909e-04,\n",
       "             2.6433e-03,  4.2768e-04,  4.6654e-04,  3.3749e-04,  1.9884e-05,\n",
       "             5.0674e-04,  6.3975e-04,  1.5169e-03,  8.4971e-04,  3.6596e-04,\n",
       "             1.7313e-03,  9.0565e-05,  2.0252e-03,  1.2210e-03,  1.1699e-03,\n",
       "             1.4540e-03,  2.2591e-03,  7.4086e-04,  3.2876e-04,  2.3981e-03,\n",
       "             8.3772e-04, -1.0811e-04,  7.6308e-04,  1.4918e-03,  5.3245e-04,\n",
       "             4.7422e-04,  4.2217e-04,  3.1862e-03,  1.3789e-03,  1.8926e-03,\n",
       "             1.6820e-03,  2.8360e-03,  1.6333e-04,  7.6441e-04,  5.3041e-04,\n",
       "             5.6963e-04, -2.4580e-04,  7.9460e-04,  6.5452e-04,  9.3134e-04,\n",
       "             9.1062e-04,  7.7593e-04,  3.3223e-04,  1.2434e-03,  1.3454e-03,\n",
       "             6.2824e-04,  8.0274e-04,  1.6612e-03,  1.1986e-03,  6.4926e-04,\n",
       "             1.3092e-03,  6.3157e-04,  1.0729e-03,  5.8217e-05,  1.0660e-03,\n",
       "             3.5744e-03,  7.8663e-04,  9.8943e-04,  5.7834e-04,  1.7145e-03,\n",
       "             1.9065e-03,  1.0065e-03,  5.0924e-04,  7.9473e-04,  9.4892e-04,\n",
       "             7.6389e-04,  1.0058e-03,  1.2288e-03,  3.5053e-05,  1.2574e-03,\n",
       "             8.1107e-04,  2.6764e-03,  1.3283e-03,  3.0104e-03,  1.5249e-03,\n",
       "             4.0042e-04,  1.3209e-03,  1.2143e-03,  1.1876e-03,  2.3457e-03,\n",
       "             3.2522e-04,  8.2362e-04,  1.0300e-03,  1.6674e-03,  5.0566e-04,\n",
       "             6.0184e-04,  1.6798e-03,  2.1910e-03,  2.9508e-03,  8.3593e-04,\n",
       "             8.6029e-04,  1.9910e-04,  1.2066e-03,  2.9995e-03,  8.7477e-04,\n",
       "            -1.1270e-03,  1.6643e-03,  1.7097e-04,  2.5524e-03,  1.0678e-03,\n",
       "             4.1338e-04,  1.6598e-03,  4.7328e-04,  3.5620e-03,  1.5346e-03,\n",
       "             5.9537e-04,  2.7069e-03,  1.7059e-03,  1.1370e-04,  1.1883e-03,\n",
       "             5.1241e-04,  6.0597e-04,  1.3224e-03,  9.5014e-04,  1.1782e-03,\n",
       "             1.3511e-03,  3.3041e-03,  2.2271e-03,  6.5808e-04,  2.0517e-03,\n",
       "             3.0238e-03, -3.7210e-04,  1.8961e-03,  3.6208e-03,  2.5737e-03,\n",
       "             1.2196e-03,  1.5957e-03,  8.0731e-04,  2.3624e-04,  4.5328e-04,\n",
       "             8.7253e-04,  4.1172e-04,  2.2643e-03,  2.7586e-04,  1.0433e-03,\n",
       "             2.9248e-04,  7.4107e-04,  8.8498e-04, -5.7122e-04,  1.4000e-03,\n",
       "             1.0968e-03,  2.5357e-03,  6.4202e-04,  8.5088e-04,  2.1661e-03,\n",
       "             7.3554e-04,  7.6546e-04,  5.6822e-04,  5.1705e-04,  8.5126e-04,\n",
       "            -1.1895e-04,  1.0515e-03,  5.8368e-04,  1.8403e-03,  1.1573e-03,\n",
       "            -6.4437e-05,  7.2572e-04,  1.6005e-03,  3.1141e-03,  2.9123e-03,\n",
       "             7.4769e-04,  1.6484e-03,  1.7898e-03,  2.8028e-04,  2.1217e-05,\n",
       "             1.2707e-03,  4.8418e-04,  1.0441e-03,  7.6357e-04,  5.4571e-04,\n",
       "             4.8017e-04,  1.4848e-03,  8.3224e-04,  6.6477e-04,  4.2038e-04,\n",
       "             4.0760e-04,  6.6434e-04,  2.7448e-03,  3.1091e-03,  1.3182e-03,\n",
       "             1.2630e-03,  1.4265e-03,  7.5624e-04,  2.8492e-03,  7.2899e-04,\n",
       "             3.0255e-04,  4.2983e-04,  5.9844e-04,  6.7312e-04,  2.4683e-03,\n",
       "             4.7641e-04,  1.6022e-03,  1.2297e-03,  4.0176e-04,  2.3448e-03,\n",
       "             5.2731e-04,  1.6903e-03,  5.0281e-04,  1.5031e-04,  3.4878e-04,\n",
       "             1.0388e-03,  6.5152e-04,  5.7342e-04,  2.5624e-03,  1.5495e-03,\n",
       "             5.0196e-04,  8.1031e-04,  8.1224e-04, -8.6212e-05,  2.0564e-03,\n",
       "             8.6349e-04,  1.9473e-03,  1.6355e-03,  1.9254e-03,  1.0724e-03,\n",
       "             6.9163e-04,  1.6881e-03,  3.4559e-04,  6.8525e-04,  4.9474e-04,\n",
       "             4.9928e-04,  2.9348e-03,  4.9319e-04,  2.6174e-03,  1.6311e-03,\n",
       "             5.3386e-04,  3.3870e-03,  1.0520e-03,  2.2711e-03,  1.3057e-03,\n",
       "             2.0065e-03,  5.7833e-04,  1.6376e-03,  7.7149e-04,  1.8962e-04,\n",
       "             2.1538e-03, -6.5182e-06,  7.9973e-04,  8.1082e-04,  4.0722e-04,\n",
       "            -2.2843e-04,  1.4904e-03,  1.1173e-03,  1.4259e-03,  1.9194e-03,\n",
       "             2.3541e-03,  1.0478e-03,  2.7146e-04,  3.3482e-03,  1.4661e-03,\n",
       "             1.7976e-03,  3.4255e-04,  7.8435e-04,  9.5630e-04,  8.0652e-05,\n",
       "             6.1199e-04,  1.1021e-04,  1.0437e-03,  1.4498e-03,  1.7163e-03,\n",
       "             7.9279e-04,  1.1333e-03,  5.6789e-04,  9.8027e-04,  2.0438e-03,\n",
       "             1.0067e-03,  7.7030e-04,  1.1199e-03,  1.7084e-03,  1.9517e-03,\n",
       "             1.0541e-03, -3.7241e-04,  2.0299e-03,  1.0996e-03,  7.2652e-04,\n",
       "             2.0782e-03,  2.4262e-04,  1.1068e-03,  5.4941e-04,  2.4107e-03,\n",
       "             6.8645e-04,  3.3274e-03,  8.7957e-04,  9.1096e-04,  3.3076e-04,\n",
       "             1.5157e-04,  5.5712e-04,  5.3783e-04,  6.9169e-04,  5.2877e-04,\n",
       "             2.7186e-03,  2.0311e-03,  9.5293e-04,  8.9177e-04,  7.3820e-04,\n",
       "             1.3124e-03,  9.8365e-04,  6.3645e-04,  9.8652e-04,  9.8525e-04,\n",
       "             6.8983e-04,  3.4191e-04,  1.0738e-03,  1.2628e-03,  9.2214e-04,\n",
       "             2.8604e-04, -2.4015e-04,  5.7792e-04,  2.1314e-03,  1.2465e-03,\n",
       "             6.5011e-04,  1.2383e-03,  1.8479e-03,  1.1792e-03,  4.2322e-04,\n",
       "             1.8949e-03,  5.8725e-04,  1.2010e-03,  2.4312e-03,  6.6008e-04,\n",
       "             9.0023e-04,  8.1980e-04,  1.6000e-03,  9.9447e-04,  7.9737e-04,\n",
       "             1.2275e-03,  9.5355e-04,  1.3283e-03,  2.8769e-04,  7.0693e-04,\n",
       "             1.9435e-03,  2.8166e-03,  4.2328e-03,  6.6628e-04,  6.9006e-04,\n",
       "             8.4427e-04,  1.0559e-03,  2.6858e-04,  7.4516e-04,  5.2156e-04,\n",
       "             1.2625e-03,  1.6938e-03,  7.6153e-04,  2.7937e-04,  1.5520e-03,\n",
       "             7.9946e-04,  4.1540e-04,  1.4240e-03,  2.0936e-03, -1.5211e-04,\n",
       "             4.5038e-04,  4.1282e-04,  1.2006e-03,  4.6996e-04,  3.3462e-03,\n",
       "             9.8467e-04,  2.9399e-03,  5.4745e-04,  1.3707e-03,  8.7906e-04,\n",
       "             9.9315e-04,  4.9371e-04,  2.1655e-04,  1.1812e-03,  2.5723e-03,\n",
       "             1.7638e-04,  1.8704e-03,  1.0621e-03,  1.1654e-03,  1.0288e-03,\n",
       "             6.5423e-04,  1.3020e-03,  1.3181e-03,  2.9919e-04,  3.8142e-04,\n",
       "             9.9141e-04,  4.2183e-03,  1.3022e-03,  8.5235e-04,  1.6961e-04,\n",
       "             1.3846e-03,  1.7619e-03,  1.5174e-03,  1.4750e-03,  3.6760e-05,\n",
       "             1.6512e-04,  2.0227e-04,  1.8354e-03,  8.5486e-04,  2.2232e-03,\n",
       "             9.9407e-04,  1.6529e-03,  1.6230e-03,  2.7157e-03,  1.8679e-04,\n",
       "             5.2317e-04,  1.7308e-04,  7.0903e-04,  1.1323e-03,  4.7079e-04,\n",
       "             1.3610e-03, -1.3630e-06,  1.7415e-04,  1.0742e-03,  1.2245e-03,\n",
       "             4.9278e-04,  1.5029e-03,  1.1282e-03, -3.8203e-05,  8.1392e-05,\n",
       "             1.9183e-03,  3.0008e-03,  5.4515e-04,  3.3065e-04,  3.6261e-06,\n",
       "             1.0132e-03,  1.6458e-03,  3.3845e-04,  3.9952e-04,  1.0140e-03,\n",
       "             5.0484e-05,  1.3159e-03,  4.7521e-04,  4.8185e-04,  5.8691e-04,\n",
       "             1.6833e-03,  5.6135e-04,  5.5713e-04,  5.3339e-04,  1.9199e-03,\n",
       "             5.2186e-04,  2.3456e-03,  8.0382e-04,  2.9554e-03,  4.4089e-04,\n",
       "             1.1279e-03,  2.0725e-04,  2.7474e-03, -1.6998e-04,  2.0479e-03,\n",
       "             1.3968e-03,  1.7094e-03,  5.6010e-04,  4.4043e-04,  7.4513e-05,\n",
       "             7.0629e-04,  1.6940e-03,  8.8879e-04,  1.2247e-03,  1.0859e-03,\n",
       "             2.8655e-03,  5.2180e-04,  1.1801e-03,  7.7404e-04,  1.1676e-03,\n",
       "             1.7860e-03,  1.7456e-03,  6.2702e-04,  6.4979e-04,  9.8056e-04,\n",
       "             9.2936e-04,  2.3128e-03,  1.1554e-03,  5.0363e-04, -1.0880e-03,\n",
       "             8.6121e-04, -5.9569e-04,  6.7296e-04,  2.5741e-03,  4.3001e-04,\n",
       "             5.0612e-04,  4.5889e-04,  5.3147e-04,  4.3681e-04,  2.1731e-03,\n",
       "             5.5059e-04,  3.0661e-03,  1.2260e-03,  8.3315e-04,  1.8245e-03,\n",
       "             1.1864e-03,  9.5714e-04,  3.3619e-04,  7.3577e-04,  4.9550e-04,\n",
       "             4.0329e-03,  8.2049e-04,  2.5490e-03,  1.2471e-03,  9.0473e-04,\n",
       "             8.5406e-04,  2.0926e-03,  2.2215e-03,  1.2261e-03,  1.3757e-04,\n",
       "             9.0706e-04,  1.4751e-03,  7.1378e-04,  4.5147e-04,  1.4125e-03,\n",
       "             1.4500e-04,  4.7625e-04], device='cuda:0')},\n",
       "   44: {'momentum_buffer': tensor([ 1.1782e-03, -3.3405e-04,  5.4301e-04,  1.5001e-03,  3.8334e-04,\n",
       "            -1.8404e-03, -9.6256e-04,  6.3639e-04,  1.2845e-05, -9.9974e-04,\n",
       "            -3.4458e-04,  7.8349e-04, -1.8852e-04,  1.1004e-03, -2.3809e-04,\n",
       "            -1.3900e-04,  1.7357e-04, -1.6473e-04, -5.1546e-04, -1.2422e-04,\n",
       "             4.3800e-04,  8.2999e-04,  7.1768e-04,  1.0346e-04,  3.2549e-04,\n",
       "            -9.9090e-04, -2.8792e-03, -2.2693e-04,  7.3995e-04,  9.5823e-05,\n",
       "            -2.9600e-05,  5.9991e-04, -3.3560e-04, -9.0093e-04, -2.0931e-04,\n",
       "             2.5369e-07, -1.1130e-04, -2.6033e-04,  3.9656e-05,  3.1868e-04,\n",
       "            -1.5351e-04,  9.1845e-04, -7.9126e-05, -1.2761e-04,  4.6199e-04,\n",
       "            -1.9280e-04,  1.7909e-04, -4.5754e-04, -3.9205e-04,  8.7688e-04,\n",
       "            -1.1531e-04, -4.0741e-04,  1.3550e-04, -8.5117e-05, -1.0524e-03,\n",
       "             5.4341e-04,  8.4541e-05, -1.8622e-04,  1.9728e-03,  5.8704e-04,\n",
       "             1.8949e-04,  1.6831e-03,  8.3032e-04, -8.8719e-05,  1.3556e-03,\n",
       "             3.5343e-04,  1.9432e-04,  5.4796e-04, -3.7480e-04, -2.3964e-05,\n",
       "             9.2708e-04,  4.2782e-04, -5.7694e-04,  3.4828e-04,  3.4358e-04,\n",
       "             3.6808e-04,  4.4546e-04,  7.2054e-06, -3.2532e-04,  1.5771e-04,\n",
       "            -2.2152e-04, -1.3902e-03,  6.3260e-05,  9.6097e-04, -2.3403e-04,\n",
       "            -2.4961e-04,  1.0114e-03, -2.8529e-05,  1.2406e-04, -2.4702e-04,\n",
       "             9.4177e-04,  5.8357e-04, -4.1453e-04,  1.1398e-05,  8.9892e-04,\n",
       "            -2.2751e-04, -1.1322e-03, -8.5563e-04,  7.9762e-04, -7.8936e-04,\n",
       "             3.0297e-04,  3.2900e-05, -1.0346e-03,  1.8313e-03,  9.8982e-04,\n",
       "             7.6769e-04, -5.3474e-04, -1.0561e-04,  6.7204e-04,  5.1636e-04,\n",
       "             7.7812e-04,  6.2686e-04, -2.0897e-04, -2.1517e-03,  2.4179e-04,\n",
       "             1.2307e-04,  1.2718e-04, -2.7017e-04,  4.5584e-04,  1.4892e-04,\n",
       "             6.3968e-04, -5.1168e-04, -4.1205e-04,  3.0068e-04,  7.8851e-05,\n",
       "            -7.7627e-05, -9.5015e-05, -4.7011e-04, -1.7204e-04,  5.1845e-04,\n",
       "            -1.9824e-03,  8.2835e-04, -2.0769e-03,  1.5035e-04,  1.6223e-03,\n",
       "            -1.1375e-03,  1.2653e-04, -3.9663e-04, -4.1974e-06,  6.0373e-05,\n",
       "            -2.3741e-05, -3.0274e-04,  4.3107e-04,  3.4339e-04, -7.5569e-05,\n",
       "            -9.6317e-04,  7.1144e-04, -2.2234e-04,  1.1761e-03, -1.2076e-04,\n",
       "             3.0879e-04,  1.4562e-03, -3.1609e-04, -5.0632e-04,  6.9691e-04,\n",
       "             6.4472e-04, -2.9916e-04,  2.5691e-04,  1.1117e-04,  7.0468e-04,\n",
       "             1.9515e-03,  2.8301e-04, -2.1192e-04,  4.3152e-04, -1.0245e-03,\n",
       "             5.3346e-04,  2.0374e-03, -1.9370e-04, -1.6618e-04,  1.3911e-03,\n",
       "             1.3890e-03, -1.0362e-03, -7.8898e-04,  8.1831e-05,  6.0029e-05,\n",
       "            -4.7434e-04,  7.3114e-04, -2.0171e-05,  3.7572e-04, -1.7725e-04,\n",
       "            -1.0295e-03, -2.0381e-03,  3.0413e-04,  5.6122e-05,  1.9859e-04,\n",
       "            -3.3627e-04,  3.9271e-05,  8.1843e-04,  4.5426e-04,  7.2906e-04,\n",
       "            -1.2830e-04,  1.7907e-04,  4.0185e-04, -8.3564e-04, -1.6076e-04,\n",
       "             4.6791e-05, -3.4230e-04,  7.6963e-04, -2.1118e-05, -2.5243e-03,\n",
       "             1.7528e-04,  5.6650e-04, -1.4558e-04,  1.3281e-03,  1.1935e-03,\n",
       "            -5.8364e-04, -2.0377e-04,  4.2591e-04, -5.1174e-05,  9.9499e-04,\n",
       "             9.9495e-04,  1.1218e-04, -9.2043e-05, -2.9933e-03, -1.0758e-03,\n",
       "            -1.0533e-04,  6.1845e-05,  4.7922e-04,  1.6941e-04, -8.3582e-04,\n",
       "            -4.2696e-05,  1.1743e-03,  1.0645e-03,  7.3313e-04,  1.1184e-04,\n",
       "             5.5331e-04, -1.3540e-03,  6.2653e-05, -9.4055e-05,  6.5023e-05,\n",
       "            -6.4147e-04, -1.6000e-04, -1.9904e-04,  6.2115e-04, -3.8936e-04,\n",
       "            -2.4826e-04, -8.2388e-04,  8.9739e-04, -5.5478e-04,  2.8694e-04,\n",
       "            -6.7483e-04, -3.0114e-04,  8.2339e-04,  4.0463e-04, -4.8205e-05,\n",
       "            -2.0872e-04,  7.9757e-04,  8.1706e-04,  3.0749e-04, -2.0949e-04,\n",
       "             3.6307e-05,  2.0233e-03, -3.4179e-04, -6.3239e-05,  5.1769e-04,\n",
       "            -4.8936e-04, -6.6052e-05,  5.3710e-05,  5.6899e-05,  1.5615e-03,\n",
       "             3.7094e-04,  2.8030e-04, -5.2268e-04,  8.5216e-05,  1.9402e-04,\n",
       "            -2.9807e-04,  3.7405e-04, -3.5794e-06, -1.3015e-03, -1.0064e-03,\n",
       "             7.7990e-04, -3.2311e-04, -8.5503e-05, -9.5214e-04, -6.9985e-04,\n",
       "             4.4334e-04,  4.3208e-04, -4.3028e-04,  2.4754e-04,  4.3594e-04,\n",
       "             5.8974e-04,  6.6892e-04, -6.3400e-04, -4.8018e-04,  1.9150e-03,\n",
       "             1.2547e-03,  2.2884e-04,  7.8635e-04, -6.6408e-05, -4.2405e-04,\n",
       "             5.2388e-04, -1.5993e-03, -3.4190e-04,  1.2552e-04, -3.2585e-04,\n",
       "             1.6386e-04,  2.9227e-04,  2.7894e-04,  2.9928e-04, -1.9874e-04,\n",
       "             3.4897e-04,  1.8772e-04,  2.5646e-04,  4.7453e-04, -4.7264e-04,\n",
       "             6.1121e-05,  2.3620e-04,  9.8806e-05, -3.5614e-04,  7.6350e-04,\n",
       "            -1.3144e-05,  3.1146e-06, -8.0317e-05,  6.8700e-04, -4.0112e-04,\n",
       "             3.4648e-04,  8.0193e-04,  2.1494e-04, -1.4971e-03, -1.1037e-04,\n",
       "             1.8535e-03,  1.1779e-04,  1.2020e-03,  2.7379e-04,  3.8031e-04,\n",
       "             5.3928e-04, -1.7141e-04, -3.0030e-04,  4.8560e-04, -1.1850e-03,\n",
       "            -4.3427e-04, -3.1968e-04, -1.0805e-03, -1.6357e-04,  1.6038e-04,\n",
       "             3.2892e-04,  2.7131e-04, -1.9565e-04,  4.4382e-04,  7.4695e-04,\n",
       "            -5.3264e-04, -1.0529e-03, -2.1943e-04,  1.8487e-04, -2.2931e-04,\n",
       "             2.6920e-04,  7.3024e-04,  1.1289e-03, -2.8960e-04, -3.4877e-04,\n",
       "            -2.2637e-03,  1.2189e-03, -1.1822e-04,  1.1836e-04,  2.1597e-04,\n",
       "             1.1060e-03,  4.6267e-04,  3.3052e-05, -6.0112e-04, -3.6205e-04,\n",
       "            -5.4479e-05,  1.2352e-04, -3.6802e-04,  4.4923e-04, -8.9407e-04,\n",
       "             7.9178e-05,  3.2501e-04, -1.1085e-04,  3.6455e-05, -2.1648e-04,\n",
       "             5.7419e-04,  4.6362e-04, -3.3219e-04,  4.9989e-04,  5.7574e-04,\n",
       "             2.9803e-04, -9.8476e-04,  8.5201e-04,  4.4921e-04, -1.7017e-03,\n",
       "            -7.9102e-04, -2.1964e-06, -4.8429e-04,  7.7591e-04,  6.2475e-04,\n",
       "             4.6748e-04, -2.8070e-03,  2.5702e-04, -3.1798e-04, -1.7766e-04,\n",
       "             1.5909e-04, -3.3764e-04, -1.3904e-04,  3.2947e-04, -4.0590e-04,\n",
       "             9.4626e-04, -1.3081e-04, -2.0332e-03,  5.0799e-04,  2.1002e-03,\n",
       "             6.9448e-05,  3.4369e-05, -3.6314e-04, -9.1961e-04,  1.0324e-03,\n",
       "            -6.0691e-04, -2.3021e-04,  5.0413e-04,  7.2641e-04, -5.0673e-04,\n",
       "             4.0333e-04, -7.3848e-04, -2.2362e-05,  7.2046e-04,  9.2443e-04,\n",
       "            -1.7599e-05,  6.7645e-04, -1.1714e-03,  2.7755e-04,  4.7906e-04,\n",
       "             7.3308e-05, -1.3985e-03,  6.4143e-04,  2.5794e-04,  6.0416e-05,\n",
       "             3.7099e-04, -2.2060e-03, -1.0130e-04,  8.2566e-04,  5.9591e-05,\n",
       "            -7.2407e-04, -9.1160e-04,  9.7891e-05,  2.1998e-04,  4.3624e-04,\n",
       "             1.0781e-04,  7.3305e-04, -1.3934e-04, -7.0180e-04, -1.4262e-03,\n",
       "            -2.1085e-04,  1.7939e-04,  8.3464e-05, -1.0947e-03,  1.5355e-03,\n",
       "             5.2962e-04,  2.6803e-04,  1.2328e-03,  8.7416e-04,  6.1712e-04,\n",
       "             8.4886e-04,  1.9363e-03, -3.5310e-04, -2.1960e-04,  5.9417e-04,\n",
       "             2.3006e-04,  2.0660e-03, -4.6511e-05,  9.2459e-04,  2.0473e-03,\n",
       "            -4.8074e-04,  1.0805e-04, -3.9554e-04, -4.3197e-04,  8.6806e-04,\n",
       "            -9.8426e-04, -6.7856e-04, -5.4341e-04,  4.0480e-04,  1.2500e-03,\n",
       "            -1.4439e-06,  1.4410e-03, -1.9135e-04, -3.3276e-04,  1.4823e-03,\n",
       "            -3.8324e-04, -3.1044e-04, -3.4134e-04,  7.0883e-04,  5.6044e-04,\n",
       "            -3.0492e-04,  1.5783e-03, -7.7322e-05, -9.0786e-04, -2.6800e-04,\n",
       "             6.9819e-05, -1.1879e-03,  4.3528e-05,  6.3881e-05,  5.5383e-04,\n",
       "            -2.8593e-04,  1.0862e-03,  3.7394e-04,  8.5315e-04,  1.1789e-03,\n",
       "            -3.2860e-03, -9.5821e-05, -6.5652e-04, -1.4339e-03, -3.4558e-04,\n",
       "            -7.1522e-07, -2.0051e-03,  2.7048e-04, -1.6597e-04, -5.3263e-04,\n",
       "             2.6628e-04, -3.0365e-04, -1.5455e-04,  6.7108e-04,  1.1495e-03,\n",
       "             7.2574e-05, -9.8582e-05], device='cuda:0')},\n",
       "   45: {'momentum_buffer': tensor([[[[-1.3191e-04]],\n",
       "    \n",
       "             [[ 2.9550e-05]],\n",
       "    \n",
       "             [[-1.1878e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.8790e-04]],\n",
       "    \n",
       "             [[-1.9678e-04]],\n",
       "    \n",
       "             [[ 9.9133e-07]]],\n",
       "    \n",
       "    \n",
       "            [[[ 9.1977e-05]],\n",
       "    \n",
       "             [[-1.6002e-05]],\n",
       "    \n",
       "             [[ 1.5266e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.3276e-04]],\n",
       "    \n",
       "             [[-1.1068e-04]],\n",
       "    \n",
       "             [[-1.1344e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.8476e-04]],\n",
       "    \n",
       "             [[ 2.8192e-05]],\n",
       "    \n",
       "             [[-2.5451e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.3334e-04]],\n",
       "    \n",
       "             [[ 4.5504e-05]],\n",
       "    \n",
       "             [[ 3.4330e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-8.6503e-05]],\n",
       "    \n",
       "             [[ 1.0634e-04]],\n",
       "    \n",
       "             [[-1.0390e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.8888e-04]],\n",
       "    \n",
       "             [[-4.1690e-05]],\n",
       "    \n",
       "             [[-1.5224e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.3035e-05]],\n",
       "    \n",
       "             [[ 7.8094e-05]],\n",
       "    \n",
       "             [[-2.5854e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.9888e-06]],\n",
       "    \n",
       "             [[-4.0238e-04]],\n",
       "    \n",
       "             [[ 3.0726e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.8393e-04]],\n",
       "    \n",
       "             [[ 1.2811e-05]],\n",
       "    \n",
       "             [[-4.4033e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.1377e-04]],\n",
       "    \n",
       "             [[ 4.9892e-04]],\n",
       "    \n",
       "             [[ 7.0338e-05]]]], device='cuda:0')},\n",
       "   46: {'momentum_buffer': tensor([ 0.0014,  0.0020,  0.0016,  0.0009,  0.0018,  0.0010,  0.0014,  0.0007,\n",
       "             0.0009,  0.0008,  0.0003,  0.0012,  0.0023,  0.0014,  0.0018,  0.0035,\n",
       "             0.0018,  0.0009,  0.0024,  0.0015,  0.0006,  0.0004,  0.0016,  0.0014,\n",
       "             0.0016,  0.0011,  0.0014,  0.0011,  0.0024,  0.0019,  0.0017, -0.0002,\n",
       "             0.0022,  0.0014,  0.0038,  0.0006,  0.0015,  0.0011,  0.0016,  0.0013,\n",
       "             0.0015,  0.0031,  0.0013,  0.0013,  0.0012,  0.0015,  0.0002,  0.0020,\n",
       "             0.0015,  0.0012,  0.0012,  0.0012,  0.0011,  0.0018,  0.0014,  0.0022,\n",
       "             0.0006,  0.0021,  0.0010,  0.0009,  0.0013,  0.0014,  0.0014,  0.0012,\n",
       "             0.0013,  0.0024,  0.0005,  0.0012,  0.0005,  0.0022,  0.0007,  0.0018,\n",
       "             0.0010,  0.0022,  0.0025,  0.0017,  0.0012,  0.0011,  0.0012,  0.0018,\n",
       "             0.0010,  0.0016,  0.0011,  0.0019,  0.0012,  0.0011,  0.0022,  0.0027,\n",
       "             0.0017,  0.0001,  0.0018,  0.0018,  0.0012,  0.0017,  0.0010,  0.0031,\n",
       "             0.0010,  0.0015,  0.0008,  0.0013,  0.0006,  0.0032,  0.0014,  0.0034,\n",
       "             0.0014,  0.0007,  0.0016,  0.0031,  0.0013,  0.0026,  0.0025,  0.0015,\n",
       "             0.0004,  0.0043,  0.0015,  0.0029,  0.0005,  0.0012,  0.0012,  0.0011,\n",
       "             0.0016,  0.0019,  0.0015,  0.0016,  0.0012,  0.0018,  0.0004,  0.0017],\n",
       "           device='cuda:0')},\n",
       "   47: {'momentum_buffer': tensor([-7.1714e-04, -1.4286e-03, -3.1854e-04, -1.0211e-04, -1.1649e-03,\n",
       "             7.3322e-04, -1.1423e-03,  9.8938e-04,  8.3471e-04,  1.1447e-03,\n",
       "             1.0453e-03,  5.5779e-04, -8.6066e-04,  6.1884e-04, -8.9809e-04,\n",
       "            -5.4747e-03, -1.8245e-03, -2.7514e-04, -1.8326e-03,  8.9970e-05,\n",
       "             1.0781e-03,  1.2608e-03, -1.7043e-03, -1.6162e-03, -4.8803e-04,\n",
       "            -1.5327e-03,  6.3968e-04,  7.9617e-04, -3.8155e-03, -2.8893e-04,\n",
       "            -6.5834e-04,  1.3333e-03, -2.4777e-03, -6.8587e-04, -5.5500e-03,\n",
       "             1.5333e-03, -1.4147e-03, -2.7051e-04,  7.1807e-04,  2.7884e-03,\n",
       "            -1.6345e-03, -2.5635e-03,  5.8743e-04,  1.3983e-03,  2.8563e-04,\n",
       "            -6.8455e-04,  2.2782e-03, -1.6973e-03,  1.2485e-04,  5.0918e-04,\n",
       "             3.5723e-04, -1.6485e-03, -1.8760e-04, -2.6403e-03,  6.1140e-04,\n",
       "            -1.2028e-03,  7.0253e-04, -2.0801e-03,  1.8789e-04,  1.2836e-03,\n",
       "            -1.1761e-03, -8.7575e-04, -6.5019e-04,  2.5453e-03, -1.6660e-03,\n",
       "             2.3083e-03,  1.4826e-03, -5.0798e-04,  5.3994e-04, -2.0704e-03,\n",
       "             1.8316e-04, -5.2297e-04, -8.2444e-05, -1.2232e-03, -2.4775e-03,\n",
       "            -1.6706e-03,  6.0393e-04,  1.3102e-03,  2.4899e-03, -1.8316e-04,\n",
       "             1.2119e-03, -5.7617e-04,  5.3782e-04, -5.3793e-04,  1.6085e-03,\n",
       "             3.2130e-05, -5.7385e-04, -4.2198e-03, -8.6678e-04,  1.0924e-03,\n",
       "            -1.5507e-04,  2.2327e-03, -9.3771e-04, -1.9845e-03, -5.9841e-04,\n",
       "            -1.3336e-03, -3.0700e-05, -5.5034e-04,  2.0489e-03, -1.1765e-03,\n",
       "             1.6510e-03, -5.4792e-03, -1.2640e-03, -3.0520e-03,  5.0939e-04,\n",
       "            -6.7962e-04,  5.6067e-04, -1.7507e-03,  6.2003e-04, -2.0389e-03,\n",
       "            -2.4561e-03,  1.4680e-04,  9.0656e-05, -5.8604e-03,  6.6565e-04,\n",
       "            -2.6618e-03, -1.8723e-04, -6.3880e-04, -4.7979e-04, -3.2704e-04,\n",
       "             3.6779e-04, -2.4962e-04, -6.6144e-04,  2.7521e-05,  4.6961e-04,\n",
       "            -1.3901e-03,  1.6996e-03, -2.0328e-03], device='cuda:0')},\n",
       "   48: {'momentum_buffer': tensor([[[[ 6.2871e-04,  5.6552e-04,  2.7060e-04],\n",
       "              [ 5.5209e-04,  7.0367e-04,  4.2211e-04],\n",
       "              [ 5.5954e-04,  7.8173e-04,  3.5969e-04]],\n",
       "    \n",
       "             [[-2.6399e-05,  2.0416e-04, -5.1000e-05],\n",
       "              [-2.2767e-04,  1.7337e-04, -8.4127e-05],\n",
       "              [-3.1635e-04,  1.0846e-04,  1.2129e-05]],\n",
       "    \n",
       "             [[-4.6421e-04, -4.9848e-04, -2.5221e-05],\n",
       "              [-4.1430e-04, -4.4212e-04, -3.3266e-04],\n",
       "              [-7.5135e-04, -4.2886e-04, -5.0452e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.8794e-05,  2.4011e-04, -2.8488e-04],\n",
       "              [-2.8921e-04,  2.6389e-06, -2.4848e-04],\n",
       "              [-4.8386e-04, -1.9939e-04, -2.4082e-04]],\n",
       "    \n",
       "             [[ 1.6141e-04,  5.6513e-04,  1.7277e-04],\n",
       "              [-3.1314e-05,  9.8764e-05,  1.1762e-04],\n",
       "              [-2.3967e-06, -1.4275e-04, -2.1678e-04]],\n",
       "    \n",
       "             [[-2.2666e-04, -1.6340e-04, -2.3206e-04],\n",
       "              [-3.2298e-04,  1.5594e-04, -1.0964e-04],\n",
       "              [-3.0098e-04,  1.3031e-04, -6.0831e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.2169e-04, -7.5681e-05, -1.0575e-04],\n",
       "              [ 9.2030e-05,  3.6573e-04,  1.4176e-04],\n",
       "              [ 3.1684e-04,  5.0549e-04,  1.5700e-04]],\n",
       "    \n",
       "             [[-8.1788e-05, -1.7916e-04, -4.9439e-05],\n",
       "              [-9.6982e-05, -3.5553e-06, -1.5982e-04],\n",
       "              [ 4.7872e-05, -5.1880e-05, -2.2990e-04]],\n",
       "    \n",
       "             [[-3.2028e-04, -7.7301e-05,  1.6610e-04],\n",
       "              [ 1.7143e-04, -4.0924e-05, -1.4154e-04],\n",
       "              [-3.1044e-04, -1.9373e-04, -2.5151e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.5068e-05,  7.2103e-05, -1.8260e-04],\n",
       "              [ 1.5334e-05,  3.4863e-05, -7.4679e-05],\n",
       "              [ 1.1411e-04, -4.1948e-05, -9.3530e-05]],\n",
       "    \n",
       "             [[ 2.3274e-04,  6.9243e-05, -3.7811e-04],\n",
       "              [ 5.1984e-05,  1.5457e-04, -2.0511e-04],\n",
       "              [ 2.3459e-04,  3.2022e-04, -1.4656e-04]],\n",
       "    \n",
       "             [[-1.9379e-04, -2.8807e-04, -1.7422e-04],\n",
       "              [ 2.0653e-04,  1.3803e-04, -2.8994e-04],\n",
       "              [-6.4032e-05,  6.2770e-05, -1.6152e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-8.8686e-05, -1.0251e-04,  1.1851e-04],\n",
       "              [-6.9986e-05, -1.1390e-04,  2.3261e-05],\n",
       "              [-1.2705e-04, -3.0985e-05,  3.5258e-07]],\n",
       "    \n",
       "             [[ 6.3039e-05, -5.1457e-06, -2.6513e-04],\n",
       "              [ 4.2317e-05,  7.2883e-05, -3.4334e-05],\n",
       "              [ 4.6642e-05,  3.5003e-05,  1.3551e-04]],\n",
       "    \n",
       "             [[-1.0059e-04, -1.4761e-04, -1.4372e-04],\n",
       "              [-1.4578e-04, -5.2318e-05,  6.2890e-05],\n",
       "              [-3.4169e-04,  2.2576e-05,  2.8084e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.8077e-05, -1.2835e-04, -5.5370e-05],\n",
       "              [-1.4332e-04, -1.6607e-04, -1.3556e-04],\n",
       "              [-1.8915e-04, -9.5671e-05,  4.2350e-05]],\n",
       "    \n",
       "             [[ 2.1374e-04, -9.6291e-05,  5.0999e-06],\n",
       "              [ 9.4632e-05, -9.5224e-05,  3.6202e-05],\n",
       "              [-1.7389e-05, -1.3041e-04, -9.7497e-05]],\n",
       "    \n",
       "             [[-1.4660e-04, -1.4571e-04, -9.0815e-05],\n",
       "              [-2.9203e-05, -7.6743e-05,  6.1267e-05],\n",
       "              [-5.0503e-05, -3.5130e-06,  1.7329e-06]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.0432e-04, -5.1850e-05, -2.1477e-04],\n",
       "              [-4.2601e-05, -3.1259e-04, -3.0153e-04],\n",
       "              [-5.1975e-05, -2.8470e-04, -1.7884e-04]],\n",
       "    \n",
       "             [[-2.4396e-04, -2.7307e-05, -1.8452e-04],\n",
       "              [-1.3323e-04, -2.2998e-05, -6.0871e-06],\n",
       "              [-2.9689e-06,  4.0655e-05, -1.1331e-04]],\n",
       "    \n",
       "             [[ 2.7880e-04,  1.5631e-04,  3.2803e-04],\n",
       "              [ 1.2536e-04, -6.9480e-05,  4.5260e-04],\n",
       "              [-2.5219e-05, -1.6706e-05,  3.1656e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.7729e-04, -8.1440e-05, -4.1709e-05],\n",
       "              [-5.9881e-05,  2.2774e-05,  2.8728e-05],\n",
       "              [-6.9688e-05, -3.9860e-05, -1.1030e-04]],\n",
       "    \n",
       "             [[ 1.7056e-04,  1.6153e-04,  1.8897e-04],\n",
       "              [ 5.0343e-05, -1.1813e-04, -1.5460e-04],\n",
       "              [-3.2991e-04, -3.9182e-04,  1.3025e-04]],\n",
       "    \n",
       "             [[ 1.0443e-04, -4.0062e-05,  1.3578e-04],\n",
       "              [-5.4019e-05, -8.7552e-05,  6.0991e-05],\n",
       "              [-1.1707e-04,  8.6605e-05, -1.3000e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.3218e-04,  1.9514e-04,  2.7378e-04],\n",
       "              [ 4.7206e-04,  5.0334e-04,  3.6211e-04],\n",
       "              [ 3.3268e-04,  1.5318e-04,  1.4579e-05]],\n",
       "    \n",
       "             [[-7.5453e-05, -5.1606e-05,  1.5593e-04],\n",
       "              [-4.2846e-05, -7.4744e-05,  6.5894e-05],\n",
       "              [-1.9097e-04, -2.0635e-04, -2.0613e-05]],\n",
       "    \n",
       "             [[-8.7648e-05,  3.6289e-05, -1.1966e-04],\n",
       "              [-2.9548e-05, -3.3230e-05,  9.6342e-05],\n",
       "              [-7.3372e-05,  2.1583e-05,  9.6482e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.6649e-04,  4.4804e-05,  3.5701e-05],\n",
       "              [-5.0692e-05,  9.0485e-05, -3.7735e-05],\n",
       "              [-1.3689e-04, -5.9676e-05,  1.3739e-05]],\n",
       "    \n",
       "             [[ 1.3392e-04,  3.2721e-04,  5.4831e-04],\n",
       "              [ 8.8809e-05,  3.3212e-04,  6.1148e-04],\n",
       "              [-1.2003e-04, -7.2928e-05,  9.9386e-06]],\n",
       "    \n",
       "             [[-4.4208e-05, -1.4092e-05,  4.2706e-05],\n",
       "              [ 2.0845e-06, -1.2577e-04,  2.3795e-05],\n",
       "              [-7.8591e-05,  9.4133e-06,  9.5165e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.1685e-04, -4.3588e-04, -2.9305e-04],\n",
       "              [-1.5108e-04, -1.7890e-04, -2.3277e-04],\n",
       "              [-2.8151e-04, -3.1994e-04, -2.5515e-04]],\n",
       "    \n",
       "             [[ 2.4063e-05,  1.5984e-06, -1.5775e-04],\n",
       "              [ 4.2704e-05,  7.5993e-05,  1.0100e-04],\n",
       "              [ 1.9593e-04,  1.5799e-04,  2.0748e-04]],\n",
       "    \n",
       "             [[-8.0441e-05, -2.5147e-04, -1.5038e-05],\n",
       "              [-7.2207e-05, -2.0357e-04, -4.8592e-05],\n",
       "              [ 2.1353e-05, -1.1753e-05,  8.7301e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-9.4102e-05,  5.1730e-05,  1.5497e-05],\n",
       "              [-4.4604e-06,  1.0551e-04,  1.8298e-05],\n",
       "              [ 2.8891e-05,  4.2467e-05,  2.0868e-06]],\n",
       "    \n",
       "             [[-3.7916e-04, -3.8887e-04, -2.6508e-04],\n",
       "              [-2.2987e-04, -1.5222e-04, -2.7508e-05],\n",
       "              [ 6.0407e-05, -3.4800e-05,  1.0939e-04]],\n",
       "    \n",
       "             [[ 6.1041e-07, -1.0178e-04, -2.0407e-05],\n",
       "              [ 4.3865e-05, -1.2606e-04,  2.1947e-05],\n",
       "              [ 2.8397e-05, -3.3680e-05,  4.5898e-05]]]], device='cuda:0')},\n",
       "   49: {'momentum_buffer': tensor([ 1.5384e-03,  2.7507e-03,  2.3700e-03,  1.8029e-03,  1.6093e-03,\n",
       "             1.3870e-03,  3.5970e-03,  2.3949e-03,  1.8272e-03,  1.8406e-03,\n",
       "             1.2968e-03,  1.9967e-03,  1.1535e-03,  4.6198e-04,  2.2444e-03,\n",
       "             1.8351e-03,  1.9249e-03,  1.0774e-03,  1.9225e-03,  2.1611e-03,\n",
       "             7.2078e-04,  2.0255e-03,  1.5739e-03,  2.7071e-03,  2.2626e-03,\n",
       "             3.6444e-03,  1.2095e-03,  1.7781e-03,  2.1085e-03,  6.9113e-04,\n",
       "             1.5319e-03,  2.6342e-03,  1.5420e-03,  2.1477e-03,  2.2463e-03,\n",
       "             8.0141e-05,  2.3544e-03,  1.0154e-03,  3.7597e-03,  2.1914e-03,\n",
       "             1.9006e-03,  2.4306e-03,  1.7485e-03,  2.3239e-03,  2.1641e-03,\n",
       "             1.8401e-03,  1.8435e-03,  2.0847e-03, -2.1236e-04,  2.2374e-03,\n",
       "             2.0601e-03,  2.2462e-03,  1.3981e-03,  1.5580e-03,  1.8573e-03,\n",
       "             1.9182e-03,  2.1715e-03,  2.0215e-03,  1.6923e-03,  2.0794e-03,\n",
       "             2.7397e-03,  1.5562e-03,  1.7555e-03,  9.1955e-04,  1.6067e-03,\n",
       "             1.2342e-03,  1.8354e-03,  2.4456e-03,  2.5406e-03,  1.3733e-03,\n",
       "             1.8976e-03,  2.4590e-03,  2.1460e-03,  2.2153e-03,  1.8877e-03,\n",
       "             2.1072e-03,  1.9748e-03,  1.7927e-03,  2.0275e-03,  2.1159e-03,\n",
       "             1.3839e-03,  1.8552e-03,  1.8624e-03,  1.4740e-03,  1.6915e-03,\n",
       "             1.2160e-03,  1.8787e-03,  1.6402e-03,  2.1503e-03,  1.9002e-03,\n",
       "             1.4702e-03,  2.0047e-03,  2.2097e-03,  1.9184e-03,  2.0447e-03,\n",
       "             1.8741e-03,  1.7137e-03,  1.7474e-03,  2.1331e-03,  2.3083e-03,\n",
       "             1.5681e-03,  2.1087e-03,  2.0729e-03,  1.4199e-03,  1.8664e-03,\n",
       "             2.0331e-03,  1.3463e-03,  2.3384e-03,  7.9755e-04,  1.3844e-03,\n",
       "             3.1297e-03,  2.0297e-03,  1.4105e-03,  2.1128e-03,  1.9869e-03,\n",
       "             1.8945e-03,  2.1293e-03,  1.6113e-03,  2.5667e-03,  2.8340e-03,\n",
       "             1.0191e-03,  2.3250e-03,  1.7044e-03,  1.7297e-03,  6.5086e-04,\n",
       "             1.4721e-03,  2.3714e-03,  1.8935e-03], device='cuda:0')},\n",
       "   50: {'momentum_buffer': tensor([ 5.7321e-04, -1.4480e-03, -1.3925e-03, -6.3066e-04,  2.0377e-03,\n",
       "             2.6769e-03, -8.2730e-03, -1.0698e-03,  2.2750e-04,  6.1309e-05,\n",
       "             7.5393e-04,  9.1429e-04,  2.4615e-03, -9.1575e-04, -3.9924e-04,\n",
       "            -2.2838e-04,  1.3052e-03,  5.7741e-04,  7.2351e-04,  1.6228e-04,\n",
       "             2.2928e-03,  9.4814e-05, -1.6107e-03, -3.4510e-03, -2.1384e-03,\n",
       "            -3.0612e-03,  1.0800e-03,  6.9495e-04, -1.1778e-03,  9.9090e-04,\n",
       "             8.4425e-04, -2.1905e-03,  8.2804e-04,  7.7178e-04, -1.7863e-03,\n",
       "             2.2714e-03, -1.5332e-04,  3.8408e-04, -5.7627e-03, -1.3286e-03,\n",
       "            -1.1108e-03, -2.0512e-03, -2.3313e-06, -8.9686e-04, -2.0705e-03,\n",
       "             6.5184e-04, -1.7246e-03, -3.3265e-03,  2.0710e-03,  1.7372e-03,\n",
       "             2.0246e-04, -1.0825e-03,  2.0929e-04, -9.5256e-04, -9.0992e-04,\n",
       "            -1.1785e-03, -2.0656e-03,  5.5737e-04, -6.4502e-04, -1.7601e-03,\n",
       "            -1.8268e-03,  1.1135e-03,  4.5483e-04,  1.2757e-03, -1.8251e-03,\n",
       "            -1.1605e-05,  1.0134e-03, -5.3685e-04, -8.1202e-04,  8.4275e-04,\n",
       "            -6.5756e-04, -1.6403e-03,  1.9743e-04,  4.4620e-04, -8.2283e-04,\n",
       "            -1.0969e-03, -8.5819e-04, -5.8320e-04, -1.1725e-03, -6.1274e-04,\n",
       "            -3.0709e-04,  1.5143e-03,  1.2822e-03, -7.5919e-05, -1.1465e-03,\n",
       "             1.3009e-03,  1.2942e-04, -1.7547e-04, -1.2743e-03, -2.9646e-04,\n",
       "            -4.7030e-04,  1.3599e-04, -9.2319e-04,  4.5079e-04, -1.6307e-03,\n",
       "            -1.0396e-03,  2.5309e-04, -1.9024e-03,  5.1444e-04, -9.8973e-04,\n",
       "            -3.7648e-04, -1.0717e-03,  1.7394e-04, -8.6006e-04, -2.1645e-03,\n",
       "             1.7410e-03,  5.5396e-05, -1.2198e-03,  1.3561e-03, -1.2527e-03,\n",
       "            -1.7919e-03, -1.6871e-03,  6.8112e-04, -1.3517e-03, -2.0065e-03,\n",
       "            -2.4483e-03, -2.4001e-03,  3.7166e-03, -1.4448e-03, -2.5129e-03,\n",
       "             6.6429e-04, -8.6021e-04, -6.3639e-04, -1.1687e-03,  1.1369e-03,\n",
       "            -2.4761e-05, -1.1311e-03, -2.5424e-03], device='cuda:0')},\n",
       "   51: {'momentum_buffer': tensor([[[[-1.1075e-04]],\n",
       "    \n",
       "             [[-2.0717e-04]],\n",
       "    \n",
       "             [[-9.5112e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.6450e-04]],\n",
       "    \n",
       "             [[ 1.0069e-04]],\n",
       "    \n",
       "             [[-1.5519e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.2261e-04]],\n",
       "    \n",
       "             [[ 3.4453e-04]],\n",
       "    \n",
       "             [[ 2.4382e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.0105e-05]],\n",
       "    \n",
       "             [[-2.6420e-05]],\n",
       "    \n",
       "             [[ 1.0240e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-9.8895e-04]],\n",
       "    \n",
       "             [[-4.4193e-04]],\n",
       "    \n",
       "             [[-1.1673e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.0528e-04]],\n",
       "    \n",
       "             [[ 2.3182e-04]],\n",
       "    \n",
       "             [[-1.1024e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-5.9906e-05]],\n",
       "    \n",
       "             [[ 4.0950e-04]],\n",
       "    \n",
       "             [[-4.9094e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.6230e-04]],\n",
       "    \n",
       "             [[-1.3550e-04]],\n",
       "    \n",
       "             [[-1.3983e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-8.5485e-08]],\n",
       "    \n",
       "             [[ 8.5238e-05]],\n",
       "    \n",
       "             [[ 3.6491e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.0500e-05]],\n",
       "    \n",
       "             [[ 4.7421e-05]],\n",
       "    \n",
       "             [[ 7.2722e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.0206e-04]],\n",
       "    \n",
       "             [[ 2.2807e-04]],\n",
       "    \n",
       "             [[ 3.9116e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.4936e-04]],\n",
       "    \n",
       "             [[ 7.1059e-04]],\n",
       "    \n",
       "             [[ 3.3465e-05]]]], device='cuda:0')},\n",
       "   52: {'momentum_buffer': tensor([ 1.1726e-03,  1.3175e-03,  2.3308e-03,  7.7239e-05,  1.6434e-04,\n",
       "             2.2899e-03,  1.5001e-03,  1.0912e-03,  7.5147e-04,  5.1767e-04,\n",
       "             9.0103e-04, -1.3653e-04, -6.1228e-05, -4.3601e-04, -3.9002e-04,\n",
       "             3.7900e-04, -1.9688e-04,  5.9239e-04,  7.0272e-04, -9.9204e-05,\n",
       "            -7.2424e-05,  2.1560e-05,  1.7734e-03,  5.8816e-04,  9.5648e-04,\n",
       "             2.1400e-03,  1.7637e-03,  4.4724e-04,  4.6194e-04,  4.2657e-04,\n",
       "             1.2903e-03,  2.1256e-03,  5.5833e-04,  9.3472e-04,  3.3943e-04,\n",
       "             4.2667e-04,  5.9614e-04,  1.8014e-03,  8.4257e-04,  1.2566e-03,\n",
       "             3.9100e-04,  2.6675e-04,  9.7633e-04,  5.4196e-04,  9.3586e-04,\n",
       "             8.0073e-04,  2.1032e-04,  8.1658e-04,  2.7182e-03,  9.2315e-04,\n",
       "             2.2584e-03,  1.2503e-03, -2.1742e-04,  8.2066e-04,  1.5725e-03,\n",
       "            -5.4212e-04,  1.6501e-03,  2.6825e-04,  7.7683e-04,  6.5434e-04,\n",
       "             6.0640e-04, -1.4986e-04,  1.6643e-03,  1.7635e-03,  1.4276e-03,\n",
       "             1.2600e-03,  1.2563e-03,  1.0111e-03,  4.1668e-04,  1.0726e-03,\n",
       "             1.8933e-03,  8.5700e-04,  1.6097e-03,  1.8441e-04,  4.9266e-04,\n",
       "             5.6367e-04,  1.3824e-03,  1.5787e-04,  8.4747e-04,  9.0354e-04,\n",
       "             4.4123e-04,  1.7494e-03,  1.0153e-03,  9.3277e-04,  1.1466e-04,\n",
       "             1.8000e-03,  1.1050e-03,  1.1441e-03,  7.4541e-04,  3.9639e-04,\n",
       "             1.4707e-03,  1.5822e-03,  5.1725e-04,  7.3450e-04,  1.6136e-03,\n",
       "            -3.2453e-05,  7.5763e-04,  3.1025e-03,  5.5761e-04,  6.2144e-04,\n",
       "             1.3899e-03,  7.0025e-04,  1.3658e-03,  5.8983e-04,  1.1009e-03,\n",
       "             1.5872e-03,  1.1567e-03,  7.1505e-04,  1.4270e-03,  1.0264e-03,\n",
       "             5.6411e-04,  1.0213e-03,  9.9260e-04,  1.3268e-03,  7.5097e-04,\n",
       "             7.6748e-04,  9.5211e-04, -2.5508e-04, -2.1954e-04,  7.9445e-04,\n",
       "             1.3062e-03,  1.3446e-03,  8.8962e-04,  1.2539e-03,  3.6890e-04,\n",
       "             9.4701e-04,  8.6884e-04,  1.5264e-03,  3.8420e-04,  1.7998e-03,\n",
       "             1.1754e-03,  3.0771e-04,  1.7329e-03,  1.3802e-03,  1.2892e-03,\n",
       "             5.9669e-04,  5.8687e-04,  1.0191e-03,  4.0721e-04,  1.9062e-03,\n",
       "             8.5197e-04,  7.6326e-04,  1.1250e-03,  1.5137e-03,  1.5558e-03,\n",
       "             5.9109e-04,  4.7693e-05,  1.0267e-03,  1.2991e-03,  1.0567e-03,\n",
       "             9.3308e-04,  1.8795e-03,  1.0851e-03,  1.1610e-03,  3.1559e-04,\n",
       "            -3.5942e-05,  1.2792e-03,  1.4419e-03,  9.2722e-05,  9.6613e-04,\n",
       "             4.1583e-04,  1.2650e-03,  5.6384e-04,  1.6783e-03,  3.7770e-03,\n",
       "             4.9608e-04,  3.2169e-04,  9.2674e-04,  1.0274e-03,  1.0798e-03,\n",
       "             5.1762e-04,  8.1782e-04,  1.3443e-03,  1.9170e-03,  9.0306e-04,\n",
       "             9.2487e-04,  7.7369e-04,  3.7106e-04,  1.2406e-03,  7.5408e-04,\n",
       "             6.0063e-04,  7.7103e-04,  4.6175e-04,  1.6783e-03,  7.6477e-04,\n",
       "             6.5096e-04,  2.2050e-03,  2.0861e-03,  1.1009e-03,  6.8456e-04,\n",
       "             3.1650e-03,  8.9045e-04,  2.9803e-04,  1.0571e-03,  6.0617e-04,\n",
       "             2.2807e-03,  2.7367e-03,  2.5105e-04,  1.9231e-03,  1.7468e-03,\n",
       "             5.6598e-04,  4.5741e-04,  6.6089e-04,  7.4975e-04,  6.0142e-04,\n",
       "             2.1440e-04,  7.6599e-04,  8.3236e-04,  3.2785e-04,  1.7714e-03,\n",
       "             1.0684e-03,  2.3333e-03,  3.8091e-04,  1.9687e-03,  2.9609e-03,\n",
       "             1.6561e-03,  2.0958e-03,  1.4320e-03,  3.3155e-04,  9.4655e-04,\n",
       "             9.6250e-04,  6.0523e-04,  6.7598e-04,  1.9654e-03,  2.1266e-03,\n",
       "             1.3654e-03,  2.1846e-03,  1.2555e-03,  2.6087e-03,  8.4567e-04,\n",
       "             1.4238e-03,  4.2549e-04,  2.4087e-03,  7.6578e-04,  1.0690e-03,\n",
       "             2.7566e-03,  1.5733e-03,  8.5759e-05,  6.6057e-04,  5.7350e-04,\n",
       "             1.7074e-03,  7.8671e-04,  7.5781e-04,  4.1940e-04,  5.1240e-04,\n",
       "             5.9197e-03, -8.6656e-04,  1.2099e-03,  1.0433e-03,  1.3144e-03,\n",
       "             4.9009e-05,  9.5260e-04,  5.7077e-04,  2.4929e-04,  1.1479e-03,\n",
       "             7.3961e-04,  6.1380e-04,  3.1266e-04,  3.1852e-03,  7.2112e-04,\n",
       "             1.9864e-04,  5.2967e-04,  3.2463e-04,  2.1020e-03,  5.0097e-04,\n",
       "             1.3255e-03,  9.9159e-04,  7.2079e-04,  1.3154e-03,  8.7942e-04,\n",
       "             4.8080e-04,  4.6239e-04,  1.2705e-03,  2.3213e-03,  1.8759e-03,\n",
       "             7.4124e-04,  7.1380e-04,  1.2624e-03,  7.5257e-04,  5.1464e-04,\n",
       "             1.6648e-03,  2.2746e-04,  9.0813e-04,  2.7265e-04,  8.1821e-04,\n",
       "             5.6736e-04,  4.8248e-04,  6.0224e-04,  1.1567e-03,  7.6942e-04,\n",
       "             6.3668e-04,  7.9537e-04,  8.6709e-04,  9.4946e-04,  1.9170e-03,\n",
       "             1.1592e-03,  8.2429e-04,  3.0198e-04,  1.0981e-03,  1.6105e-03,\n",
       "             1.4969e-03,  1.9762e-03,  3.4436e-04,  3.8306e-04,  6.4363e-04,\n",
       "             5.2045e-04,  2.3943e-03,  5.4930e-04,  5.3378e-04,  1.2331e-03,\n",
       "             1.1612e-03,  1.4082e-03,  3.3331e-03,  5.8270e-04,  8.7717e-04,\n",
       "             9.1205e-04,  5.3649e-04,  1.1632e-03,  1.7522e-03,  4.6650e-04,\n",
       "             7.1007e-04,  1.8072e-03,  9.1988e-05,  1.4163e-04,  5.0363e-04,\n",
       "             7.4819e-04,  1.2212e-03,  1.5776e-03,  1.1982e-03,  4.8990e-04,\n",
       "             8.3129e-04,  6.4262e-04,  3.7608e-03,  3.8814e-03,  1.1159e-03,\n",
       "             1.5809e-03,  7.5736e-04,  4.4071e-04,  2.8442e-03,  1.2795e-03,\n",
       "             1.3810e-03,  1.1308e-03,  1.1034e-03,  2.1609e-03,  7.3345e-04,\n",
       "             7.4936e-04,  3.4816e-03,  8.4463e-04,  2.1175e-03,  2.5314e-03,\n",
       "             1.1430e-03,  1.1986e-03,  2.9496e-04,  1.1553e-05,  1.1395e-03,\n",
       "             1.4183e-03,  1.3119e-03,  7.2887e-04,  8.5409e-04,  6.4595e-04,\n",
       "             1.7016e-03,  1.0242e-03,  9.2205e-04,  2.2510e-03,  9.1380e-04,\n",
       "             1.3693e-03,  9.5123e-04,  3.6321e-04,  6.8086e-04,  1.4712e-03,\n",
       "             4.6627e-04,  4.4755e-04,  1.8869e-03,  2.4854e-04,  1.2747e-03,\n",
       "             3.6789e-04,  5.8592e-04,  9.3651e-04,  3.9549e-05,  2.6667e-03,\n",
       "             1.2631e-04,  1.3619e-03,  7.9997e-04,  2.8217e-05,  6.7310e-04,\n",
       "             1.3440e-03,  1.0698e-03,  7.0694e-04, -2.0442e-04,  1.5737e-03,\n",
       "             5.5744e-04,  1.6079e-03,  1.0575e-03,  2.8448e-04,  4.3853e-04,\n",
       "             1.3094e-03,  2.5472e-03,  1.7574e-03,  6.8073e-04,  6.7953e-04,\n",
       "             9.7430e-04,  1.6969e-03,  2.6756e-04,  4.6630e-04,  2.6868e-03,\n",
       "             7.7000e-04,  2.0269e-04,  1.4635e-03,  1.1084e-03,  9.2783e-04,\n",
       "             4.1559e-04, -2.8096e-05,  5.7617e-04,  1.9577e-03,  1.4757e-03,\n",
       "             2.1047e-03,  1.4671e-03,  3.6544e-04,  1.0517e-03, -3.7310e-06,\n",
       "             9.5005e-04,  2.1121e-03,  5.3133e-04,  4.6896e-04,  5.7532e-04,\n",
       "             1.5829e-03,  2.6342e-03,  4.8817e-04,  4.4468e-04,  1.0761e-03,\n",
       "             1.4127e-03,  1.2906e-03,  8.5347e-04,  5.8536e-05,  6.2011e-04,\n",
       "             7.0812e-04,  1.9471e-03,  9.9053e-04,  3.1571e-04,  1.3862e-03,\n",
       "             7.4950e-04,  5.2989e-04,  2.4786e-03,  9.1200e-04,  8.9924e-04,\n",
       "             9.9665e-04,  2.0825e-03,  2.3467e-03,  9.9286e-04,  8.8724e-04,\n",
       "             6.9709e-04,  6.7232e-04,  1.6383e-03,  2.5751e-03,  1.2907e-03,\n",
       "             1.2533e-03,  1.6223e-03,  1.5777e-03,  8.5662e-04,  1.1777e-03,\n",
       "             4.0466e-03,  4.0056e-04,  7.6542e-04,  7.6042e-04, -3.8371e-04,\n",
       "             1.5009e-03,  1.8469e-03,  4.2861e-04,  2.5811e-04,  1.6300e-03,\n",
       "             5.1454e-04,  2.2634e-04,  2.0403e-03,  9.3988e-04, -2.3348e-04,\n",
       "             8.2030e-04,  5.8527e-04,  4.6022e-04,  4.4686e-04,  1.3403e-03,\n",
       "             1.3408e-03,  2.0806e-03,  6.2890e-04,  1.4844e-03,  1.4722e-03,\n",
       "             1.7087e-03,  1.9667e-03,  7.9703e-04,  1.9303e-04,  8.6173e-04,\n",
       "             6.9490e-04,  6.3801e-04,  2.9461e-03,  2.3197e-04,  2.3689e-03,\n",
       "             1.1907e-03,  8.4757e-04,  1.1001e-03,  3.5600e-03,  7.7356e-04,\n",
       "             1.1162e-03,  2.9631e-03,  8.8622e-04,  3.0605e-04,  1.0598e-03,\n",
       "             8.2364e-04,  1.0522e-03,  1.0418e-03,  1.7691e-03,  1.7544e-03,\n",
       "             3.6862e-04,  1.0450e-03], device='cuda:0')},\n",
       "   53: {'momentum_buffer': tensor([-1.2319e-03,  1.2042e-03, -8.6266e-04, -2.7432e-03, -6.4790e-04,\n",
       "             8.8511e-05, -1.9507e-03, -3.5615e-04, -1.5967e-03,  2.1262e-04,\n",
       "            -5.2598e-04, -9.7755e-06, -3.7803e-04, -1.9023e-04,  1.4007e-03,\n",
       "            -5.1196e-04, -1.8161e-04, -8.0168e-04, -2.2628e-04, -2.9064e-04,\n",
       "            -8.5691e-04,  9.7211e-05, -1.7439e-03, -2.2365e-05, -6.0783e-04,\n",
       "            -9.5382e-04, -3.3912e-03, -7.6923e-04,  1.3022e-03, -2.4101e-03,\n",
       "            -1.1974e-03,  5.3785e-04, -8.1862e-04, -9.1370e-05, -8.9698e-04,\n",
       "             1.6444e-03, -4.4465e-04, -1.5335e-03, -7.8102e-04,  1.2065e-03,\n",
       "            -2.9869e-04,  2.1676e-04,  1.1344e-03, -4.6244e-04, -7.1803e-04,\n",
       "            -8.1594e-04,  2.7549e-04, -1.0570e-03,  1.9783e-03,  2.5419e-04,\n",
       "            -4.5832e-04,  4.4487e-04,  2.4933e-04, -9.8576e-04, -2.4550e-03,\n",
       "             3.2247e-04, -1.0401e-03, -6.9424e-04, -1.1222e-03,  5.5859e-04,\n",
       "            -4.9248e-04,  3.0074e-04, -3.4024e-03,  2.2768e-03, -2.0757e-03,\n",
       "            -1.6751e-03, -6.3408e-04,  1.3045e-03, -5.3748e-04, -6.4199e-04,\n",
       "            -1.8363e-03, -1.1350e-03,  1.1737e-03,  2.0479e-04, -8.8070e-04,\n",
       "            -3.6878e-04, -8.0046e-04,  9.4980e-06, -6.7528e-04, -2.2220e-04,\n",
       "            -2.0382e-04, -8.8366e-04,  1.5165e-04, -1.4844e-03, -2.4681e-04,\n",
       "             1.3003e-03, -9.9690e-04, -2.0250e-03, -2.4602e-04, -1.8056e-04,\n",
       "             6.3134e-04, -1.7614e-04, -9.5189e-04, -6.8659e-04,  4.9341e-05,\n",
       "             2.0797e-04, -4.9303e-04, -2.1484e-03, -1.1518e-03, -4.2531e-04,\n",
       "            -1.5719e-03, -1.2285e-03, -1.7084e-03, -2.9275e-03, -6.9887e-04,\n",
       "            -8.5816e-04, -1.2573e-03, -9.9934e-04, -2.6840e-03, -1.0941e-03,\n",
       "            -7.9885e-04, -1.7169e-03, -1.0893e-03, -1.2392e-03, -3.8636e-04,\n",
       "            -5.2363e-04, -1.0152e-03, -4.0874e-04,  2.5432e-04, -1.2340e-03,\n",
       "            -1.4658e-03, -4.8113e-04, -7.4704e-04, -3.6840e-04, -1.4303e-04,\n",
       "            -2.1678e-03, -1.3600e-03, -1.2215e-03, -9.7006e-04, -1.7992e-03,\n",
       "            -1.4033e-03, -4.6628e-04, -1.2413e-03, -2.9334e-03, -3.8092e-03,\n",
       "            -5.9156e-04, -4.6163e-04,  8.7357e-04,  1.4409e-04, -1.4152e-03,\n",
       "            -2.2871e-04, -1.7761e-03, -2.8777e-03,  5.5420e-05, -1.3423e-03,\n",
       "             1.3035e-03,  3.0047e-04,  3.9362e-04,  1.9892e-03,  1.1708e-04,\n",
       "            -1.6083e-03, -2.5087e-03, -3.0538e-04,  5.7936e-04, -1.2730e-03,\n",
       "             7.0297e-05, -1.3979e-03,  2.7588e-03, -2.8384e-04, -1.2483e-03,\n",
       "             3.4791e-04, -1.6448e-03, -1.1868e-03, -1.4165e-03, -2.1004e-03,\n",
       "            -2.8003e-04, -8.5950e-06, -1.3646e-03, -1.2488e-03, -1.0356e-03,\n",
       "            -9.0503e-04,  2.8605e-04,  5.6309e-04,  1.0167e-03, -1.9618e-03,\n",
       "            -9.8137e-04,  5.0559e-04, -8.2581e-04, -2.3090e-03, -1.3022e-03,\n",
       "             6.1172e-04,  1.4236e-03, -3.6522e-04,  6.0113e-05, -1.1890e-03,\n",
       "             4.2846e-04,  5.5818e-06, -2.3500e-03, -1.0138e-03, -5.9303e-04,\n",
       "            -2.4763e-03, -1.7665e-04, -7.2030e-05, -1.3945e-03, -9.1413e-04,\n",
       "            -4.9278e-04, -7.1580e-04,  3.2325e-04, -3.9307e-04, -5.0568e-04,\n",
       "            -6.8741e-05,  1.5468e-05, -1.4043e-04, -2.3823e-03, -4.5799e-04,\n",
       "            -1.2347e-03, -7.9153e-04, -6.7211e-04, -9.0684e-05, -2.3472e-04,\n",
       "            -1.9311e-04, -4.0606e-04,  7.6195e-04, -3.0739e-03, -3.1550e-03,\n",
       "             9.3771e-04, -1.2822e-03, -1.1185e-03, -5.8914e-04, -8.6133e-04,\n",
       "            -9.3920e-04, -3.6518e-03, -1.1285e-03, -1.6468e-03, -3.2494e-04,\n",
       "            -1.6504e-03, -3.8107e-03, -1.5888e-03,  9.5386e-04, -1.0108e-03,\n",
       "             1.0812e-03, -7.0515e-04, -1.0700e-03, -1.1563e-03, -1.2448e-03,\n",
       "            -2.7573e-04, -1.7693e-03, -3.1324e-04, -5.4819e-04,  2.6315e-05,\n",
       "             1.1285e-04,  2.6456e-04, -1.4620e-03, -3.2158e-03, -5.4534e-05,\n",
       "            -5.0942e-03, -1.2182e-03, -6.6034e-04, -9.4877e-04, -3.4793e-04,\n",
       "            -6.8542e-05, -1.6108e-03, -5.2775e-04, -2.0813e-04,  3.3544e-04,\n",
       "            -1.5849e-03, -3.2764e-04, -4.2750e-04, -1.0767e-03, -2.0826e-03,\n",
       "             1.1580e-04, -5.4962e-04, -7.5269e-04, -3.6161e-04, -3.0017e-04,\n",
       "             1.8841e-03, -7.0471e-04, -6.5639e-04, -4.6983e-05, -2.4311e-03,\n",
       "            -1.6870e-05, -5.5103e-04, -1.4445e-03, -1.8448e-03, -2.8322e-03,\n",
       "            -7.1694e-04, -4.3913e-04, -2.0576e-03, -7.1037e-04, -5.7514e-04,\n",
       "            -1.6284e-04, -3.6152e-04, -7.6021e-04, -5.5288e-04, -8.1252e-05,\n",
       "            -3.2684e-03, -9.0494e-04, -3.4195e-04, -1.2469e-03, -8.3381e-04,\n",
       "            -1.1303e-03,  7.6554e-04, -1.5513e-03, -8.3569e-05,  1.2773e-03,\n",
       "            -3.6718e-04, -7.0136e-04, -6.7785e-04, -9.6377e-04, -1.6706e-04,\n",
       "            -1.5067e-03, -1.9390e-03, -4.3619e-04, -5.3240e-05, -2.1582e-04,\n",
       "            -7.7839e-04, -1.0945e-04,  5.0835e-05,  6.4028e-05, -1.2321e-03,\n",
       "             4.6382e-05,  1.3116e-03, -2.4986e-03, -1.1565e-03, -1.0266e-03,\n",
       "             2.2489e-04,  9.6295e-05, -1.6238e-04, -2.3876e-03, -3.1190e-04,\n",
       "            -1.8875e-04, -1.2306e-03, -1.6705e-03, -1.2618e-03, -2.3322e-05,\n",
       "            -1.1229e-03, -8.7701e-04, -1.3043e-03, -1.0073e-03, -2.7094e-04,\n",
       "            -8.5608e-04, -3.3248e-04, -4.7176e-03, -2.2482e-03, -3.9432e-04,\n",
       "            -7.8385e-04, -9.3184e-04, -6.5044e-04, -9.9690e-04, -2.3015e-03,\n",
       "            -6.4257e-04, -2.5075e-03, -2.6316e-03, -4.9393e-04,  6.2818e-05,\n",
       "            -2.5089e-04,  1.3198e-03, -1.8577e-04,  7.6658e-05, -1.8135e-04,\n",
       "            -6.1653e-04, -2.7601e-03, -4.5262e-04,  8.1209e-04, -1.0746e-03,\n",
       "             2.4171e-03, -1.7077e-03, -4.8608e-04, -6.2763e-04, -8.5395e-04,\n",
       "            -2.5974e-04, -1.7477e-03, -3.8850e-04, -6.3970e-04, -1.5037e-03,\n",
       "            -1.4144e-04, -1.4651e-03,  1.2158e-03, -1.9343e-04, -1.2263e-03,\n",
       "             1.7478e-04,  1.3675e-03,  1.0398e-03,  1.8070e-04, -9.8858e-04,\n",
       "            -3.9705e-04, -1.0820e-04, -2.1033e-03, -6.6788e-05, -1.1702e-04,\n",
       "             2.3239e-04,  2.3509e-05, -6.5042e-04, -4.1028e-04, -4.7530e-04,\n",
       "            -6.9198e-04, -3.2532e-03,  1.2556e-04,  1.7137e-04,  1.0218e-03,\n",
       "             2.1382e-06, -2.3329e-03, -1.3496e-03,  1.1573e-04, -2.3782e-04,\n",
       "             1.6213e-04, -7.7934e-04, -2.3647e-03, -5.3932e-04,  1.0312e-03,\n",
       "            -1.3472e-03, -5.1990e-04,  5.3407e-04, -9.4056e-04,  1.4745e-03,\n",
       "             7.9658e-04, -1.9409e-04, -6.4377e-04, -9.0500e-04,  4.9654e-05,\n",
       "            -1.7514e-04,  1.7445e-03, -5.4322e-04,  3.1700e-04, -1.6181e-03,\n",
       "             1.2625e-03, -2.0168e-03, -3.3395e-04, -4.6517e-04, -5.1533e-04,\n",
       "            -1.2124e-03, -1.9178e-03, -3.0676e-05, -2.1510e-03, -5.3370e-04,\n",
       "            -1.1607e-03, -1.8768e-03, -4.6619e-05,  1.7320e-05, -1.5646e-03,\n",
       "             6.6568e-04, -7.7677e-04, -5.1280e-04, -2.6963e-04, -6.9088e-04,\n",
       "            -1.8372e-04, -9.2114e-04, -1.1911e-03, -9.5026e-04,  1.5984e-04,\n",
       "            -8.1997e-04, -1.0174e-03, -1.2357e-03, -1.0417e-03,  1.3044e-04,\n",
       "            -1.4093e-03, -1.3525e-04, -3.3924e-03, -2.9907e-04, -4.8256e-04,\n",
       "             7.7334e-05, -3.3126e-03,  1.1679e-03, -5.9628e-04, -1.0331e-03,\n",
       "            -1.2062e-03, -1.1530e-03, -2.2581e-04,  2.7223e-04, -3.6258e-03,\n",
       "            -4.0874e-03, -4.5086e-04, -1.7319e-03, -4.0511e-04, -7.1395e-05,\n",
       "            -3.3472e-04, -2.0501e-03, -3.7128e-04,  8.4252e-04, -1.0889e-03,\n",
       "            -1.2397e-04, -2.9826e-03, -2.4979e-03,  6.3511e-04, -1.1252e-04,\n",
       "            -1.7759e-03, -1.0713e-03, -8.9766e-04, -8.8668e-04,  1.3776e-04,\n",
       "            -8.8441e-04,  8.8102e-04, -3.4404e-04,  1.4522e-03, -2.7268e-04,\n",
       "            -1.3635e-03, -3.1544e-03,  2.4073e-04,  1.5792e-05, -1.5781e-03,\n",
       "            -1.5611e-03, -1.1017e-03, -1.3513e-03,  3.7170e-04, -2.1716e-04,\n",
       "            -1.6579e-03, -1.0638e-04, -4.2877e-04, -3.6264e-03, -3.9286e-04,\n",
       "             3.5671e-04, -1.8172e-03, -6.0345e-04, -9.1758e-04,  1.0821e-03,\n",
       "            -8.2027e-04, -1.2981e-03, -9.6380e-04, -1.0114e-04,  1.5546e-04,\n",
       "            -8.2765e-04, -1.0118e-03], device='cuda:0')},\n",
       "   54: {'momentum_buffer': tensor([[[[-2.8247e-04]],\n",
       "    \n",
       "             [[-1.9106e-04]],\n",
       "    \n",
       "             [[-6.1192e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.6626e-04]],\n",
       "    \n",
       "             [[ 7.4422e-05]],\n",
       "    \n",
       "             [[ 6.4267e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.0148e-05]],\n",
       "    \n",
       "             [[-4.3074e-05]],\n",
       "    \n",
       "             [[-7.3651e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.1221e-05]],\n",
       "    \n",
       "             [[ 7.8939e-05]],\n",
       "    \n",
       "             [[-3.2548e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 9.6975e-05]],\n",
       "    \n",
       "             [[ 1.9143e-04]],\n",
       "    \n",
       "             [[-5.9099e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.2920e-04]],\n",
       "    \n",
       "             [[ 9.7748e-05]],\n",
       "    \n",
       "             [[ 7.2010e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-4.8408e-05]],\n",
       "    \n",
       "             [[-3.0632e-04]],\n",
       "    \n",
       "             [[ 5.7167e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.1642e-05]],\n",
       "    \n",
       "             [[ 3.3905e-04]],\n",
       "    \n",
       "             [[-1.6151e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.4624e-05]],\n",
       "    \n",
       "             [[-3.4467e-05]],\n",
       "    \n",
       "             [[-3.5963e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.3434e-05]],\n",
       "    \n",
       "             [[ 2.0566e-05]],\n",
       "    \n",
       "             [[-1.8306e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.5496e-04]],\n",
       "    \n",
       "             [[ 1.0874e-04]],\n",
       "    \n",
       "             [[ 3.6717e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.0285e-04]],\n",
       "    \n",
       "             [[-3.6999e-05]],\n",
       "    \n",
       "             [[-3.1422e-04]]]], device='cuda:0')},\n",
       "   55: {'momentum_buffer': tensor([0.0027, 0.0007, 0.0015, 0.0018, 0.0023, 0.0021, 0.0013, 0.0012, 0.0017,\n",
       "            0.0018, 0.0012, 0.0019, 0.0016, 0.0020, 0.0014, 0.0020, 0.0018, 0.0006,\n",
       "            0.0023, 0.0009, 0.0014, 0.0015, 0.0025, 0.0018, 0.0022, 0.0011, 0.0013,\n",
       "            0.0029, 0.0009, 0.0010, 0.0015, 0.0016, 0.0014, 0.0015, 0.0019, 0.0024,\n",
       "            0.0021, 0.0011, 0.0008, 0.0029, 0.0014, 0.0013, 0.0020, 0.0007, 0.0017,\n",
       "            0.0019, 0.0020, 0.0009, 0.0019, 0.0019, 0.0025, 0.0019, 0.0016, 0.0009,\n",
       "            0.0023, 0.0017, 0.0031, 0.0017, 0.0024, 0.0015, 0.0019, 0.0013, 0.0018,\n",
       "            0.0022, 0.0020, 0.0011, 0.0009, 0.0015, 0.0015, 0.0019, 0.0017, 0.0010,\n",
       "            0.0045, 0.0023, 0.0017, 0.0018, 0.0028, 0.0017, 0.0018, 0.0025, 0.0018,\n",
       "            0.0022, 0.0018, 0.0014, 0.0017, 0.0024, 0.0003, 0.0026, 0.0012, 0.0023,\n",
       "            0.0031, 0.0011, 0.0018, 0.0027, 0.0013, 0.0018, 0.0011, 0.0016, 0.0018,\n",
       "            0.0016, 0.0017, 0.0033, 0.0024, 0.0020, 0.0014, 0.0021, 0.0019, 0.0021,\n",
       "            0.0016, 0.0016, 0.0014, 0.0020, 0.0025, 0.0023, 0.0022, 0.0019, 0.0012,\n",
       "            0.0023, 0.0014, 0.0007, 0.0014, 0.0017, 0.0014, 0.0026, 0.0018, 0.0018,\n",
       "            0.0018, 0.0017], device='cuda:0')},\n",
       "   56: {'momentum_buffer': tensor([-1.8365e-03, -1.2618e-03, -6.0046e-04, -7.8253e-04, -2.6655e-03,\n",
       "            -5.0940e-04, -2.3080e-05, -5.1404e-04,  1.6330e-03, -1.9357e-03,\n",
       "            -6.2290e-04, -3.9525e-04, -1.3574e-03, -1.2821e-03,  5.7888e-04,\n",
       "             2.1807e-04, -5.6953e-04,  7.4054e-04, -1.0671e-03,  6.2035e-04,\n",
       "            -6.5396e-04, -2.3544e-05, -2.0477e-03, -7.2275e-04, -3.1106e-04,\n",
       "             7.8767e-04,  8.0495e-05, -9.4339e-06, -3.7181e-04,  6.2526e-05,\n",
       "            -1.7178e-03, -5.0649e-04, -5.5061e-05, -1.8846e-04, -9.5220e-04,\n",
       "            -1.3429e-03,  4.8657e-04,  1.9191e-04, -6.9784e-04, -2.2996e-03,\n",
       "            -3.1094e-04,  5.3948e-04, -1.4006e-03, -1.1093e-03, -8.4876e-05,\n",
       "            -3.1228e-04, -2.2492e-04,  3.3018e-04,  1.8051e-04, -5.1573e-04,\n",
       "            -3.2024e-03,  3.6477e-04,  2.2825e-05,  2.0179e-04, -5.3887e-04,\n",
       "            -1.6064e-03, -1.6381e-03, -3.4527e-04, -1.6400e-03, -1.5077e-04,\n",
       "             1.5412e-03, -1.5411e-03, -1.1776e-03,  2.4897e-05, -1.2038e-03,\n",
       "             2.9412e-04,  3.1454e-04,  5.6552e-04, -7.8632e-04, -2.3411e-03,\n",
       "            -2.9434e-04,  7.8010e-04, -5.7544e-03, -3.6119e-04, -1.4443e-03,\n",
       "            -5.0085e-04, -1.4139e-03, -1.4437e-03, -1.8524e-03, -2.3505e-03,\n",
       "             2.0653e-04, -1.1734e-03, -1.0828e-03, -5.8830e-04, -9.7423e-04,\n",
       "            -2.9687e-03,  1.8179e-03, -4.1296e-03,  4.0901e-05, -1.3028e-03,\n",
       "            -3.2942e-05,  4.6006e-04, -1.8942e-04, -1.8626e-03,  3.5115e-04,\n",
       "             4.9294e-04,  6.5065e-04,  5.5561e-04, -1.0623e-03, -1.2991e-03,\n",
       "            -1.6827e-03, -3.0456e-03,  3.4651e-04, -1.0299e-03, -1.5373e-03,\n",
       "            -1.3690e-03,  1.0993e-05, -1.2803e-04, -1.5592e-03, -1.1503e-03,\n",
       "            -1.4311e-03, -4.8416e-04, -3.5390e-03, -1.0646e-03, -2.2233e-03,\n",
       "            -4.9166e-04,  4.9145e-04, -5.8424e-04,  3.7995e-04,  2.2078e-04,\n",
       "            -8.9450e-04, -1.0306e-03,  2.8122e-04, -2.4892e-03, -1.6424e-04,\n",
       "             1.2175e-04, -1.9875e-03, -9.5606e-05], device='cuda:0')},\n",
       "   57: {'momentum_buffer': tensor([[[[-4.2973e-05,  9.8793e-05,  1.2827e-04],\n",
       "              [-3.0931e-04, -3.8586e-05, -7.5124e-05],\n",
       "              [-1.7545e-04, -2.0035e-04, -1.2178e-05]],\n",
       "    \n",
       "             [[-1.9597e-04, -1.4411e-04, -3.1579e-04],\n",
       "              [-1.1556e-04, -1.0689e-04, -9.4208e-05],\n",
       "              [-1.6619e-04, -1.6134e-04, -1.4764e-04]],\n",
       "    \n",
       "             [[-1.3893e-04, -1.0813e-04, -1.3710e-04],\n",
       "              [ 4.5160e-05, -1.5592e-04, -1.2831e-04],\n",
       "              [-3.8718e-05, -2.0032e-04, -1.1527e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.1734e-04,  1.4763e-04,  5.1107e-05],\n",
       "              [ 2.7627e-04,  2.8098e-04, -1.6489e-05],\n",
       "              [ 3.8885e-04,  1.5263e-04, -3.6465e-05]],\n",
       "    \n",
       "             [[-3.8127e-05, -8.8014e-05, -1.2404e-04],\n",
       "              [-5.9391e-05,  4.5711e-04,  1.4238e-05],\n",
       "              [ 3.7162e-05,  1.5027e-04,  6.9191e-05]],\n",
       "    \n",
       "             [[-2.2415e-04, -4.9595e-04, -2.4009e-04],\n",
       "              [-1.8065e-04, -5.3529e-04, -1.7340e-04],\n",
       "              [-1.5483e-04, -1.8809e-04,  4.0874e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.5499e-04, -1.1799e-04, -2.9610e-04],\n",
       "              [ 1.8549e-04,  4.9863e-05, -3.6668e-06],\n",
       "              [ 4.4043e-04,  1.8477e-04, -8.3387e-06]],\n",
       "    \n",
       "             [[ 9.6923e-06, -1.8022e-04,  4.6768e-05],\n",
       "              [ 1.3147e-04, -3.7480e-04, -4.2063e-04],\n",
       "              [-4.7199e-05, -2.7609e-04, -5.7708e-04]],\n",
       "    \n",
       "             [[-1.9753e-04,  8.5777e-05,  2.9234e-04],\n",
       "              [-1.9257e-04, -3.4600e-04,  1.4498e-04],\n",
       "              [-1.6781e-04, -5.3650e-05, -6.2766e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.2354e-04,  4.4142e-05, -3.0732e-05],\n",
       "              [-1.9201e-07,  4.9123e-05, -1.2805e-04],\n",
       "              [ 2.1895e-04,  1.6891e-04, -1.1274e-05]],\n",
       "    \n",
       "             [[ 7.5594e-05,  1.0229e-04,  3.2894e-05],\n",
       "              [ 2.3450e-05, -2.5926e-05, -3.8081e-05],\n",
       "              [ 3.9498e-05, -5.6068e-05,  9.5534e-06]],\n",
       "    \n",
       "             [[-1.5928e-04, -7.7183e-05,  1.5673e-04],\n",
       "              [-5.3172e-05,  2.4902e-04,  2.0910e-04],\n",
       "              [-2.0817e-04, -3.0859e-04,  1.3013e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.0945e-04, -2.6041e-04,  1.6581e-05],\n",
       "              [-2.9534e-05,  3.9885e-05,  1.6674e-04],\n",
       "              [ 7.0548e-05,  5.5957e-04, -2.9345e-04]],\n",
       "    \n",
       "             [[ 1.9059e-05, -2.3264e-04, -3.2863e-04],\n",
       "              [ 1.7901e-04,  1.8250e-05, -5.2604e-04],\n",
       "              [-1.5896e-04, -3.0654e-04, -1.5037e-05]],\n",
       "    \n",
       "             [[ 4.2372e-04,  3.4924e-04,  1.6358e-04],\n",
       "              [ 3.1717e-04,  6.8232e-04,  3.6385e-04],\n",
       "              [-3.1199e-04,  1.9758e-04,  5.8247e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.2409e-04, -2.2114e-04,  8.4700e-06],\n",
       "              [-2.7794e-04, -6.1955e-05,  1.7791e-04],\n",
       "              [ 1.6800e-04,  7.3474e-05, -7.7508e-05]],\n",
       "    \n",
       "             [[-4.6480e-05, -2.4569e-05, -2.6581e-06],\n",
       "              [ 1.0725e-04,  2.9610e-05,  9.9366e-05],\n",
       "              [ 5.7882e-05,  4.5065e-05,  1.5939e-05]],\n",
       "    \n",
       "             [[-5.4079e-04, -2.8604e-04, -2.1914e-04],\n",
       "              [-4.8279e-04, -1.5760e-04, -5.1712e-04],\n",
       "              [-4.0940e-04, -2.0885e-04, -1.6831e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-1.2271e-04,  4.2531e-05,  3.9071e-05],\n",
       "              [ 1.2772e-04,  2.8593e-04,  1.7253e-04],\n",
       "              [ 3.7900e-05,  1.6916e-04,  6.7557e-06]],\n",
       "    \n",
       "             [[-4.2807e-05, -9.0067e-05, -5.1827e-05],\n",
       "              [-6.9212e-05, -5.5041e-05, -6.7653e-05],\n",
       "              [-7.7064e-05,  6.2655e-06, -1.1542e-05]],\n",
       "    \n",
       "             [[ 2.6702e-05, -1.0968e-04, -5.2926e-05],\n",
       "              [-3.5529e-05, -9.7475e-05, -1.0143e-04],\n",
       "              [ 3.0252e-05,  1.7679e-05,  3.1573e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.9208e-04, -3.8679e-05, -6.0032e-05],\n",
       "              [-1.9496e-04, -2.8672e-05, -8.8396e-05],\n",
       "              [-2.0110e-04, -1.6753e-05, -7.2631e-05]],\n",
       "    \n",
       "             [[-5.8841e-04, -9.8875e-04, -6.9826e-05],\n",
       "              [-3.7799e-04, -6.1219e-04, -1.4035e-04],\n",
       "              [ 1.6244e-04,  1.0682e-05, -1.1458e-04]],\n",
       "    \n",
       "             [[ 1.6932e-05, -4.1507e-04, -1.1759e-04],\n",
       "              [ 4.4878e-04, -1.8992e-04, -6.8750e-05],\n",
       "              [ 5.0502e-04, -5.8317e-05,  2.3735e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-5.3066e-04, -3.5262e-04, -2.7118e-04],\n",
       "              [-3.5229e-04,  3.5265e-05, -1.2725e-04],\n",
       "              [-6.9144e-05, -3.9635e-04, -2.3053e-04]],\n",
       "    \n",
       "             [[ 2.6710e-04,  2.0300e-04,  3.5029e-04],\n",
       "              [ 3.3382e-04, -2.5741e-04,  1.8445e-04],\n",
       "              [ 2.9542e-05,  1.9801e-04,  1.1331e-04]],\n",
       "    \n",
       "             [[-4.0230e-05,  1.1240e-04, -2.4138e-04],\n",
       "              [-6.9880e-05,  1.0124e-04,  1.2199e-04],\n",
       "              [ 3.3721e-04,  3.8773e-04,  7.1853e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.7840e-05,  1.0811e-05, -1.6134e-04],\n",
       "              [-1.8430e-05, -1.4567e-04, -1.6679e-04],\n",
       "              [-5.3414e-04, -3.2550e-04, -2.5838e-04]],\n",
       "    \n",
       "             [[ 1.4868e-04,  1.6248e-04,  8.2603e-05],\n",
       "              [ 9.9090e-05, -1.0755e-03, -1.6832e-05],\n",
       "              [ 4.6260e-05, -5.3432e-05, -5.9255e-05]],\n",
       "    \n",
       "             [[-1.1467e-04, -7.2441e-05, -5.7969e-05],\n",
       "              [-1.2683e-05, -4.7245e-04, -9.0193e-05],\n",
       "              [-2.6297e-04, -1.5193e-04,  8.2458e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.1699e-04,  1.0278e-04,  3.0706e-04],\n",
       "              [ 2.5781e-04,  3.1361e-04,  4.2427e-04],\n",
       "              [ 3.6874e-04,  1.8627e-04,  3.6953e-04]],\n",
       "    \n",
       "             [[ 8.0708e-05,  7.8973e-05,  3.1323e-04],\n",
       "              [-9.3759e-05, -1.2488e-04,  3.5724e-04],\n",
       "              [ 1.1292e-04, -3.3908e-04,  2.4210e-04]],\n",
       "    \n",
       "             [[ 2.3182e-04,  3.3570e-04,  4.4452e-05],\n",
       "              [ 3.2754e-04,  1.4375e-04,  1.9092e-04],\n",
       "              [ 1.2743e-04, -1.6076e-05,  1.0554e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.4208e-04, -6.1623e-04, -2.9321e-04],\n",
       "              [-2.4792e-04,  5.1944e-05, -2.8562e-04],\n",
       "              [ 2.1332e-04,  2.8905e-04, -2.9585e-04]],\n",
       "    \n",
       "             [[ 4.7032e-05,  6.2828e-08,  4.0371e-05],\n",
       "              [-3.5868e-05,  5.4354e-04,  2.2359e-05],\n",
       "              [-1.6269e-05,  5.8025e-05,  1.4321e-05]],\n",
       "    \n",
       "             [[-4.2300e-04, -1.5503e-04, -1.9196e-04],\n",
       "              [-5.7808e-04,  1.0754e-04, -3.3579e-04],\n",
       "              [-7.0100e-04,  1.3063e-04,  1.2478e-04]]]], device='cuda:0')},\n",
       "   58: {'momentum_buffer': tensor([ 0.0012,  0.0025,  0.0018,  0.0020,  0.0022,  0.0021,  0.0018,  0.0018,\n",
       "             0.0027,  0.0018,  0.0024,  0.0014,  0.0042,  0.0024,  0.0027,  0.0016,\n",
       "             0.0019,  0.0010,  0.0023,  0.0023,  0.0017,  0.0011,  0.0017,  0.0026,\n",
       "             0.0026,  0.0020,  0.0016,  0.0012,  0.0005,  0.0014,  0.0024,  0.0019,\n",
       "             0.0019,  0.0011,  0.0024,  0.0026,  0.0015,  0.0019,  0.0018,  0.0016,\n",
       "             0.0037,  0.0005,  0.0024,  0.0022,  0.0024,  0.0030,  0.0012,  0.0020,\n",
       "             0.0022,  0.0024,  0.0031,  0.0020,  0.0021,  0.0021,  0.0018,  0.0021,\n",
       "             0.0012,  0.0011,  0.0031,  0.0028,  0.0020,  0.0027,  0.0032,  0.0013,\n",
       "             0.0022,  0.0020,  0.0037,  0.0023,  0.0013,  0.0029,  0.0024,  0.0010,\n",
       "             0.0024, -0.0004,  0.0014,  0.0020,  0.0013,  0.0015,  0.0012,  0.0017,\n",
       "             0.0022,  0.0015,  0.0020,  0.0023,  0.0028,  0.0021,  0.0026,  0.0014,\n",
       "             0.0021,  0.0014,  0.0019,  0.0016,  0.0024,  0.0019,  0.0013,  0.0024,\n",
       "             0.0020,  0.0024,  0.0017,  0.0020,  0.0016,  0.0027,  0.0029,  0.0024,\n",
       "             0.0021,  0.0027,  0.0022,  0.0019,  0.0033,  0.0020,  0.0031,  0.0032,\n",
       "             0.0021,  0.0029,  0.0009,  0.0024,  0.0021,  0.0024,  0.0020,  0.0030,\n",
       "             0.0030,  0.0035,  0.0023,  0.0017,  0.0014,  0.0039,  0.0032,  0.0018],\n",
       "           device='cuda:0')},\n",
       "   59: {'momentum_buffer': tensor([-1.1031e-03, -1.0309e-03, -9.8596e-04, -1.0618e-03, -1.2094e-03,\n",
       "            -1.3135e-03, -1.7071e-03, -8.6184e-04, -1.0917e-03, -2.2135e-03,\n",
       "            -1.3750e-03,  1.8327e-03, -9.7932e-04, -1.5384e-03, -2.1333e-03,\n",
       "             1.2592e-03, -1.2124e-03,  2.6536e-03, -7.4908e-04, -1.1801e-03,\n",
       "             5.4923e-04,  3.3598e-03, -1.8543e-03, -1.0578e-03, -2.5322e-03,\n",
       "            -9.9406e-04,  2.1448e-03,  2.5301e-03,  2.8623e-03, -3.6868e-04,\n",
       "            -3.5499e-04, -3.6636e-04,  3.3565e-04, -2.8099e-04, -9.0112e-04,\n",
       "            -1.7899e-03,  2.8946e-03, -1.0951e-03, -2.0004e-04, -5.3644e-04,\n",
       "            -2.4702e-03,  2.0648e-03, -9.7094e-04, -1.3027e-03, -1.5097e-03,\n",
       "            -1.8216e-03,  3.2883e-03, -1.6045e-03, -1.7732e-03, -2.3916e-04,\n",
       "            -1.4086e-03, -4.8651e-04, -1.9889e-03, -9.0593e-04, -5.0125e-06,\n",
       "            -4.1491e-04, -1.5004e-03, -1.8614e-03, -1.7050e-03, -1.0012e-03,\n",
       "            -2.8998e-04, -1.9739e-03, -1.2129e-03, -9.7728e-04, -1.0104e-03,\n",
       "            -1.3047e-03, -2.8761e-03, -1.2720e-03,  3.1454e-03, -1.9333e-03,\n",
       "            -6.8685e-04,  9.6028e-04, -1.9693e-03,  1.9112e-03,  1.5438e-04,\n",
       "             1.1492e-04, -2.2778e-03, -2.0134e-03,  3.5110e-03,  3.1732e-03,\n",
       "             3.1666e-04,  1.1764e-03, -7.3838e-04, -1.4089e-03, -1.4275e-03,\n",
       "            -1.3706e-03, -2.0941e-03, -1.4064e-03, -6.6610e-04, -6.3000e-06,\n",
       "            -1.1027e-03, -1.3319e-03, -1.1664e-03,  3.9074e-04,  2.1588e-03,\n",
       "            -7.4098e-04,  1.9123e-03, -6.1084e-04, -4.8385e-04, -6.4240e-04,\n",
       "             4.4633e-04, -2.8498e-04, -3.4791e-03,  8.6629e-05, -8.3195e-04,\n",
       "            -1.8378e-03, -6.4754e-04, -1.7755e-03, -2.6002e-03, -4.0998e-06,\n",
       "            -1.1429e-03, -2.3639e-03, -1.4141e-03, -8.9555e-04,  3.5146e-03,\n",
       "            -1.1483e-03, -2.4329e-03, -1.7516e-03,  1.8146e-04, -3.7724e-04,\n",
       "            -1.8067e-03, -1.7707e-03, -9.3080e-04,  2.6660e-04, -1.3509e-03,\n",
       "            -3.6219e-03, -1.3677e-03, -1.0297e-03], device='cuda:0')},\n",
       "   60: {'momentum_buffer': tensor([[[[ 1.5951e-04]],\n",
       "    \n",
       "             [[ 1.3550e-04]],\n",
       "    \n",
       "             [[ 2.2297e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.5819e-05]],\n",
       "    \n",
       "             [[-8.2120e-05]],\n",
       "    \n",
       "             [[-5.4708e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.5313e-04]],\n",
       "    \n",
       "             [[ 3.7833e-04]],\n",
       "    \n",
       "             [[ 6.6118e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.2196e-04]],\n",
       "    \n",
       "             [[ 6.6883e-05]],\n",
       "    \n",
       "             [[-1.3314e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.2199e-04]],\n",
       "    \n",
       "             [[ 4.0827e-06]],\n",
       "    \n",
       "             [[ 9.1109e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-7.7435e-05]],\n",
       "    \n",
       "             [[-6.9158e-05]],\n",
       "    \n",
       "             [[ 1.2614e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 3.7594e-04]],\n",
       "    \n",
       "             [[ 1.4984e-04]],\n",
       "    \n",
       "             [[ 1.7712e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.3090e-06]],\n",
       "    \n",
       "             [[-3.3942e-04]],\n",
       "    \n",
       "             [[ 2.7678e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.5116e-05]],\n",
       "    \n",
       "             [[-1.8582e-04]],\n",
       "    \n",
       "             [[ 1.2888e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.6293e-04]],\n",
       "    \n",
       "             [[-9.0899e-05]],\n",
       "    \n",
       "             [[ 1.6757e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.1342e-04]],\n",
       "    \n",
       "             [[-3.4063e-04]],\n",
       "    \n",
       "             [[-6.8523e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.5402e-04]],\n",
       "    \n",
       "             [[ 4.1113e-04]],\n",
       "    \n",
       "             [[-3.0913e-04]]]], device='cuda:0')},\n",
       "   61: {'momentum_buffer': tensor([ 3.7039e-04,  1.1803e-03,  7.5647e-04,  6.9080e-04,  1.1849e-03,\n",
       "             7.6851e-04,  5.4234e-04,  1.4680e-03,  5.2985e-04,  1.6969e-03,\n",
       "             2.9677e-04,  6.3632e-05, -4.2874e-06,  1.5382e-03,  1.7683e-03,\n",
       "             1.3613e-03,  2.6060e-04,  2.4996e-04,  1.2360e-03, -5.8108e-04,\n",
       "             6.8210e-04,  3.9142e-04,  1.0209e-03, -9.5647e-06,  1.9424e-03,\n",
       "             1.2234e-03,  1.5813e-03,  1.2289e-03,  1.2653e-03,  3.5086e-04,\n",
       "             1.5703e-03,  1.4450e-03,  1.6141e-03,  2.8203e-03,  9.4283e-04,\n",
       "             6.2080e-04,  5.2557e-04,  2.2926e-04,  9.7464e-04,  8.3066e-04,\n",
       "             4.5834e-04,  1.2916e-04,  6.4852e-04,  1.4844e-03,  1.0372e-03,\n",
       "             1.8032e-03,  1.1724e-05,  1.4262e-03,  1.3142e-03,  4.8470e-04,\n",
       "             3.7717e-04, -1.5843e-04,  1.1098e-03,  6.7514e-04,  9.7433e-04,\n",
       "             3.2254e-04,  2.2259e-05,  1.8011e-04,  9.0991e-04,  5.7027e-04,\n",
       "             3.6868e-04,  1.4774e-04,  1.3057e-03,  8.8014e-04,  4.2527e-04,\n",
       "             1.3919e-03,  8.1555e-04,  5.6669e-04,  2.3994e-04,  4.9745e-04,\n",
       "             1.2968e-03,  1.0479e-03,  2.1158e-03,  5.9258e-04,  1.8716e-03,\n",
       "             3.1895e-04,  6.1400e-04,  6.3176e-04,  1.1757e-03,  3.7457e-04,\n",
       "             3.4557e-04,  1.1090e-03,  1.0357e-03,  6.4002e-04,  6.1493e-04,\n",
       "             1.7126e-03,  1.2034e-03,  2.7486e-03,  4.2952e-04,  4.7700e-04,\n",
       "             1.0960e-03,  1.9934e-03,  2.8743e-04,  1.0304e-04,  1.4119e-03,\n",
       "             9.7804e-04,  7.2693e-04,  2.4657e-03,  7.5753e-04,  1.4808e-03,\n",
       "             1.5831e-03,  1.5638e-03,  1.5425e-03,  4.9708e-04,  1.3045e-03,\n",
       "             1.3688e-04,  1.1432e-03,  1.0147e-03,  8.5898e-04,  2.2213e-04,\n",
       "             4.7573e-04,  6.9592e-04,  4.1425e-04,  1.5911e-03,  3.9918e-04,\n",
       "             1.1813e-04,  8.4723e-04,  2.6333e-04,  6.8102e-05,  6.2102e-04,\n",
       "             2.7753e-04,  1.8570e-03,  7.5844e-04,  1.3542e-03,  9.9230e-05,\n",
       "             6.8113e-04,  7.5567e-04,  1.8174e-03,  1.3328e-03,  1.3402e-03,\n",
       "             1.0980e-03,  1.4008e-03,  2.9024e-03,  2.0877e-03,  1.2901e-03,\n",
       "             3.5337e-04,  9.9746e-04,  1.8561e-03,  3.1368e-04,  1.2848e-03,\n",
       "             9.3864e-04,  1.0022e-03,  8.1002e-04,  2.0472e-03,  1.4832e-03,\n",
       "             8.6951e-04,  1.2697e-03,  9.0316e-04,  1.0851e-03,  8.5072e-04,\n",
       "             1.1663e-03,  1.8009e-03,  1.5477e-03,  1.3829e-03,  6.3791e-04,\n",
       "             4.8586e-04,  1.0527e-03,  1.2100e-03,  6.5199e-04, -4.0105e-04,\n",
       "             9.9724e-04,  5.1135e-04,  1.5072e-03,  8.5424e-04,  9.0584e-04,\n",
       "             1.1280e-03,  7.3870e-04,  9.6703e-04,  1.0441e-03,  7.4803e-04,\n",
       "             1.0340e-04,  2.5821e-03,  3.9533e-04,  7.7249e-04,  1.4872e-03,\n",
       "             1.0390e-03,  1.0870e-03,  2.4658e-04,  2.1754e-03,  1.7708e-03,\n",
       "             4.3851e-04, -1.5651e-04,  1.4831e-04,  1.2835e-03,  1.8589e-03,\n",
       "             1.1162e-03,  5.6464e-04,  9.1711e-04,  8.7714e-04, -6.3917e-05,\n",
       "             3.3650e-03,  1.7215e-04,  1.2336e-03,  7.3557e-04,  9.3106e-04,\n",
       "             1.0280e-04,  4.1100e-04,  3.5912e-04,  1.2052e-03,  1.2299e-03,\n",
       "             5.8340e-04, -1.4156e-04,  1.1566e-05,  6.9737e-05,  8.3596e-04,\n",
       "             5.5126e-04,  5.4603e-04,  5.2324e-04,  1.1050e-03,  1.1069e-03,\n",
       "             1.2771e-03,  5.4216e-04,  6.9875e-04,  7.8771e-04,  1.6270e-03,\n",
       "             2.1011e-03,  8.6979e-04,  7.6235e-04,  4.9770e-04,  6.8331e-04,\n",
       "             9.5508e-04,  2.8058e-04,  4.3529e-04,  1.2745e-03, -4.2259e-05,\n",
       "             1.0542e-03,  4.0481e-03,  1.4110e-03,  6.5574e-04,  1.4335e-03,\n",
       "             8.1418e-04,  8.0016e-04,  2.4651e-04,  2.7438e-04,  9.7858e-04,\n",
       "             2.8172e-04,  1.3313e-03,  4.5519e-04,  5.6505e-04,  5.4628e-05,\n",
       "             5.9701e-04,  1.6689e-03,  7.1473e-04, -3.1513e-04,  9.3567e-04,\n",
       "             2.6786e-03, -7.0842e-05,  1.7329e-03,  4.6418e-04,  1.2221e-03,\n",
       "             2.3280e-04,  2.8205e-04,  6.2403e-04,  1.5021e-04,  5.3248e-04,\n",
       "             4.6076e-04,  3.0863e-04,  6.3724e-04,  2.5664e-03,  1.0856e-03,\n",
       "             5.3161e-04,  1.0948e-03,  4.8252e-04,  6.6715e-04,  1.2290e-04,\n",
       "             7.9516e-04,  9.2721e-04,  5.1857e-04,  1.7089e-03,  2.0029e-03,\n",
       "             5.6017e-04, -1.4389e-04,  1.7700e-03,  1.8066e-03,  1.2866e-03,\n",
       "            -4.4255e-05,  2.0932e-03,  3.3721e-03,  4.9454e-04,  8.7657e-04,\n",
       "             1.4939e-03, -8.9399e-04,  1.3622e-03,  1.1715e-04,  7.3796e-04,\n",
       "             6.1510e-04,  3.4760e-04,  7.4293e-04,  1.5111e-03,  6.2154e-04,\n",
       "             1.7944e-04, -7.4300e-06,  1.6999e-03,  4.9276e-04,  1.4458e-03,\n",
       "             5.4553e-04,  6.5634e-04,  1.0648e-03,  2.0135e-03,  1.2107e-03,\n",
       "             4.2155e-04,  9.7194e-04,  2.5004e-04,  1.0972e-03,  2.7390e-04,\n",
       "             2.2610e-04,  1.1905e-03,  5.2358e-04,  6.7501e-04,  1.6124e-03,\n",
       "            -8.2873e-05,  1.1715e-03,  3.3096e-03,  1.5362e-03,  1.2157e-03,\n",
       "             5.7987e-04,  1.6467e-04,  1.1157e-03,  1.0374e-03,  6.5929e-04,\n",
       "             1.4338e-03,  1.4321e-03,  8.6409e-04,  1.9362e-04,  1.1895e-03,\n",
       "             7.7056e-04,  1.1905e-03,  1.0951e-03,  5.1763e-04,  2.7864e-04,\n",
       "             1.4901e-03,  1.1395e-03,  2.1445e-03,  1.5500e-03,  1.0585e-03,\n",
       "             7.5841e-04,  1.3353e-04,  1.9286e-03,  8.1514e-05,  2.3241e-03,\n",
       "             5.5865e-04,  5.4543e-04,  2.9305e-03,  1.3262e-03,  4.5217e-04,\n",
       "             1.7278e-03,  7.5367e-04,  8.6127e-04,  6.4690e-04,  7.5296e-04,\n",
       "             1.1185e-03,  8.6112e-04,  2.0562e-03,  7.7132e-04,  4.2996e-05,\n",
       "             5.1344e-04,  1.1909e-03,  7.1082e-04,  7.9539e-04,  6.9645e-04,\n",
       "             5.6915e-04,  1.8518e-03,  1.0247e-03,  2.2104e-04,  6.0779e-04,\n",
       "             1.0873e-03,  4.7962e-04,  6.3016e-04,  1.9073e-03,  2.0122e-03,\n",
       "            -5.8737e-04,  8.9402e-04,  2.6742e-03,  4.7013e-04,  1.6455e-04,\n",
       "             5.2732e-04,  9.9319e-04,  1.7486e-03,  4.3886e-04,  5.7142e-04,\n",
       "             1.1866e-05, -1.1875e-04,  1.0191e-03,  1.5823e-04,  8.8504e-04,\n",
       "             1.6506e-03,  1.5352e-03,  8.4949e-04,  6.7952e-04,  7.1000e-04,\n",
       "             5.5095e-05,  2.0616e-03,  5.9620e-04,  1.2766e-04,  4.6997e-04,\n",
       "             1.1346e-03,  3.6425e-04,  1.9793e-03,  1.0413e-03,  8.4609e-04,\n",
       "             8.5321e-04,  3.1371e-04,  6.0011e-04,  9.7063e-04,  1.2325e-03,\n",
       "             1.5485e-03,  2.1114e-04,  4.0103e-05,  3.9000e-04,  5.9340e-04,\n",
       "             7.7289e-04,  1.8529e-03,  8.7078e-04,  1.3538e-03,  7.6295e-04,\n",
       "             1.1825e-03, -1.2417e-04,  2.5994e-04,  9.7090e-04,  6.3110e-04,\n",
       "             4.0471e-04,  4.2005e-03,  3.7693e-05,  1.2419e-03,  1.2464e-03,\n",
       "             1.5847e-03,  1.2489e-03,  6.7425e-04,  1.9244e-03,  1.6753e-03,\n",
       "             1.4515e-03,  9.3934e-04,  1.1289e-03,  8.6587e-05,  5.6434e-04,\n",
       "             5.3636e-04,  2.5348e-03,  1.0313e-03,  1.7754e-03,  1.0559e-03,\n",
       "             1.5009e-03,  4.8085e-04,  1.4435e-03,  7.8623e-04,  8.8539e-04,\n",
       "             6.2054e-04,  1.0380e-03,  1.5641e-03,  3.3232e-04,  5.5507e-04,\n",
       "             9.9609e-04,  1.0638e-04,  1.2523e-03,  2.6031e-04,  9.9352e-04,\n",
       "             1.9311e-03,  1.9100e-03,  1.5810e-03,  6.3753e-04, -2.0246e-04,\n",
       "             3.2600e-03,  5.1103e-04,  2.2938e-03,  9.9612e-04,  4.5200e-05,\n",
       "             1.4167e-03,  1.6619e-03,  8.1675e-04,  8.8875e-04,  1.5924e-03,\n",
       "             3.5212e-04,  6.8436e-04,  1.1451e-03,  1.4566e-03,  1.0734e-04,\n",
       "             1.0858e-03,  9.4315e-04,  5.7874e-04,  1.7095e-03,  8.0254e-04,\n",
       "             1.5542e-03,  1.5032e-03,  9.5532e-04,  1.8249e-03,  5.1307e-04,\n",
       "             1.3433e-03,  1.9873e-03,  1.2831e-03,  4.5247e-04,  3.8499e-04,\n",
       "             4.3192e-04,  1.0379e-03, -4.7268e-05,  1.3540e-03,  1.6473e-03,\n",
       "             2.0617e-03,  7.0699e-04,  8.8037e-04,  1.9872e-03,  4.3875e-04,\n",
       "             1.3235e-03,  2.0882e-03,  6.4382e-04,  3.2910e-04,  7.8850e-04,\n",
       "             1.7068e-03,  4.1031e-04,  7.2071e-04,  5.7930e-04,  6.6859e-04,\n",
       "             4.1149e-04,  1.4763e-03], device='cuda:0')},\n",
       "   62: {'momentum_buffer': tensor([-6.5904e-04, -2.6694e-03,  3.4926e-04, -4.1107e-04, -1.3821e-03,\n",
       "             2.1793e-04, -8.7060e-04, -2.3995e-03, -7.0740e-04,  1.0172e-03,\n",
       "            -4.8849e-04,  1.9152e-04, -2.5896e-04, -4.4175e-04,  5.2724e-04,\n",
       "            -9.1536e-04, -4.6721e-04, -3.6152e-04, -1.1492e-03, -2.9166e-04,\n",
       "             2.8699e-04,  4.8988e-06, -2.0962e-03, -7.9183e-05, -1.8073e-03,\n",
       "            -1.5744e-03,  7.0411e-05, -6.6390e-04,  1.4664e-04, -1.1013e-03,\n",
       "            -1.9264e-03, -3.9277e-03,  5.7344e-04, -2.1294e-03, -4.9621e-04,\n",
       "            -1.2867e-04,  2.5128e-03,  6.0239e-04, -1.1514e-03, -1.6532e-03,\n",
       "            -5.1822e-04, -2.3196e-05,  8.2144e-04, -7.6641e-04, -1.9148e-03,\n",
       "             9.0275e-04, -8.1916e-05,  3.2588e-04, -3.5782e-03,  8.5901e-05,\n",
       "            -6.4547e-06,  3.1232e-04, -5.3902e-04, -3.6795e-04, -8.0715e-04,\n",
       "             2.2148e-04, -2.6197e-04, -3.8851e-04, -1.5349e-03, -1.5360e-03,\n",
       "             2.3648e-04,  2.2233e-05,  1.4390e-03, -7.6225e-04, -4.4806e-04,\n",
       "            -1.9716e-03, -5.4122e-04,  5.4724e-07, -1.0976e-03, -1.8959e-04,\n",
       "            -1.0800e-03, -2.0944e-03, -1.9725e-03, -9.0779e-04, -2.1094e-03,\n",
       "            -3.3908e-04, -3.9676e-04, -4.3061e-04, -1.0199e-03,  2.3066e-05,\n",
       "            -3.7144e-04, -1.1911e-03, -1.8923e-03, -1.3696e-04, -8.4879e-04,\n",
       "            -3.1087e-03, -1.2905e-03, -3.7084e-04, -1.8225e-04, -4.2101e-04,\n",
       "             6.5058e-04, -1.7734e-03, -6.6035e-04,  5.7937e-04, -2.9209e-03,\n",
       "             5.5794e-05,  3.5585e-04, -3.1005e-03, -5.4772e-04, -1.7611e-03,\n",
       "            -7.3687e-04, -2.7193e-03, -6.4926e-04, -3.3290e-05, -1.6415e-03,\n",
       "            -8.9365e-04, -1.2763e-03, -1.3722e-03, -1.0698e-03, -1.7513e-04,\n",
       "             3.3487e-05, -2.4572e-03, -6.0809e-04, -2.1313e-03, -2.8939e-04,\n",
       "             8.1996e-05, -7.5078e-04, -5.6132e-04, -1.3971e-04, -5.4548e-04,\n",
       "            -1.8628e-04, -1.3153e-03, -8.1758e-04, -1.8460e-03,  1.0643e-04,\n",
       "            -7.8873e-04, -1.1215e-03,  2.4773e-04, -1.2224e-03, -1.2156e-03,\n",
       "             1.2152e-04, -1.4012e-03, -4.5730e-03, -2.9303e-03, -2.0958e-03,\n",
       "            -2.1355e-04,  6.1626e-05, -5.7672e-04, -4.7781e-04, -1.9114e-03,\n",
       "            -2.0005e-03,  7.9057e-04,  1.1000e-03,  1.8477e-03, -1.6436e-03,\n",
       "             2.7408e-04,  2.4407e-04, -1.6999e-03,  9.4445e-04, -1.0196e-03,\n",
       "            -2.8669e-04, -3.8425e-03, -7.3544e-04, -9.1031e-04, -1.6724e-04,\n",
       "             1.2763e-04, -1.2940e-04,  2.1591e-03, -9.6319e-04, -4.4716e-04,\n",
       "            -2.4815e-03, -6.6264e-04, -2.4381e-03, -4.5825e-04, -2.8524e-03,\n",
       "            -2.2274e-03, -3.5924e-03, -1.4133e-03, -6.5740e-04, -1.3620e-04,\n",
       "            -5.6204e-04, -1.2466e-03,  6.8958e-04, -2.9599e-03,  7.7842e-04,\n",
       "            -1.6235e-03, -4.8723e-04, -6.0780e-04,  1.3555e-03, -8.6680e-05,\n",
       "             4.2563e-04,  8.5755e-04,  3.1752e-05,  6.6465e-05,  1.8987e-04,\n",
       "            -4.9460e-04, -6.5711e-04, -1.0101e-03, -2.1405e-04, -2.1330e-05,\n",
       "            -1.6656e-03, -6.4383e-05, -5.6066e-04, -1.7910e-04, -1.5330e-03,\n",
       "             2.7873e-04, -3.4171e-05,  3.2041e-04, -6.8691e-04, -1.2469e-03,\n",
       "            -1.8398e-04,  4.6987e-04, -1.4999e-04, -2.6148e-04, -7.5254e-05,\n",
       "            -7.5922e-04, -5.4515e-04, -2.9017e-04,  1.0948e-03, -2.9401e-03,\n",
       "            -1.3024e-03,  1.4000e-04,  5.7705e-04,  8.4660e-04, -3.6447e-04,\n",
       "            -2.5368e-03, -1.8138e-03, -1.9057e-03, -3.7226e-04,  1.2051e-04,\n",
       "            -1.0100e-03, -9.8197e-04, -1.5432e-03, -2.7815e-03, -1.7327e-04,\n",
       "            -4.8599e-04, -8.1598e-04, -2.8577e-04, -1.0802e-03, -2.4959e-03,\n",
       "            -3.1241e-03, -5.2124e-05, -8.3176e-05, -2.9434e-04, -1.3730e-04,\n",
       "             7.5417e-05,  1.9991e-04,  2.1496e-05, -4.5691e-04,  4.0477e-05,\n",
       "            -7.2067e-04, -1.1943e-03, -7.7655e-04, -7.0930e-04,  2.6225e-04,\n",
       "            -4.0015e-03,  2.6914e-04,  8.5232e-05, -4.8426e-05, -8.0247e-04,\n",
       "            -1.8192e-04,  4.9901e-05, -4.1414e-05, -2.2243e-04,  4.3898e-04,\n",
       "             4.1114e-04, -2.5763e-04, -5.1847e-04, -4.2292e-03, -3.0652e-04,\n",
       "            -1.1297e-03, -2.3029e-03, -1.1295e-03, -5.5174e-06, -2.1878e-04,\n",
       "            -1.9295e-04,  2.2816e-04, -6.1632e-04, -1.2794e-03, -1.6926e-03,\n",
       "            -5.1427e-04, -4.0390e-04, -7.6134e-04, -2.3231e-04, -1.0896e-03,\n",
       "            -3.3003e-04, -2.0630e-03, -5.5537e-04, -3.6634e-04, -5.9132e-04,\n",
       "            -3.6512e-04, -2.5101e-04, -1.1327e-03, -3.1101e-06, -1.9491e-03,\n",
       "            -5.1132e-04, -3.5752e-04,  2.9075e-04,  2.6450e-04, -5.7812e-04,\n",
       "             9.7629e-04, -6.7230e-05, -1.0934e-03, -9.9656e-04, -1.9047e-03,\n",
       "             1.8017e-05, -1.5560e-04,  3.2829e-04, -1.6340e-03, -2.7299e-04,\n",
       "            -3.6845e-04, -1.3639e-03, -1.1331e-03,  1.6445e-04,  5.1826e-04,\n",
       "            -1.5297e-04, -8.8053e-04, -1.7122e-04, -3.5117e-04,  1.8880e-03,\n",
       "            -3.8491e-04,  1.4209e-04, -2.6396e-03, -7.4871e-04, -1.1552e-03,\n",
       "            -2.6972e-03,  4.9627e-04, -9.8069e-04, -1.9138e-03, -2.0511e-04,\n",
       "            -3.4395e-03, -1.3559e-03, -2.7403e-04, -3.7331e-04, -1.1598e-03,\n",
       "            -3.7225e-04, -2.1216e-03, -1.4470e-03, -2.9270e-04, -4.2443e-04,\n",
       "            -4.3508e-05, -5.9190e-04, -2.9996e-03, -3.2119e-03, -6.3142e-04,\n",
       "            -2.3241e-03, -5.0804e-04, -2.4354e-03,  4.8784e-04, -1.7398e-03,\n",
       "            -1.3998e-03, -7.5838e-04, -5.0076e-03, -2.7134e-04,  4.5287e-05,\n",
       "            -3.3821e-03, -2.8270e-03,  3.5977e-04, -1.3444e-03, -1.6993e-03,\n",
       "             4.0882e-04, -9.0703e-04, -1.8149e-03,  1.1139e-04, -2.2812e-04,\n",
       "             1.0751e-03,  4.6741e-04, -5.7295e-05, -6.3919e-04,  1.2189e-03,\n",
       "             2.4206e-04,  8.4580e-05, -7.1317e-04, -2.9108e-05, -4.5610e-04,\n",
       "             1.1040e-03, -4.8144e-04,  2.5832e-04, -1.0092e-03, -4.5125e-04,\n",
       "             9.6394e-04,  1.3676e-03, -3.3006e-03, -8.5342e-04,  8.4748e-04,\n",
       "            -1.5980e-04,  2.7591e-04,  3.3685e-03,  6.6289e-05,  8.7789e-05,\n",
       "             7.0153e-04, -1.2105e-05, -7.2188e-04, -3.5876e-04, -3.6267e-04,\n",
       "            -6.1528e-04,  2.5326e-04,  1.6288e-04,  2.1591e-05, -2.1047e-04,\n",
       "            -2.3704e-04,  3.1903e-04, -7.9007e-04,  7.1964e-05,  7.5431e-04,\n",
       "            -3.5309e-03, -1.4852e-04, -3.3357e-03, -1.3249e-03, -3.8172e-03,\n",
       "             1.4405e-04, -7.4766e-05, -1.0562e-04, -1.5858e-03, -6.8055e-04,\n",
       "             4.0185e-04, -1.3468e-04,  2.0339e-03, -2.0048e-04, -1.7305e-04,\n",
       "             2.1517e-05,  4.6811e-04, -7.4147e-04, -2.8138e-03, -5.6522e-04,\n",
       "            -3.4764e-03,  1.7303e-03, -7.6405e-04, -9.2740e-05, -2.7414e-04,\n",
       "            -7.3065e-04, -4.7678e-03, -1.6149e-04,  2.9082e-04,  1.3379e-03,\n",
       "            -6.8870e-04, -2.8466e-04, -5.0675e-04, -1.4282e-04, -1.2127e-03,\n",
       "            -1.4555e-03, -7.1118e-04, -9.1901e-04,  6.7740e-05,  9.1937e-05,\n",
       "            -7.1611e-04, -9.5394e-04, -2.0425e-03, -1.0414e-03, -5.4909e-04,\n",
       "             9.7804e-04, -6.4292e-04, -2.0089e-03, -1.1511e-03, -3.4307e-03,\n",
       "            -7.3353e-04, -2.3694e-03, -2.2538e-03,  9.0569e-05, -1.4195e-05,\n",
       "            -1.8317e-03,  3.9717e-04, -2.7714e-03, -1.0637e-03, -2.0744e-03,\n",
       "            -1.4297e-03, -3.1155e-03, -1.4691e-03,  2.7684e-04,  1.5073e-04,\n",
       "            -4.2405e-03, -2.3918e-04, -1.4109e-03, -1.4949e-03,  7.4707e-05,\n",
       "            -1.1777e-03, -1.4634e-03, -1.0553e-04, -5.6032e-04, -2.0926e-03,\n",
       "            -2.7229e-04, -5.1516e-04, -2.6649e-03, -1.2901e-03, -9.0126e-05,\n",
       "             4.1083e-04, -1.6329e-04, -8.1094e-04, -9.8304e-04, -2.1001e-03,\n",
       "            -2.4330e-03, -1.7239e-03, -9.8886e-04,  2.1888e-05, -3.5099e-04,\n",
       "            -4.5050e-04, -3.8387e-03, -2.1326e-03, -1.1013e-03,  2.1773e-04,\n",
       "            -9.4760e-04, -6.5417e-04, -1.3990e-04, -3.1045e-04, -3.5284e-03,\n",
       "            -2.5247e-03, -9.1270e-04, -4.8556e-04, -2.5009e-03, -7.7671e-04,\n",
       "             4.3788e-04, -4.6969e-03, -7.3003e-04, -3.3632e-04, -1.3815e-05,\n",
       "            -2.0300e-03,  6.3065e-04, -1.0915e-03, -2.3553e-03, -3.9425e-04,\n",
       "            -6.7873e-04, -1.1371e-03], device='cuda:0')},\n",
       "   63: {'momentum_buffer': tensor([[[[ 3.2033e-04]],\n",
       "    \n",
       "             [[-3.3779e-04]],\n",
       "    \n",
       "             [[ 5.0622e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.9876e-04]],\n",
       "    \n",
       "             [[ 7.8317e-06]],\n",
       "    \n",
       "             [[ 5.0401e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.2159e-04]],\n",
       "    \n",
       "             [[ 2.3793e-06]],\n",
       "    \n",
       "             [[-1.1070e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.6960e-04]],\n",
       "    \n",
       "             [[ 1.1112e-04]],\n",
       "    \n",
       "             [[-4.4357e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[-4.9228e-04]],\n",
       "    \n",
       "             [[-2.3513e-04]],\n",
       "    \n",
       "             [[ 3.2037e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.3434e-04]],\n",
       "    \n",
       "             [[-4.9194e-04]],\n",
       "    \n",
       "             [[ 2.2422e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-1.7417e-04]],\n",
       "    \n",
       "             [[ 3.1253e-05]],\n",
       "    \n",
       "             [[-3.9757e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.0439e-06]],\n",
       "    \n",
       "             [[ 4.4204e-04]],\n",
       "    \n",
       "             [[-5.8398e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-7.0249e-04]],\n",
       "    \n",
       "             [[-1.0760e-04]],\n",
       "    \n",
       "             [[ 2.9961e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.1145e-04]],\n",
       "    \n",
       "             [[-5.6829e-05]],\n",
       "    \n",
       "             [[ 9.1680e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.0313e-04]],\n",
       "    \n",
       "             [[-1.6729e-04]],\n",
       "    \n",
       "             [[-1.6454e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.2287e-04]],\n",
       "    \n",
       "             [[-1.2427e-04]],\n",
       "    \n",
       "             [[ 1.1202e-04]]]], device='cuda:0')},\n",
       "   64: {'momentum_buffer': tensor([0.0013, 0.0019, 0.0025, 0.0020, 0.0005, 0.0007, 0.0015, 0.0018, 0.0018,\n",
       "            0.0020, 0.0021, 0.0017, 0.0012, 0.0016, 0.0017, 0.0017, 0.0012, 0.0016,\n",
       "            0.0015, 0.0021, 0.0019, 0.0026, 0.0003, 0.0019, 0.0013, 0.0020, 0.0017,\n",
       "            0.0021, 0.0020, 0.0016, 0.0022, 0.0007, 0.0031, 0.0022, 0.0021, 0.0007,\n",
       "            0.0010, 0.0015, 0.0018, 0.0013, 0.0016, 0.0023, 0.0017, 0.0008, 0.0012,\n",
       "            0.0014, 0.0014, 0.0020, 0.0012, 0.0020, 0.0024, 0.0012, 0.0017, 0.0026,\n",
       "            0.0011, 0.0022, 0.0016, 0.0013, 0.0022, 0.0013, 0.0022, 0.0020, 0.0012,\n",
       "            0.0026, 0.0012, 0.0016, 0.0009, 0.0007, 0.0017, 0.0023, 0.0018, 0.0020,\n",
       "            0.0021, 0.0016, 0.0012, 0.0020, 0.0020, 0.0029, 0.0016, 0.0021, 0.0021,\n",
       "            0.0015, 0.0025, 0.0015, 0.0023, 0.0025, 0.0011, 0.0024, 0.0012, 0.0023,\n",
       "            0.0022, 0.0011, 0.0023, 0.0035, 0.0021, 0.0017, 0.0019, 0.0017, 0.0018,\n",
       "            0.0029, 0.0014, 0.0009, 0.0013, 0.0019, 0.0024, 0.0011, 0.0020, 0.0009,\n",
       "            0.0026, 0.0013, 0.0014, 0.0025, 0.0008, 0.0021, 0.0024, 0.0023, 0.0025,\n",
       "            0.0012, 0.0023, 0.0016, 0.0009, 0.0023, 0.0016, 0.0015, 0.0020, 0.0022,\n",
       "            0.0020, 0.0020], device='cuda:0')},\n",
       "   65: {'momentum_buffer': tensor([-3.9964e-06, -1.4389e-03,  1.9462e-04, -2.5781e-04,  9.7026e-04,\n",
       "             1.4509e-03, -3.9191e-05, -2.1706e-03, -1.4367e-03, -1.2191e-03,\n",
       "            -3.6940e-04, -9.1317e-04,  1.4581e-03, -8.8983e-04, -1.2685e-03,\n",
       "             7.2237e-04,  3.5584e-04, -2.3154e-03,  1.1004e-05, -1.1277e-03,\n",
       "            -1.0810e-03, -1.4741e-03,  1.4691e-03, -7.8455e-04,  1.1665e-03,\n",
       "            -8.4580e-04, -7.0902e-05,  3.6680e-04, -6.4086e-04,  1.6629e-04,\n",
       "            -1.3815e-04,  1.0699e-03, -1.8444e-03, -8.2358e-04, -1.0632e-03,\n",
       "             1.6183e-03, -1.1283e-03, -1.1447e-03,  5.7658e-04, -9.7125e-04,\n",
       "            -1.2574e-03, -2.0868e-03, -1.7609e-03, -2.1498e-03, -1.1572e-03,\n",
       "            -5.0732e-04, -3.9270e-05, -1.1621e-03,  8.2567e-04, -9.0295e-04,\n",
       "            -2.2390e-04,  1.2929e-03, -1.0012e-03, -4.0605e-04,  4.9686e-04,\n",
       "            -2.3323e-03, -2.4172e-04, -1.3362e-04,  1.6669e-03, -7.5323e-05,\n",
       "            -1.8667e-03, -1.4732e-03,  3.8762e-05, -2.5246e-03,  3.7325e-05,\n",
       "             2.9838e-04,  8.6838e-04,  4.9604e-04,  6.5580e-04, -1.1638e-03,\n",
       "            -1.1193e-03, -2.6849e-03, -1.3589e-03,  1.7416e-04, -3.3255e-05,\n",
       "            -4.8472e-04, -7.8967e-04, -1.5490e-03,  1.2469e-03, -5.2440e-03,\n",
       "            -1.2077e-03, -1.3975e-03, -1.1117e-03, -2.4684e-03, -1.7030e-03,\n",
       "            -2.8476e-03, -4.9856e-04,  2.3573e-04, -2.4561e-03, -2.0461e-04,\n",
       "             1.5734e-04,  1.5706e-03, -8.0719e-04, -1.0183e-03, -1.6462e-03,\n",
       "            -1.6604e-03, -3.8758e-04, -8.7186e-04,  9.5634e-04, -2.4414e-03,\n",
       "            -1.9986e-03, -7.1854e-04,  9.9447e-04, -1.6510e-03, -4.4523e-04,\n",
       "             1.4553e-04, -2.1871e-03,  3.2932e-04, -2.0044e-03,  9.3099e-04,\n",
       "            -1.2306e-03, -8.6205e-04, -2.4071e-03,  1.8172e-04, -6.6546e-04,\n",
       "            -2.5847e-05,  2.6987e-04,  3.3036e-04, -1.1171e-03, -9.3550e-04,\n",
       "            -1.1462e-03, -7.7201e-04,  9.2063e-05, -3.2493e-03, -7.4479e-04,\n",
       "            -5.3792e-04,  2.8338e-04, -1.6648e-03], device='cuda:0')},\n",
       "   66: {'momentum_buffer': tensor([[[[-1.5527e-04, -5.6762e-05,  8.7855e-05],\n",
       "              [ 9.6382e-06,  2.0334e-04,  3.6822e-04],\n",
       "              [ 5.2421e-05,  3.0489e-04,  2.6387e-04]],\n",
       "    \n",
       "             [[-2.7700e-04,  4.9953e-05, -1.4677e-05],\n",
       "              [-7.8853e-05, -5.5035e-05,  2.6568e-04],\n",
       "              [-2.0496e-04, -2.9137e-05, -7.1789e-05]],\n",
       "    \n",
       "             [[ 2.4321e-04,  1.8341e-04,  1.1666e-04],\n",
       "              [-2.1770e-06, -1.4100e-04, -2.5687e-04],\n",
       "              [ 1.1440e-04, -1.6034e-05,  7.8472e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.8142e-05, -4.1112e-05, -2.2184e-04],\n",
       "              [-1.7010e-04, -1.5523e-05, -4.9677e-05],\n",
       "              [-1.8670e-04, -1.5245e-04,  5.6434e-05]],\n",
       "    \n",
       "             [[ 1.2621e-04, -8.1648e-05, -1.5398e-04],\n",
       "              [ 1.4936e-04,  3.1966e-04, -1.4600e-04],\n",
       "              [ 3.2136e-04,  2.2813e-04,  4.4504e-04]],\n",
       "    \n",
       "             [[ 1.3524e-04,  1.6211e-04,  1.6900e-04],\n",
       "              [ 2.2901e-05,  1.4959e-05,  2.0056e-04],\n",
       "              [-1.7640e-05,  1.3113e-04,  1.7611e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-4.9400e-04, -5.8019e-04,  1.0821e-05],\n",
       "              [-1.6030e-04, -1.8316e-04,  2.9759e-05],\n",
       "              [-6.6281e-04, -7.1442e-04, -1.6453e-04]],\n",
       "    \n",
       "             [[-1.0834e-03, -3.1294e-04,  7.1937e-05],\n",
       "              [-1.2043e-04,  3.5773e-04,  3.2013e-04],\n",
       "              [ 1.4373e-05,  4.2445e-05,  4.1539e-05]],\n",
       "    \n",
       "             [[ 1.3982e-04,  1.3333e-05,  2.5744e-04],\n",
       "              [-2.9035e-04, -4.8052e-04,  4.5714e-04],\n",
       "              [-1.2782e-04, -2.6199e-04,  6.2759e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.1716e-04,  1.4858e-04, -1.4654e-04],\n",
       "              [-1.4674e-04, -1.3331e-04, -3.7054e-05],\n",
       "              [-5.5782e-04, -2.0074e-04,  1.1161e-04]],\n",
       "    \n",
       "             [[-2.0414e-04, -1.0494e-05, -3.0948e-04],\n",
       "              [-2.5482e-04,  2.3414e-04, -7.5329e-04],\n",
       "              [-2.2972e-04,  2.1546e-04,  1.3361e-04]],\n",
       "    \n",
       "             [[ 1.2608e-04, -7.5042e-05, -2.3620e-04],\n",
       "              [ 3.5998e-04,  1.0780e-04, -1.1810e-04],\n",
       "              [-9.5291e-06, -4.8537e-05, -2.4964e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.9369e-04,  3.8569e-04,  1.2790e-04],\n",
       "              [-3.4579e-04,  2.2062e-04, -2.7082e-04],\n",
       "              [-3.5465e-04,  1.2082e-04,  1.0594e-04]],\n",
       "    \n",
       "             [[ 6.6647e-04,  4.0776e-04,  1.6783e-04],\n",
       "              [ 5.5873e-04,  4.2980e-04,  2.7104e-04],\n",
       "              [ 2.6443e-04,  1.6620e-04,  8.5981e-05]],\n",
       "    \n",
       "             [[ 5.5550e-06, -4.0153e-04, -3.2754e-04],\n",
       "              [ 5.9433e-05, -5.7662e-04, -4.3180e-04],\n",
       "              [-3.5711e-04, -1.6602e-04,  4.7323e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.8380e-05, -1.5032e-04, -2.5328e-04],\n",
       "              [ 7.7673e-05, -5.6281e-05,  2.2280e-05],\n",
       "              [ 1.5728e-04,  1.2791e-04,  1.2562e-04]],\n",
       "    \n",
       "             [[-2.2899e-04,  9.5532e-05, -2.7176e-04],\n",
       "              [-1.1482e-04,  6.1503e-05, -3.3325e-04],\n",
       "              [-1.5098e-04,  7.2974e-05,  3.7671e-05]],\n",
       "    \n",
       "             [[-6.1717e-06,  5.8254e-05,  1.6786e-04],\n",
       "              [ 3.4152e-06, -1.7237e-05,  6.8252e-05],\n",
       "              [ 4.5128e-05,  8.7596e-05,  2.3579e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 3.3716e-04, -7.7770e-05, -2.4827e-04],\n",
       "              [ 1.2648e-04, -2.7405e-04, -4.7676e-04],\n",
       "              [ 9.1520e-05, -7.8072e-05,  3.1201e-04]],\n",
       "    \n",
       "             [[ 5.7513e-05,  2.9483e-05,  7.2027e-06],\n",
       "              [-1.9037e-04, -3.3609e-04,  2.9295e-04],\n",
       "              [ 2.4778e-04,  2.9503e-04,  8.2461e-05]],\n",
       "    \n",
       "             [[-7.9540e-05,  3.2232e-04,  4.4395e-04],\n",
       "              [ 2.5848e-04,  5.1315e-04,  1.4080e-04],\n",
       "              [ 4.0784e-04,  3.5036e-04, -1.8290e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.3091e-04,  4.7498e-04, -1.3854e-04],\n",
       "              [ 2.4076e-04,  5.0180e-05,  2.3354e-05],\n",
       "              [ 4.3555e-05, -1.5807e-04,  1.5875e-05]],\n",
       "    \n",
       "             [[-8.3433e-05, -1.2672e-04, -8.1071e-05],\n",
       "              [-5.0162e-04, -3.4065e-04, -2.9075e-04],\n",
       "              [-4.3759e-04, -5.1817e-04, -2.8617e-04]],\n",
       "    \n",
       "             [[-2.7876e-04, -2.2911e-05, -1.8289e-04],\n",
       "              [-1.4258e-04, -4.6947e-05, -9.3239e-05],\n",
       "              [-1.2432e-04, -3.7936e-05,  4.9959e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.0054e-05, -1.7028e-04, -8.9397e-05],\n",
       "              [ 9.4867e-06, -1.6820e-04, -2.7000e-04],\n",
       "              [ 1.7938e-04,  3.4381e-04,  1.0378e-04]],\n",
       "    \n",
       "             [[ 3.1896e-05, -2.9314e-05,  1.4356e-04],\n",
       "              [-1.7884e-04, -6.4341e-05,  2.1753e-04],\n",
       "              [ 2.2844e-04,  8.4280e-05,  3.0827e-04]],\n",
       "    \n",
       "             [[ 4.3783e-04,  4.0031e-04,  3.1116e-04],\n",
       "              [ 4.6162e-04,  3.4334e-04,  3.0454e-04],\n",
       "              [ 6.0160e-04,  6.1033e-04,  4.8419e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.2508e-04,  7.2797e-05,  8.6521e-05],\n",
       "              [-3.8568e-04, -4.3994e-04, -2.3758e-04],\n",
       "              [-5.0721e-04, -6.0534e-04, -5.2320e-04]],\n",
       "    \n",
       "             [[-1.6170e-04, -6.0530e-04, -8.9661e-05],\n",
       "              [-2.9240e-04, -9.7018e-04, -3.4919e-04],\n",
       "              [-1.8321e-04, -1.0110e-03, -7.7992e-04]],\n",
       "    \n",
       "             [[ 3.2192e-04,  1.5794e-04,  1.3872e-04],\n",
       "              [ 8.2494e-05, -1.5130e-05,  7.7737e-05],\n",
       "              [ 2.1296e-04,  2.2911e-04,  1.4395e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.7047e-04, -3.5411e-04, -7.9033e-05],\n",
       "              [-5.2093e-05, -2.8841e-04, -1.3387e-05],\n",
       "              [ 6.9415e-05, -1.0017e-04, -9.7926e-05]],\n",
       "    \n",
       "             [[ 4.0274e-05,  5.7582e-05, -1.0589e-04],\n",
       "              [-8.9274e-05, -3.2179e-04,  1.5937e-04],\n",
       "              [ 3.8457e-05,  4.9967e-05,  4.6485e-04]],\n",
       "    \n",
       "             [[ 1.4841e-04,  2.9950e-04,  1.1916e-04],\n",
       "              [ 1.8554e-04,  1.2922e-04,  8.5018e-05],\n",
       "              [-8.6262e-05,  2.7987e-05,  1.2679e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.3622e-04, -1.9229e-05, -2.3766e-04],\n",
       "              [-4.3816e-04, -5.5921e-04, -6.2478e-04],\n",
       "              [-5.1251e-05, -1.8558e-04, -1.7998e-04]],\n",
       "    \n",
       "             [[-2.8889e-04,  2.6282e-04,  1.5490e-04],\n",
       "              [ 4.7746e-05, -1.1116e-04,  6.0038e-04],\n",
       "              [ 4.7536e-05, -1.9157e-04,  3.5557e-04]],\n",
       "    \n",
       "             [[-7.9934e-05, -1.6615e-04, -8.6181e-05],\n",
       "              [-5.1845e-05, -1.9469e-05, -2.0074e-04],\n",
       "              [ 1.2586e-04, -9.4274e-05, -7.9625e-05]]]], device='cuda:0')},\n",
       "   67: {'momentum_buffer': tensor([ 1.5306e-03,  9.5868e-04,  2.3230e-03,  1.8263e-03,  2.7048e-03,\n",
       "            -6.5418e-04,  3.2847e-04,  2.1216e-03,  2.2543e-03,  1.2763e-03,\n",
       "             2.3378e-03,  8.3193e-04,  1.5319e-03,  1.7230e-03,  9.3868e-04,\n",
       "             1.7097e-03,  9.9261e-04,  1.5393e-03,  1.9095e-03,  2.5133e-03,\n",
       "             1.6789e-03,  1.7220e-03,  1.6517e-03,  1.5269e-03,  2.2958e-03,\n",
       "             2.1834e-03,  2.4254e-03,  2.2611e-03,  2.6044e-03,  3.0936e-03,\n",
       "             9.2003e-04,  9.8384e-04,  2.0495e-03,  1.0932e-03,  5.8799e-04,\n",
       "             2.1090e-03,  1.8129e-03,  2.7621e-03,  6.4193e-04,  1.6141e-03,\n",
       "             7.8155e-04,  1.6021e-03,  1.8706e-03,  5.0200e-04,  2.1601e-03,\n",
       "             1.0884e-03,  2.8224e-03,  1.6459e-03,  7.6646e-04,  1.2995e-03,\n",
       "             1.6126e-03,  1.8944e-03,  3.4503e-03,  2.4210e-03,  1.3278e-03,\n",
       "             9.5511e-04,  3.1476e-03,  3.6346e-03,  2.0430e-03,  1.9913e-03,\n",
       "             3.4577e-03,  2.2753e-03,  1.5860e-03,  1.4848e-03,  1.6457e-03,\n",
       "             1.9797e-03,  2.5347e-03,  7.9050e-04,  1.9854e-03,  2.1550e-03,\n",
       "             2.2977e-03,  7.4566e-04,  9.9198e-04,  2.0052e-03,  1.7367e-03,\n",
       "             2.1713e-03,  4.3835e-03,  2.3284e-03,  1.7396e-03,  1.6894e-03,\n",
       "             1.2162e-03,  1.4424e-03,  2.6790e-03,  4.5048e-04,  1.6255e-03,\n",
       "             1.8713e-03,  1.7819e-03,  1.7161e-03,  2.3334e-03,  1.7073e-03,\n",
       "             1.7814e-03,  2.1344e-03,  2.1987e-03,  1.8300e-03,  1.9136e-03,\n",
       "             1.6255e-03,  4.3664e-03,  2.6708e-03,  2.6878e-03,  1.4316e-03,\n",
       "             1.2837e-03,  2.2034e-03,  1.9322e-03,  1.5410e-03,  2.3182e-03,\n",
       "             1.8905e-03,  1.1668e-03,  2.5546e-03,  2.0296e-03,  2.8646e-03,\n",
       "             1.3304e-03,  1.1821e-03,  1.7425e-03,  1.5757e-03,  2.0744e-03,\n",
       "             2.0079e-03,  2.4495e-03,  1.0935e-03,  2.5606e-04,  1.8864e-03,\n",
       "             1.5711e-03,  1.9318e-03,  2.5817e-03, -9.6191e-05,  1.6472e-03,\n",
       "             2.2488e-03,  1.6519e-03,  5.6140e-04], device='cuda:0')},\n",
       "   68: {'momentum_buffer': tensor([-3.0127e-04,  2.6611e-03, -2.7774e-03, -3.3383e-03, -2.0900e-03,\n",
       "             2.4307e-03,  2.0791e-03, -1.6121e-03, -4.7087e-04,  3.5855e-04,\n",
       "            -1.8665e-03,  5.0724e-04,  8.6820e-04, -1.2750e-03, -5.9251e-04,\n",
       "            -3.1494e-03,  2.1076e-03, -1.4352e-03, -1.3186e-03, -1.2228e-03,\n",
       "             2.1974e-03,  2.8739e-03, -3.9600e-04, -8.2641e-04, -1.5396e-03,\n",
       "            -1.9743e-04, -2.6743e-03, -2.1427e-03, -1.1386e-03, -1.3964e-03,\n",
       "             2.7931e-03, -7.4091e-04, -6.9302e-04, -5.9662e-04, -5.7842e-04,\n",
       "            -1.1663e-03, -1.3741e-03, -1.1150e-03,  1.9288e-03, -1.1360e-03,\n",
       "             2.4193e-03,  7.5651e-04, -1.4141e-03,  2.0202e-03, -1.2681e-03,\n",
       "             5.5236e-04, -9.1352e-04, -7.7454e-04, -2.4774e-04, -1.2525e-03,\n",
       "             2.3178e-04, -1.5007e-04, -3.5833e-03, -2.2980e-03, -1.1709e-03,\n",
       "            -4.6844e-04, -2.7766e-03, -2.7445e-03, -1.0095e-03, -1.2962e-03,\n",
       "            -2.6017e-03, -7.9361e-04,  3.1210e-03, -9.5167e-04,  1.8642e-03,\n",
       "            -1.2540e-03, -5.9848e-04,  8.2462e-04, -7.4172e-04, -4.3783e-04,\n",
       "            -9.1313e-04,  3.4151e-04,  2.5566e-03,  4.4722e-04,  4.5167e-03,\n",
       "            -8.0502e-04, -2.7892e-03, -1.8538e-04, -1.3582e-04, -1.2667e-04,\n",
       "             2.7708e-04,  8.1580e-04, -5.5377e-04,  2.8600e-04, -1.2378e-03,\n",
       "            -1.0838e-03, -1.9289e-03, -1.4637e-03, -5.1582e-04, -5.3019e-04,\n",
       "             4.1023e-03, -1.4457e-03, -1.4353e-03, -3.3062e-04, -1.6003e-03,\n",
       "            -3.4802e-04, -3.2815e-03, -2.4234e-04, -1.2141e-03,  2.9604e-03,\n",
       "            -1.2398e-03, -4.3495e-04, -1.5895e-03, -1.4075e-03, -8.7105e-04,\n",
       "            -7.2263e-04,  7.0467e-04, -8.1628e-04, -2.0965e-03, -1.8489e-03,\n",
       "            -9.9514e-04,  7.3753e-05, -9.4449e-04, -1.2739e-03,  6.0154e-04,\n",
       "             5.0702e-04, -2.2631e-03, -1.5157e-04, -1.2655e-03, -1.9950e-03,\n",
       "            -3.3082e-04, -4.5675e-04, -9.3889e-04,  1.7120e-03, -8.9428e-04,\n",
       "            -8.6206e-04, -5.4193e-04,  1.7029e-03], device='cuda:0')},\n",
       "   69: {'momentum_buffer': tensor([[[[ 4.4629e-04]],\n",
       "    \n",
       "             [[-8.0452e-05]],\n",
       "    \n",
       "             [[ 1.8870e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.9962e-04]],\n",
       "    \n",
       "             [[-4.0473e-04]],\n",
       "    \n",
       "             [[ 9.0248e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.6959e-05]],\n",
       "    \n",
       "             [[-7.7348e-06]],\n",
       "    \n",
       "             [[ 1.7076e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.2495e-06]],\n",
       "    \n",
       "             [[-1.6327e-05]],\n",
       "    \n",
       "             [[-1.7045e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.2909e-04]],\n",
       "    \n",
       "             [[ 2.7120e-04]],\n",
       "    \n",
       "             [[ 6.6710e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.3070e-05]],\n",
       "    \n",
       "             [[ 1.2577e-04]],\n",
       "    \n",
       "             [[ 2.7701e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-5.9169e-05]],\n",
       "    \n",
       "             [[ 1.6854e-04]],\n",
       "    \n",
       "             [[ 1.5207e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.8009e-05]],\n",
       "    \n",
       "             [[-1.2355e-05]],\n",
       "    \n",
       "             [[-9.4206e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.6581e-05]],\n",
       "    \n",
       "             [[-1.0995e-04]],\n",
       "    \n",
       "             [[-2.4902e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.5446e-04]],\n",
       "    \n",
       "             [[ 2.4913e-05]],\n",
       "    \n",
       "             [[-1.4705e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.2945e-04]],\n",
       "    \n",
       "             [[ 1.7427e-04]],\n",
       "    \n",
       "             [[-4.1717e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.7108e-04]],\n",
       "    \n",
       "             [[-3.2060e-04]],\n",
       "    \n",
       "             [[ 2.0496e-04]]]], device='cuda:0')},\n",
       "   70: {'momentum_buffer': tensor([ 5.8586e-04, -4.2750e-05,  1.4598e-03, -3.2703e-05,  9.6490e-04,\n",
       "             6.8056e-04,  5.1596e-04,  4.1750e-04, -3.8023e-05,  2.5128e-03,\n",
       "             1.8417e-04,  1.6825e-05,  3.4532e-04, -1.4896e-04,  2.3113e-04,\n",
       "             2.1413e-03,  1.4025e-03,  5.6073e-04,  1.4282e-03,  4.1468e-04,\n",
       "            -2.2581e-04, -6.1388e-04,  6.2330e-04,  5.8921e-04,  2.0717e-03,\n",
       "             2.2235e-03,  9.8676e-04,  1.0685e-03,  8.6083e-04,  3.5222e-04,\n",
       "             2.0441e-03,  3.3265e-04,  1.4587e-03,  3.1542e-03,  1.0898e-03,\n",
       "             2.2495e-04,  5.0847e-04,  6.0028e-04,  1.2054e-03,  7.0265e-04,\n",
       "             6.8173e-04, -5.8905e-05,  1.3780e-03,  1.3036e-03,  9.6641e-04,\n",
       "             1.3874e-03,  9.1049e-06,  1.8851e-03,  3.7283e-04,  3.7897e-04,\n",
       "             9.4276e-04,  5.2629e-04,  1.5232e-03,  8.3750e-04,  5.9716e-04,\n",
       "             8.3628e-04,  2.0055e-03,  8.3520e-05,  4.7543e-04,  1.0195e-03,\n",
       "             1.5863e-03, -1.2080e-04,  4.7269e-04,  1.0582e-03,  1.1637e-04,\n",
       "            -7.0479e-05,  1.5846e-03, -3.2446e-04,  2.1844e-03,  4.0004e-04,\n",
       "             4.6441e-04,  1.0721e-03,  6.2381e-04,  1.9939e-03,  2.0538e-03,\n",
       "             2.4561e-04,  3.3402e-04,  7.5161e-04,  1.8606e-03,  1.7313e-03,\n",
       "             1.3207e-03,  4.6106e-04,  2.2220e-03, -1.4972e-04,  2.0983e-03,\n",
       "             2.1702e-03,  1.1552e-03,  1.7133e-04,  8.6048e-04,  1.2471e-03,\n",
       "             5.6251e-04,  1.4492e-03,  4.6650e-04,  8.1558e-04, -2.6025e-04,\n",
       "             6.8005e-04,  9.7096e-04,  3.5993e-03,  1.4394e-04,  1.8009e-03,\n",
       "             1.5109e-03,  1.8711e-03,  1.5061e-03, -6.3726e-05,  1.3518e-03,\n",
       "             2.4945e-04,  1.9946e-03,  1.3137e-03,  4.0438e-04, -2.1414e-04,\n",
       "             5.4748e-04,  1.0998e-03,  1.3975e-04,  7.9578e-04,  1.2915e-03,\n",
       "             9.0954e-04,  1.4363e-03,  1.0709e-03,  2.1559e-04,  7.6060e-04,\n",
       "             4.7335e-04,  2.3108e-03,  1.1145e-03,  2.1125e-03,  7.4380e-04,\n",
       "            -7.8700e-06,  2.0719e-04,  1.5514e-03,  2.1525e-03,  6.3745e-04,\n",
       "             4.7772e-04,  5.9166e-04,  9.2838e-04,  3.9198e-04, -3.3408e-04,\n",
       "             3.1668e-04,  7.1044e-04,  2.1820e-03,  1.3898e-03,  1.9229e-03,\n",
       "             2.6654e-03,  1.1168e-03,  1.3576e-03,  1.4279e-03,  2.0580e-03,\n",
       "             1.3305e-03,  9.6843e-05,  2.2255e-03,  4.7431e-04,  3.7715e-04,\n",
       "             1.6992e-03,  2.4730e-04,  1.6170e-03,  1.8196e-03,  4.1273e-05,\n",
       "            -1.6430e-04,  1.6953e-03, -7.7400e-05,  1.4859e-03,  8.7658e-04,\n",
       "             9.0440e-04,  6.4815e-04,  1.9216e-03,  7.3681e-04,  3.5748e-03,\n",
       "             1.5421e-03,  1.0492e-03,  7.9489e-04,  7.8126e-05, -1.4329e-04,\n",
       "             4.6010e-04,  1.9493e-03,  9.6265e-04,  3.8122e-04, -2.7562e-05,\n",
       "             1.6181e-03,  1.5422e-03,  1.8720e-03,  1.3183e-03,  1.7155e-03,\n",
       "             1.9529e-03,  6.5078e-04,  1.4362e-03,  1.3151e-03,  1.8785e-03,\n",
       "             2.3869e-03,  3.1364e-05,  2.3521e-04,  3.9504e-04,  1.2146e-03,\n",
       "             1.6793e-03, -2.8211e-05,  1.5168e-03,  6.0897e-04,  2.6287e-03,\n",
       "             1.2378e-03,  1.3688e-03,  7.9706e-04,  1.2976e-03,  2.0968e-03,\n",
       "             1.4367e-03,  1.4417e-03,  4.9109e-04,  2.0841e-04,  7.5528e-04,\n",
       "             7.0820e-04,  1.6398e-03,  3.0802e-04,  1.2129e-03,  1.1354e-03,\n",
       "             1.7007e-03,  9.6672e-04,  7.3048e-04,  8.2014e-04,  1.6072e-03,\n",
       "             1.0239e-03,  1.1695e-03,  6.9658e-04,  1.4717e-04,  1.0508e-03,\n",
       "             1.7944e-03,  5.5797e-04,  4.5897e-04,  3.2371e-04,  1.0515e-03,\n",
       "             8.7479e-04,  3.9808e-03,  1.6017e-03,  3.4885e-04,  1.5774e-03,\n",
       "             1.7522e-03,  4.9028e-04,  1.3694e-03,  5.1152e-04,  8.0297e-04,\n",
       "             4.1089e-04,  7.3566e-04,  6.1992e-04,  3.6996e-04,  1.0915e-03,\n",
       "             5.1674e-04,  2.0407e-03, -2.5845e-05,  8.5204e-04,  1.1603e-03,\n",
       "             2.2606e-03, -1.9170e-04,  4.1938e-04,  8.7622e-04,  1.2330e-03,\n",
       "            -1.6330e-04, -1.1575e-05,  2.3407e-03, -4.0606e-05,  2.0623e-04,\n",
       "             3.1581e-05,  5.2880e-04,  1.6336e-04,  2.0201e-03, -8.2899e-05,\n",
       "             7.0809e-04,  7.1160e-04,  1.1545e-03,  1.0978e-03, -1.4644e-04,\n",
       "             7.6415e-05,  1.3865e-03,  1.2593e-03,  1.3325e-03,  1.4822e-03,\n",
       "             1.9557e-03,  9.7903e-04,  1.3277e-03,  2.5187e-03,  1.0079e-03,\n",
       "             6.5018e-04,  1.1827e-03,  3.5301e-03,  2.7442e-04,  4.6989e-04,\n",
       "             1.7991e-03,  3.3420e-04,  7.9019e-04,  9.5455e-04,  5.8012e-04,\n",
       "            -2.8424e-05,  3.8094e-04,  1.8797e-03,  1.2951e-03,  4.2827e-04,\n",
       "             2.0603e-03,  8.8367e-04,  1.5711e-03,  3.2935e-04,  5.1973e-04,\n",
       "             1.1479e-03,  1.5458e-03,  1.3739e-03,  1.6280e-03,  6.5348e-04,\n",
       "             2.2481e-04,  2.1144e-03,  5.0709e-04,  1.7358e-03,  4.8398e-04,\n",
       "             9.8391e-04,  1.2628e-03,  1.1401e-03,  6.2406e-04,  3.0637e-05,\n",
       "             1.3185e-03,  1.0015e-03,  3.4200e-03,  9.8276e-04,  1.9547e-03,\n",
       "             1.4458e-03,  5.8159e-04,  3.3740e-04,  1.5822e-03,  6.8453e-04,\n",
       "             1.6490e-03,  2.0256e-03, -1.4818e-04,  6.5524e-04,  1.7353e-03,\n",
       "             1.2805e-03,  1.9106e-03,  2.2132e-03,  1.7874e-04,  4.3022e-04,\n",
       "             1.2295e-03,  9.4418e-04,  2.5172e-03,  2.7416e-03,  1.4633e-03,\n",
       "             5.6186e-04,  7.1716e-04, -4.9811e-05,  2.8323e-04,  1.0903e-03,\n",
       "             1.5239e-03,  3.1562e-04,  4.4234e-04,  1.4383e-03,  2.6098e-04,\n",
       "             2.8219e-03,  1.6640e-03,  5.0362e-04, -1.3123e-04,  3.5150e-04,\n",
       "             1.9361e-03,  2.2776e-06,  9.3303e-04,  1.1520e-03,  1.1484e-03,\n",
       "             9.1358e-04,  1.4781e-03,  1.0822e-03,  1.8508e-03,  3.8324e-04,\n",
       "             1.4402e-03,  1.7454e-03,  2.6301e-03,  6.3074e-04,  1.3834e-05,\n",
       "             1.5095e-03,  1.4802e-04,  4.1287e-04,  1.9146e-03,  1.3708e-03,\n",
       "            -7.4610e-06,  1.1994e-04,  1.0393e-03,  1.9157e-03, -2.4678e-04,\n",
       "             7.6302e-04,  5.0652e-04, -1.1778e-04,  8.6522e-04,  6.1638e-04,\n",
       "             3.4510e-04,  1.2399e-03,  1.3985e-03, -1.4207e-04,  1.0032e-03,\n",
       "             1.8293e-03,  1.1243e-03,  6.4918e-04,  1.0333e-03,  2.8647e-04,\n",
       "             7.6883e-04,  1.2122e-03,  1.0164e-03,  8.8063e-04,  1.7436e-03,\n",
       "             6.8624e-04,  3.4142e-04,  5.1878e-04,  2.0900e-03,  1.2660e-03,\n",
       "             1.4985e-03,  1.6262e-03, -1.6677e-05,  2.3430e-04,  1.4250e-03,\n",
       "             1.4716e-03,  9.6805e-04,  7.2218e-04,  3.3245e-04,  1.2614e-03,\n",
       "             9.2570e-04,  1.1759e-03,  2.0867e-03,  9.7556e-04,  1.2549e-04,\n",
       "             3.2299e-04,  8.7167e-04,  2.0324e-04,  3.6689e-04,  7.8754e-04,\n",
       "             2.0841e-04,  1.2212e-03,  1.8435e-03,  9.6074e-04, -3.8659e-04,\n",
       "             1.0696e-04,  7.1541e-04,  2.0257e-03, -1.9323e-04,  1.8315e-03,\n",
       "             4.1084e-04,  1.6826e-03,  9.9039e-04, -1.6758e-04,  4.1116e-04,\n",
       "             9.5033e-04,  7.8663e-04,  1.6123e-03,  1.2325e-03,  1.2403e-03,\n",
       "            -3.1622e-04,  1.7796e-04,  2.8269e-03,  5.7836e-04,  1.5028e-03,\n",
       "             3.5309e-04,  1.0491e-03,  4.6722e-04,  1.0492e-03,  7.2301e-04,\n",
       "             7.8072e-05, -4.5049e-04,  1.2396e-03,  2.3582e-04,  1.5430e-03,\n",
       "             1.9529e-03,  1.4161e-04,  2.0847e-03,  9.8568e-04, -9.0294e-05,\n",
       "             2.7919e-03,  6.9871e-04,  7.7693e-04,  2.0494e-03,  1.6544e-03,\n",
       "             1.0443e-03,  1.5247e-03,  1.9555e-03,  8.5245e-04, -7.7938e-05,\n",
       "             5.4776e-04, -7.0967e-06,  2.2940e-03,  1.1721e-03,  9.1621e-07,\n",
       "             1.0889e-03,  1.2616e-03,  3.9796e-04,  9.8638e-04,  1.2136e-03,\n",
       "             2.6049e-03,  1.5824e-03,  1.5080e-03,  1.0738e-03,  1.0453e-03,\n",
       "             1.8219e-03,  1.8401e-04,  3.7271e-03,  1.3389e-03,  7.2657e-04,\n",
       "             9.6873e-04,  9.7779e-04,  5.8526e-04,  1.4194e-03,  3.0795e-04,\n",
       "             5.1712e-04,  2.5502e-05,  4.9603e-04,  1.2803e-03,  5.6902e-04,\n",
       "             1.4758e-03,  1.1862e-03,  1.1918e-04,  6.2606e-04,  8.4885e-04,\n",
       "             1.8091e-03,  3.9893e-04,  1.4978e-04,  5.6368e-04,  3.0878e-04,\n",
       "             2.1911e-04,  1.2684e-03], device='cuda:0')},\n",
       "   71: {'momentum_buffer': tensor([-8.4936e-04, -1.0464e-05, -1.4871e-03,  1.1171e-04,  1.7783e-03,\n",
       "             1.0628e-03, -5.7949e-04, -2.2728e-04,  1.7665e-05,  1.4102e-03,\n",
       "            -3.8082e-04, -5.6575e-04, -5.5520e-04, -7.6202e-04, -8.5682e-04,\n",
       "            -1.6070e-03, -2.4053e-03, -1.2419e-03, -1.4835e-03, -7.6585e-04,\n",
       "             9.4659e-06,  6.2761e-04, -7.7599e-04, -1.3662e-03, -2.2748e-03,\n",
       "            -8.6835e-04, -8.4684e-05, -2.0361e-04,  7.3195e-05, -2.9348e-04,\n",
       "            -1.6046e-03, -1.9023e-04, -1.3352e-03, -2.6612e-03, -1.6757e-03,\n",
       "             2.6265e-05,  5.4143e-04, -2.0545e-04, -1.6983e-03, -6.4918e-04,\n",
       "            -9.0354e-04, -3.8480e-05,  1.7134e-04, -5.4189e-04, -2.2011e-03,\n",
       "            -3.0476e-03,  8.3215e-04, -2.0485e-03, -1.5116e-04, -6.4498e-05,\n",
       "            -1.1038e-03, -4.4878e-04, -1.7416e-03, -1.3278e-03, -1.3393e-03,\n",
       "            -3.0461e-04, -2.4262e-03, -4.6254e-04, -6.9601e-04, -1.6147e-03,\n",
       "            -1.5602e-03, -1.4789e-05, -5.6398e-04, -8.4471e-04, -8.1250e-04,\n",
       "             4.9858e-05, -1.2645e-03, -9.9885e-04,  1.8732e-03, -9.3380e-04,\n",
       "            -8.8750e-04,  5.8342e-04, -1.5993e-03, -2.3207e-03, -2.9137e-03,\n",
       "            -3.4388e-04, -3.8691e-04, -1.0157e-03, -2.8473e-03, -1.2939e-03,\n",
       "            -2.0716e-03, -1.9299e-04, -7.5946e-04,  9.1798e-05, -3.7716e-04,\n",
       "            -3.2028e-03, -1.1700e-03,  2.0152e-04, -8.5618e-04, -1.0143e-03,\n",
       "             1.4590e-03, -1.8142e-03, -4.8271e-04,  1.5782e-04, -2.8158e-04,\n",
       "            -3.8320e-04, -4.5382e-04, -4.8520e-03,  1.6869e-04, -1.0310e-03,\n",
       "            -1.7850e-03, -1.2343e-03, -8.9212e-04,  2.0862e-04, -1.7643e-03,\n",
       "            -5.7881e-04, -1.0591e-03,  1.3564e-03, -2.4736e-04,  6.3386e-04,\n",
       "            -5.0878e-04,  1.8996e-03, -1.0797e-03,  9.6226e-05, -1.6038e-03,\n",
       "            -7.1453e-04, -5.5413e-04, -1.0480e-03, -9.4285e-04, -8.7256e-04,\n",
       "             2.8141e-04, -3.5844e-03, -1.1759e-03, -2.2818e-03, -2.9604e-04,\n",
       "            -1.0155e-03,  2.8849e-04, -8.6659e-04, -2.4412e-03, -6.9120e-04,\n",
       "            -3.0511e-04, -3.5060e-04, -2.2720e-03, -5.4421e-04, -1.9926e-04,\n",
       "             5.0515e-04, -1.9725e-03, -3.6960e-03, -1.7429e-03, -3.1731e-03,\n",
       "            -2.6952e-03, -9.2810e-04, -5.2397e-04, -2.5587e-03, -2.7756e-03,\n",
       "             6.9108e-04, -1.3328e-04, -1.2106e-03, -1.2978e-04, -9.7444e-04,\n",
       "            -2.2328e-03, -1.5621e-04, -1.4077e-03, -2.9202e-03, -2.8612e-04,\n",
       "             1.9501e-04, -1.4027e-03,  1.4629e-04, -2.0415e-03, -1.4054e-03,\n",
       "            -5.4819e-04, -1.5683e-03, -2.5046e-03, -1.8636e-03, -3.0602e-03,\n",
       "            -2.2239e-03, -8.8730e-04, -1.9127e-03,  4.1386e-04,  2.0158e-04,\n",
       "             1.0555e-03, -1.9892e-03,  7.2420e-04,  9.0919e-04,  2.9083e-04,\n",
       "            -4.2407e-04, -3.1615e-03, -2.5604e-03, -4.7258e-04, -1.6695e-03,\n",
       "            -1.1496e-03,  7.9883e-04, -1.4237e-03, -1.2858e-03, -3.0227e-03,\n",
       "            -2.9732e-03, -4.3535e-04, -2.8707e-04, -1.5308e-04, -1.8851e-03,\n",
       "            -2.0990e-03,  1.4524e-04, -1.1138e-03, -5.7023e-04, -1.2345e-03,\n",
       "            -1.0008e-03, -1.3480e-03, -7.9262e-04, -1.6128e-03, -2.8792e-03,\n",
       "            -1.7363e-03, -1.4331e-03, -8.4058e-04, -6.5478e-04, -5.8810e-04,\n",
       "            -2.3743e-03, -1.4162e-03, -5.6276e-04, -3.5367e-04, -2.0124e-03,\n",
       "            -3.1207e-04, -1.4650e-03, -6.5620e-04,  7.4354e-05, -2.0026e-04,\n",
       "            -1.2134e-03,  9.4993e-04, -1.8260e-03,  3.6060e-06, -5.1656e-04,\n",
       "            -1.9144e-03, -6.9620e-04, -7.3730e-04, -3.7613e-04, -6.9304e-04,\n",
       "            -1.5694e-03, -2.2726e-03, -1.8011e-03, -4.2853e-05, -1.1789e-03,\n",
       "            -1.4247e-04, -7.4905e-04, -1.7461e-03, -2.7307e-04, -1.2715e-03,\n",
       "            -8.6849e-04, -4.3445e-04, -4.3143e-04, -5.3608e-04, -1.3660e-03,\n",
       "             1.2058e-03, -1.7195e-03, -1.8198e-04, -1.1001e-03, -1.5855e-03,\n",
       "            -2.2643e-03,  9.9583e-06,  5.5359e-04, -7.5406e-04, -2.0890e-03,\n",
       "            -4.4067e-04,  6.4296e-06, -1.9378e-03, -5.3791e-04,  4.2368e-06,\n",
       "             1.5311e-04, -9.1494e-04, -2.8116e-04,  1.9403e-03, -6.4473e-05,\n",
       "            -1.0656e-03, -2.4886e-04, -1.4032e-03, -1.2540e-03, -4.8345e-04,\n",
       "            -3.3381e-04, -2.6531e-03, -1.4585e-03, -1.4930e-03, -6.6748e-04,\n",
       "            -2.3638e-03, -4.1850e-04, -1.3878e-03, -1.3068e-03, -2.3502e-03,\n",
       "            -7.8011e-04, -1.8512e-03, -2.4886e-03, -3.8380e-04, -1.7690e-04,\n",
       "            -1.6824e-03, -7.0402e-04, -9.0478e-04, -1.5356e-03, -3.7180e-03,\n",
       "             9.0326e-05, -4.1734e-04,  2.0046e-04,  1.8463e-03, -3.3229e-04,\n",
       "             1.2338e-03,  1.6252e-04,  2.6620e-04, -7.0624e-04, -3.4167e-04,\n",
       "            -1.7527e-03, -1.8823e-03, -1.2230e-03, -2.9300e-03, -9.6122e-04,\n",
       "            -3.9066e-04,  1.0129e-03, -1.3561e-03, -2.1576e-03,  8.0256e-05,\n",
       "            -1.5194e-03, -1.7095e-03, -1.8468e-03, -9.4960e-04,  3.8263e-06,\n",
       "             1.0401e-03, -1.4066e-03, -3.1064e-03, -1.4024e-03, -2.1900e-03,\n",
       "            -1.9248e-03, -7.3853e-05, -1.2089e-03, -7.6367e-04, -8.0653e-04,\n",
       "            -1.9573e-03, -1.6771e-03,  8.5986e-04,  1.9806e-03, -1.5604e-03,\n",
       "            -1.0722e-03,  2.8773e-04,  1.7514e-04,  3.3942e-05, -1.1792e-03,\n",
       "            -1.6401e-03, -2.3340e-03, -4.5740e-05, -1.3083e-03, -1.5573e-03,\n",
       "            -6.7037e-04, -1.6156e-03,  4.7524e-04,  6.0086e-04, -1.1640e-03,\n",
       "             8.4946e-04,  1.1071e-04, -1.1573e-03, -2.6048e-03, -6.2774e-04,\n",
       "            -1.3934e-03, -1.6441e-03, -7.9037e-05,  3.7724e-04,  5.8630e-04,\n",
       "            -6.7257e-04,  3.2447e-04, -9.6116e-04,  2.6821e-04, -1.1310e-03,\n",
       "             1.0869e-03, -1.6479e-03, -9.6895e-04, -1.3994e-03, -5.2278e-04,\n",
       "            -1.5818e-03, -1.7323e-03, -2.3558e-03, -1.0373e-03, -2.7778e-04,\n",
       "            -2.5352e-03, -4.3025e-04,  7.5270e-05, -1.9517e-03, -7.4295e-04,\n",
       "             8.0840e-04,  4.2860e-04, -1.5770e-03, -3.0085e-03,  6.9799e-06,\n",
       "            -7.2969e-04, -7.1568e-04, -6.9457e-05, -1.4361e-03, -4.1819e-04,\n",
       "             5.2497e-04, -1.4442e-03, -2.2489e-03,  6.2428e-06, -6.9081e-04,\n",
       "            -1.7797e-03, -3.9098e-04, -1.1015e-03, -1.2746e-03,  3.2057e-04,\n",
       "            -1.2080e-03, -1.2073e-03, -6.4636e-04, -1.6631e-03,  1.0877e-03,\n",
       "            -1.7887e-03, -1.1432e-03,  7.0417e-04, -3.0186e-03, -2.1779e-03,\n",
       "            -2.3102e-03, -1.1473e-03,  2.3842e-05, -2.1593e-04, -2.9247e-03,\n",
       "            -3.0679e-03, -2.1071e-03,  1.7451e-03, -2.9247e-04, -4.0989e-04,\n",
       "            -6.5678e-04, -1.1455e-03, -2.6239e-03, -2.0065e-03, -5.8300e-04,\n",
       "            -4.5402e-04,  1.4903e-03, -1.1190e-03, -9.0415e-04, -9.5200e-05,\n",
       "            -6.1913e-04, -1.3201e-03,  1.9410e-04, -2.0266e-03, -9.2592e-04,\n",
       "            -1.7846e-04,  1.8929e-04, -1.7207e-03, -1.6761e-05, -1.1700e-03,\n",
       "             3.9995e-04, -5.4267e-04, -1.1841e-03, -2.4378e-04, -1.2177e-04,\n",
       "            -3.6898e-04, -1.5152e-03,  1.3660e-03, -1.6508e-03, -1.6331e-03,\n",
       "             2.1811e-04, -3.5037e-04, -1.7867e-03, -5.4755e-04, -2.2914e-03,\n",
       "            -9.5297e-04, -1.7310e-03, -5.0005e-04, -8.4308e-04, -1.9272e-03,\n",
       "             2.9264e-05,  1.3522e-04, -1.8892e-03,  3.8740e-04, -2.2549e-03,\n",
       "            -1.7378e-03, -3.2305e-05, -2.0228e-03, -7.1917e-04,  7.8639e-07,\n",
       "            -3.4494e-03, -7.1224e-04, -6.1114e-04,  4.3856e-04, -1.3964e-03,\n",
       "            -8.7341e-04,  1.0477e-04, -1.7067e-03, -2.3391e-03, -7.8971e-06,\n",
       "            -7.6083e-04,  4.6428e-05, -8.4461e-04, -6.4290e-04, -6.0321e-05,\n",
       "            -8.5530e-04, -1.6465e-03, -8.6993e-04,  8.4653e-05,  7.8406e-04,\n",
       "            -1.7311e-03, -2.9644e-03, -1.4952e-03, -1.9199e-03, -1.3247e-03,\n",
       "            -1.6954e-03,  8.3271e-04, -3.5060e-03, -1.7504e-03, -5.0645e-04,\n",
       "            -1.3009e-03, -1.3716e-03, -5.7151e-04, -1.6344e-03, -2.8914e-04,\n",
       "            -1.0596e-03,  7.2081e-05, -1.0599e-03,  1.5687e-03, -9.6175e-04,\n",
       "            -2.6056e-03, -3.4445e-04, -3.3309e-04, -6.9345e-04, -1.0345e-03,\n",
       "            -1.9569e-03,  4.6195e-04, -1.7366e-03,  1.4802e-03, -3.5072e-04,\n",
       "            -6.5459e-04, -3.4021e-04], device='cuda:0')},\n",
       "   72: {'momentum_buffer': tensor([[[[ 3.2730e-04]],\n",
       "    \n",
       "             [[ 5.8593e-04]],\n",
       "    \n",
       "             [[-3.7346e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.0564e-03]],\n",
       "    \n",
       "             [[ 2.8791e-04]],\n",
       "    \n",
       "             [[-2.1963e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.2589e-04]],\n",
       "    \n",
       "             [[-1.6148e-04]],\n",
       "    \n",
       "             [[ 2.6947e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.0522e-05]],\n",
       "    \n",
       "             [[ 2.3140e-04]],\n",
       "    \n",
       "             [[-9.3170e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.5781e-04]],\n",
       "    \n",
       "             [[ 6.3241e-04]],\n",
       "    \n",
       "             [[-8.1718e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.4070e-04]],\n",
       "    \n",
       "             [[ 4.0343e-04]],\n",
       "    \n",
       "             [[ 7.1249e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 2.7994e-04]],\n",
       "    \n",
       "             [[ 3.3161e-04]],\n",
       "    \n",
       "             [[ 9.2679e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.8995e-04]],\n",
       "    \n",
       "             [[ 2.5885e-04]],\n",
       "    \n",
       "             [[-1.8522e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.3683e-05]],\n",
       "    \n",
       "             [[-7.6297e-05]],\n",
       "    \n",
       "             [[ 4.8614e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.0130e-05]],\n",
       "    \n",
       "             [[-4.3868e-04]],\n",
       "    \n",
       "             [[ 1.1760e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.6393e-04]],\n",
       "    \n",
       "             [[-5.7707e-04]],\n",
       "    \n",
       "             [[-1.9276e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.7147e-05]],\n",
       "    \n",
       "             [[-6.6800e-04]],\n",
       "    \n",
       "             [[-3.3480e-05]]]], device='cuda:0')},\n",
       "   73: {'momentum_buffer': tensor([ 2.7201e-03,  2.3624e-03,  1.4393e-03,  3.6180e-03,  2.2301e-03,\n",
       "             1.9135e-03,  1.9335e-03,  2.4341e-03,  2.2923e-03,  2.1135e-03,\n",
       "             2.4453e-03,  2.4926e-03,  2.4247e-03,  2.6596e-03,  1.9594e-03,\n",
       "             3.3121e-03,  1.9732e-03,  2.1143e-03,  3.4027e-03,  1.7583e-03,\n",
       "             2.5391e-03,  2.5909e-03,  1.9296e-03,  2.7845e-03,  2.4485e-03,\n",
       "             2.1311e-03,  2.1242e-03,  2.6151e-03,  2.8582e-03,  2.6577e-03,\n",
       "             2.3455e-03,  1.8500e-03,  2.6316e-03,  2.1606e-03,  1.5187e-03,\n",
       "             3.1701e-03,  3.2409e-03,  3.9871e-03,  3.4754e-03,  1.8328e-03,\n",
       "             3.0053e-03,  1.8546e-03,  2.1613e-03,  2.6826e-04,  2.5249e-03,\n",
       "            -6.4264e-05,  3.0786e-03,  1.8712e-03,  2.0119e-03,  1.4622e-03,\n",
       "             2.1990e-03,  2.7877e-03,  1.9155e-03,  1.4832e-03,  2.2547e-03,\n",
       "             2.0712e-03,  2.8660e-03,  2.1004e-03,  3.0599e-03,  2.1185e-03,\n",
       "             2.9848e-03,  1.4463e-03,  1.5388e-03,  1.7287e-03,  2.2605e-03,\n",
       "             1.7576e-03,  1.4283e-03,  2.2341e-03,  1.7104e-03,  2.0377e-03,\n",
       "             1.6678e-03,  4.3852e-03,  2.8164e-03,  2.2218e-03,  1.4832e-03,\n",
       "             2.8307e-03,  2.9258e-03,  2.1276e-03,  2.5350e-03,  2.6813e-03,\n",
       "             3.2207e-03,  1.7681e-03,  2.7028e-03,  2.9213e-03,  6.5302e-04,\n",
       "             2.9076e-03,  2.7552e-03,  2.6634e-03,  1.2455e-03,  2.1933e-03,\n",
       "             2.7710e-03,  3.4279e-03,  2.2255e-03,  2.7063e-03,  3.0369e-03,\n",
       "             2.0690e-03,  1.2043e-03,  1.9323e-03,  3.5175e-03,  3.0964e-03,\n",
       "             1.8972e-03,  1.6251e-03,  2.4539e-03,  1.6624e-03,  3.0911e-03,\n",
       "             1.5510e-03,  2.1730e-03,  3.2109e-03,  2.7820e-03,  2.4415e-03,\n",
       "             3.4321e-03,  2.9968e-03,  2.5326e-03,  2.5367e-03,  2.2122e-03,\n",
       "             2.6254e-03,  2.8418e-03,  2.9900e-03,  2.6928e-03,  3.0721e-03,\n",
       "             1.7380e-03,  2.3983e-03,  2.3319e-03,  2.2533e-03,  2.9779e-03,\n",
       "             2.1797e-03,  7.2619e-04,  2.3375e-03,  3.6445e-03,  2.7748e-03,\n",
       "             2.7294e-03,  1.0404e-04,  4.1339e-04,  2.2156e-03,  1.5031e-03,\n",
       "             3.2378e-03,  2.4373e-03,  2.4511e-03,  2.8791e-03,  2.2239e-03,\n",
       "             3.0814e-03,  2.6825e-03,  2.1451e-03,  3.0852e-03,  2.1866e-03,\n",
       "             2.5417e-03,  2.4348e-03,  1.7254e-03,  3.3743e-03,  2.5493e-03,\n",
       "             2.2325e-03,  2.2418e-03,  3.0567e-03,  2.9410e-03,  1.7062e-03,\n",
       "             2.9541e-03,  2.9853e-03,  1.9369e-03,  2.6656e-03,  1.6515e-03,\n",
       "             2.4092e-03,  1.7703e-03,  2.4269e-03,  1.8444e-03,  2.4431e-03,\n",
       "             3.6700e-03,  1.9225e-03,  1.8170e-03,  3.3990e-03,  2.4987e-03,\n",
       "             3.0524e-03,  3.2640e-03,  2.7997e-03,  9.0464e-04,  3.0025e-03,\n",
       "             1.7538e-03,  2.2308e-03,  2.2199e-03,  2.1381e-03,  2.5015e-03,\n",
       "             2.7078e-03,  2.1281e-03,  8.8084e-04,  1.6047e-03,  1.7690e-03,\n",
       "             2.6318e-03,  2.3593e-03,  2.6551e-03,  2.6402e-03,  3.9738e-03,\n",
       "             3.5874e-03,  2.1791e-03,  3.1039e-03,  2.7977e-03,  2.9312e-03,\n",
       "             3.5663e-03,  1.5872e-03,  1.4275e-03,  2.4102e-03,  2.8027e-03,\n",
       "             2.6322e-03,  2.3056e-03,  3.4503e-03,  2.4086e-03,  2.8602e-03,\n",
       "             2.7358e-03,  2.5190e-03,  1.9586e-03,  2.4625e-03,  2.7058e-03,\n",
       "             1.2730e-03,  4.1272e-04,  2.5278e-03,  1.5434e-03,  3.5401e-03,\n",
       "             1.4582e-03,  1.6429e-03,  2.2983e-03,  2.3488e-03,  2.5525e-03,\n",
       "             2.4162e-03,  2.1507e-03,  3.1469e-03,  2.5942e-03,  3.0404e-03,\n",
       "             3.1476e-03,  2.8846e-03,  4.5980e-03,  2.9966e-03,  2.5570e-03,\n",
       "             3.2078e-03,  3.0405e-03,  2.3919e-03,  1.7288e-03,  1.8704e-03,\n",
       "             3.3167e-03,  2.2425e-03,  2.4677e-03,  1.6763e-03,  3.2805e-03,\n",
       "             2.0739e-03,  1.8893e-03,  3.1409e-03,  2.1395e-03,  2.7045e-03,\n",
       "             2.3726e-03,  2.3205e-03,  2.2654e-03,  1.9754e-03,  2.5050e-03,\n",
       "             2.3107e-03,  2.6587e-03,  3.2430e-03,  3.5795e-03,  2.7390e-03,\n",
       "             3.5134e-03], device='cuda:0')},\n",
       "   74: {'momentum_buffer': tensor([-3.6880e-03, -2.4717e-04, -1.7965e-03, -4.8080e-03, -3.1246e-04,\n",
       "            -2.6334e-03, -1.3833e-03, -1.2842e-03, -9.7211e-04, -1.5198e-03,\n",
       "            -7.5446e-04, -2.6784e-04, -2.2453e-03, -8.8278e-04, -9.3905e-04,\n",
       "            -3.4706e-03, -1.0223e-03, -3.4505e-04, -3.0874e-03, -1.5204e-03,\n",
       "            -1.2663e-03, -1.1132e-03,  4.7561e-05, -3.9171e-03, -3.2185e-03,\n",
       "            -1.8773e-03, -1.3152e-03, -1.3932e-03, -2.5489e-03, -2.6307e-03,\n",
       "            -3.9671e-04, -1.3214e-03, -7.8153e-04, -2.2584e-03, -1.3884e-03,\n",
       "            -2.3752e-03, -2.5591e-03, -3.6745e-03, -2.6463e-03, -2.6235e-03,\n",
       "            -1.1597e-03, -2.0616e-03, -1.8321e-03, -1.3479e-03, -1.0694e-03,\n",
       "            -1.6624e-04, -4.5586e-03,  6.5438e-04, -6.0011e-04, -1.2311e-03,\n",
       "            -3.2049e-03, -2.2314e-03, -1.0048e-03, -1.4689e-03, -7.8661e-04,\n",
       "            -1.3804e-03, -3.3627e-03, -1.8706e-03, -1.1242e-03, -1.3869e-03,\n",
       "            -2.2860e-03, -1.4964e-03, -3.0221e-03, -1.1328e-03, -2.2778e-03,\n",
       "            -1.2918e-03, -1.1152e-03, -1.0113e-03, -2.5698e-03, -1.2878e-03,\n",
       "            -9.0259e-04, -3.6002e-03, -2.2019e-03, -1.4178e-04, -2.7007e-03,\n",
       "            -4.9694e-03, -2.0317e-03, -1.2381e-03, -1.2521e-03, -1.1727e-03,\n",
       "            -3.6547e-03, -9.4515e-04, -3.0773e-03, -3.7618e-03, -5.8815e-04,\n",
       "            -9.0341e-04, -2.8871e-03, -4.7353e-03, -9.3487e-04, -2.5749e-03,\n",
       "            -3.7239e-03, -4.3313e-03, -2.0729e-03, -2.4487e-03, -1.0678e-03,\n",
       "            -2.0199e-03, -7.9824e-04, -1.3663e-03, -2.0989e-03, -2.7984e-03,\n",
       "            -2.6633e-04, -9.0388e-04, -1.9460e-03, -1.1414e-03, -1.9591e-03,\n",
       "            -1.4773e-03, -7.3122e-04, -1.7343e-03, -1.9810e-03, -2.8532e-03,\n",
       "            -2.5327e-03, -2.8267e-03, -2.9070e-03, -1.4940e-03, -2.0809e-03,\n",
       "            -1.2088e-03, -1.6623e-03, -7.9145e-04, -1.4484e-03, -3.6767e-03,\n",
       "            -9.9033e-04, -1.5557e-03, -1.7264e-03, -2.1103e-03, -1.9859e-03,\n",
       "            -8.7570e-04, -7.7537e-04, -2.2315e-03, -3.0229e-03, -2.8524e-03,\n",
       "            -5.0254e-04, -5.4504e-04,  9.7989e-04, -3.0604e-04, -3.6420e-04,\n",
       "            -3.8363e-03, -2.3990e-04, -2.5888e-03, -1.1991e-03, -2.2445e-03,\n",
       "            -2.7954e-03,  4.8683e-05,  6.5919e-05, -1.5844e-03,  4.7999e-05,\n",
       "            -9.5292e-04, -6.3127e-04, -1.6168e-03, -5.7695e-04, -1.2532e-04,\n",
       "            -5.7787e-04, -8.8548e-04, -5.3085e-03, -3.6225e-04, -2.2466e-03,\n",
       "            -2.3405e-03, -2.8480e-03, -1.2485e-03, -3.1924e-03, -1.9625e-04,\n",
       "            -1.6344e-03,  1.2254e-04, -1.1909e-03, -2.2976e-03, -2.2508e-03,\n",
       "            -1.7365e-03, -5.0487e-04, -1.3916e-03,  3.4635e-05, -1.1805e-03,\n",
       "            -4.8957e-03, -3.3761e-03, -2.2755e-03, -1.1549e-03, -1.4383e-03,\n",
       "            -4.4093e-04, -1.3705e-03, -8.6947e-04, -2.9105e-03, -2.0828e-03,\n",
       "            -2.3389e-03, -1.7630e-03, -2.6632e-03, -1.8721e-04, -1.8497e-03,\n",
       "            -1.4678e-03, -1.0828e-03, -1.2135e-03, -3.1662e-03, -3.2671e-03,\n",
       "            -2.0271e-03, -1.7115e-03, -1.4611e-03, -2.9614e-03, -1.4848e-03,\n",
       "            -2.5463e-03, -1.5535e-03, -1.7481e-03, -3.3099e-03, -1.0652e-03,\n",
       "            -2.6374e-03, -1.1701e-03, -4.5649e-03, -1.9167e-03, -2.2970e-03,\n",
       "            -2.3432e-03, -3.1158e-03, -3.1342e-03, -1.9759e-03, -5.9966e-04,\n",
       "            -9.7505e-04, -1.5232e-03, -1.6987e-03, -1.9495e-03, -4.2579e-03,\n",
       "            -1.0266e-03, -2.1387e-03, -1.3078e-03, -1.3874e-03, -1.4256e-03,\n",
       "            -2.8447e-03, -2.9635e-03, -4.5829e-03, -1.2153e-03, -1.0444e-03,\n",
       "            -4.2518e-03, -1.5743e-03, -6.6643e-03, -2.2879e-03, -7.7863e-04,\n",
       "            -2.1408e-03, -2.6836e-03, -1.0241e-03, -1.3331e-03, -1.0328e-03,\n",
       "            -2.8100e-03, -1.5679e-03, -2.2265e-03, -2.1074e-03, -2.5590e-03,\n",
       "            -2.0357e-03, -1.0364e-03, -2.0020e-03, -2.1419e-03, -1.7721e-03,\n",
       "            -6.6939e-04, -2.2628e-03, -1.6565e-03, -1.9686e-03, -2.1494e-03,\n",
       "            -2.4105e-03, -6.4883e-04, -4.0146e-03, -1.6979e-03, -3.5292e-03,\n",
       "            -3.4320e-03], device='cuda:0')},\n",
       "   75: {'momentum_buffer': tensor([[[[ 3.2684e-04,  6.8197e-05,  6.8925e-05],\n",
       "              [ 3.3329e-04, -5.1515e-05,  3.4513e-05],\n",
       "              [ 4.0410e-06, -1.9516e-04, -1.6685e-04]],\n",
       "    \n",
       "             [[-1.1061e-04,  1.3212e-04, -3.7598e-04],\n",
       "              [-1.2742e-04,  7.7711e-05, -9.6100e-05],\n",
       "              [-1.8320e-04, -3.7914e-04, -2.0806e-04]],\n",
       "    \n",
       "             [[ 2.6219e-04,  2.6575e-05,  1.2769e-05],\n",
       "              [ 4.0224e-04,  7.7927e-05,  3.0485e-04],\n",
       "              [ 1.9683e-04, -3.4954e-05, -1.1171e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.9261e-05, -1.7923e-05, -1.2866e-04],\n",
       "              [ 7.7751e-05,  1.3018e-04, -1.3687e-04],\n",
       "              [ 8.8103e-05, -1.8917e-06,  1.1101e-04]],\n",
       "    \n",
       "             [[-1.5565e-04,  2.3549e-04, -1.0200e-04],\n",
       "              [-2.2841e-04, -1.1763e-04, -1.8975e-04],\n",
       "              [-3.8549e-05,  1.7543e-05, -2.3438e-04]],\n",
       "    \n",
       "             [[ 3.0761e-05,  1.7263e-04,  5.0568e-04],\n",
       "              [ 1.6514e-04,  2.8291e-04, -3.9392e-04],\n",
       "              [ 2.9854e-04,  4.2335e-04,  3.9687e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 6.7463e-05,  1.3412e-04,  2.5242e-04],\n",
       "              [ 2.9214e-05,  5.9112e-06,  4.7643e-06],\n",
       "              [-1.5966e-05,  4.4291e-05, -5.2145e-06]],\n",
       "    \n",
       "             [[-1.3718e-04, -1.1726e-05,  1.2806e-04],\n",
       "              [ 7.4596e-05,  3.0006e-04,  6.4400e-06],\n",
       "              [-6.2677e-05,  7.5787e-05,  2.8967e-04]],\n",
       "    \n",
       "             [[ 5.3149e-05, -5.3756e-05,  1.2798e-05],\n",
       "              [-2.3398e-04, -3.8205e-04, -2.8578e-04],\n",
       "              [-1.8271e-04, -2.9780e-04, -2.5691e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.0419e-05,  2.5372e-04,  1.7852e-04],\n",
       "              [ 9.0700e-05, -3.9124e-05, -6.4724e-05],\n",
       "              [ 1.9547e-04, -4.8512e-05, -1.0503e-04]],\n",
       "    \n",
       "             [[-2.2016e-04,  7.4260e-05, -3.5187e-04],\n",
       "              [-4.5906e-04,  3.3458e-04, -2.2125e-04],\n",
       "              [-2.8600e-04,  1.6127e-04, -1.3318e-04]],\n",
       "    \n",
       "             [[-2.8521e-04, -3.3772e-04,  1.8281e-04],\n",
       "              [-2.2990e-04, -1.2510e-04, -2.7897e-04],\n",
       "              [-3.5593e-04, -1.1218e-04,  1.6693e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-7.1383e-05,  1.6748e-05,  1.8514e-04],\n",
       "              [-4.1999e-04, -1.0655e-04, -1.3896e-04],\n",
       "              [ 2.6507e-05, -1.8057e-04,  1.0342e-04]],\n",
       "    \n",
       "             [[-3.8581e-04, -5.6018e-04, -3.9266e-04],\n",
       "              [-1.4196e-04, -4.3667e-04, -4.0728e-04],\n",
       "              [-1.5376e-06, -1.0964e-04, -9.3216e-05]],\n",
       "    \n",
       "             [[ 9.8823e-05, -1.8603e-04, -9.4124e-05],\n",
       "              [-5.7454e-04, -2.3159e-04, -9.6310e-05],\n",
       "              [ 5.5953e-06, -9.1179e-05, -2.5348e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-9.9529e-05, -3.0948e-04,  4.1211e-05],\n",
       "              [ 1.0720e-04, -3.2901e-04, -2.8888e-07],\n",
       "              [ 5.4739e-05, -7.0422e-05,  2.0369e-04]],\n",
       "    \n",
       "             [[ 5.5170e-05, -1.1893e-04, -1.9648e-04],\n",
       "              [-3.6662e-04,  9.3040e-05,  1.7625e-04],\n",
       "              [-3.6827e-04, -3.8035e-04, -5.5586e-04]],\n",
       "    \n",
       "             [[ 2.6963e-04,  2.9006e-04,  1.3065e-04],\n",
       "              [ 3.5078e-05,  3.2730e-05, -1.2664e-05],\n",
       "              [-2.4081e-04, -2.5563e-05,  4.0736e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-6.5402e-06,  1.4905e-04,  1.3007e-04],\n",
       "              [-5.0994e-05, -9.2413e-05, -1.9606e-04],\n",
       "              [ 4.5400e-05,  6.8330e-05, -9.9786e-05]],\n",
       "    \n",
       "             [[-1.3243e-05,  2.2493e-04,  2.9502e-04],\n",
       "              [-5.7761e-05,  1.6318e-04,  1.2598e-04],\n",
       "              [ 1.7957e-04, -2.6507e-05, -4.6825e-05]],\n",
       "    \n",
       "             [[ 1.7872e-04,  9.1878e-05,  1.2113e-04],\n",
       "              [ 1.2649e-04, -2.9311e-04, -1.2554e-04],\n",
       "              [ 2.0697e-04,  8.8175e-05, -6.6212e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.0420e-05, -2.8701e-06,  6.0091e-05],\n",
       "              [-8.0319e-05, -9.7879e-05,  1.0337e-04],\n",
       "              [ 6.5269e-05,  6.7903e-05,  4.6997e-05]],\n",
       "    \n",
       "             [[-1.7969e-04,  1.3231e-05, -5.1873e-05],\n",
       "              [-1.0839e-04, -4.1834e-05, -1.2601e-04],\n",
       "              [-1.7266e-05, -4.9302e-05,  1.8374e-05]],\n",
       "    \n",
       "             [[-6.0928e-05,  1.2084e-05,  1.1307e-04],\n",
       "              [-1.0420e-04,  3.4551e-05, -4.9478e-05],\n",
       "              [-6.0636e-05,  9.3425e-05, -7.3796e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-4.7271e-05,  4.5892e-05,  5.9962e-05],\n",
       "              [-3.0005e-04, -2.3811e-04, -6.1418e-05],\n",
       "              [ 4.7337e-05, -7.5687e-05,  9.8633e-05]],\n",
       "    \n",
       "             [[ 2.5563e-04,  2.9760e-04,  1.0957e-04],\n",
       "              [ 1.2491e-04,  1.9405e-04,  2.0812e-04],\n",
       "              [ 1.2355e-04,  1.1411e-04, -5.5657e-05]],\n",
       "    \n",
       "             [[-1.7797e-04, -2.2968e-04,  6.2045e-05],\n",
       "              [-1.0112e-04, -2.0134e-04, -3.4504e-04],\n",
       "              [-8.9277e-05,  1.1080e-06, -1.0816e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.2495e-04,  1.7279e-04,  3.0388e-04],\n",
       "              [ 1.2073e-04,  1.2881e-04,  2.6133e-04],\n",
       "              [ 2.3413e-04,  3.2111e-04,  1.7784e-04]],\n",
       "    \n",
       "             [[-1.9529e-04,  1.0926e-04,  4.4893e-05],\n",
       "              [-3.3878e-04,  2.3883e-04,  2.5830e-04],\n",
       "              [ 2.3981e-04, -6.3063e-05,  1.7425e-04]],\n",
       "    \n",
       "             [[ 9.4444e-05, -5.5243e-05,  1.6182e-04],\n",
       "              [ 2.2665e-04,  1.9867e-04,  4.3839e-04],\n",
       "              [-3.2590e-04, -1.1097e-04,  7.7269e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.2813e-05, -9.4125e-05,  6.2492e-04],\n",
       "              [-4.5483e-05, -4.2497e-05, -2.9843e-05],\n",
       "              [ 1.2632e-04, -4.9552e-05,  4.4853e-04]],\n",
       "    \n",
       "             [[ 8.2527e-05, -1.8061e-04, -1.1480e-04],\n",
       "              [ 6.8041e-05,  8.9433e-05,  1.9132e-04],\n",
       "              [-2.1140e-04, -2.0295e-04, -2.2514e-04]],\n",
       "    \n",
       "             [[ 1.5456e-04,  1.3875e-05, -5.9211e-05],\n",
       "              [ 2.0509e-04,  1.6002e-04,  3.9826e-04],\n",
       "              [ 3.3364e-05, -1.8360e-04, -3.9873e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.9668e-05, -2.2698e-05,  1.8842e-05],\n",
       "              [-6.4994e-05, -9.5644e-06,  1.1413e-04],\n",
       "              [-2.1691e-05, -1.9796e-05,  4.3645e-05]],\n",
       "    \n",
       "             [[-8.9201e-05, -1.6938e-04,  3.1419e-05],\n",
       "              [-1.2168e-06,  4.6411e-05, -4.5799e-05],\n",
       "              [-6.8783e-05,  2.0483e-05, -1.7351e-05]],\n",
       "    \n",
       "             [[-4.9156e-04,  2.2235e-04,  5.4389e-04],\n",
       "              [ 2.4089e-04, -2.1147e-06, -6.3868e-05],\n",
       "              [ 4.9857e-04,  3.1787e-04,  2.2511e-04]]]], device='cuda:0')},\n",
       "   76: {'momentum_buffer': tensor([ 2.0323e-03,  1.4382e-03,  1.3788e-03,  1.5949e-03,  1.8125e-03,\n",
       "             6.0917e-04,  1.1460e-03,  1.2948e-03,  1.1215e-03,  1.4067e-03,\n",
       "             1.8604e-03,  8.8905e-04,  2.5313e-03,  8.0805e-04,  1.2287e-03,\n",
       "             2.0937e-03,  1.3010e-03,  1.8598e-03,  1.3168e-03,  1.1971e-03,\n",
       "             8.5064e-04,  1.4685e-03,  1.9633e-03,  2.1268e-03,  1.8149e-03,\n",
       "             1.5855e-03,  1.4875e-03,  1.6858e-03,  2.5916e-03,  1.9618e-03,\n",
       "             2.0480e-03,  1.3316e-03,  2.9859e-03,  1.5244e-03,  2.1769e-03,\n",
       "            -6.6494e-04,  1.1687e-03,  1.1123e-03,  1.3907e-03,  1.8597e-03,\n",
       "             5.7291e-04,  2.4930e-03,  1.2671e-03,  6.4659e-04,  8.5302e-04,\n",
       "             1.1930e-03,  1.5114e-03,  2.0360e-03,  1.5832e-03,  1.5508e-03,\n",
       "             1.1708e-03,  1.0620e-03,  1.3098e-03,  1.0772e-03,  1.5907e-03,\n",
       "             8.0462e-04,  1.3076e-03,  9.1494e-04,  1.5865e-03,  7.6719e-04,\n",
       "             2.3294e-03,  1.0983e-03,  1.4460e-03,  4.8085e-04,  1.1514e-03,\n",
       "             1.8199e-03,  1.5951e-03,  1.7123e-03,  7.0075e-04,  1.4458e-03,\n",
       "             2.0610e-03,  1.7191e-03,  1.2064e-03,  1.2957e-03,  1.1491e-03,\n",
       "             1.2309e-03,  1.4056e-03,  1.3243e-03,  1.8048e-03,  2.1846e-03,\n",
       "             4.8462e-04,  1.6234e-03,  8.3056e-04,  2.7282e-04,  2.0442e-03,\n",
       "             1.2303e-03,  8.0538e-04,  1.2912e-03,  1.7083e-03,  1.0349e-03,\n",
       "             1.4917e-03,  1.1979e-03,  1.8076e-03,  1.5720e-03,  3.1004e-04,\n",
       "             1.7808e-03,  1.6703e-03,  1.2454e-03,  1.3420e-03,  1.8763e-03,\n",
       "             1.9182e-03,  1.6600e-03,  1.8044e-03,  1.3218e-03,  1.6997e-03,\n",
       "             1.4292e-03,  1.6833e-03,  9.1203e-04,  1.7166e-04,  1.7965e-03,\n",
       "             2.2245e-03,  1.4191e-03,  1.0455e-03,  1.5405e-03,  5.4210e-03,\n",
       "             1.5775e-03,  1.6385e-03,  1.5912e-03,  1.9737e-03,  1.8692e-03,\n",
       "             1.3535e-03,  1.7083e-03,  1.4495e-03,  1.8551e-03,  1.3258e-03,\n",
       "             1.2048e-03,  1.8446e-03,  1.0937e-03,  5.7301e-04,  2.1090e-03,\n",
       "             1.8111e-03, -3.0534e-04,  1.3566e-03,  1.3981e-03,  1.6267e-03,\n",
       "             1.4547e-03,  1.9780e-03,  1.0896e-03,  1.8025e-03,  1.1213e-03,\n",
       "             1.1783e-03,  1.2205e-03,  8.3653e-04,  1.3921e-03,  1.6057e-03,\n",
       "             5.7560e-04,  1.3530e-03,  2.1347e-03,  6.6824e-04,  1.5992e-03,\n",
       "             1.0117e-03,  1.0882e-03,  1.6093e-03,  9.6426e-04,  1.9308e-03,\n",
       "             1.1975e-03,  1.3366e-03,  1.8205e-03,  1.5817e-03,  1.5620e-03,\n",
       "             1.8754e-03,  1.6007e-03,  1.2396e-03,  1.4543e-03,  1.6176e-03,\n",
       "             1.9485e-03,  1.2442e-04,  2.8690e-04,  1.2087e-03,  1.1997e-03,\n",
       "             7.9245e-04,  5.0182e-04, -1.6592e-04,  2.0218e-03,  8.4771e-04,\n",
       "             1.3765e-03,  1.8494e-03,  1.6844e-03,  8.5549e-04,  9.5439e-04,\n",
       "             2.2087e-03,  1.4085e-03,  9.2674e-04,  1.3083e-03,  3.0340e-03,\n",
       "             1.2890e-03,  7.2025e-04,  6.0184e-04,  7.3884e-04,  1.0389e-03,\n",
       "             2.3030e-03,  1.4557e-03,  1.5098e-03,  1.8611e-03,  1.2663e-03,\n",
       "             1.8206e-03,  1.6952e-03,  1.1467e-03,  1.0247e-03,  9.5543e-04,\n",
       "             1.7805e-03,  2.1967e-03,  1.8094e-03,  1.5803e-03,  1.3883e-03,\n",
       "             2.0521e-03,  1.1790e-03,  1.8780e-03,  1.3061e-03,  3.6333e-04,\n",
       "             2.7239e-04,  1.9691e-03,  7.5622e-04,  1.2467e-03,  1.2761e-03,\n",
       "             1.6176e-03,  1.4105e-03,  1.4110e-03,  1.9267e-03,  1.2375e-03,\n",
       "             1.8297e-03,  1.4365e-03,  1.7408e-03,  1.8236e-03,  7.0188e-04,\n",
       "             1.5960e-03,  1.8520e-03,  1.3729e-03,  1.4934e-03,  8.6112e-04,\n",
       "             2.7622e-03,  1.3273e-03,  9.5011e-04,  9.3202e-04,  1.4264e-03,\n",
       "             9.6112e-04,  6.7137e-04,  1.6464e-03,  1.0911e-03,  1.4531e-03,\n",
       "             5.5731e-04,  1.3938e-03,  1.6044e-03,  2.0550e-03,  1.5162e-03,\n",
       "             2.2554e-03,  2.0491e-03,  1.8390e-04,  1.3811e-03,  3.2377e-05,\n",
       "             5.0023e-04,  1.6248e-03,  1.7133e-03,  2.4518e-03,  1.3542e-03,\n",
       "             1.5397e-03], device='cuda:0')},\n",
       "   77: {'momentum_buffer': tensor([-5.0668e-05,  5.5466e-04,  1.0898e-03,  3.7808e-05,  1.9601e-03,\n",
       "             1.3994e-03,  8.9257e-04, -1.5691e-04, -9.8045e-05,  3.7435e-05,\n",
       "            -6.3199e-04, -7.1927e-06, -6.3461e-04,  2.1087e-03,  2.3982e-03,\n",
       "            -5.0230e-04,  1.3893e-04,  1.3362e-03,  1.9738e-03,  1.7937e-03,\n",
       "             1.1813e-03, -8.6603e-05,  2.0731e-03, -9.5501e-04,  1.4950e-03,\n",
       "             1.7559e-03, -5.1775e-04,  1.3559e-03, -1.9497e-04,  1.6355e-04,\n",
       "             5.6083e-04,  3.7380e-04, -1.8152e-03,  2.4368e-03, -5.6603e-04,\n",
       "             2.2560e-03,  8.7569e-04,  1.3549e-03,  1.9165e-03, -4.4235e-04,\n",
       "             3.1367e-03, -4.8631e-04,  1.1396e-03,  2.6416e-03,  2.6699e-03,\n",
       "             9.7057e-04,  1.2041e-03,  1.8174e-03,  6.8645e-04,  3.5223e-04,\n",
       "             2.5395e-03,  2.1597e-03,  1.7481e-04,  2.8177e-03,  1.3673e-03,\n",
       "             2.2670e-03,  9.0410e-04,  6.0624e-04,  2.8242e-03,  2.8080e-03,\n",
       "            -7.2774e-04,  1.1074e-03, -3.9249e-04,  2.4933e-03,  6.1639e-04,\n",
       "            -7.4356e-04, -6.7640e-04,  1.2215e-04,  1.1400e-03, -2.7484e-04,\n",
       "             1.0483e-03,  1.0243e-03,  2.1128e-03,  2.5459e-03, -4.2573e-04,\n",
       "             2.8796e-03,  2.8746e-03, -4.3757e-04, -2.1979e-04,  2.0653e-03,\n",
       "             1.1136e-03,  2.0403e-03,  2.2092e-03,  2.7496e-03,  7.3006e-04,\n",
       "             1.0473e-04,  2.9160e-03,  4.7805e-04,  1.5280e-03,  4.9603e-04,\n",
       "             6.2955e-04,  3.1468e-03,  6.1351e-04,  1.1167e-03,  2.5364e-03,\n",
       "            -3.1067e-04,  3.0878e-03,  2.3444e-03,  1.2844e-03,  9.8664e-05,\n",
       "            -5.1081e-04, -3.0912e-04, -1.5858e-04,  1.2676e-04,  9.2444e-04,\n",
       "             8.1486e-04,  1.1626e-03,  2.0105e-03,  2.6959e-03,  2.1688e-04,\n",
       "            -9.2507e-04,  2.8584e-03,  1.7949e-03, -7.5105e-04, -5.0037e-03,\n",
       "            -7.2388e-04,  5.2813e-04,  7.9373e-04, -2.1859e-04,  6.3002e-05,\n",
       "            -3.2357e-04,  1.8023e-04,  2.1346e-03,  5.2903e-05,  5.3262e-04,\n",
       "             6.1194e-04,  1.1495e-04, -9.4695e-04,  2.7260e-03, -1.2334e-04,\n",
       "             6.3906e-04,  1.4790e-03, -5.7777e-04,  1.6287e-03, -3.7754e-04,\n",
       "            -7.3689e-04, -8.3920e-04, -2.3202e-04,  2.6635e-03,  1.2536e-03,\n",
       "             3.0843e-03,  1.3894e-03,  2.1143e-03, -2.1735e-04,  7.2112e-04,\n",
       "             2.0182e-03,  2.5047e-04, -2.3029e-04,  1.1192e-04, -1.0021e-03,\n",
       "             2.6112e-03,  1.6764e-03, -2.4579e-04,  3.2925e-03,  5.7739e-04,\n",
       "             1.1183e-03,  1.5402e-03, -9.4659e-05,  6.9652e-04,  1.5806e-03,\n",
       "            -2.7971e-04,  3.6310e-04,  2.0917e-03,  3.4179e-04,  3.6443e-05,\n",
       "            -3.0434e-04,  6.7349e-04,  2.1852e-03, -5.2696e-04,  1.0051e-03,\n",
       "             2.9219e-03,  2.8567e-03,  3.0613e-03, -7.1209e-04,  1.0116e-03,\n",
       "             9.9449e-04, -4.8384e-04, -1.8174e-04,  1.7001e-03,  3.4297e-03,\n",
       "             7.2662e-04, -6.9233e-05,  1.3292e-03,  1.6031e-03, -1.0525e-03,\n",
       "            -2.2369e-04,  8.7531e-04,  1.8900e-03,  2.1272e-03,  8.3939e-04,\n",
       "             2.3906e-03,  1.2262e-03,  3.0169e-04, -7.4888e-04,  1.1803e-03,\n",
       "            -1.2508e-03,  9.4974e-04,  2.4234e-05, -9.8294e-04,  1.4393e-03,\n",
       "            -1.0302e-03,  3.2030e-04, -6.5257e-04, -2.9691e-04,  1.7908e-03,\n",
       "             4.9101e-04,  3.3247e-03,  9.2003e-04,  9.2875e-04,  6.9444e-04,\n",
       "             2.7239e-03, -1.0058e-03,  1.3197e-03,  3.3253e-04, -4.6700e-04,\n",
       "             5.0741e-04,  2.1552e-03, -6.1012e-04,  1.5102e-04, -1.9082e-04,\n",
       "             1.4865e-03, -3.8583e-04,  8.4474e-04,  1.7270e-03,  2.2452e-03,\n",
       "            -7.0586e-05, -6.4793e-04,  5.5232e-04,  1.7701e-03,  1.5067e-03,\n",
       "            -1.4969e-03,  3.0414e-03,  2.9277e-03,  9.1597e-04,  4.7975e-04,\n",
       "             2.8316e-03, -5.1866e-04,  1.3327e-03, -1.1038e-04,  2.9130e-04,\n",
       "             1.6411e-04,  1.2256e-03,  6.2542e-04,  1.0929e-03,  1.4168e-03,\n",
       "            -2.0832e-04, -7.6957e-04,  2.5745e-03, -5.2615e-05,  3.0851e-03,\n",
       "             2.3217e-03,  5.5144e-04,  1.3089e-03,  4.8064e-04, -5.2516e-05,\n",
       "            -1.1436e-05], device='cuda:0')},\n",
       "   78: {'momentum_buffer': tensor([[[[ 2.6061e-04]],\n",
       "    \n",
       "             [[ 7.7609e-05]],\n",
       "    \n",
       "             [[-2.5194e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.5443e-04]],\n",
       "    \n",
       "             [[ 1.4896e-04]],\n",
       "    \n",
       "             [[-3.5398e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.3777e-04]],\n",
       "    \n",
       "             [[-4.0048e-04]],\n",
       "    \n",
       "             [[ 3.6560e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.3775e-04]],\n",
       "    \n",
       "             [[ 7.1041e-04]],\n",
       "    \n",
       "             [[ 9.6080e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.2856e-04]],\n",
       "    \n",
       "             [[ 2.1534e-04]],\n",
       "    \n",
       "             [[-2.6875e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.0081e-04]],\n",
       "    \n",
       "             [[-6.1822e-05]],\n",
       "    \n",
       "             [[-1.3087e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.3493e-04]],\n",
       "    \n",
       "             [[-3.5274e-04]],\n",
       "    \n",
       "             [[ 6.5113e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.9198e-04]],\n",
       "    \n",
       "             [[ 5.4742e-05]],\n",
       "    \n",
       "             [[-2.3411e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.1173e-03]],\n",
       "    \n",
       "             [[ 4.0345e-04]],\n",
       "    \n",
       "             [[-5.5561e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.6549e-05]],\n",
       "    \n",
       "             [[-4.9712e-04]],\n",
       "    \n",
       "             [[ 2.4368e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.9233e-04]],\n",
       "    \n",
       "             [[ 7.0966e-05]],\n",
       "    \n",
       "             [[-5.6352e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.5137e-04]],\n",
       "    \n",
       "             [[ 4.2440e-04]],\n",
       "    \n",
       "             [[ 1.0698e-04]]]], device='cuda:0')},\n",
       "   79: {'momentum_buffer': tensor([0.0012, 0.0023, 0.0017,  ..., 0.0023, 0.0016, 0.0009], device='cuda:0')},\n",
       "   80: {'momentum_buffer': tensor([-2.1912e-04, -1.0485e-03,  4.7970e-05,  ..., -6.6604e-04,\n",
       "            -3.3579e-04, -1.4422e-04], device='cuda:0')},\n",
       "   81: {'momentum_buffer': tensor([[[[-5.4295e-05]],\n",
       "    \n",
       "             [[ 1.2811e-04]],\n",
       "    \n",
       "             [[ 1.9690e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.1518e-05]],\n",
       "    \n",
       "             [[-3.6984e-04]],\n",
       "    \n",
       "             [[ 9.3494e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.1378e-05]],\n",
       "    \n",
       "             [[-2.3483e-04]],\n",
       "    \n",
       "             [[ 1.0504e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.6144e-07]],\n",
       "    \n",
       "             [[ 2.5204e-05]],\n",
       "    \n",
       "             [[ 7.7604e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.8080e-05]],\n",
       "    \n",
       "             [[ 1.1503e-04]],\n",
       "    \n",
       "             [[ 2.6377e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.8129e-04]],\n",
       "    \n",
       "             [[ 8.6380e-05]],\n",
       "    \n",
       "             [[ 4.9504e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-1.7541e-04]],\n",
       "    \n",
       "             [[-1.4861e-04]],\n",
       "    \n",
       "             [[ 1.3521e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.1835e-04]],\n",
       "    \n",
       "             [[-2.0283e-04]],\n",
       "    \n",
       "             [[-2.8300e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.6608e-04]],\n",
       "    \n",
       "             [[-1.2277e-05]],\n",
       "    \n",
       "             [[-3.0842e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.1562e-04]],\n",
       "    \n",
       "             [[-6.5397e-05]],\n",
       "    \n",
       "             [[-4.0019e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.8987e-04]],\n",
       "    \n",
       "             [[ 1.0890e-04]],\n",
       "    \n",
       "             [[-1.4026e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.3590e-05]],\n",
       "    \n",
       "             [[ 4.2891e-04]],\n",
       "    \n",
       "             [[ 4.0306e-05]]]], device='cuda:0')},\n",
       "   82: {'momentum_buffer': tensor([0.0004, 0.0008, 0.0013,  ..., 0.0015, 0.0003, 0.0011], device='cuda:0')},\n",
       "   83: {'momentum_buffer': tensor([-2.1912e-04, -1.0485e-03,  4.7970e-05,  ..., -6.6604e-04,\n",
       "            -3.3579e-04, -1.4422e-04], device='cuda:0')},\n",
       "   84: {'momentum_buffer': tensor([[[[-4.0424e-04]],\n",
       "    \n",
       "             [[-1.2726e-04]],\n",
       "    \n",
       "             [[ 6.8859e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-8.7840e-05]],\n",
       "    \n",
       "             [[ 2.5952e-04]],\n",
       "    \n",
       "             [[-2.0556e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.9701e-05]],\n",
       "    \n",
       "             [[-1.0040e-05]],\n",
       "    \n",
       "             [[-1.0191e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.3469e-05]],\n",
       "    \n",
       "             [[ 8.0790e-05]],\n",
       "    \n",
       "             [[-4.3117e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.1674e-04]],\n",
       "    \n",
       "             [[ 1.9245e-04]],\n",
       "    \n",
       "             [[-1.0593e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.8186e-05]],\n",
       "    \n",
       "             [[ 1.3114e-04]],\n",
       "    \n",
       "             [[ 2.2162e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-7.4857e-05]],\n",
       "    \n",
       "             [[-1.7336e-04]],\n",
       "    \n",
       "             [[-1.1101e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.1455e-05]],\n",
       "    \n",
       "             [[ 3.0462e-04]],\n",
       "    \n",
       "             [[ 9.1034e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.4924e-05]],\n",
       "    \n",
       "             [[-1.5865e-04]],\n",
       "    \n",
       "             [[ 7.9938e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.6466e-06]],\n",
       "    \n",
       "             [[ 5.3115e-06]],\n",
       "    \n",
       "             [[-6.2828e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-9.0920e-05]],\n",
       "    \n",
       "             [[-2.2510e-04]],\n",
       "    \n",
       "             [[ 3.2762e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.7321e-04]],\n",
       "    \n",
       "             [[-7.8263e-05]],\n",
       "    \n",
       "             [[ 2.3197e-05]]]], device='cuda:0')},\n",
       "   85: {'momentum_buffer': tensor([ 1.6277e-03,  1.9275e-03,  1.6433e-03,  1.3455e-03,  1.9363e-03,\n",
       "             8.9244e-04,  7.6453e-04,  6.6330e-04,  1.7461e-03,  1.5351e-03,\n",
       "             2.1696e-03,  1.5271e-03,  1.7000e-03,  6.2067e-04,  9.8670e-04,\n",
       "             8.3100e-04,  1.1001e-03,  1.6710e-03,  1.5305e-03,  1.4493e-03,\n",
       "             1.0271e-03,  1.5247e-03,  3.5491e-04,  1.8321e-03,  9.7518e-04,\n",
       "             1.4670e-03,  1.7645e-03,  9.6628e-04,  1.1908e-03,  8.0698e-04,\n",
       "             1.5009e-03,  1.7956e-03,  1.1956e-03,  1.4348e-03,  2.3408e-03,\n",
       "             1.8363e-03,  1.5960e-03,  1.4709e-03,  1.6172e-03,  1.5930e-03,\n",
       "             7.3394e-04,  1.6363e-03,  1.6924e-03,  1.8584e-03,  2.0994e-03,\n",
       "             1.3988e-03,  1.1625e-03,  2.1530e-03,  7.1024e-04,  7.6952e-04,\n",
       "             6.9251e-04,  1.0348e-03,  1.2199e-03,  1.2162e-03,  4.3646e-03,\n",
       "             1.7099e-03,  1.5555e-03, -5.9225e-05,  1.7883e-03,  1.2582e-03,\n",
       "             1.1947e-03,  1.4240e-03,  5.9449e-04,  4.3199e-04,  1.2215e-03,\n",
       "             2.0191e-03,  1.3529e-03,  1.7065e-03,  1.0860e-03,  1.0432e-03,\n",
       "             1.8249e-03,  2.0148e-03,  2.4873e-03,  1.6292e-03,  3.6933e-04,\n",
       "             3.0763e-03,  7.2769e-04,  1.7605e-03,  1.4123e-03,  8.8575e-04,\n",
       "             1.0737e-03,  1.7358e-03, -1.9946e-04,  9.5084e-04,  1.7681e-03,\n",
       "             2.3543e-03,  2.3509e-03,  3.3759e-03,  1.7556e-03,  1.3800e-03,\n",
       "             1.4060e-03,  8.2292e-04,  1.3431e-03,  1.0962e-03,  1.4196e-03,\n",
       "             1.8856e-03,  1.6892e-03,  2.4791e-03,  7.2683e-04,  1.0078e-03,\n",
       "             2.5011e-03,  7.6734e-04,  1.1706e-03,  1.5923e-03,  1.0861e-03,\n",
       "             9.6250e-04,  1.1843e-03,  1.6383e-03,  7.2748e-04,  1.0217e-03,\n",
       "             8.7996e-04,  2.9212e-04,  7.8725e-04,  6.1782e-04,  1.4429e-03,\n",
       "             7.6710e-04,  1.5998e-03,  1.4478e-03,  1.1586e-03,  1.8173e-03,\n",
       "             5.4745e-04,  1.1577e-03,  1.2217e-03,  1.3121e-03,  1.4341e-03,\n",
       "             4.6525e-04,  1.6022e-03,  7.3465e-04,  1.5900e-03,  1.6306e-03,\n",
       "             1.4479e-03,  1.2390e-03,  1.2956e-03, -2.0895e-04,  1.1485e-03,\n",
       "             1.4533e-03,  1.8797e-03,  8.1578e-04,  1.2490e-03,  1.8055e-03,\n",
       "             2.1130e-03,  8.3083e-04,  2.7316e-03,  2.0291e-03,  1.3424e-03,\n",
       "            -1.0018e-04,  6.2401e-04,  1.6916e-03,  1.5144e-03,  1.6222e-03,\n",
       "             1.3143e-03,  2.6525e-04,  1.3354e-03,  7.1770e-04,  8.8547e-04,\n",
       "             8.8224e-05,  9.0226e-04,  1.2203e-04,  5.1022e-04,  1.6829e-03,\n",
       "             2.4287e-03,  6.3305e-04,  9.2584e-04,  1.2990e-03,  1.1867e-03,\n",
       "             8.5529e-04,  3.3620e-03,  1.3142e-03,  1.7431e-03,  1.4105e-03,\n",
       "             2.1204e-03,  1.1554e-03,  9.9846e-04,  1.4230e-03,  1.0263e-03,\n",
       "             2.8909e-04,  8.5131e-04,  8.6711e-04,  1.5430e-03,  1.6910e-03,\n",
       "             9.1852e-04,  1.8405e-03,  1.3278e-03,  1.3268e-03,  1.4471e-03,\n",
       "             1.2513e-03,  1.1381e-03,  1.1416e-03,  1.6365e-03,  1.2606e-03,\n",
       "             1.2775e-03,  1.1217e-03,  1.6383e-03,  1.6014e-03,  1.1236e-03,\n",
       "             1.3775e-03,  1.3445e-03,  1.1544e-03,  1.5071e-03,  1.0378e-03,\n",
       "             1.9870e-03,  2.4078e-03,  2.3154e-03,  1.0631e-03,  1.1800e-03,\n",
       "             1.6459e-03,  1.3256e-03,  1.3907e-03,  2.0765e-03,  9.8152e-04,\n",
       "             2.0280e-03,  2.1293e-03,  3.3910e-03,  8.0266e-04,  7.1988e-04,\n",
       "             1.8449e-03,  9.1936e-04,  1.5997e-03,  1.5124e-03,  1.7604e-03,\n",
       "             4.8287e-04,  1.1330e-03,  1.0138e-03,  1.0936e-03,  1.1390e-03,\n",
       "             1.6871e-03,  1.8677e-03,  1.7464e-03,  2.0942e-03,  1.6419e-03,\n",
       "             1.5670e-03,  1.6203e-03,  1.2628e-03,  1.5896e-03,  8.9983e-04,\n",
       "             6.8384e-04,  3.7703e-04,  6.6176e-04,  1.2639e-03,  1.6077e-03,\n",
       "             1.4829e-03,  1.7086e-03,  1.0430e-03,  1.0300e-03,  9.0699e-04,\n",
       "             1.8363e-03,  2.1738e-03,  8.1742e-04,  1.0101e-03,  1.4916e-03,\n",
       "             9.7199e-04,  1.1735e-03,  3.3811e-05,  1.4463e-03,  8.2431e-04,\n",
       "             1.4246e-03], device='cuda:0')},\n",
       "   86: {'momentum_buffer': tensor([-1.7297e-03, -9.9640e-04, -1.3323e-03,  8.2903e-04, -2.2837e-03,\n",
       "             2.2496e-04, -9.3191e-04,  1.9980e-04, -2.1702e-03, -1.8691e-04,\n",
       "            -2.0675e-03, -3.9808e-04, -1.0560e-03, -1.0496e-03, -3.8349e-06,\n",
       "            -4.7676e-04, -8.0432e-04, -8.4917e-04, -1.0443e-03, -4.6316e-04,\n",
       "             1.0701e-03, -1.9317e-03,  1.0196e-03, -1.0550e-03,  1.0528e-03,\n",
       "            -1.4273e-04, -1.0604e-03,  2.8970e-04, -2.0044e-03, -1.0120e-03,\n",
       "            -6.7578e-04, -3.3236e-04, -5.0388e-04, -1.8566e-03, -1.8907e-03,\n",
       "            -7.1248e-04, -1.8418e-03, -1.4082e-03, -6.1147e-04, -1.0966e-03,\n",
       "            -1.8549e-05, -2.0784e-03, -1.9575e-03,  9.3145e-04, -2.1988e-03,\n",
       "            -1.5139e-03, -5.5419e-04, -8.9458e-04,  5.7605e-04,  5.8754e-04,\n",
       "            -1.7076e-04, -4.3185e-04, -6.1070e-04, -6.1198e-04, -4.5273e-03,\n",
       "            -1.3581e-03, -6.5984e-04,  5.1401e-04, -3.9633e-06, -1.8343e-04,\n",
       "            -1.4778e-03, -1.6780e-03,  3.2937e-04, -7.8535e-04,  1.5106e-04,\n",
       "            -1.2253e-03, -1.3411e-03, -5.1287e-04, -1.2842e-03,  3.5672e-04,\n",
       "            -8.8415e-04, -1.7186e-03, -1.7489e-03, -6.1488e-04, -2.0750e-04,\n",
       "             1.1158e-04, -2.9617e-04, -1.6950e-03,  2.2986e-04, -3.4488e-04,\n",
       "            -3.2552e-04, -1.6342e-03, -4.2775e-04, -1.4574e-04, -8.4418e-04,\n",
       "            -3.2842e-03, -2.5723e-03, -1.4895e-03, -2.0386e-03, -7.8128e-04,\n",
       "            -1.2738e-03,  5.8303e-05,  2.9105e-04, -9.9532e-04, -3.6961e-04,\n",
       "            -1.1852e-03, -1.7124e-03, -6.9055e-04,  1.5808e-04, -6.3680e-04,\n",
       "            -4.0297e-03, -1.0861e-03, -5.7304e-04, -1.3026e-03,  3.5346e-05,\n",
       "            -4.0139e-04, -4.6859e-04,  1.8741e-04, -3.5309e-04, -1.7743e-04,\n",
       "            -5.9939e-04, -7.0728e-05,  4.0209e-04, -1.2027e-03, -1.1257e-03,\n",
       "            -8.0319e-04,  1.1660e-04, -1.2951e-03, -3.3175e-04, -2.9995e-04,\n",
       "            -5.9894e-04, -1.0622e-03, -2.6536e-04, -1.2365e-03, -9.5561e-04,\n",
       "            -3.4866e-04, -1.2715e-03, -7.3673e-04, -1.1593e-03, -1.3390e-03,\n",
       "            -7.5702e-04, -4.5820e-04, -1.1852e-03,  1.2470e-03, -1.4189e-03,\n",
       "            -2.0369e-03, -1.1794e-04, -1.5259e-03, -1.5091e-03, -1.6555e-03,\n",
       "            -4.3330e-04, -1.6079e-03, -1.9067e-03, -1.4717e-03, -2.1419e-03,\n",
       "             5.4947e-04, -1.5666e-04, -1.7177e-03, -1.3009e-03, -1.0079e-03,\n",
       "            -9.4099e-05, -2.1007e-04, -8.9834e-04, -5.0419e-04, -1.8937e-03,\n",
       "            -2.5520e-04,  3.9049e-05,  1.5392e-03,  1.5914e-03, -4.4527e-04,\n",
       "            -3.2366e-03, -1.1607e-04, -5.9481e-04,  1.7039e-04, -1.0012e-03,\n",
       "             9.8321e-04, -7.0261e-04, -1.1424e-03,  5.4680e-04, -3.4415e-04,\n",
       "            -6.0237e-04, -2.0918e-04,  7.0695e-04, -4.4448e-04, -1.0541e-03,\n",
       "             1.0663e-03, -3.6322e-04,  1.3052e-03, -9.0732e-04, -2.3377e-03,\n",
       "             9.3693e-05,  3.7366e-04,  1.5616e-05,  3.6007e-04, -1.3723e-05,\n",
       "            -1.3889e-03, -3.2718e-04,  5.0401e-04, -1.3013e-03, -6.7698e-04,\n",
       "            -4.3140e-04, -9.4217e-05, -1.4274e-04, -4.6336e-04, -1.1653e-03,\n",
       "            -6.2743e-04, -1.3568e-03, -5.2393e-04, -6.7455e-04, -1.8823e-03,\n",
       "            -2.8025e-03, -2.4458e-03, -1.1703e-03, -1.3040e-03,  7.2225e-04,\n",
       "             1.2430e-03, -1.3219e-03, -5.2847e-04, -7.4652e-04, -1.7979e-04,\n",
       "            -2.5478e-03,  3.6146e-06, -1.1791e-03,  2.5368e-05, -6.3929e-04,\n",
       "            -5.7851e-04, -1.1186e-03, -1.2395e-03,  1.1142e-04,  2.0772e-04,\n",
       "            -2.5342e-04, -1.6740e-04, -3.9498e-04, -6.2324e-05, -7.3504e-04,\n",
       "            -8.8216e-04,  5.1192e-04, -1.2370e-03, -1.9580e-03, -1.1285e-03,\n",
       "             9.7598e-04, -6.6140e-04, -3.5660e-04, -1.5066e-03,  2.1429e-05,\n",
       "            -1.3476e-03, -5.2691e-04,  8.8523e-05,  2.5564e-04, -1.9218e-03,\n",
       "            -1.0682e-03, -5.8190e-04, -1.9068e-04,  3.1785e-04, -8.7615e-04,\n",
       "            -2.6212e-03, -1.2295e-03,  1.1967e-03,  3.4292e-04, -1.6347e-04,\n",
       "            -3.6952e-04,  9.3602e-04,  5.7902e-04,  1.2391e-03, -9.2808e-04,\n",
       "            -1.4862e-05], device='cuda:0')},\n",
       "   87: {'momentum_buffer': tensor([[[[-3.2076e-05,  1.4590e-04,  7.3890e-05],\n",
       "              [ 4.9649e-05, -5.5804e-05, -4.8791e-05],\n",
       "              [ 4.6064e-05, -5.6907e-05,  5.1971e-06]],\n",
       "    \n",
       "             [[-2.0605e-04, -2.3758e-05,  7.3858e-05],\n",
       "              [-4.2977e-05,  4.9771e-05,  2.7773e-05],\n",
       "              [ 1.5125e-04, -3.9980e-05, -2.8986e-05]],\n",
       "    \n",
       "             [[ 2.1176e-04, -1.2430e-04, -9.2262e-05],\n",
       "              [-7.6439e-05, -2.2322e-04, -2.0720e-04],\n",
       "              [-1.4979e-04, -2.7673e-04,  3.6085e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.7548e-04, -2.7691e-04, -1.3550e-04],\n",
       "              [-4.3767e-04, -1.7149e-04, -6.6035e-05],\n",
       "              [-5.6890e-04, -5.0060e-04, -2.5682e-04]],\n",
       "    \n",
       "             [[-1.0897e-04,  1.4439e-05,  3.8137e-05],\n",
       "              [-4.0050e-04,  1.1883e-04, -2.6396e-05],\n",
       "              [-3.7006e-04, -2.4554e-04, -1.5023e-04]],\n",
       "    \n",
       "             [[ 1.2113e-04,  2.2306e-04,  1.0336e-04],\n",
       "              [ 2.1251e-04,  1.4563e-04,  1.1198e-04],\n",
       "              [-9.1189e-05,  2.1822e-04,  3.0278e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.9329e-05,  6.2780e-06,  2.2542e-05],\n",
       "              [-1.1731e-06, -3.9969e-05,  1.3410e-05],\n",
       "              [-2.2732e-05,  3.8409e-05, -4.0793e-05]],\n",
       "    \n",
       "             [[-1.5427e-05, -2.9673e-05,  1.8780e-05],\n",
       "              [-2.0579e-05, -6.4943e-05, -5.0825e-05],\n",
       "              [ 8.9130e-07, -1.1516e-05, -7.5757e-05]],\n",
       "    \n",
       "             [[ 6.6290e-05,  4.0929e-05,  7.8435e-05],\n",
       "              [-3.1022e-05,  2.2892e-06,  3.6818e-05],\n",
       "              [ 7.4597e-05,  4.3430e-05,  6.1253e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.5690e-04, -6.0067e-05, -5.6325e-05],\n",
       "              [-1.7934e-04, -7.3635e-05, -5.9496e-05],\n",
       "              [-1.1962e-04, -1.1713e-04, -1.1854e-04]],\n",
       "    \n",
       "             [[-3.2874e-05, -2.0234e-05, -1.1502e-04],\n",
       "              [ 1.7461e-05, -5.0943e-05, -2.6278e-05],\n",
       "              [-4.1007e-05,  3.6803e-05, -5.6493e-05]],\n",
       "    \n",
       "             [[-4.9231e-05,  1.1278e-05,  4.1628e-05],\n",
       "              [ 2.8787e-05, -8.7222e-05,  9.9746e-05],\n",
       "              [-1.8453e-05,  8.9040e-05,  5.7630e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 9.8511e-05,  6.7688e-05,  1.1898e-04],\n",
       "              [ 6.5045e-05,  4.3982e-05,  9.8680e-05],\n",
       "              [-1.3657e-05, -5.2857e-05, -4.0531e-07]],\n",
       "    \n",
       "             [[ 1.0321e-04, -1.8466e-06,  5.4371e-06],\n",
       "              [ 9.4898e-05, -2.3988e-05,  5.5413e-05],\n",
       "              [ 1.5871e-04, -3.8488e-05, -9.5836e-05]],\n",
       "    \n",
       "             [[ 2.0836e-04, -2.0634e-05, -1.0158e-04],\n",
       "              [-9.5751e-06, -5.2717e-05, -5.3060e-05],\n",
       "              [-4.6359e-05, -1.3993e-04, -1.6360e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.7582e-04,  1.2439e-04,  1.1846e-04],\n",
       "              [ 2.2949e-04,  6.0483e-05, -1.1471e-05],\n",
       "              [ 3.6905e-04,  2.3993e-04,  9.5656e-05]],\n",
       "    \n",
       "             [[ 2.3203e-04,  3.7701e-04, -3.0280e-04],\n",
       "              [ 3.1848e-04,  2.0483e-04, -1.1684e-04],\n",
       "              [ 2.0298e-04, -4.2198e-05, -4.0807e-05]],\n",
       "    \n",
       "             [[ 9.6270e-05,  1.2930e-04,  1.1514e-04],\n",
       "              [-9.7361e-05, -7.1285e-05,  1.3425e-04],\n",
       "              [ 4.2485e-05,  1.1457e-04,  2.2466e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 4.6027e-05, -1.0959e-04, -1.0184e-04],\n",
       "              [ 1.3844e-04,  5.9825e-05, -2.1615e-05],\n",
       "              [ 1.1575e-04,  1.8745e-04, -7.2064e-05]],\n",
       "    \n",
       "             [[ 6.3247e-05,  2.8545e-05, -1.1139e-04],\n",
       "              [ 3.1120e-04,  2.1400e-04, -4.8411e-06],\n",
       "              [-1.2418e-04, -2.1354e-05, -2.6025e-06]],\n",
       "    \n",
       "             [[ 2.3384e-04,  2.0388e-04,  5.1528e-06],\n",
       "              [ 1.4773e-04,  8.0656e-05, -2.3802e-05],\n",
       "              [ 1.2285e-04,  2.6472e-04, -7.7605e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-9.9734e-05, -2.7596e-04, -2.5017e-04],\n",
       "              [-1.1660e-04, -1.5884e-04, -2.3842e-05],\n",
       "              [-1.0208e-04,  3.9568e-05,  9.2080e-05]],\n",
       "    \n",
       "             [[ 8.2427e-05, -1.9813e-04, -1.4461e-04],\n",
       "              [ 1.2456e-04, -9.5475e-05, -2.9568e-04],\n",
       "              [ 2.0504e-04,  1.2923e-04,  7.8125e-05]],\n",
       "    \n",
       "             [[-4.0991e-05, -2.5237e-04, -1.0740e-04],\n",
       "              [-5.8505e-05, -1.2256e-04, -7.4835e-05],\n",
       "              [-8.7137e-05, -2.9191e-04, -6.3308e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.4379e-05, -4.1626e-05, -4.7637e-05],\n",
       "              [-6.8032e-05, -1.6274e-05, -5.3345e-05],\n",
       "              [-5.2517e-05, -4.1172e-05, -4.3457e-05]],\n",
       "    \n",
       "             [[ 4.4885e-05,  7.0562e-05,  3.7294e-05],\n",
       "              [-7.2425e-06, -2.2017e-06, -3.7693e-05],\n",
       "              [-3.4077e-05, -1.1145e-04, -2.9969e-05]],\n",
       "    \n",
       "             [[-4.3872e-05, -1.0068e-04, -3.3035e-05],\n",
       "              [-1.0178e-04, -9.8416e-05,  8.0097e-06],\n",
       "              [-5.1697e-05, -8.7864e-05, -6.1635e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.0928e-05,  4.2492e-05,  8.5997e-05],\n",
       "              [-6.0649e-05,  2.8145e-05,  1.0635e-04],\n",
       "              [-3.6696e-05,  1.4306e-05,  2.8841e-05]],\n",
       "    \n",
       "             [[-1.3940e-04, -1.1322e-04,  1.2957e-04],\n",
       "              [-1.9650e-04, -1.5332e-04,  8.6117e-05],\n",
       "              [-6.0755e-05, -1.0291e-04, -7.0858e-05]],\n",
       "    \n",
       "             [[ 2.8646e-05,  2.2043e-05, -6.4263e-06],\n",
       "              [ 8.4256e-06,  1.8554e-05, -2.6649e-05],\n",
       "              [-2.9468e-06, -1.6890e-05, -1.0690e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.4464e-05, -5.0857e-05, -7.1583e-05],\n",
       "              [-7.6578e-05, -1.3546e-04, -9.8488e-05],\n",
       "              [-8.2752e-05, -1.3448e-04, -1.2460e-05]],\n",
       "    \n",
       "             [[-1.3337e-05, -8.4335e-05, -3.8998e-05],\n",
       "              [-1.0286e-04, -7.6032e-05, -1.7374e-05],\n",
       "              [-1.5063e-05,  2.8516e-05, -3.2537e-05]],\n",
       "    \n",
       "             [[ 1.2184e-04,  1.1309e-04,  7.8048e-05],\n",
       "              [ 9.2944e-05,  4.0351e-05,  2.0634e-05],\n",
       "              [ 5.5206e-05, -1.7495e-05,  6.1557e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.1629e-04,  3.7662e-04,  3.9388e-04],\n",
       "              [ 2.5653e-04,  3.0662e-04,  2.0513e-04],\n",
       "              [ 2.8496e-04,  2.8168e-04,  3.1563e-04]],\n",
       "    \n",
       "             [[ 6.9975e-05, -9.9790e-05,  2.0384e-04],\n",
       "              [-1.0905e-04, -2.4904e-04,  4.7117e-05],\n",
       "              [-5.8015e-05,  2.3480e-06, -8.2615e-05]],\n",
       "    \n",
       "             [[-1.2975e-04, -1.5964e-04, -2.4193e-04],\n",
       "              [-1.6339e-04, -2.0950e-04, -7.2114e-05],\n",
       "              [-1.5009e-04, -1.0366e-04, -1.4730e-04]]]], device='cuda:0')},\n",
       "   88: {'momentum_buffer': tensor([ 1.7255e-03,  1.9167e-03,  1.2339e-03,  1.3832e-03,  2.1353e-03,\n",
       "             1.4773e-03,  1.6874e-03,  1.8846e-03,  1.8229e-03,  2.0355e-03,\n",
       "             1.5821e-03,  6.8505e-04,  6.5508e-04,  2.3819e-03,  1.7422e-03,\n",
       "             2.9994e-03,  1.9605e-03,  1.7680e-03,  1.4571e-03,  1.4570e-03,\n",
       "             5.6354e-04,  1.6947e-03,  1.9824e-03,  1.2946e-03,  1.6202e-03,\n",
       "             8.1536e-04,  9.3704e-04,  1.3440e-03,  3.6122e-03,  1.3642e-03,\n",
       "             2.2314e-03,  1.5204e-03,  1.1794e-03,  1.5737e-03,  9.1321e-04,\n",
       "             2.1708e-03,  8.2731e-04,  1.4401e-03,  2.5462e-03,  1.0061e-03,\n",
       "             1.2476e-03,  3.2224e-03,  1.6746e-03,  1.4761e-03,  2.1143e-03,\n",
       "             1.7917e-03,  2.0422e-03,  1.8611e-03,  1.2271e-03,  2.8590e-03,\n",
       "             1.4432e-03,  2.2599e-03,  1.3335e-03,  1.1761e-03,  1.6399e-03,\n",
       "             1.9506e-03,  1.1314e-03,  1.9114e-03,  1.7702e-03,  1.4841e-03,\n",
       "             1.8567e-03,  2.3678e-03,  3.1423e-03,  1.6069e-03,  1.8206e-03,\n",
       "             1.8311e-03,  1.1640e-03,  1.9454e-03,  1.2714e-03,  2.1104e-03,\n",
       "             1.9299e-03,  1.6231e-03,  7.4045e-04,  1.6195e-03,  2.5300e-03,\n",
       "             1.5904e-03,  1.9332e-03,  1.7054e-03,  1.4088e-03,  1.7542e-03,\n",
       "             1.9655e-03,  1.2094e-03,  1.2243e-03,  1.5079e-03,  2.0881e-03,\n",
       "             1.3792e-03,  8.4632e-04,  1.2573e-03, -1.8433e-04,  1.5013e-03,\n",
       "             1.8477e-03,  1.5150e-03,  1.7382e-03,  2.9451e-04,  9.2248e-04,\n",
       "             3.3640e-03,  3.9446e-03,  1.4567e-04,  8.9026e-04,  1.7181e-03,\n",
       "             2.2202e-03,  2.4169e-03,  1.0881e-03,  1.4778e-03,  1.1250e-03,\n",
       "             3.6250e-03,  1.3201e-03,  5.2985e-04,  1.7154e-03,  2.0165e-03,\n",
       "             1.2324e-03,  1.9412e-03,  1.0057e-03,  1.7528e-03,  1.6735e-03,\n",
       "             3.9796e-05,  1.1063e-03,  2.5675e-03,  2.1266e-03,  2.2048e-03,\n",
       "             1.4695e-03,  1.7426e-03,  9.6563e-04,  1.7064e-03,  1.4023e-03,\n",
       "             1.4130e-03,  1.3257e-03,  7.0501e-04,  7.2322e-04,  1.6389e-03,\n",
       "             1.3806e-03,  1.6331e-03,  2.0307e-03,  2.2580e-03,  1.4987e-03,\n",
       "             9.0661e-04,  1.9619e-03,  2.3223e-03,  1.4173e-03,  1.7479e-03,\n",
       "             1.2037e-03,  1.8721e-03,  1.1728e-03,  1.2643e-03,  1.8170e-03,\n",
       "             2.5173e-03,  1.2879e-03,  1.2977e-03,  2.2462e-03,  1.2393e-03,\n",
       "             3.9863e-04,  1.0905e-03,  2.0821e-03,  1.7902e-03,  1.2096e-03,\n",
       "             1.5903e-03,  9.6692e-04,  1.2915e-03,  1.9544e-03,  1.1474e-03,\n",
       "             1.9050e-03,  1.4631e-03,  1.5177e-03,  5.7128e-04,  9.1396e-04,\n",
       "             1.0230e-03,  1.6998e-03,  1.2703e-03,  1.5102e-03,  1.6709e-03,\n",
       "             1.3727e-03,  1.9165e-03,  1.9517e-03,  1.4363e-03,  1.0467e-03,\n",
       "             6.9687e-04,  1.2808e-03,  1.0050e-03,  1.2392e-03,  1.2561e-03,\n",
       "             1.2838e-03,  2.0848e-03,  9.7198e-04,  2.3969e-03,  1.9985e-03,\n",
       "             8.8927e-04,  1.6031e-03,  2.2003e-03,  1.7474e-03,  1.7198e-03,\n",
       "             7.5526e-04,  7.0859e-04,  1.1722e-03,  1.4695e-03,  1.1585e-03,\n",
       "             1.3459e-03,  1.7406e-03,  1.1710e-03,  5.8075e-03,  1.7891e-03,\n",
       "             6.1556e-04,  1.2883e-03,  3.1817e-04,  2.2945e-03,  1.5910e-03,\n",
       "             1.7224e-03,  1.4681e-03,  2.2902e-03,  1.8553e-03,  1.1008e-03,\n",
       "             1.1783e-03,  5.7787e-03,  2.3335e-03,  1.3528e-03,  1.4006e-03,\n",
       "             1.8896e-03,  1.3188e-03,  1.1650e-03,  2.4035e-03,  1.8454e-03,\n",
       "             1.8795e-03,  1.7209e-03,  2.4287e-03,  2.2133e-03,  1.7284e-03,\n",
       "             1.6529e-03,  1.1315e-03,  2.2880e-03,  3.2653e-03,  1.5979e-03,\n",
       "             1.1811e-03,  2.1019e-03,  1.6059e-03,  1.5676e-03,  2.1503e-03,\n",
       "             1.5336e-03,  1.4927e-03,  2.1360e-03,  1.7084e-03,  1.6655e-03,\n",
       "             1.7260e-03,  1.5345e-03,  1.5757e-03,  1.8005e-03,  3.3638e-03,\n",
       "             1.0832e-03,  1.6874e-03,  2.2296e-03, -1.8369e-04,  1.5680e-03,\n",
       "             5.5919e-04,  1.6737e-03,  4.4228e-03,  1.7947e-03,  2.2918e-03,\n",
       "             1.2628e-03], device='cuda:0')},\n",
       "   89: {'momentum_buffer': tensor([ 5.3717e-04, -1.0024e-03,  1.0816e-04,  5.6835e-04, -6.8987e-04,\n",
       "             1.3548e-03, -1.1000e-03, -9.0416e-04, -1.0278e-03, -1.0060e-03,\n",
       "            -1.0717e-03, -4.1506e-04,  9.2768e-04, -2.1250e-03, -1.8146e-03,\n",
       "            -2.2746e-03, -8.1995e-04, -1.6118e-03, -7.7338e-04, -1.4711e-03,\n",
       "            -9.6833e-05, -7.0024e-04, -1.2622e-03, -1.0262e-03, -7.6639e-04,\n",
       "            -6.2586e-04,  2.1050e-03, -3.6574e-04, -3.2662e-03, -1.2431e-03,\n",
       "            -5.7859e-04, -1.3207e-03, -8.4238e-04,  8.2465e-04,  5.2197e-06,\n",
       "            -1.0192e-03, -3.4957e-04, -1.7851e-03, -1.2887e-03, -1.4891e-03,\n",
       "            -1.0024e-03, -4.2684e-04,  4.5893e-05, -3.9048e-04, -1.0604e-03,\n",
       "            -1.0098e-03, -2.1623e-03, -1.1463e-03, -6.0168e-04, -1.8634e-03,\n",
       "            -1.3930e-03, -4.8476e-04, -8.1077e-04, -3.9866e-04, -1.3238e-03,\n",
       "            -6.8350e-04,  1.0598e-03, -9.2096e-04, -6.0308e-04, -2.1660e-04,\n",
       "            -9.6008e-04, -1.9595e-03, -2.9442e-03, -1.1215e-03, -8.0536e-04,\n",
       "            -1.2469e-03, -2.2004e-04, -1.1650e-03,  3.5749e-04, -7.1208e-04,\n",
       "            -1.4723e-03, -1.5474e-03, -3.0979e-05,  5.7575e-05, -7.4336e-04,\n",
       "             1.0527e-04, -5.5040e-04, -1.0424e-03,  3.3007e-04,  1.7288e-03,\n",
       "            -1.5119e-03, -6.1528e-04, -1.9712e-03, -2.1130e-03, -8.8945e-04,\n",
       "            -7.4296e-04,  1.4723e-04, -2.0135e-04,  1.6393e-03, -7.5214e-04,\n",
       "            -8.9120e-04,  2.5119e-03, -6.8984e-04, -1.3118e-03, -7.1242e-04,\n",
       "            -2.7209e-03, -1.9871e-03, -1.7406e-03, -1.6130e-04, -8.6387e-04,\n",
       "            -1.1693e-03, -1.9233e-03, -3.1785e-03, -3.2325e-04, -1.1788e-03,\n",
       "            -3.1902e-03,  5.6263e-05,  6.8581e-04, -1.3805e-03, -8.8995e-04,\n",
       "            -1.2071e-03, -1.3791e-03,  3.1589e-04, -4.1973e-04, -5.3024e-04,\n",
       "             1.2594e-03, -1.1695e-03, -1.6148e-03,  1.1920e-04, -1.2906e-03,\n",
       "             7.6896e-05, -1.8068e-03, -1.9149e-03, -5.9249e-04, -1.0861e-03,\n",
       "            -2.3717e-03,  4.3393e-04, -5.8352e-05,  7.9350e-06, -3.3007e-04,\n",
       "             4.5098e-04, -2.2225e-04, -1.6811e-03, -7.5717e-04, -8.1067e-04,\n",
       "            -9.4851e-04, -1.8289e-03, -1.8921e-03, -1.4290e-03,  1.8922e-03,\n",
       "            -1.5219e-03, -7.9570e-04, -9.3552e-04, -5.5347e-04, -4.6997e-04,\n",
       "            -2.5444e-03, -8.7784e-04, -1.2408e-03, -1.5428e-04, -2.3964e-03,\n",
       "            -1.1353e-03,  1.9101e-04, -1.2128e-03,  5.8754e-04, -1.4530e-03,\n",
       "            -4.4241e-04,  7.4419e-05, -1.4642e-03, -2.3891e-04, -6.8881e-05,\n",
       "            -5.7041e-04,  7.1901e-04,  4.7703e-04,  7.9414e-04,  6.5475e-04,\n",
       "            -9.5001e-04, -2.2219e-03, -6.8740e-04, -1.8012e-03, -3.8590e-05,\n",
       "            -9.1599e-04, -1.7159e-03, -7.4659e-04, -6.3498e-04, -1.1927e-04,\n",
       "            -1.2462e-03, -9.1310e-04, -1.0478e-03, -7.4218e-04, -7.9504e-04,\n",
       "            -1.4676e-03, -1.8348e-03,  1.0019e-03, -2.2010e-03, -5.0912e-04,\n",
       "            -1.1651e-03, -9.1190e-04, -1.0229e-03, -1.4167e-03, -1.1989e-03,\n",
       "             9.5552e-04, -1.1661e-03, -1.0879e-03, -8.8941e-04,  3.8890e-04,\n",
       "            -1.5395e-03,  2.7467e-04, -2.0764e-03, -6.2279e-03, -1.0692e-03,\n",
       "             1.4443e-04, -4.9939e-04,  6.0915e-04, -2.6145e-03, -1.1712e-03,\n",
       "            -3.9482e-04, -1.1467e-03, -2.3154e-03, -5.3922e-04, -1.2915e-04,\n",
       "             1.2534e-03, -5.0022e-03, -4.2265e-06,  4.5117e-04,  3.7656e-04,\n",
       "            -7.3329e-04, -1.1251e-03, -3.0242e-04, -7.8680e-04,  2.2893e-03,\n",
       "            -1.1871e-03, -5.3857e-04, -1.1152e-03, -6.3487e-04, -1.0308e-03,\n",
       "            -1.4671e-03, -4.6017e-05, -5.1976e-04, -3.6753e-03,  5.3912e-04,\n",
       "             1.1846e-04, -9.3217e-04, -1.9495e-03, -8.4503e-04, -2.2869e-03,\n",
       "            -7.7434e-04,  2.5996e-04, -1.0883e-03, -6.1399e-04, -1.4540e-04,\n",
       "            -1.0557e-03, -1.5082e-03, -8.3278e-04, -7.0269e-04, -4.6459e-03,\n",
       "            -8.3031e-04, -6.8944e-04, -1.0845e-03,  1.7722e-03, -1.4931e-04,\n",
       "             1.5261e-03, -1.0487e-03, -2.4713e-03, -2.1923e-04, -2.4473e-03,\n",
       "            -6.1992e-05], device='cuda:0')},\n",
       "   90: {'momentum_buffer': tensor([[[[ 2.5276e-04]],\n",
       "    \n",
       "             [[-3.4753e-04]],\n",
       "    \n",
       "             [[-2.7912e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.0614e-04]],\n",
       "    \n",
       "             [[ 1.6298e-05]],\n",
       "    \n",
       "             [[-1.5047e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.2162e-04]],\n",
       "    \n",
       "             [[-2.7525e-04]],\n",
       "    \n",
       "             [[ 6.9243e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.1303e-04]],\n",
       "    \n",
       "             [[-1.3591e-04]],\n",
       "    \n",
       "             [[-1.1682e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.7105e-04]],\n",
       "    \n",
       "             [[ 3.4068e-04]],\n",
       "    \n",
       "             [[ 1.8051e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.4568e-04]],\n",
       "    \n",
       "             [[ 3.2031e-04]],\n",
       "    \n",
       "             [[ 3.6733e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 3.5758e-04]],\n",
       "    \n",
       "             [[-8.4059e-05]],\n",
       "    \n",
       "             [[-3.2426e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.8754e-04]],\n",
       "    \n",
       "             [[-7.4828e-05]],\n",
       "    \n",
       "             [[-1.2365e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.1499e-05]],\n",
       "    \n",
       "             [[-6.7038e-05]],\n",
       "    \n",
       "             [[-2.2888e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.1363e-04]],\n",
       "    \n",
       "             [[ 3.5416e-05]],\n",
       "    \n",
       "             [[ 3.7596e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.2150e-05]],\n",
       "    \n",
       "             [[ 4.1275e-05]],\n",
       "    \n",
       "             [[ 2.3663e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.3060e-05]],\n",
       "    \n",
       "             [[ 1.4998e-04]],\n",
       "    \n",
       "             [[ 1.6323e-04]]]], device='cuda:0')},\n",
       "   91: {'momentum_buffer': tensor([0.0008, 0.0006, 0.0008,  ..., 0.0008, 0.0003, 0.0005], device='cuda:0')},\n",
       "   92: {'momentum_buffer': tensor([-1.2254e-03, -7.0496e-04, -6.2735e-04,  ..., -8.4355e-04,\n",
       "            -3.1684e-05, -7.8700e-05], device='cuda:0')},\n",
       "   93: {'momentum_buffer': tensor([[[[-3.6855e-05]],\n",
       "    \n",
       "             [[ 3.9898e-05]],\n",
       "    \n",
       "             [[ 3.6853e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-7.6583e-05]],\n",
       "    \n",
       "             [[ 2.3564e-04]],\n",
       "    \n",
       "             [[ 4.7174e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.6219e-05]],\n",
       "    \n",
       "             [[-5.5192e-05]],\n",
       "    \n",
       "             [[-6.7292e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.6928e-05]],\n",
       "    \n",
       "             [[ 3.7730e-05]],\n",
       "    \n",
       "             [[-1.7831e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.8631e-05]],\n",
       "    \n",
       "             [[ 1.0465e-04]],\n",
       "    \n",
       "             [[-1.5966e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.9593e-05]],\n",
       "    \n",
       "             [[-1.7615e-04]],\n",
       "    \n",
       "             [[ 3.5127e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 2.1292e-04]],\n",
       "    \n",
       "             [[ 6.8331e-05]],\n",
       "    \n",
       "             [[-1.1935e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.0734e-04]],\n",
       "    \n",
       "             [[-4.4422e-04]],\n",
       "    \n",
       "             [[-1.1738e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.6622e-04]],\n",
       "    \n",
       "             [[-2.9291e-05]],\n",
       "    \n",
       "             [[ 1.5645e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.1034e-04]],\n",
       "    \n",
       "             [[ 2.2696e-04]],\n",
       "    \n",
       "             [[-1.7034e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.4399e-05]],\n",
       "    \n",
       "             [[ 8.9667e-05]],\n",
       "    \n",
       "             [[ 1.8318e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.8386e-04]],\n",
       "    \n",
       "             [[ 1.4466e-04]],\n",
       "    \n",
       "             [[ 5.7859e-05]]]], device='cuda:0')},\n",
       "   94: {'momentum_buffer': tensor([ 1.8839e-03,  1.6862e-03,  1.4082e-03,  1.1095e-03,  4.9617e-03,\n",
       "             8.7396e-04,  1.2236e-03,  1.4828e-03,  1.8116e-03,  1.3545e-03,\n",
       "            -3.0200e-06,  2.1350e-03,  1.6752e-03,  1.9933e-03,  2.4997e-04,\n",
       "             1.0760e-03,  1.4106e-03,  7.1470e-04,  3.1133e-04,  2.1537e-03,\n",
       "             1.2851e-03,  4.9372e-04,  2.0273e-03,  1.3770e-03,  1.2780e-03,\n",
       "             5.0199e-04,  2.0359e-03,  2.3013e-03,  3.4935e-04,  1.3243e-03,\n",
       "             1.9233e-03,  1.7869e-03,  1.5360e-03,  1.0152e-03,  1.0880e-03,\n",
       "             1.3440e-03,  1.3837e-03,  1.4700e-03,  5.2277e-04,  1.0414e-03,\n",
       "             1.3758e-03,  2.1036e-03,  1.2740e-03,  1.3783e-03,  1.9076e-03,\n",
       "             1.1060e-03,  8.8762e-04,  8.0708e-04,  8.0535e-04,  1.4991e-03,\n",
       "             9.7627e-04,  1.1429e-03,  2.4052e-03,  7.3028e-04,  1.3003e-03,\n",
       "             1.4069e-03,  3.0233e-03,  1.2486e-03,  2.0311e-03,  1.3893e-03,\n",
       "             2.3055e-03,  6.6142e-04,  2.7633e-03,  7.8609e-04,  1.5739e-03,\n",
       "             1.2372e-03,  1.1103e-03,  6.0477e-04,  2.2841e-03,  1.7510e-03,\n",
       "             1.0894e-03,  2.0609e-03,  7.7322e-04,  1.6810e-03,  1.8568e-03,\n",
       "             1.3935e-03,  1.4076e-03,  2.1059e-03,  1.6291e-03,  2.2878e-03,\n",
       "             1.9012e-03,  7.6870e-04,  2.0258e-03,  1.5393e-03, -1.5264e-04,\n",
       "             7.3640e-04,  8.6560e-04,  1.8534e-03,  2.3394e-03,  1.9192e-04,\n",
       "             9.1367e-04,  1.1974e-03,  2.0477e-03,  1.5532e-03,  2.0961e-03,\n",
       "             7.7529e-04,  9.5232e-05,  1.1469e-03,  1.4019e-03,  2.0398e-03,\n",
       "             1.2890e-03,  1.9237e-03,  1.9780e-03,  1.4212e-03,  1.3063e-03,\n",
       "             7.1368e-04,  5.1379e-04,  1.2833e-03,  9.7780e-04,  1.0218e-03,\n",
       "             1.4652e-03,  1.1080e-03,  1.6582e-03,  9.8037e-04,  1.4557e-03,\n",
       "             8.2524e-04,  1.7250e-03,  1.5095e-03,  1.0520e-03,  4.4172e-04,\n",
       "             1.2529e-03,  1.9369e-03,  1.2102e-03,  1.3734e-03,  1.1519e-03,\n",
       "             1.3900e-03,  1.6681e-03,  1.1697e-03,  2.1264e-03,  1.4004e-03,\n",
       "             1.8553e-03,  1.6726e-03,  6.2192e-04,  1.0881e-03,  1.4350e-03,\n",
       "             1.1304e-03,  1.5887e-03,  1.2303e-03,  3.5225e-04,  2.0874e-03,\n",
       "             1.9056e-03,  1.1993e-03,  1.1818e-03,  1.4363e-03,  1.0504e-03,\n",
       "             7.4800e-04,  1.3286e-03,  1.8803e-03,  1.1015e-03,  2.6499e-04,\n",
       "             5.3333e-04,  3.6240e-04,  1.1819e-03,  2.6002e-03,  3.3387e-03,\n",
       "             6.0970e-04,  1.0836e-03,  1.5167e-03,  8.6240e-04,  2.3764e-03,\n",
       "             1.2011e-03,  1.2157e-03,  1.4341e-03,  3.4235e-04,  1.7841e-03,\n",
       "             1.5300e-03,  1.1913e-03,  9.9856e-04,  1.8700e-03,  2.3639e-03,\n",
       "             1.7315e-03,  1.3651e-03,  1.6819e-03,  1.4852e-03,  1.2043e-03,\n",
       "             1.5108e-03,  6.2135e-04,  1.9994e-03,  1.7677e-03, -1.4186e-04,\n",
       "             1.4501e-03,  6.3919e-04,  1.7403e-03,  1.3682e-03,  1.9654e-03,\n",
       "             2.3505e-03,  1.3810e-03,  1.7415e-03,  1.8547e-03,  1.6943e-03,\n",
       "             1.6997e-03,  2.6131e-04,  1.6390e-03,  5.3507e-04,  1.6348e-03,\n",
       "             1.1119e-03,  1.7875e-03,  1.0636e-03,  1.0634e-03,  4.3847e-04,\n",
       "             2.4366e-03,  6.1612e-04,  1.2445e-03,  1.6659e-03,  1.3752e-03,\n",
       "             1.8128e-03,  7.0172e-04,  1.1287e-03,  2.1781e-03,  1.0946e-03,\n",
       "             1.7002e-03,  1.4342e-03,  1.9852e-03,  1.6998e-03,  1.8634e-03,\n",
       "             1.2209e-03,  1.6126e-03,  7.0255e-04,  1.4799e-03,  2.0632e-03,\n",
       "             1.2950e-03,  2.2412e-03,  2.0181e-03,  1.9636e-03,  1.5524e-03,\n",
       "             1.4407e-03,  8.7263e-04,  1.0432e-03,  1.1198e-03,  1.1895e-03,\n",
       "             1.0216e-03,  2.1647e-03,  1.0256e-03, -8.5450e-05,  2.5435e-03,\n",
       "             4.3740e-04, -3.8927e-05,  1.7534e-03,  9.2500e-04,  1.2508e-03,\n",
       "             1.5752e-03,  1.2037e-03,  2.0208e-03,  2.0390e-03,  8.1695e-04,\n",
       "             9.8001e-04,  8.0773e-04,  1.3400e-03,  1.0101e-03,  2.1003e-03,\n",
       "             1.8912e-03,  1.8552e-03,  1.2453e-03,  2.2283e-03,  1.3634e-03,\n",
       "             1.6261e-03], device='cuda:0')},\n",
       "   95: {'momentum_buffer': tensor([-7.1491e-04, -2.1876e-03, -1.5600e-03, -1.2440e-03, -8.5539e-04,\n",
       "            -8.7195e-04, -5.8578e-04, -2.2679e-03,  2.7475e-04, -1.4627e-03,\n",
       "            -1.1319e-03, -3.2439e-03, -1.3504e-03, -4.2646e-03,  9.6593e-04,\n",
       "             7.3055e-04, -1.6067e-03, -1.7908e-04, -7.2799e-04, -1.2285e-03,\n",
       "            -1.9500e-03, -8.1867e-04, -2.7586e-03, -2.9984e-04, -2.0009e-03,\n",
       "            -1.5983e-03, -2.1317e-03, -1.0939e-03,  3.5277e-04, -1.0089e-03,\n",
       "            -1.1278e-03,  3.2400e-04, -9.3413e-04, -2.0581e-03, -5.4015e-04,\n",
       "            -1.5604e-03, -3.1323e-04, -2.9467e-03, -8.5004e-04, -1.0393e-03,\n",
       "            -7.7648e-04, -1.7344e-03, -1.7199e-03, -1.0048e-04, -2.7262e-03,\n",
       "            -1.0136e-03,  3.7435e-04, -2.6451e-04, -5.8202e-04, -1.4213e-04,\n",
       "            -1.5229e-03, -2.4382e-04, -2.4868e-03, -8.4711e-04,  1.7692e-04,\n",
       "            -6.4244e-04, -2.2154e-03,  1.5629e-04, -2.1984e-03, -1.4717e-03,\n",
       "            -1.8501e-03,  4.9467e-04, -4.0393e-04, -5.0318e-04, -8.0140e-04,\n",
       "            -1.5292e-03, -1.4047e-03, -9.8398e-04, -1.6647e-03,  4.0334e-04,\n",
       "             1.7632e-04, -2.0753e-03, -1.8235e-03, -1.0511e-03, -1.0204e-03,\n",
       "            -7.1241e-04, -1.5103e-03, -5.1181e-04, -7.0280e-04, -1.0840e-03,\n",
       "            -2.8775e-04,  8.4761e-04, -1.7543e-03, -6.6794e-04, -1.0672e-03,\n",
       "            -8.6729e-04,  4.4368e-04, -1.8041e-03, -5.6258e-04, -3.7856e-04,\n",
       "            -1.1902e-03, -7.3132e-04, -4.5374e-04, -1.9458e-03, -1.4782e-03,\n",
       "            -5.5622e-04, -5.8841e-04, -1.3624e-03,  3.4032e-05, -1.9141e-03,\n",
       "            -1.8620e-03, -9.9889e-04, -8.6369e-04, -9.3158e-04, -6.0127e-05,\n",
       "            -2.9451e-04, -4.5276e-04, -4.1203e-04, -1.2060e-03, -6.2232e-04,\n",
       "            -1.5973e-03, -1.2461e-03, -7.2899e-04, -1.7147e-03,  3.8538e-04,\n",
       "            -7.2573e-04, -2.2129e-04, -4.2711e-04, -8.6303e-04, -7.9484e-04,\n",
       "             1.2645e-05, -2.5151e-03,  5.5307e-04, -1.9858e-03, -9.1893e-04,\n",
       "            -1.0610e-03, -1.1521e-03, -4.3053e-05, -2.0609e-03, -9.4850e-05,\n",
       "            -3.1068e-03, -1.4587e-04, -6.5997e-04, -3.9939e-04, -1.2590e-04,\n",
       "            -9.7568e-04,  3.6160e-04, -1.6779e-03, -2.0225e-03,  5.9043e-04,\n",
       "            -4.8498e-04, -5.0149e-04, -1.4712e-03, -1.9207e-03, -1.2002e-03,\n",
       "            -1.1497e-03, -9.2438e-04, -1.5090e-03, -1.4395e-04, -1.3703e-03,\n",
       "            -1.9069e-03,  6.3821e-04, -1.0383e-03, -2.3459e-03, -1.9885e-03,\n",
       "            -8.2185e-04, -7.5196e-05, -2.0175e-04,  7.4376e-04, -3.5215e-03,\n",
       "            -7.1160e-04, -3.9629e-04, -8.1418e-04, -6.4599e-04,  1.0665e-03,\n",
       "            -2.3490e-03, -1.4096e-03, -2.6167e-04, -9.2119e-04,  6.8404e-04,\n",
       "            -1.9471e-03, -1.0563e-03, -2.3569e-03, -1.1186e-03, -1.0397e-03,\n",
       "            -1.3670e-03, -8.1978e-04, -1.5781e-03, -1.0624e-03,  1.2342e-03,\n",
       "            -2.5766e-04, -1.3371e-04,  3.0080e-04,  3.4370e-04, -2.6340e-03,\n",
       "            -2.0931e-03, -1.6019e-03, -1.8753e-03, -1.6640e-03, -2.7686e-04,\n",
       "            -1.1778e-03, -1.1527e-03, -1.8767e-03, -7.8271e-04, -2.2939e-03,\n",
       "            -1.2410e-03, -1.1695e-03, -1.8937e-03, -1.9661e-03, -1.0577e-03,\n",
       "            -1.9228e-03, -1.3086e-03, -2.0977e-03, -1.5508e-03, -8.8372e-04,\n",
       "            -1.1288e-03, -1.5543e-03, -1.7865e-03, -2.1499e-03, -2.2970e-03,\n",
       "             3.1417e-04, -3.8121e-04, -1.8210e-03, -8.5028e-04, -6.7077e-04,\n",
       "            -2.2393e-04, -2.6230e-04,  1.5848e-05, -5.2052e-04, -7.1859e-04,\n",
       "             1.5299e-03, -2.2779e-03, -2.1160e-03, -2.2907e-03, -1.1766e-03,\n",
       "            -9.3041e-04, -1.3493e-03,  1.0237e-03, -1.0112e-03, -7.6303e-04,\n",
       "            -1.4661e-03, -1.5622e-03, -1.9520e-03, -1.4524e-03, -3.8397e-03,\n",
       "            -2.5586e-03, -1.3901e-03, -1.0167e-03,  2.0153e-04, -2.2184e-04,\n",
       "            -1.4943e-03, -2.0057e-03, -1.6008e-03, -1.6742e-03, -2.6976e-03,\n",
       "            -1.2638e-03, -4.1933e-04, -1.2596e-03, -1.1185e-03, -2.7102e-03,\n",
       "            -2.4886e-03, -1.3166e-03, -4.1412e-04, -1.8977e-03, -9.9206e-04,\n",
       "             5.0106e-05], device='cuda:0')},\n",
       "   96: {'momentum_buffer': tensor([[[[ 5.2675e-05, -6.4952e-05, -3.8867e-04],\n",
       "              [ 1.8815e-04, -2.7876e-04, -2.7574e-04],\n",
       "              [ 1.5650e-04, -1.3985e-04, -2.9752e-04]],\n",
       "    \n",
       "             [[-2.6311e-05,  2.3579e-05, -7.2038e-05],\n",
       "              [-8.5640e-05, -6.2038e-05, -1.1608e-04],\n",
       "              [ 4.1849e-05,  2.8478e-05,  7.0158e-05]],\n",
       "    \n",
       "             [[ 5.4362e-05,  1.2216e-04,  9.4814e-06],\n",
       "              [ 7.4210e-05,  1.4858e-05, -3.1287e-05],\n",
       "              [-1.4814e-05, -1.5368e-05,  4.4421e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.4683e-04, -1.6963e-04, -1.2762e-04],\n",
       "              [ 1.5107e-04,  1.0864e-04, -1.2932e-04],\n",
       "              [ 3.6045e-06, -1.2916e-04,  6.4060e-05]],\n",
       "    \n",
       "             [[ 5.6313e-04,  3.5221e-04,  3.8737e-04],\n",
       "              [ 1.8899e-04, -5.0097e-05,  3.1625e-04],\n",
       "              [ 1.0681e-04,  1.3493e-04,  1.1727e-04]],\n",
       "    \n",
       "             [[-8.8754e-05, -1.7132e-04, -1.5920e-04],\n",
       "              [-1.6228e-04, -2.4395e-04, -9.1511e-05],\n",
       "              [ 1.7403e-04, -2.6505e-05, -1.5962e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.0243e-04, -1.5313e-04,  2.7661e-04],\n",
       "              [-4.9180e-05, -1.1910e-04,  2.1977e-04],\n",
       "              [ 5.0838e-05, -2.8950e-04,  1.3428e-04]],\n",
       "    \n",
       "             [[-4.7369e-05, -8.7157e-07,  1.4322e-04],\n",
       "              [-8.1293e-05, -2.7173e-05,  5.5728e-05],\n",
       "              [ 7.0827e-05,  1.1042e-04,  8.5154e-05]],\n",
       "    \n",
       "             [[-5.7060e-05, -5.3867e-05, -7.4871e-05],\n",
       "              [ 4.8390e-05,  5.2464e-05,  1.1962e-04],\n",
       "              [ 1.6997e-04, -2.1346e-05, -9.7841e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.3991e-04,  6.3634e-05,  2.5926e-04],\n",
       "              [-1.2718e-04,  1.9310e-04,  2.1916e-05],\n",
       "              [-8.5269e-05,  1.6753e-04,  7.5136e-05]],\n",
       "    \n",
       "             [[ 1.6211e-04, -9.5225e-06,  2.4647e-04],\n",
       "              [ 3.5034e-04,  1.7054e-04,  2.2086e-04],\n",
       "              [ 1.9447e-04,  1.6662e-04,  2.9044e-04]],\n",
       "    \n",
       "             [[ 1.1410e-04,  5.0411e-06, -6.7802e-05],\n",
       "              [ 3.8788e-04, -3.9495e-05,  1.3041e-04],\n",
       "              [ 2.7440e-04, -1.4861e-04, -7.3246e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.4512e-05, -3.1734e-04, -1.7990e-04],\n",
       "              [-3.5749e-04, -1.2904e-05, -3.5616e-05],\n",
       "              [-2.4732e-04, -9.8644e-05,  4.6642e-05]],\n",
       "    \n",
       "             [[ 4.6632e-05,  1.1821e-04, -5.6482e-06],\n",
       "              [ 1.2407e-04,  1.8043e-05, -2.4188e-05],\n",
       "              [ 2.7838e-06, -7.3742e-06,  5.5734e-05]],\n",
       "    \n",
       "             [[-1.5455e-05, -2.3475e-05, -6.7245e-05],\n",
       "              [-8.4085e-05, -1.4996e-04, -4.1288e-05],\n",
       "              [-1.1481e-04, -5.3287e-05,  4.9030e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.2795e-05, -8.6383e-05, -2.6517e-04],\n",
       "              [-1.5355e-04,  1.6423e-04,  1.1641e-04],\n",
       "              [-2.0939e-04, -1.4525e-05,  3.5928e-04]],\n",
       "    \n",
       "             [[ 2.5227e-04,  9.7385e-05,  1.4175e-05],\n",
       "              [ 6.9715e-05,  1.4472e-04,  2.2867e-04],\n",
       "              [ 9.3578e-05, -1.9437e-04,  4.5032e-05]],\n",
       "    \n",
       "             [[-1.2022e-04, -1.8800e-04, -2.2802e-04],\n",
       "              [ 2.9370e-04,  4.9376e-06, -2.3210e-04],\n",
       "              [ 4.0188e-04,  2.6310e-04,  5.5127e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-4.8122e-05, -2.4691e-04, -3.8724e-04],\n",
       "              [-1.8373e-04, -1.9689e-04, -2.4509e-04],\n",
       "              [-1.8632e-04, -1.0005e-04, -2.6020e-04]],\n",
       "    \n",
       "             [[ 5.0660e-05,  1.5010e-04,  5.3972e-05],\n",
       "              [-8.2517e-05,  8.9878e-05,  8.9361e-05],\n",
       "              [-1.5639e-04, -6.1773e-05, -8.4074e-05]],\n",
       "    \n",
       "             [[ 1.5625e-04,  1.0302e-04,  1.8167e-05],\n",
       "              [-5.1048e-05, -5.4557e-05, -4.9930e-05],\n",
       "              [-8.8251e-05, -1.5677e-04,  9.7102e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.0888e-04,  5.8709e-05,  1.3529e-04],\n",
       "              [ 1.0628e-04, -1.8230e-04, -7.8834e-05],\n",
       "              [ 1.0617e-04,  4.7483e-05,  1.4494e-04]],\n",
       "    \n",
       "             [[ 1.4480e-04,  4.3480e-05,  1.9416e-04],\n",
       "              [ 1.7272e-05, -1.0245e-04,  3.3527e-05],\n",
       "              [-3.8650e-05, -1.2113e-04,  1.4162e-04]],\n",
       "    \n",
       "             [[-3.3940e-06,  4.3484e-04,  2.9416e-04],\n",
       "              [-4.0848e-04,  1.3142e-04,  1.9766e-04],\n",
       "              [-1.2579e-04,  1.2729e-04,  1.5182e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.9707e-05,  6.0076e-05,  1.1254e-04],\n",
       "              [ 4.6515e-05,  7.2469e-05, -2.0717e-05],\n",
       "              [-1.8873e-04, -2.7473e-05, -1.6705e-04]],\n",
       "    \n",
       "             [[ 7.6608e-05,  1.1186e-04,  5.6155e-05],\n",
       "              [ 1.3343e-04,  1.5470e-04,  7.9281e-05],\n",
       "              [ 1.2167e-04,  1.6398e-04,  5.9458e-05]],\n",
       "    \n",
       "             [[-3.2143e-05,  2.9005e-06,  2.3021e-05],\n",
       "              [-4.2780e-05,  7.0136e-05, -9.5493e-06],\n",
       "              [ 2.3969e-05,  3.7027e-05, -2.7585e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.0383e-05,  2.9402e-04, -1.7438e-04],\n",
       "              [ 2.2342e-05,  1.1539e-04,  1.3296e-04],\n",
       "              [ 4.8337e-05, -6.4274e-06, -4.2386e-06]],\n",
       "    \n",
       "             [[-5.1597e-05,  2.1841e-05, -1.2756e-04],\n",
       "              [ 9.6199e-05,  7.5499e-06,  3.7226e-05],\n",
       "              [ 1.9953e-04,  1.2682e-04,  1.2095e-04]],\n",
       "    \n",
       "             [[ 3.3942e-06,  1.5626e-04,  1.4942e-04],\n",
       "              [-2.0803e-04, -4.0450e-05,  2.0821e-05],\n",
       "              [-3.2255e-04, -4.4544e-04, -2.4910e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.6600e-04, -8.9425e-05, -2.0963e-04],\n",
       "              [-3.0979e-04, -2.1182e-04, -5.0294e-05],\n",
       "              [-3.3758e-04, -1.5829e-04,  8.2724e-05]],\n",
       "    \n",
       "             [[-6.7019e-05, -6.6713e-05, -2.7439e-05],\n",
       "              [-9.1938e-05, -8.4620e-05,  2.1503e-05],\n",
       "              [-1.1278e-05,  5.9199e-05,  6.2284e-06]],\n",
       "    \n",
       "             [[-1.8577e-04, -2.3493e-04,  4.3523e-06],\n",
       "              [-3.0917e-04, -1.3671e-04,  3.1966e-05],\n",
       "              [-4.8980e-05, -9.8712e-05, -2.7901e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.0956e-05,  2.9355e-04,  2.5009e-04],\n",
       "              [-1.3806e-04,  3.2150e-04,  7.8943e-04],\n",
       "              [-8.8517e-05, -7.1736e-05,  8.2963e-04]],\n",
       "    \n",
       "             [[ 2.7660e-04,  1.6929e-04, -2.3682e-04],\n",
       "              [ 4.6504e-04,  1.9866e-04, -8.3687e-05],\n",
       "              [ 6.2157e-05,  8.0890e-05,  1.0978e-04]],\n",
       "    \n",
       "             [[ 6.8912e-04,  2.3558e-04,  8.0668e-05],\n",
       "              [ 9.0299e-04,  2.7290e-04,  1.3857e-04],\n",
       "              [ 6.2217e-04, -1.5969e-04,  2.1044e-04]]]], device='cuda:0')},\n",
       "   97: {'momentum_buffer': tensor([ 1.8563e-03,  2.1052e-04,  1.9507e-03,  1.5994e-03,  1.6875e-03,\n",
       "             7.5803e-04,  1.5736e-03,  2.0110e-03,  1.5276e-03,  1.6725e-03,\n",
       "             1.4313e-03,  1.1323e-03,  6.2631e-04,  1.5719e-03,  1.9971e-03,\n",
       "             2.7299e-03,  1.6086e-03,  8.6255e-04,  1.4540e-03,  1.6907e-03,\n",
       "             2.2393e-03,  1.3849e-03,  3.6248e-03,  4.0139e-04,  2.0461e-03,\n",
       "             1.6367e-03,  1.6803e-03,  2.0358e-03,  1.8721e-03,  1.2681e-03,\n",
       "             1.2931e-03,  9.5751e-04,  7.4463e-04,  7.4329e-04,  2.1678e-03,\n",
       "             1.1080e-03,  7.6509e-04,  1.4046e-03,  1.7313e-03,  2.5655e-03,\n",
       "             1.6641e-03,  1.7229e-03,  2.2846e-03,  2.1482e-03,  1.2074e-03,\n",
       "             1.6129e-03,  1.3845e-03,  1.7589e-03,  1.6789e-03,  1.8061e-03,\n",
       "             1.5623e-03,  1.4309e-03,  1.5393e-03,  1.7245e-03,  1.8196e-03,\n",
       "             1.0492e-03,  1.2384e-03,  1.9456e-03,  1.7977e-03,  5.5056e-04,\n",
       "             2.4901e-03,  2.2639e-03,  1.0097e-03,  7.4619e-04,  1.8500e-03,\n",
       "             1.7299e-03,  2.0109e-03,  1.0550e-03,  8.2567e-04,  1.3452e-03,\n",
       "             8.2037e-04,  2.3697e-03,  8.6773e-06, -1.7571e-04,  1.3298e-03,\n",
       "             1.7535e-03,  1.5873e-03,  1.9145e-03,  2.0221e-03,  2.4761e-03,\n",
       "             3.6899e-04,  7.6330e-04,  1.9411e-03,  1.9396e-03,  8.4393e-04,\n",
       "             1.5092e-03,  1.6434e-03,  1.6751e-03,  3.1138e-04,  1.8577e-03,\n",
       "             1.4361e-03,  1.5276e-03,  1.0326e-03,  3.0735e-03,  1.2446e-03,\n",
       "             9.3067e-04,  1.4720e-04,  1.5758e-03,  1.6196e-03,  1.6694e-03,\n",
       "             1.9186e-03,  1.1790e-03,  1.3621e-03,  9.8047e-04,  8.1326e-04,\n",
       "             2.4465e-04,  1.9933e-03,  1.6972e-03,  1.2433e-03,  8.7157e-04,\n",
       "             1.2322e-03,  1.5098e-03,  2.7964e-03,  1.7209e-03,  9.6719e-04,\n",
       "             1.5363e-03,  2.2636e-03,  9.1457e-04,  1.2347e-03,  1.0776e-03,\n",
       "             1.7816e-03,  2.3613e-03,  2.5041e-03,  1.6481e-03,  1.4713e-03,\n",
       "             1.5888e-03,  7.6702e-05,  2.6540e-03,  1.1419e-03,  1.4518e-03,\n",
       "             1.4563e-03,  1.1556e-03,  1.6379e-03,  1.8253e-03,  2.5744e-03,\n",
       "             1.8287e-03,  2.2859e-03,  1.7058e-03,  1.2018e-03,  1.6577e-03,\n",
       "             2.7252e-03,  6.5804e-04,  1.6502e-03,  1.4751e-03,  1.4342e-03,\n",
       "             2.3083e-03,  2.0150e-03,  5.9890e-04,  2.0316e-03,  1.7531e-03,\n",
       "             1.2605e-03,  2.1413e-03,  1.3608e-03,  1.0983e-03,  7.7452e-04,\n",
       "             2.1581e-03,  1.2280e-03,  2.1219e-03,  1.4149e-03,  1.7343e-03,\n",
       "             1.2249e-03,  1.8732e-03,  1.7516e-03,  9.1095e-04,  1.5830e-03,\n",
       "             2.4412e-03,  3.5411e-03,  1.3995e-03,  6.2742e-04,  2.5151e-03,\n",
       "             1.4096e-03,  2.0584e-03,  1.3299e-03,  1.1140e-03,  1.4971e-03,\n",
       "             1.1301e-03,  2.0522e-03,  1.7453e-03,  1.7197e-03,  1.5542e-03,\n",
       "             1.9181e-03,  1.1378e-03,  2.1221e-03,  1.7211e-03,  7.9213e-04,\n",
       "             7.6612e-04,  1.0028e-03,  1.7929e-03,  1.8627e-03,  6.3613e-05,\n",
       "             1.4788e-03,  1.1772e-03,  1.8686e-03,  2.3821e-03,  8.1794e-04,\n",
       "             5.9904e-04,  1.4042e-03,  2.2194e-03,  2.9038e-04,  1.0718e-03,\n",
       "             2.4257e-03,  1.4392e-03,  1.3543e-03,  4.6715e-03,  1.7015e-03,\n",
       "             2.1467e-03,  1.0228e-03,  1.5394e-03,  2.5773e-03,  1.4920e-03,\n",
       "             8.8684e-04,  1.6223e-03,  1.6830e-03,  1.3365e-03,  1.8971e-03,\n",
       "             2.2436e-03,  1.2747e-03,  1.2804e-03,  1.0235e-03,  2.3773e-03,\n",
       "             6.8643e-04,  1.6739e-03,  1.7355e-03,  1.3427e-03,  1.6956e-03,\n",
       "             4.8608e-04,  1.6508e-03,  8.4300e-04,  2.0314e-03,  1.1769e-03,\n",
       "             1.3044e-03,  1.8944e-03,  1.5299e-03,  1.5110e-03,  1.1875e-03,\n",
       "             9.3645e-04,  1.2526e-03,  5.3412e-04,  8.2070e-04,  1.6326e-03,\n",
       "             1.5908e-03,  1.3514e-03,  1.3779e-03,  2.1114e-03,  6.4071e-04,\n",
       "             1.7333e-03,  1.2286e-03,  1.4752e-03,  1.8145e-03,  5.8082e-04,\n",
       "             8.4149e-04,  2.1401e-03,  1.5289e-03,  9.8398e-04,  1.5491e-03,\n",
       "             9.4645e-04], device='cuda:0')},\n",
       "   98: {'momentum_buffer': tensor([-8.5442e-04,  1.5574e-03, -1.1966e-03, -1.7709e-03, -1.4594e-03,\n",
       "            -1.0746e-03,  6.8374e-04, -1.3735e-03, -2.9414e-04,  1.6356e-04,\n",
       "            -2.4275e-03, -9.3933e-04, -7.2678e-04,  1.1504e-03, -6.7827e-04,\n",
       "            -2.6238e-03, -1.7537e-03,  2.5458e-04, -4.9196e-04,  3.8799e-04,\n",
       "            -1.0008e-03,  1.0122e-03, -4.5832e-03,  9.9105e-04, -8.7398e-04,\n",
       "             1.9850e-03, -1.3252e-03, -1.6400e-03, -1.4222e-03,  4.1705e-04,\n",
       "            -4.9598e-04,  2.0208e-03, -9.2352e-04, -1.0642e-03, -7.9028e-04,\n",
       "            -1.5250e-03,  2.6060e-04,  2.6645e-04, -9.3031e-04, -9.2882e-04,\n",
       "            -1.4521e-03, -1.5236e-03, -1.6352e-03, -2.5705e-03, -9.5683e-04,\n",
       "            -6.1275e-05, -2.1244e-04, -9.1174e-04,  1.5862e-03, -2.7019e-04,\n",
       "            -9.8725e-04, -9.9128e-04, -4.8532e-04, -1.0463e-03, -1.6934e-03,\n",
       "            -1.7374e-03, -1.3051e-03, -1.8770e-03, -5.7369e-04, -1.1623e-03,\n",
       "             4.1598e-04, -1.5972e-03, -7.8134e-04,  4.4576e-04, -1.4234e-03,\n",
       "            -2.3647e-03, -2.4079e-03, -9.2083e-05, -9.7264e-04, -1.8907e-03,\n",
       "            -5.9635e-04, -7.2768e-04,  2.0022e-03,  1.4378e-03, -1.7374e-03,\n",
       "            -9.8418e-04, -1.4894e-03, -1.8604e-03,  1.8551e-04, -2.5659e-03,\n",
       "            -1.1402e-03,  2.5807e-03, -9.2526e-05, -1.7447e-03, -2.0344e-03,\n",
       "            -1.0960e-03, -1.0042e-03, -1.2806e-03, -2.9207e-04, -6.5245e-04,\n",
       "            -1.2944e-03, -5.6737e-04, -2.0223e-03, -8.5981e-05, -1.1926e-03,\n",
       "            -9.1164e-04,  2.1014e-03,  8.3473e-04, -3.7498e-04, -1.2796e-04,\n",
       "            -1.9875e-03,  5.0611e-04, -1.6188e-03, -1.2812e-03, -1.3728e-03,\n",
       "            -3.4182e-04, -5.7626e-04, -1.2534e-03,  2.6052e-04,  6.1190e-04,\n",
       "             5.0787e-04, -8.1986e-04, -2.0148e-03, -3.5757e-03, -5.8845e-05,\n",
       "            -3.9648e-04, -2.8387e-04, -6.6204e-04, -1.8211e-03, -7.3519e-04,\n",
       "            -1.2241e-03, -1.4760e-03, -7.6785e-04, -1.4228e-03, -1.5313e-03,\n",
       "            -1.9097e-03, -2.4332e-03, -2.2703e-03, -7.9962e-04, -7.7719e-04,\n",
       "            -8.3842e-04,  4.0590e-05, -1.1784e-03, -1.7398e-03, -2.6598e-03,\n",
       "            -1.1088e-03, -1.7276e-03, -2.4937e-03, -7.2857e-04, -7.7069e-04,\n",
       "            -2.7578e-03, -1.2385e-04, -1.2643e-03,  5.6629e-04, -1.7753e-03,\n",
       "            -2.0209e-03, -1.7207e-03, -9.9589e-06, -1.0014e-03, -1.2885e-03,\n",
       "            -7.9797e-04, -1.0946e-03, -6.0891e-04, -2.1712e-03, -5.2033e-04,\n",
       "            -7.5032e-04, -6.0183e-04, -3.0286e-04, -1.3892e-03, -8.8041e-04,\n",
       "            -2.0516e-04, -1.5733e-03, -2.9045e-03, -8.2717e-04,  2.1823e-04,\n",
       "            -1.6583e-03, -3.4796e-04, -8.5861e-04, -2.6851e-03, -3.7964e-04,\n",
       "            -1.4003e-03, -3.1291e-03, -1.6332e-03, -2.4299e-03, -2.2418e-03,\n",
       "             1.8892e-04,  4.6469e-05, -7.4699e-04,  7.5401e-04,  1.6004e-03,\n",
       "            -1.3995e-03, -4.7955e-04, -2.7008e-03, -1.0273e-03,  4.0326e-04,\n",
       "            -2.4009e-03, -5.7026e-04, -1.7251e-03, -1.1497e-03, -1.7364e-03,\n",
       "            -1.3688e-03, -1.4723e-03, -8.2917e-04, -2.1226e-03,  2.0636e-03,\n",
       "             6.3840e-04,  5.5199e-04, -7.6704e-04, -1.5460e-03,  3.5785e-04,\n",
       "            -1.9905e-03, -7.4640e-04, -6.3724e-04, -8.4174e-03, -9.0867e-04,\n",
       "             1.2838e-05, -1.6952e-04, -1.3010e-03,  2.0455e-03, -1.5374e-03,\n",
       "            -7.4674e-04, -1.6455e-03, -1.6802e-03, -1.5695e-03, -8.0502e-04,\n",
       "            -5.5345e-04, -1.2017e-03, -8.2929e-04,  7.7456e-04, -2.3661e-03,\n",
       "            -1.0471e-03, -1.0569e-03, -1.7012e-03, -1.4666e-03, -5.0092e-05,\n",
       "            -9.1459e-05, -1.4403e-03,  2.2073e-04, -1.2915e-03, -1.1854e-04,\n",
       "            -9.7482e-04, -1.4260e-03, -2.2580e-03, -9.9195e-04, -9.1438e-04,\n",
       "             7.2118e-04,  2.5667e-04, -2.5654e-04, -1.2587e-03, -7.5117e-04,\n",
       "            -2.7731e-03,  9.1698e-04, -8.2843e-04,  4.5276e-04,  1.2521e-04,\n",
       "            -1.2939e-03,  2.4285e-04, -9.1969e-05, -7.8031e-04, -7.3725e-04,\n",
       "            -4.4157e-04, -1.3083e-03, -1.3601e-03, -1.0122e-03, -2.8467e-03,\n",
       "             8.1360e-05], device='cuda:0')},\n",
       "   99: {'momentum_buffer': tensor([[[[ 2.2478e-05]],\n",
       "    \n",
       "             [[ 2.7922e-06]],\n",
       "    \n",
       "             [[-2.1554e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.8018e-04]],\n",
       "    \n",
       "             [[ 2.9177e-05]],\n",
       "    \n",
       "             [[ 9.1129e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.7681e-05]],\n",
       "    \n",
       "             [[-3.1065e-04]],\n",
       "    \n",
       "             [[ 4.8928e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.5445e-04]],\n",
       "    \n",
       "             [[-4.9239e-04]],\n",
       "    \n",
       "             [[-2.2513e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.7996e-05]],\n",
       "    \n",
       "             [[-2.7228e-04]],\n",
       "    \n",
       "             [[-1.1038e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.0610e-04]],\n",
       "    \n",
       "             [[-2.1296e-04]],\n",
       "    \n",
       "             [[-1.0284e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-4.2634e-05]],\n",
       "    \n",
       "             [[ 2.7295e-04]],\n",
       "    \n",
       "             [[-1.1142e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.7444e-05]],\n",
       "    \n",
       "             [[ 4.5008e-04]],\n",
       "    \n",
       "             [[ 1.6377e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 4.9527e-04]],\n",
       "    \n",
       "             [[ 6.7305e-04]],\n",
       "    \n",
       "             [[ 2.5365e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.6600e-04]],\n",
       "    \n",
       "             [[ 2.2053e-04]],\n",
       "    \n",
       "             [[ 1.2686e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.0000e-04]],\n",
       "    \n",
       "             [[ 6.8827e-04]],\n",
       "    \n",
       "             [[ 2.2375e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.9325e-05]],\n",
       "    \n",
       "             [[ 5.6994e-04]],\n",
       "    \n",
       "             [[ 2.1582e-04]]]], device='cuda:0')},\n",
       "   100: {'momentum_buffer': tensor([ 4.6035e-04, -1.9821e-04, -2.9529e-05,  ...,  1.1169e-03,\n",
       "             1.0193e-03,  1.9757e-03], device='cuda:0')},\n",
       "   101: {'momentum_buffer': tensor([-0.0004, -0.0004, -0.0002,  ..., -0.0010, -0.0010, -0.0007],\n",
       "           device='cuda:0')},\n",
       "   102: {'momentum_buffer': tensor([[[[ 3.1523e-05]],\n",
       "    \n",
       "             [[-4.0910e-05]],\n",
       "    \n",
       "             [[ 1.5202e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.9535e-04]],\n",
       "    \n",
       "             [[-2.4868e-04]],\n",
       "    \n",
       "             [[ 3.9254e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.5728e-04]],\n",
       "    \n",
       "             [[-1.1137e-04]],\n",
       "    \n",
       "             [[-5.0212e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.9732e-05]],\n",
       "    \n",
       "             [[-1.5955e-04]],\n",
       "    \n",
       "             [[ 2.6896e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.6937e-05]],\n",
       "    \n",
       "             [[ 1.3109e-04]],\n",
       "    \n",
       "             [[-1.6992e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.9778e-04]],\n",
       "    \n",
       "             [[-2.3904e-04]],\n",
       "    \n",
       "             [[ 4.1435e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-5.0632e-05]],\n",
       "    \n",
       "             [[-9.3079e-05]],\n",
       "    \n",
       "             [[-2.9081e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.0855e-05]],\n",
       "    \n",
       "             [[ 9.5918e-05]],\n",
       "    \n",
       "             [[ 1.6045e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.5276e-04]],\n",
       "    \n",
       "             [[ 1.9715e-04]],\n",
       "    \n",
       "             [[ 2.1363e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 8.6589e-05]],\n",
       "    \n",
       "             [[ 2.1687e-04]],\n",
       "    \n",
       "             [[ 1.3374e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.2897e-04]],\n",
       "    \n",
       "             [[ 8.9989e-05]],\n",
       "    \n",
       "             [[-1.0771e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.4439e-05]],\n",
       "    \n",
       "             [[ 1.1548e-03]],\n",
       "    \n",
       "             [[-4.1601e-04]]]], device='cuda:0')},\n",
       "   103: {'momentum_buffer': tensor([ 0.0020,  0.0008,  0.0019,  0.0018,  0.0010,  0.0020,  0.0026,  0.0007,\n",
       "             0.0014,  0.0007,  0.0019,  0.0020,  0.0008,  0.0007,  0.0020,  0.0008,\n",
       "             0.0011,  0.0016,  0.0009,  0.0017,  0.0006,  0.0018,  0.0012,  0.0020,\n",
       "             0.0024,  0.0008,  0.0015,  0.0012,  0.0019,  0.0007,  0.0005,  0.0020,\n",
       "             0.0016,  0.0018,  0.0018,  0.0016,  0.0016,  0.0005,  0.0017,  0.0017,\n",
       "             0.0019,  0.0021,  0.0012,  0.0015,  0.0011,  0.0013,  0.0014,  0.0012,\n",
       "             0.0020,  0.0016,  0.0022,  0.0015,  0.0014,  0.0023,  0.0020,  0.0014,\n",
       "             0.0018,  0.0015,  0.0022,  0.0013,  0.0017,  0.0012,  0.0034,  0.0011,\n",
       "             0.0016,  0.0020,  0.0011,  0.0012,  0.0026,  0.0011,  0.0008,  0.0017,\n",
       "             0.0013,  0.0021,  0.0011,  0.0011,  0.0018,  0.0018,  0.0015,  0.0026,\n",
       "             0.0006, -0.0005,  0.0015,  0.0020,  0.0027,  0.0017,  0.0016,  0.0021,\n",
       "             0.0012,  0.0018,  0.0013,  0.0022, -0.0003,  0.0024,  0.0016,  0.0011,\n",
       "             0.0017,  0.0016,  0.0017,  0.0023,  0.0026,  0.0010,  0.0008,  0.0011,\n",
       "             0.0017,  0.0016,  0.0015,  0.0024,  0.0009,  0.0013,  0.0027,  0.0017,\n",
       "             0.0017,  0.0014,  0.0014,  0.0005,  0.0008,  0.0019,  0.0015,  0.0010,\n",
       "             0.0007,  0.0008,  0.0012,  0.0016,  0.0013,  0.0020,  0.0020,  0.0008,\n",
       "             0.0002,  0.0022,  0.0011,  0.0017,  0.0017,  0.0010,  0.0009,  0.0009,\n",
       "             0.0014,  0.0013,  0.0026,  0.0012,  0.0002,  0.0009,  0.0012,  0.0018,\n",
       "             0.0016,  0.0002,  0.0011,  0.0012,  0.0008,  0.0020,  0.0016,  0.0020,\n",
       "             0.0014,  0.0015,  0.0011,  0.0023,  0.0012,  0.0014,  0.0015,  0.0019,\n",
       "             0.0009,  0.0025,  0.0017,  0.0017,  0.0011,  0.0012,  0.0014,  0.0017,\n",
       "             0.0015,  0.0019,  0.0016,  0.0018,  0.0008,  0.0013,  0.0011,  0.0022,\n",
       "             0.0009,  0.0005,  0.0014,  0.0013,  0.0013,  0.0019,  0.0018,  0.0012,\n",
       "             0.0020,  0.0006,  0.0007,  0.0015,  0.0004,  0.0022,  0.0005,  0.0020,\n",
       "             0.0011,  0.0019,  0.0015,  0.0013,  0.0016,  0.0006,  0.0006,  0.0019,\n",
       "             0.0019,  0.0015,  0.0003,  0.0003,  0.0016,  0.0022,  0.0012,  0.0004,\n",
       "             0.0014,  0.0008,  0.0014,  0.0018,  0.0006,  0.0011,  0.0015,  0.0019,\n",
       "             0.0011,  0.0016,  0.0020,  0.0020,  0.0002,  0.0016,  0.0008,  0.0015,\n",
       "             0.0019,  0.0013,  0.0011,  0.0013,  0.0021,  0.0016,  0.0004,  0.0006,\n",
       "             0.0014,  0.0010,  0.0031,  0.0015,  0.0021,  0.0014,  0.0019,  0.0002,\n",
       "             0.0012,  0.0006,  0.0011,  0.0014,  0.0012,  0.0008,  0.0017,  0.0017,\n",
       "             0.0022,  0.0016,  0.0016,  0.0018,  0.0013,  0.0004,  0.0019,  0.0007],\n",
       "           device='cuda:0')},\n",
       "   104: {'momentum_buffer': tensor([-3.0270e-03, -4.5508e-04, -7.4873e-04, -2.0586e-03, -7.5468e-04,\n",
       "            -1.6482e-03, -2.8438e-03, -1.0758e-03, -1.1872e-03, -1.8826e-03,\n",
       "            -7.2771e-04, -1.2512e-04, -1.1679e-03,  2.7997e-04, -1.6763e-04,\n",
       "            -1.1491e-03, -5.6218e-04, -2.3837e-03, -1.9524e-03, -6.5370e-04,\n",
       "             9.5176e-04, -1.2922e-03, -2.2590e-03, -2.1787e-03, -7.2992e-04,\n",
       "            -3.5696e-04,  1.4227e-04, -2.4354e-03,  7.4353e-04, -7.7891e-04,\n",
       "             1.4836e-04, -2.2833e-03, -5.0319e-04, -1.7105e-03, -2.0847e-03,\n",
       "            -6.3899e-04, -7.9104e-04, -1.2840e-03, -2.4917e-03, -1.1777e-03,\n",
       "             3.8583e-05, -3.3392e-03, -1.4238e-03,  8.5287e-04, -1.2332e-03,\n",
       "            -1.1795e-03, -1.4633e-03, -2.5846e-03, -4.0974e-04,  3.6640e-04,\n",
       "            -1.7513e-03, -1.0790e-03, -8.6902e-04, -2.3798e-03, -2.0999e-03,\n",
       "            -2.8649e-04, -1.7952e-03, -1.2382e-03,  6.1874e-04, -2.4933e-04,\n",
       "            -1.2411e-03,  1.1958e-05, -4.4904e-03,  2.8025e-04, -2.4383e-03,\n",
       "            -2.4615e-03, -5.6516e-04, -2.0616e-03, -1.4965e-03, -1.1334e-03,\n",
       "            -1.0364e-03, -7.9556e-04, -3.9751e-04, -2.1748e-03, -3.6348e-04,\n",
       "             4.3288e-04, -2.7694e-03, -1.3766e-03, -1.8743e-03, -9.5842e-04,\n",
       "            -7.6648e-04,  5.3259e-04, -1.6751e-03, -2.1405e-03, -2.8564e-03,\n",
       "            -4.5580e-04, -1.0124e-03, -2.6619e-03, -2.4158e-03, -2.8650e-04,\n",
       "            -1.5423e-03, -1.5634e-03, -4.8049e-04, -2.1587e-03, -5.3674e-04,\n",
       "            -4.1262e-04,  9.4613e-04, -1.8854e-03, -2.4464e-03, -2.9982e-03,\n",
       "            -8.5759e-04, -1.8434e-03,  6.0000e-04, -7.0209e-04, -1.5112e-03,\n",
       "            -1.8111e-03,  2.3443e-04, -4.8491e-03,  8.8134e-04, -1.0600e-04,\n",
       "            -3.7975e-03, -4.3819e-04, -5.6906e-06,  2.3273e-04,  2.2468e-04,\n",
       "            -1.4013e-03, -3.0014e-04, -5.0592e-04, -1.6331e-03, -6.8305e-04,\n",
       "            -3.2386e-04, -9.0666e-04,  6.2001e-04, -1.8530e-03, -1.7503e-03,\n",
       "            -2.0203e-03, -3.1324e-03, -1.2499e-03, -1.6038e-04, -6.9505e-04,\n",
       "            -1.3687e-03, -1.1225e-03, -3.7232e-04, -3.9076e-04, -3.3751e-04,\n",
       "             1.1662e-04, -2.0868e-03, -2.6946e-04, -3.3960e-03, -5.0435e-04,\n",
       "             1.0843e-04,  8.0344e-04, -3.7859e-04, -1.5785e-03, -2.0358e-04,\n",
       "             9.5655e-04, -4.5241e-04,  1.9464e-05, -7.8752e-04, -1.2540e-03,\n",
       "            -1.9238e-03, -9.1521e-04, -1.4328e-03, -1.2399e-03, -1.0813e-03,\n",
       "            -3.6544e-03, -1.0276e-03,  3.0494e-04, -4.7879e-04,  5.4570e-04,\n",
       "             3.4619e-04, -1.1733e-03, -2.4108e-03, -5.3820e-04, -2.0814e-04,\n",
       "             5.0352e-04, -7.2306e-04, -7.9155e-04, -1.4912e-03, -4.3928e-03,\n",
       "            -2.6176e-04, -2.3093e-03, -1.5402e-04, -6.2666e-04, -7.1287e-06,\n",
       "            -2.6660e-03, -1.0734e-03, -1.1014e-03, -1.1187e-03,  2.4364e-05,\n",
       "            -5.4193e-04, -7.6722e-04, -2.2011e-03,  8.3069e-04, -1.4059e-03,\n",
       "            -1.0706e-03, -6.7515e-04, -5.1304e-04,  1.3722e-03, -1.5724e-03,\n",
       "            -2.3102e-03, -1.3655e-03, -1.2374e-03, -1.8423e-03, -1.9652e-03,\n",
       "            -4.0440e-03, -2.0091e-03, -1.3049e-03,  2.1462e-04, -1.2247e-03,\n",
       "            -1.0894e-03, -1.6208e-03,  1.0067e-05, -2.0419e-03,  7.4850e-04,\n",
       "            -2.3052e-03, -1.0498e-04,  3.1913e-04, -2.1225e-03, -1.7817e-03,\n",
       "            -2.6156e-04, -1.0900e-03,  9.8828e-04, -1.0084e-03, -6.2283e-04,\n",
       "            -2.3831e-03, -8.9145e-04, -1.1186e-03, -1.1210e-03, -1.8719e-03,\n",
       "             8.0960e-04,  1.1060e-03, -8.4549e-04, -6.6827e-05, -1.7851e-03,\n",
       "            -2.3470e-03, -1.5210e-03, -2.2317e-03, -9.0752e-04, -8.8311e-04,\n",
       "            -1.4904e-03, -9.0280e-04, -1.5472e-03,  5.1446e-04, -3.7274e-03,\n",
       "            -1.6635e-03, -4.6137e-05, -2.0940e-03, -1.7938e-03, -5.3338e-04,\n",
       "            -1.7662e-03, -1.6775e-04, -1.3206e-03, -1.6813e-04,  6.0618e-04,\n",
       "            -6.0821e-04,  5.3441e-04, -2.3632e-03, -3.4084e-03, -8.6416e-04,\n",
       "            -2.3254e-03, -2.7525e-04, -6.7603e-04, -5.0517e-04, -1.2266e-03,\n",
       "            -6.5341e-04], device='cuda:0')},\n",
       "   105: {'momentum_buffer': tensor([[[[ 6.1081e-05,  8.4214e-06,  1.4878e-04],\n",
       "              [-2.4673e-05,  4.4009e-05, -4.1114e-05],\n",
       "              [-9.3355e-05, -8.1476e-05,  3.1848e-05]],\n",
       "    \n",
       "             [[ 1.5505e-04,  1.6657e-04,  1.9440e-06],\n",
       "              [-1.4175e-04,  1.4516e-04,  1.0195e-04],\n",
       "              [ 4.2165e-04,  6.8108e-05,  6.9385e-05]],\n",
       "    \n",
       "             [[-1.7057e-04,  3.4084e-05, -1.9914e-05],\n",
       "              [ 3.9440e-05, -8.0643e-05, -1.8827e-04],\n",
       "              [ 4.5452e-05,  4.5755e-05, -2.4806e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-7.9027e-05, -2.0782e-04, -1.0145e-05],\n",
       "              [ 5.9390e-05,  3.3482e-04,  1.2490e-04],\n",
       "              [ 7.6983e-05,  3.1451e-04,  4.1421e-04]],\n",
       "    \n",
       "             [[-2.3981e-04, -7.2261e-04, -8.1343e-04],\n",
       "              [-3.2137e-04, -3.7288e-04, -3.5327e-04],\n",
       "              [-9.7676e-05, -2.7234e-04, -2.6906e-04]],\n",
       "    \n",
       "             [[ 1.9738e-04,  7.8249e-05,  2.1653e-04],\n",
       "              [-5.7301e-05, -1.0963e-04, -3.7309e-04],\n",
       "              [ 7.3418e-05, -4.5558e-05, -1.0072e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.1443e-04, -4.7147e-05, -4.3249e-05],\n",
       "              [-1.5671e-05, -1.0278e-04, -4.1672e-05],\n",
       "              [-1.9099e-05, -7.6729e-05, -3.6725e-05]],\n",
       "    \n",
       "             [[ 5.1242e-05, -1.3212e-04,  1.0978e-04],\n",
       "              [-6.5443e-05, -2.3945e-04, -1.8162e-04],\n",
       "              [ 4.1408e-05, -1.1217e-04, -1.5718e-04]],\n",
       "    \n",
       "             [[-1.8461e-04, -2.4203e-04, -2.3993e-04],\n",
       "              [-1.3810e-04, -2.8523e-04, -4.5208e-05],\n",
       "              [-1.0861e-04, -1.0142e-04, -6.7794e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.3792e-05,  4.6733e-05, -7.6148e-05],\n",
       "              [ 2.3004e-04,  1.0863e-04,  1.3765e-04],\n",
       "              [-8.1196e-05, -1.7665e-04, -1.4199e-04]],\n",
       "    \n",
       "             [[-1.1883e-05,  3.0393e-05, -1.5561e-06],\n",
       "              [ 8.5072e-05, -4.3407e-05, -3.2732e-04],\n",
       "              [ 1.9244e-04, -1.7125e-04, -3.0705e-04]],\n",
       "    \n",
       "             [[ 1.2618e-04,  9.3816e-05,  1.0555e-05],\n",
       "              [ 2.2793e-04,  1.0747e-04,  2.0600e-04],\n",
       "              [ 2.3210e-04,  2.1034e-04,  1.3539e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-7.7246e-05,  1.0815e-06, -2.6528e-05],\n",
       "              [ 8.1854e-05,  2.3638e-04,  1.1175e-04],\n",
       "              [ 5.2544e-05,  1.2296e-04,  1.2877e-04]],\n",
       "    \n",
       "             [[ 1.0672e-04, -7.1945e-05, -5.4173e-05],\n",
       "              [ 1.7908e-04,  1.2265e-05,  2.1683e-05],\n",
       "              [ 2.6501e-04,  2.0837e-04,  5.9208e-05]],\n",
       "    \n",
       "             [[-1.1747e-04, -5.1675e-04, -2.3220e-04],\n",
       "              [-4.5983e-05, -3.1377e-04, -1.0785e-04],\n",
       "              [-2.7404e-04, -2.7133e-04, -2.5034e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.4128e-04,  6.7614e-05,  1.2084e-04],\n",
       "              [ 2.3879e-04,  2.2098e-04,  2.0135e-04],\n",
       "              [ 2.7690e-04,  2.6396e-04,  1.7569e-04]],\n",
       "    \n",
       "             [[-5.2125e-05, -3.7663e-05, -1.6138e-04],\n",
       "              [ 9.0780e-05, -3.4626e-05,  3.6805e-05],\n",
       "              [ 3.5265e-05, -1.8353e-04, -7.0004e-05]],\n",
       "    \n",
       "             [[ 1.7534e-04, -6.9130e-06,  1.1203e-04],\n",
       "              [ 1.3043e-04, -8.0674e-06, -2.8247e-05],\n",
       "              [ 9.4103e-05,  2.6652e-05, -1.2063e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-5.1203e-05,  8.5420e-06, -1.0426e-05],\n",
       "              [-2.3918e-05, -1.3389e-05,  7.9820e-05],\n",
       "              [-4.6652e-05, -9.6533e-05, -8.6718e-05]],\n",
       "    \n",
       "             [[-1.5477e-04, -1.5829e-04,  5.5573e-05],\n",
       "              [ 3.3246e-05,  1.6547e-04,  8.9841e-05],\n",
       "              [ 2.3506e-05,  1.6090e-04,  1.8343e-04]],\n",
       "    \n",
       "             [[ 2.6112e-05, -6.7697e-05, -9.7287e-05],\n",
       "              [ 4.8131e-05, -3.0484e-05, -1.9352e-04],\n",
       "              [ 1.0054e-04, -1.3824e-04, -2.8665e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.1432e-04, -7.7070e-05,  8.5751e-05],\n",
       "              [ 1.3144e-04,  1.5318e-04,  3.2920e-04],\n",
       "              [ 2.1537e-04,  1.8215e-04,  3.7199e-04]],\n",
       "    \n",
       "             [[-4.8157e-05, -4.7127e-05, -6.4447e-05],\n",
       "              [ 7.4162e-05,  8.8450e-05,  7.7334e-05],\n",
       "              [-8.3338e-05, -3.6367e-05, -7.1550e-05]],\n",
       "    \n",
       "             [[-7.2818e-05, -4.5153e-05,  1.1578e-05],\n",
       "              [-9.4497e-05, -1.1599e-04,  1.3954e-05],\n",
       "              [ 4.0458e-05,  1.0169e-04,  8.6901e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.3656e-04,  1.4931e-04,  5.1256e-05],\n",
       "              [-2.1176e-05, -1.4165e-04,  5.1370e-05],\n",
       "              [ 6.8274e-05,  6.0437e-06, -4.1898e-05]],\n",
       "    \n",
       "             [[-1.4216e-04,  5.0832e-05, -2.3064e-05],\n",
       "              [ 3.9645e-05,  2.1219e-04, -8.9626e-05],\n",
       "              [-1.5538e-04,  3.5456e-05, -3.4421e-04]],\n",
       "    \n",
       "             [[ 3.7037e-05,  1.1781e-04, -5.2219e-05],\n",
       "              [-7.3635e-05,  7.4139e-05,  1.0204e-04],\n",
       "              [-7.8631e-05,  1.1562e-06,  7.0142e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.4029e-04, -9.7373e-05, -1.8293e-04],\n",
       "              [-1.3237e-04,  3.4427e-05,  1.1144e-04],\n",
       "              [ 1.0686e-04, -1.7372e-05, -1.4489e-05]],\n",
       "    \n",
       "             [[ 2.0789e-04,  3.0827e-04,  1.7871e-04],\n",
       "              [ 2.0138e-04,  8.5457e-05,  4.7710e-04],\n",
       "              [ 3.8161e-04,  1.9868e-04,  3.9495e-04]],\n",
       "    \n",
       "             [[-7.2128e-05, -1.7266e-04, -1.8944e-04],\n",
       "              [ 1.2753e-04,  2.3801e-04, -6.6126e-05],\n",
       "              [ 1.3748e-04,  2.5877e-04,  3.1319e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.2254e-05, -4.3010e-05,  1.4203e-05],\n",
       "              [ 1.0909e-05, -3.5474e-05, -1.2578e-04],\n",
       "              [-7.3517e-05, -1.7714e-05, -6.5131e-06]],\n",
       "    \n",
       "             [[ 5.3959e-05, -2.5243e-05, -2.8695e-05],\n",
       "              [ 7.8115e-05, -3.0645e-06, -3.4749e-05],\n",
       "              [ 9.3426e-05,  1.3430e-04,  1.4280e-04]],\n",
       "    \n",
       "             [[ 1.6701e-05,  1.4605e-04, -4.6393e-05],\n",
       "              [ 9.0636e-05,  2.1374e-04,  1.9028e-04],\n",
       "              [ 5.4826e-05,  4.3651e-05, -6.5836e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.5477e-05, -4.6891e-05, -1.3435e-06],\n",
       "              [ 6.5097e-05, -1.6107e-04, -1.8109e-05],\n",
       "              [-2.1133e-05, -7.3353e-05,  1.1239e-05]],\n",
       "    \n",
       "             [[ 2.3955e-05, -2.7385e-05,  5.1541e-05],\n",
       "              [-4.3748e-05,  7.3713e-06, -1.6037e-05],\n",
       "              [-1.6957e-05,  2.9114e-05,  7.6701e-05]],\n",
       "    \n",
       "             [[-1.7181e-05, -1.3611e-05, -9.3634e-05],\n",
       "              [ 6.5091e-05,  1.5009e-05, -2.3526e-05],\n",
       "              [ 8.2252e-05,  1.1825e-04,  2.5292e-05]]]], device='cuda:0')},\n",
       "   106: {'momentum_buffer': tensor([ 1.4015e-03,  1.4263e-03,  9.6301e-04,  1.3651e-03,  1.0034e-03,\n",
       "             1.8408e-03,  1.8129e-03,  1.8606e-03,  1.4369e-03,  1.6538e-03,\n",
       "             9.8088e-04,  1.9014e-03,  1.1672e-03,  1.6956e-03,  1.5525e-03,\n",
       "             4.5489e-04,  1.4758e-03,  1.0140e-03,  1.9969e-03,  1.9409e-03,\n",
       "             1.2133e-03,  1.9758e-03,  2.0323e-03,  2.4047e-03,  1.2845e-03,\n",
       "             5.3728e-04,  1.4858e-03,  1.2545e-03, -3.8222e-05,  1.8681e-03,\n",
       "             2.1600e-03,  2.1188e-03,  2.1098e-03,  1.0648e-03,  1.7649e-03,\n",
       "             2.8064e-03,  2.3768e-03,  1.4013e-03, -2.4059e-04,  1.5975e-03,\n",
       "             1.3263e-03,  1.5842e-03,  1.0958e-03,  5.4647e-04,  7.4806e-04,\n",
       "             1.7366e-03,  1.4875e-03,  1.0883e-03,  1.6843e-03,  2.2957e-03,\n",
       "             1.3387e-03, -1.2023e-04,  6.8856e-04,  1.1558e-03,  1.4258e-03,\n",
       "             1.9436e-03,  1.6119e-03,  1.6638e-03,  1.7398e-03,  1.6185e-03,\n",
       "             9.3120e-04,  1.4636e-03,  1.7464e-03,  1.5360e-03,  1.7612e-03,\n",
       "             1.5835e-03,  1.2914e-03,  1.8309e-03,  1.4793e-03,  2.0463e-03,\n",
       "             1.6693e-03,  2.0048e-03,  1.5805e-03,  1.0217e-03,  1.4198e-03,\n",
       "             1.7225e-03,  1.8475e-03,  8.9294e-04,  1.7444e-03,  6.4333e-04,\n",
       "             1.9800e-03,  2.0909e-03,  1.5366e-03,  1.2360e-03,  1.3215e-03,\n",
       "             6.3003e-04,  8.3281e-04,  4.8812e-03,  1.5434e-03,  1.7863e-03,\n",
       "             6.6127e-04,  9.7086e-04,  2.0149e-03,  1.2756e-03,  1.5740e-03,\n",
       "             1.7058e-03,  1.6196e-03,  1.5640e-03,  1.7249e-03,  4.7586e-04,\n",
       "             2.3005e-03,  1.2760e-03,  5.9240e-04,  1.6814e-03,  1.1688e-03,\n",
       "             1.1704e-03,  1.6623e-03,  1.1116e-04,  1.2216e-03,  8.2425e-04,\n",
       "             1.1668e-03,  1.5162e-03,  5.2004e-04,  1.9356e-03,  4.9705e-04,\n",
       "             3.3075e-03,  9.0388e-04,  1.9810e-03,  1.3195e-03,  3.7807e-04,\n",
       "             1.2035e-03,  1.2476e-03,  1.9460e-03,  1.3879e-03,  1.6397e-03,\n",
       "             1.2037e-03,  1.9041e-03,  1.5355e-03,  1.4330e-03,  1.9330e-03,\n",
       "             1.7347e-03,  1.6019e-03,  1.2031e-03,  1.9019e-03,  1.8333e-03,\n",
       "             1.6053e-03,  1.2872e-03,  1.4219e-03,  2.2314e-03,  1.6605e-03,\n",
       "             1.3938e-03,  1.5739e-03,  2.1110e-03,  1.3878e-03,  9.7132e-04,\n",
       "             5.3818e-04,  1.1617e-03,  1.3032e-03,  1.3238e-03,  1.6582e-03,\n",
       "             6.5719e-04,  1.3489e-03,  1.3552e-03,  9.6073e-04,  2.0690e-03,\n",
       "             1.5041e-03,  1.3578e-03,  1.7878e-03,  8.7181e-04,  1.7631e-03,\n",
       "             2.4188e-03,  1.2463e-03,  1.2599e-03,  8.4770e-04,  1.7967e-03,\n",
       "             1.7302e-03,  1.4902e-03,  1.1845e-03,  1.0205e-03,  4.0124e-04,\n",
       "             1.7321e-03,  7.9182e-04,  1.8643e-03,  1.9725e-03,  1.3636e-03,\n",
       "            -1.0141e-03,  1.5418e-03,  1.6922e-03,  1.8735e-03,  1.4910e-03,\n",
       "             1.6613e-03,  9.2719e-04,  1.4823e-03,  8.5843e-04,  1.8272e-03,\n",
       "             1.6582e-03,  1.5688e-03,  9.3402e-04,  2.0918e-03,  1.7807e-03,\n",
       "             1.9728e-03,  1.9333e-03,  2.1051e-03,  2.2814e-03,  1.7647e-03,\n",
       "             1.2374e-03,  1.5867e-03,  1.3835e-03,  2.3090e-03, -2.4467e-05,\n",
       "             1.6402e-03,  9.1993e-04,  1.6204e-03,  9.3120e-04,  1.0085e-03,\n",
       "             9.0128e-04,  1.3720e-03,  3.8675e-04,  1.2531e-03,  1.2705e-03,\n",
       "             1.6833e-03,  1.0755e-03,  1.7881e-03,  2.5202e-03, -3.8178e-04,\n",
       "             1.5136e-03,  1.0412e-03,  2.0706e-03,  1.9060e-03,  8.7651e-04,\n",
       "             1.5652e-03,  1.7846e-03,  1.5943e-03,  9.7064e-04,  1.6417e-03,\n",
       "             1.4633e-03,  1.5053e-03,  1.3641e-03,  1.6191e-03,  1.8021e-03,\n",
       "             1.0501e-03,  1.8554e-03,  5.3708e-04,  1.4313e-03,  1.1542e-03,\n",
       "             1.4992e-03,  9.4315e-04,  2.4618e-03,  1.0120e-03,  1.2027e-03,\n",
       "             1.2467e-03,  7.3904e-04,  8.4485e-04, -3.0268e-04,  3.9646e-03,\n",
       "             2.0519e-03,  1.8078e-03,  1.4584e-03,  1.8409e-03,  1.4414e-03,\n",
       "             7.1330e-04, -1.0445e-04,  2.0559e-03,  1.1526e-03,  8.1853e-04,\n",
       "             1.6212e-03], device='cuda:0')},\n",
       "   107: {'momentum_buffer': tensor([-1.5273e-03, -1.8492e-03, -1.1359e-03, -6.4815e-04, -1.1960e-03,\n",
       "            -2.3930e-05, -1.2015e-03, -6.3728e-04, -8.2888e-04,  3.8183e-04,\n",
       "            -1.7869e-04, -5.7734e-04, -1.4920e-03, -6.5335e-04,  3.7592e-04,\n",
       "            -1.3179e-03, -2.6832e-03,  1.6008e-04, -1.6130e-03, -1.3388e-03,\n",
       "            -8.2169e-04, -1.3456e-03, -1.0290e-03, -2.0727e-03, -5.6876e-04,\n",
       "            -1.7378e-03,  1.6457e-04, -1.9958e-03,  2.1237e-03, -8.4036e-04,\n",
       "            -2.2201e-04, -2.2223e-03, -8.0252e-04, -1.2134e-03, -5.2171e-04,\n",
       "            -1.5104e-03, -2.5968e-03, -1.1297e-03,  2.5176e-03, -1.5570e-03,\n",
       "            -1.4524e-03, -1.3171e-03, -3.3883e-04, -3.8154e-04,  1.7788e-03,\n",
       "            -1.4745e-03, -1.0086e-03, -1.2008e-03, -1.8797e-03, -2.3369e-03,\n",
       "            -5.8611e-04,  1.3366e-03, -7.1682e-04,  4.9212e-04, -1.3943e-03,\n",
       "            -1.4503e-05, -1.2596e-03, -1.5683e-03, -1.4220e-03, -1.0299e-03,\n",
       "            -1.4658e-03, -3.4988e-04, -8.3958e-04, -2.1767e-03, -3.7132e-04,\n",
       "            -5.1332e-04, -2.8522e-04, -6.9701e-04, -1.7297e-03, -1.7235e-03,\n",
       "             7.6591e-05, -4.4298e-04, -1.1308e-03, -1.4272e-03, -6.3691e-04,\n",
       "            -2.0204e-03, -1.8488e-03,  3.1977e-04,  5.2259e-04, -8.1622e-04,\n",
       "            -1.1125e-03, -2.1946e-03, -1.0097e-03, -7.4005e-04, -2.4101e-03,\n",
       "            -1.2315e-03,  1.5718e-03, -2.4970e-03, -1.6616e-05, -9.9400e-04,\n",
       "            -8.9019e-04,  2.3222e-03, -1.4580e-03, -9.8665e-04, -1.2307e-03,\n",
       "            -1.2354e-03, -1.7389e-03, -4.1224e-07,  1.7744e-03, -2.5620e-03,\n",
       "            -1.9618e-03, -1.2480e-03, -1.3405e-04, -1.3653e-03, -1.0430e-03,\n",
       "            -1.9815e-03, -1.7984e-04,  9.6220e-04, -1.1461e-03,  6.9604e-04,\n",
       "             3.9074e-04, -3.5550e-04,  1.3006e-03, -2.2506e-03, -3.1998e-04,\n",
       "            -1.3358e-03,  1.7777e-04, -1.3299e-04, -2.7298e-04, -2.2313e-04,\n",
       "            -1.1430e-03,  8.3270e-04,  5.0499e-04, -1.1709e-03,  3.3653e-05,\n",
       "             7.5701e-04, -1.7307e-03,  1.0247e-03, -1.2200e-03, -8.9423e-05,\n",
       "            -1.1420e-03, -9.5309e-04,  6.5530e-04, -7.1787e-04, -2.2206e-03,\n",
       "            -8.8579e-04, -2.2681e-03, -1.3651e-03, -1.2745e-03,  7.2217e-05,\n",
       "            -1.2858e-03, -2.4584e-03, -1.3982e-03, -1.4806e-03, -1.4811e-03,\n",
       "             5.1231e-04, -1.0698e-03, -1.9700e-03, -2.2295e-04,  6.2248e-04,\n",
       "            -9.8592e-04, -5.4631e-04, -7.2753e-04, -8.6432e-04, -2.0273e-03,\n",
       "            -1.1927e-03, -6.7782e-04, -1.3299e-03, -3.8418e-04, -3.7158e-04,\n",
       "            -1.3782e-03, -2.0488e-03, -1.6182e-03, -4.5807e-04, -4.5905e-04,\n",
       "            -8.7220e-04, -1.9041e-04, -4.9407e-04, -1.4313e-03,  1.7768e-03,\n",
       "            -3.6003e-04, -1.0894e-03, -1.2209e-03, -1.8139e-03, -1.0006e-03,\n",
       "             1.6582e-03, -9.7304e-04, -1.6114e-03, -2.2541e-03,  4.0183e-04,\n",
       "            -1.4859e-03,  1.9691e-03, -1.3624e-03,  6.6888e-04, -1.9626e-03,\n",
       "             2.1434e-03, -2.2782e-03, -7.8980e-04, -1.0663e-03, -2.0607e-03,\n",
       "            -1.6015e-03, -1.4588e-03, -6.6636e-04, -2.0802e-03, -1.3895e-03,\n",
       "            -2.0751e-04, -7.8682e-04,  1.7143e-04, -2.7420e-03,  1.9206e-03,\n",
       "            -1.3189e-03, -4.0732e-05, -1.8330e-03, -1.5499e-04,  9.9162e-05,\n",
       "             2.4211e-04,  8.6296e-05, -1.1057e-03, -6.3521e-04, -1.0602e-03,\n",
       "             8.7778e-04, -9.9809e-04, -1.1972e-03, -7.9130e-04,  9.7281e-04,\n",
       "            -2.1182e-03, -8.2095e-04, -1.2017e-03, -2.0995e-03, -1.2467e-03,\n",
       "            -1.8679e-03, -7.5142e-04,  8.9158e-04, -5.1156e-04, -1.4807e-04,\n",
       "            -1.3012e-03, -1.4636e-03, -6.4586e-04, -1.1426e-03,  1.5744e-04,\n",
       "            -7.6656e-04, -1.2260e-03, -1.6046e-03, -5.7299e-04,  6.5295e-04,\n",
       "            -1.6676e-03,  1.7002e-03, -1.8148e-03, -1.5715e-03, -2.7584e-04,\n",
       "             2.0679e-03,  1.5174e-03, -8.2349e-04,  2.0955e-03, -1.3382e-03,\n",
       "            -8.3334e-04, -7.9930e-04,  1.1802e-03, -6.7732e-04, -1.6513e-03,\n",
       "             1.2234e-03,  1.6238e-03, -1.8241e-03, -5.1191e-04,  3.4227e-04,\n",
       "            -1.2552e-03], device='cuda:0')},\n",
       "   108: {'momentum_buffer': tensor([[[[-4.2479e-05]],\n",
       "    \n",
       "             [[ 4.8692e-05]],\n",
       "    \n",
       "             [[ 8.1510e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.7500e-05]],\n",
       "    \n",
       "             [[-5.1451e-05]],\n",
       "    \n",
       "             [[ 9.1237e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.4862e-04]],\n",
       "    \n",
       "             [[-2.5101e-04]],\n",
       "    \n",
       "             [[ 1.5532e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.6357e-04]],\n",
       "    \n",
       "             [[ 1.2946e-04]],\n",
       "    \n",
       "             [[-1.1581e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.6721e-04]],\n",
       "    \n",
       "             [[-5.5645e-05]],\n",
       "    \n",
       "             [[-2.6607e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.7953e-05]],\n",
       "    \n",
       "             [[ 4.1681e-04]],\n",
       "    \n",
       "             [[ 2.6354e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-2.2230e-04]],\n",
       "    \n",
       "             [[-5.0216e-05]],\n",
       "    \n",
       "             [[-3.6368e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.1869e-04]],\n",
       "    \n",
       "             [[-3.3651e-04]],\n",
       "    \n",
       "             [[ 1.1880e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.7296e-04]],\n",
       "    \n",
       "             [[-2.1051e-05]],\n",
       "    \n",
       "             [[-2.5919e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.2595e-05]],\n",
       "    \n",
       "             [[-5.4464e-06]],\n",
       "    \n",
       "             [[ 7.6183e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.1365e-05]],\n",
       "    \n",
       "             [[ 7.2160e-05]],\n",
       "    \n",
       "             [[ 9.1944e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.4469e-04]],\n",
       "    \n",
       "             [[-2.0277e-04]],\n",
       "    \n",
       "             [[ 2.8317e-04]]]], device='cuda:0')},\n",
       "   109: {'momentum_buffer': tensor([0.0008, 0.0008, 0.0005,  ..., 0.0012, 0.0009, 0.0004], device='cuda:0')},\n",
       "   110: {'momentum_buffer': tensor([-0.0008, -0.0010, -0.0006,  ..., -0.0006, -0.0003, -0.0001],\n",
       "           device='cuda:0')},\n",
       "   111: {'momentum_buffer': tensor([[[[-1.5443e-04]],\n",
       "    \n",
       "             [[-4.9306e-05]],\n",
       "    \n",
       "             [[-3.0610e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.0294e-05]],\n",
       "    \n",
       "             [[-1.9059e-04]],\n",
       "    \n",
       "             [[ 2.9956e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.0347e-05]],\n",
       "    \n",
       "             [[-1.4731e-04]],\n",
       "    \n",
       "             [[ 3.0114e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.4742e-04]],\n",
       "    \n",
       "             [[ 5.2721e-04]],\n",
       "    \n",
       "             [[-5.6622e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.9091e-05]],\n",
       "    \n",
       "             [[-6.2000e-05]],\n",
       "    \n",
       "             [[ 1.5346e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.0143e-04]],\n",
       "    \n",
       "             [[-7.5434e-05]],\n",
       "    \n",
       "             [[-2.2167e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-1.1054e-04]],\n",
       "    \n",
       "             [[ 1.0081e-04]],\n",
       "    \n",
       "             [[ 3.9284e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.4057e-05]],\n",
       "    \n",
       "             [[-6.8671e-04]],\n",
       "    \n",
       "             [[ 5.4001e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.0376e-04]],\n",
       "    \n",
       "             [[-2.6755e-04]],\n",
       "    \n",
       "             [[-2.3415e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.8571e-04]],\n",
       "    \n",
       "             [[-3.6464e-04]],\n",
       "    \n",
       "             [[ 1.6589e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.6583e-04]],\n",
       "    \n",
       "             [[ 7.3619e-05]],\n",
       "    \n",
       "             [[-6.3689e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.1865e-04]],\n",
       "    \n",
       "             [[-4.7355e-04]],\n",
       "    \n",
       "             [[-7.4869e-05]]]], device='cuda:0')},\n",
       "   112: {'momentum_buffer': tensor([ 1.1758e-03,  1.8180e-03,  1.5165e-03,  1.8393e-03,  1.6949e-03,\n",
       "             1.0493e-03,  2.3076e-03,  1.3834e-03,  5.7636e-05,  1.0553e-03,\n",
       "             1.3861e-03,  2.8629e-03, -7.7780e-05,  9.5661e-04,  1.8369e-03,\n",
       "             1.1536e-03,  2.5024e-03, -4.1216e-04,  1.2775e-03,  8.3897e-04,\n",
       "             1.3626e-03,  1.9210e-03,  1.4067e-03,  8.7177e-04,  1.4807e-03,\n",
       "             1.4455e-03,  1.8665e-03,  1.1231e-03,  2.0353e-03,  1.6234e-03,\n",
       "             9.3249e-04,  3.2578e-04,  9.4472e-04,  2.5315e-03,  8.3493e-04,\n",
       "             1.9773e-03,  1.0182e-03,  6.7937e-04,  7.5090e-04,  5.8571e-04,\n",
       "             1.1802e-03,  1.4734e-03,  9.7342e-04,  1.2085e-03,  1.3878e-03,\n",
       "             1.9554e-03,  1.9793e-03,  1.3806e-03,  1.7908e-03,  2.4489e-03,\n",
       "             1.3773e-03,  1.8107e-03,  3.5848e-04,  2.2361e-03,  1.8434e-03,\n",
       "             1.9326e-03,  1.4865e-03,  4.9075e-04,  2.2350e-03,  6.0236e-05,\n",
       "             9.7629e-04,  1.5576e-03,  3.7588e-04,  1.0131e-03,  1.9648e-03,\n",
       "             1.8293e-03,  1.3706e-03,  9.1066e-04,  1.5724e-03,  1.2808e-03,\n",
       "             9.8137e-04,  1.1980e-03,  4.8325e-04,  2.0407e-04,  3.0182e-03,\n",
       "             1.7965e-03,  1.2322e-03,  9.3887e-04,  1.3819e-03, -6.4428e-04,\n",
       "             1.8495e-03,  1.5005e-03,  1.2813e-03,  1.3817e-03,  9.3991e-04,\n",
       "             1.3970e-03,  3.4588e-04,  9.0035e-04,  2.1304e-03,  1.7493e-03,\n",
       "            -6.8507e-04,  1.3987e-03,  1.8560e-03,  1.6575e-03,  1.7992e-03,\n",
       "             4.7462e-04,  3.5300e-04,  1.6283e-03,  1.8268e-03,  2.6186e-03,\n",
       "             2.3172e-03,  1.6440e-03,  1.1366e-03,  1.8886e-03,  2.7350e-03,\n",
       "             1.3794e-03,  5.4416e-04,  1.8953e-03,  2.0789e-03,  7.3967e-04,\n",
       "             1.4037e-03,  8.1889e-04,  1.4785e-03,  1.1640e-03,  1.8279e-03,\n",
       "             1.7453e-03,  1.7604e-03,  1.3373e-03,  9.4804e-04,  2.4821e-04,\n",
       "             5.8289e-04,  1.3917e-03,  1.6119e-03,  1.7225e-03,  1.2900e-03,\n",
       "             1.5227e-03,  2.5897e-03,  2.0542e-03, -4.4446e-04,  6.2409e-04,\n",
       "             1.6885e-03,  8.1358e-04,  1.5380e-03,  1.3070e-03,  6.3752e-04,\n",
       "             2.5078e-03,  1.8810e-03,  2.2895e-03,  1.6392e-03,  1.6254e-03,\n",
       "             1.8665e-03,  1.1517e-03,  1.0971e-03,  9.3057e-04,  1.4360e-03,\n",
       "             1.2961e-03,  1.4354e-03,  1.9313e-04,  2.1133e-03,  1.3991e-03,\n",
       "             1.6848e-03,  1.3934e-03,  1.1331e-03,  1.3234e-03,  4.7309e-04,\n",
       "             1.5525e-03,  4.7189e-04,  1.6101e-03,  5.2295e-04,  5.0262e-04,\n",
       "             1.3677e-03,  2.1336e-03,  7.6906e-04,  7.0663e-04,  3.8225e-04,\n",
       "             2.0214e-03,  1.3426e-03,  1.3036e-03,  1.9261e-03,  1.7208e-03,\n",
       "             2.0434e-03,  1.9832e-03, -6.3483e-06,  9.8178e-04,  5.6519e-04,\n",
       "             1.1764e-03,  1.7772e-03,  1.5441e-03,  1.3487e-03,  1.6377e-03,\n",
       "             1.6699e-03,  1.9763e-03,  2.1164e-03,  2.3516e-03,  5.8260e-04,\n",
       "             1.4953e-03,  8.6358e-04,  2.3997e-03,  9.7762e-04,  2.5885e-03,\n",
       "             1.1222e-03,  1.4677e-03,  2.0092e-03,  1.0590e-03,  1.8387e-03,\n",
       "             1.7199e-03,  3.8120e-04,  7.7000e-05,  1.9881e-03,  5.6657e-04,\n",
       "             1.3493e-03,  1.0767e-03,  1.5548e-03,  2.6298e-03,  1.1088e-03,\n",
       "             1.7396e-03,  1.3988e-03,  1.4855e-03,  1.8867e-03,  1.6075e-03,\n",
       "             1.2093e-03,  1.7122e-03,  2.0270e-03,  2.2006e-03,  1.1070e-03,\n",
       "             4.0488e-03,  1.1766e-03,  1.6396e-03,  1.3312e-03,  2.2159e-03,\n",
       "             1.9883e-03,  2.9221e-03,  7.5707e-04,  1.9849e-03,  1.9602e-03,\n",
       "             1.2523e-03,  1.0100e-03,  1.7663e-03,  7.8922e-04,  1.5207e-03,\n",
       "             2.7383e-03,  2.2178e-03,  1.5324e-03,  1.2754e-03,  2.6933e-03,\n",
       "             1.7926e-03, -8.5018e-04,  6.2528e-04,  1.5930e-03,  1.4718e-03,\n",
       "             3.9581e-03,  1.8127e-03,  6.5508e-04,  1.4581e-03,  1.3768e-03,\n",
       "             1.0457e-03,  6.5318e-04,  2.1950e-03,  5.0555e-04,  6.7818e-04,\n",
       "             9.8780e-04,  1.7544e-03,  1.7924e-03,  1.3863e-03,  2.8221e-04,\n",
       "             1.6043e-03], device='cuda:0')},\n",
       "   113: {'momentum_buffer': tensor([ 8.9035e-04, -5.9277e-04, -1.5755e-03, -3.7077e-03, -1.4577e-03,\n",
       "            -2.3089e-03, -2.2869e-03, -2.4487e-03, -3.4947e-04, -1.3837e-03,\n",
       "            -7.9660e-04, -1.6695e-03, -7.4400e-04, -9.8065e-04,  6.9841e-04,\n",
       "            -1.4859e-03, -3.7513e-03, -7.7288e-04, -4.5417e-04,  2.0142e-04,\n",
       "             5.2086e-04, -6.4072e-04, -1.2487e-03, -1.3629e-03, -1.4354e-03,\n",
       "            -2.1931e-03, -1.7274e-03, -1.2762e-03, -8.8791e-04, -2.1051e-03,\n",
       "            -2.3740e-03, -1.0578e-03,  1.7138e-05, -5.3954e-03, -1.4889e-03,\n",
       "            -1.9003e-03, -2.3335e-03, -1.9987e-03, -2.8563e-04, -7.3498e-04,\n",
       "            -1.2641e-03, -1.5285e-03, -2.4144e-03, -4.6778e-04, -7.0925e-04,\n",
       "            -3.0451e-04, -1.7994e-03, -1.1410e-03, -2.3045e-03, -9.2168e-04,\n",
       "            -4.0541e-03, -2.7964e-03, -6.0383e-04, -6.8003e-04, -4.4354e-04,\n",
       "            -6.5834e-04, -3.8343e-04, -2.7214e-03, -1.2330e-03, -2.2349e-03,\n",
       "            -3.3918e-05, -1.8135e-03, -1.8192e-03, -3.4126e-04, -2.5395e-03,\n",
       "            -2.2769e-03, -9.0042e-04, -2.5554e-03, -1.6311e-03, -1.0245e-03,\n",
       "            -1.7210e-03, -2.4394e-03, -1.0803e-03, -1.6095e-03, -4.2556e-03,\n",
       "            -1.5780e-03, -1.5210e-03,  1.0089e-03,  2.9200e-04, -5.7551e-04,\n",
       "            -2.3000e-03, -8.6231e-04, -5.6437e-07, -2.1478e-04, -6.1842e-04,\n",
       "            -1.7661e-03, -2.2038e-05, -7.7566e-04, -2.0534e-03, -3.6331e-03,\n",
       "            -1.3614e-03,  3.1794e-04, -6.3067e-04, -5.5238e-04, -1.5417e-03,\n",
       "            -3.4402e-03, -2.3093e-04,  6.9114e-04, -1.6398e-03,  1.1661e-03,\n",
       "            -2.4673e-03, -3.3757e-04, -3.2852e-04, -2.1795e-04,  1.2914e-03,\n",
       "            -2.1125e-03, -1.2888e-03, -8.6614e-04, -1.7530e-03, -8.1262e-04,\n",
       "            -1.5285e-03,  3.7453e-04, -3.0394e-04, -1.3603e-03, -2.0289e-03,\n",
       "            -2.4120e-03, -1.1118e-03, -2.2005e-03,  1.2845e-04, -7.1932e-04,\n",
       "             4.7059e-04, -1.1794e-03, -1.5717e-03, -1.5072e-03, -2.2043e-03,\n",
       "            -7.3459e-04, -1.2838e-03, -1.1798e-03, -7.4940e-04,  3.8387e-05,\n",
       "            -1.3961e-03, -1.2830e-03, -2.4622e-03, -1.7124e-03, -3.2715e-04,\n",
       "            -4.1542e-03, -6.2917e-04, -3.9004e-03, -3.2217e-03, -3.2931e-03,\n",
       "            -1.6321e-03, -1.3703e-03, -1.1398e-03, -9.9388e-04, -8.7416e-04,\n",
       "            -1.5727e-03, -2.2462e-03, -4.4547e-03, -1.3054e-03, -1.6905e-03,\n",
       "            -1.6907e-03, -2.2921e-03, -2.7456e-03, -1.7381e-03, -1.1076e-03,\n",
       "            -1.3253e-03, -2.4491e-03, -1.1736e-03,  1.7278e-04, -1.3017e-03,\n",
       "            -1.0984e-03, -8.9571e-04, -1.4220e-03,  3.1137e-04, -8.3198e-05,\n",
       "            -1.3583e-03, -2.1090e-03, -1.1586e-03,  9.7034e-04, -2.4911e-03,\n",
       "            -5.6819e-04, -1.9586e-03, -2.4512e-04, -1.4642e-03,  5.7049e-04,\n",
       "            -1.0181e-03, -8.7272e-04, -5.5860e-04, -1.5015e-04,  2.0993e-04,\n",
       "            -2.0876e-03,  1.9272e-04, -1.6095e-03, -2.7219e-03, -1.2966e-03,\n",
       "            -3.5951e-03, -2.9037e-04, -2.0724e-03, -1.6255e-03, -2.9029e-03,\n",
       "            -3.6312e-03, -1.8515e-03, -6.4156e-04, -4.8805e-04,  4.2740e-04,\n",
       "            -1.0470e-03, -3.5767e-04,  1.4397e-03, -4.1143e-03, -1.1141e-03,\n",
       "            -1.7487e-03, -2.0788e-04, -1.7800e-03, -3.4200e-03, -1.7373e-03,\n",
       "            -1.3900e-03, -9.6737e-04, -1.3878e-03, -2.8556e-03, -1.7812e-03,\n",
       "             4.5609e-05, -1.7098e-03, -2.0308e-03,  6.0154e-04, -1.5322e-03,\n",
       "            -3.5987e-03, -1.2009e-03, -5.5303e-04, -1.3435e-03,  4.9738e-04,\n",
       "            -1.4764e-03,  4.4099e-04, -8.9585e-04, -1.0431e-03,  1.0439e-03,\n",
       "            -1.3975e-03, -5.5806e-04, -9.7034e-04, -8.8199e-05, -4.9494e-04,\n",
       "            -1.0891e-03, -7.6491e-04, -1.4989e-03,  8.6765e-04, -1.1210e-03,\n",
       "            -1.7010e-03,  7.6948e-04,  8.4309e-04, -2.6699e-03, -4.9340e-04,\n",
       "            -2.7415e-03, -1.4381e-03,  3.9854e-04, -3.1506e-04, -1.0789e-03,\n",
       "            -1.7618e-03, -6.4825e-04, -3.3125e-04, -2.7497e-03, -6.2349e-04,\n",
       "            -2.5366e-03, -1.6727e-03, -1.4190e-03, -1.8362e-03, -1.3432e-03,\n",
       "            -1.8085e-03], device='cuda:0')},\n",
       "   114: {'momentum_buffer': tensor([[[[ 2.3916e-04,  4.2297e-04,  3.3484e-04],\n",
       "              [-1.8746e-05,  5.6452e-04,  4.5428e-04],\n",
       "              [ 1.5127e-04,  4.0644e-04,  3.1995e-04]],\n",
       "    \n",
       "             [[-3.7158e-05,  3.6941e-05, -4.6126e-05],\n",
       "              [ 2.1201e-04,  8.2771e-05,  4.7442e-05],\n",
       "              [ 1.7742e-04,  2.2136e-04,  9.1770e-05]],\n",
       "    \n",
       "             [[ 3.0103e-05,  1.9560e-04,  1.0381e-04],\n",
       "              [ 6.5845e-05, -6.8998e-05,  1.3877e-04],\n",
       "              [-1.7797e-04,  2.7789e-05,  1.4639e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.1956e-04, -1.1210e-04,  2.4120e-05],\n",
       "              [-6.9969e-04, -1.5514e-04, -4.6071e-06],\n",
       "              [-5.9656e-04, -4.1773e-04, -3.5808e-05]],\n",
       "    \n",
       "             [[ 2.9353e-04,  5.1822e-04,  7.4357e-04],\n",
       "              [ 6.3993e-04,  5.2451e-04,  6.7847e-04],\n",
       "              [ 2.7480e-04,  6.3276e-04,  5.4210e-04]],\n",
       "    \n",
       "             [[-8.6248e-04, -4.2513e-04, -4.4861e-05],\n",
       "              [-4.7555e-04, -4.8595e-04, -4.2883e-05],\n",
       "              [-5.1855e-04, -1.3892e-04, -8.4423e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.2149e-05, -9.1075e-05, -3.4053e-06],\n",
       "              [ 6.4624e-05, -2.9796e-05,  1.7134e-05],\n",
       "              [ 1.3013e-04, -3.8704e-05,  1.4130e-05]],\n",
       "    \n",
       "             [[-8.8480e-06, -1.5792e-05,  7.9284e-06],\n",
       "              [ 1.8405e-06, -1.3881e-05, -3.4965e-05],\n",
       "              [-4.0245e-06, -1.2055e-05, -2.1533e-05]],\n",
       "    \n",
       "             [[-6.8482e-05, -5.4352e-04, -4.3003e-07],\n",
       "              [ 2.8839e-04, -1.8545e-04,  2.8653e-05],\n",
       "              [-3.4133e-05,  3.2212e-05,  6.1271e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.9444e-05,  5.4892e-05,  4.9975e-05],\n",
       "              [ 2.0781e-05,  1.6038e-05,  4.0013e-05],\n",
       "              [-3.3813e-06,  4.2610e-06,  2.7854e-05]],\n",
       "    \n",
       "             [[ 1.5299e-05,  4.2005e-05, -4.8123e-06],\n",
       "              [ 3.5347e-05,  3.4658e-05,  8.2454e-06],\n",
       "              [-4.0972e-06,  4.1033e-05,  6.5101e-05]],\n",
       "    \n",
       "             [[ 4.5869e-06,  4.6442e-06,  3.6222e-05],\n",
       "              [-1.2177e-05,  2.4509e-05,  7.8716e-06],\n",
       "              [ 5.6426e-05, -6.8589e-06, -5.4127e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-9.2359e-05, -1.5294e-04, -1.8135e-04],\n",
       "              [ 2.7717e-05, -3.1255e-04, -3.1595e-04],\n",
       "              [ 1.0574e-04, -9.9621e-05, -7.6541e-05]],\n",
       "    \n",
       "             [[ 1.7488e-04, -6.7672e-06, -9.5933e-05],\n",
       "              [ 3.3580e-04,  1.4965e-04,  2.1889e-05],\n",
       "              [ 4.2833e-04,  2.6648e-04,  4.9726e-05]],\n",
       "    \n",
       "             [[ 3.5557e-05,  2.5933e-05,  2.6970e-05],\n",
       "              [ 1.0789e-04, -1.7516e-03, -1.7261e-04],\n",
       "              [-1.7873e-05, -4.0535e-05,  5.9792e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-7.1159e-05, -4.2697e-05, -3.9660e-05],\n",
       "              [-1.3888e-04, -6.5447e-05, -5.9934e-05],\n",
       "              [-6.9952e-05, -5.5151e-05, -9.4464e-05]],\n",
       "    \n",
       "             [[ 1.7809e-04,  3.0789e-04, -9.1891e-05],\n",
       "              [ 1.1909e-04,  5.1702e-04,  2.8297e-04],\n",
       "              [ 3.4951e-04,  2.9102e-04,  2.5223e-04]],\n",
       "    \n",
       "             [[-2.8212e-05,  1.7732e-05,  1.7460e-05],\n",
       "              [-4.6320e-05, -3.5675e-05, -5.3504e-05],\n",
       "              [ 3.2054e-05,  2.3555e-04,  1.4529e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.4008e-04, -4.1071e-04, -2.6048e-04],\n",
       "              [ 3.4499e-04, -5.3934e-05, -9.5646e-05],\n",
       "              [ 1.6111e-05, -1.6524e-04, -1.7673e-04]],\n",
       "    \n",
       "             [[-5.2764e-05,  2.6569e-05,  4.4378e-04],\n",
       "              [-3.5521e-05,  2.1504e-05,  1.9509e-04],\n",
       "              [-2.7069e-05, -1.1179e-04,  1.4948e-04]],\n",
       "    \n",
       "             [[ 3.0188e-05, -1.5083e-04,  9.6238e-05],\n",
       "              [-7.1786e-05, -3.3986e-04,  1.0535e-04],\n",
       "              [ 9.1622e-05, -1.2862e-04, -4.7953e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.7559e-05, -6.6796e-05,  1.6501e-04],\n",
       "              [-1.3655e-04, -3.1402e-04, -2.3114e-05],\n",
       "              [-3.6427e-04, -9.5617e-04, -6.4459e-04]],\n",
       "    \n",
       "             [[ 5.2793e-05, -3.1232e-04, -3.1748e-04],\n",
       "              [ 2.5181e-04, -7.3648e-05, -4.2650e-04],\n",
       "              [ 1.1616e-04, -3.2288e-04, -3.6133e-04]],\n",
       "    \n",
       "             [[-2.8288e-04, -4.2570e-04, -3.4674e-04],\n",
       "              [-7.4245e-05, -8.6107e-04, -3.9007e-04],\n",
       "              [ 1.5854e-04, -4.6557e-04, -2.6887e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.1335e-04, -4.7870e-04, -4.7487e-04],\n",
       "              [-2.5328e-04, -5.7590e-04, -5.2377e-04],\n",
       "              [-3.4187e-04, -2.3905e-04, -5.2144e-04]],\n",
       "    \n",
       "             [[-1.0777e-03, -3.6644e-04, -1.7884e-05],\n",
       "              [-7.1265e-04, -2.0418e-04,  1.3666e-04],\n",
       "              [-3.3473e-04, -1.9110e-04,  1.0610e-04]],\n",
       "    \n",
       "             [[ 5.0244e-05, -7.2051e-05,  6.1085e-05],\n",
       "              [ 1.2175e-04,  2.0376e-04,  4.2413e-04],\n",
       "              [ 1.1930e-04,  3.1227e-04,  3.7166e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.5508e-04,  1.9781e-05, -1.9073e-04],\n",
       "              [-2.5634e-04, -9.0952e-05, -6.9430e-05],\n",
       "              [ 1.2454e-04, -1.5666e-04,  1.0006e-04]],\n",
       "    \n",
       "             [[-3.4256e-04, -9.5276e-05, -2.4958e-04],\n",
       "              [ 6.1649e-05,  3.9561e-04, -5.6503e-05],\n",
       "              [-4.6348e-04,  1.1084e-04,  1.9655e-04]],\n",
       "    \n",
       "             [[ 1.4012e-04,  1.6303e-04, -4.0054e-04],\n",
       "              [ 5.2409e-04,  1.9528e-04, -4.3614e-04],\n",
       "              [ 5.9023e-04,  1.3943e-04, -3.5474e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.1342e-05, -6.8939e-05, -5.7066e-05],\n",
       "              [-3.1430e-05,  1.5640e-04, -5.3856e-05],\n",
       "              [-3.7469e-05,  2.0756e-04,  1.2677e-04]],\n",
       "    \n",
       "             [[ 9.0857e-05,  2.5078e-05, -1.5048e-04],\n",
       "              [ 1.5653e-04,  1.5800e-04,  3.5929e-05],\n",
       "              [ 1.6940e-04,  1.5953e-04,  2.0813e-05]],\n",
       "    \n",
       "             [[-9.3381e-05, -5.5868e-05,  2.2173e-05],\n",
       "              [-3.0489e-04, -2.1909e-05, -1.2097e-04],\n",
       "              [-1.1930e-04, -9.4523e-05, -1.8436e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.6162e-06, -8.6055e-05, -3.0523e-05],\n",
       "              [ 2.0057e-04, -8.3614e-05,  2.2505e-05],\n",
       "              [ 7.3437e-05,  1.0600e-04,  1.6727e-04]],\n",
       "    \n",
       "             [[-3.2728e-04, -5.8457e-05, -1.4468e-04],\n",
       "              [-4.1079e-04,  1.7946e-04,  1.5786e-04],\n",
       "              [-1.3546e-04, -5.7121e-05,  3.1996e-04]],\n",
       "    \n",
       "             [[ 2.2487e-04,  8.1886e-05,  1.3239e-04],\n",
       "              [ 1.3481e-04,  1.4516e-04,  1.7374e-04],\n",
       "              [ 6.3147e-05,  2.2783e-04,  1.0629e-04]]]], device='cuda:0')},\n",
       "   115: {'momentum_buffer': tensor([ 1.7596e-03,  2.6695e-03,  2.1376e-03,  1.8071e-03,  2.0306e-03,\n",
       "             1.3015e-03,  2.1267e-03,  1.5911e-03,  1.5929e-03,  1.5180e-03,\n",
       "             1.6466e-03,  8.7680e-04,  1.9383e-03,  1.3893e-03,  1.0994e-03,\n",
       "             9.4162e-04,  1.9005e-03,  1.4113e-03,  8.0028e-04,  1.7984e-03,\n",
       "             1.3602e-03,  2.3063e-03,  1.1001e-03,  1.6972e-03,  1.6489e-03,\n",
       "             2.1505e-03,  9.1411e-04,  1.7237e-03,  1.5191e-03,  1.6924e-03,\n",
       "             2.3071e-03,  1.1182e-03,  1.5958e-03,  2.0278e-03,  2.7616e-03,\n",
       "             1.6670e-03,  8.8116e-04,  2.0707e-03,  1.3126e-03,  2.1080e-03,\n",
       "             1.9203e-03,  1.1010e-03,  2.1079e-03,  9.5805e-04,  2.3504e-03,\n",
       "             1.9015e-03,  1.3710e-03,  1.3417e-03,  1.4333e-03,  1.6645e-03,\n",
       "             1.0115e-03,  8.8311e-04,  7.8837e-04,  7.5947e-04,  1.5407e-03,\n",
       "             2.4339e-03,  1.5691e-03,  1.6884e-03,  2.1701e-03,  2.3327e-03,\n",
       "             5.4679e-04,  1.6347e-03,  1.8083e-03,  1.3922e-03,  1.1180e-03,\n",
       "             2.2695e-03,  1.3191e-03,  1.9945e-03,  8.6178e-04,  2.6401e-03,\n",
       "             2.1231e-03,  2.2813e-03,  1.8332e-03,  2.2038e-03,  1.8867e-03,\n",
       "             1.5471e-03,  1.3180e-03,  1.8498e-03,  1.4374e-03,  1.0851e-03,\n",
       "             2.1803e-03,  1.9436e-03,  1.2480e-03,  1.4410e-03,  1.2673e-03,\n",
       "             1.7338e-03,  2.0275e-03,  1.9297e-03,  1.6781e-03,  1.0781e-03,\n",
       "             1.6886e-03,  1.8495e-03,  1.5033e-03,  2.4839e-03,  1.7330e-03,\n",
       "             9.2149e-04,  2.3067e-03,  1.7181e-03,  2.0484e-03,  9.1057e-04,\n",
       "             2.1596e-03,  8.1997e-04,  1.0508e-03,  1.2510e-03,  1.4291e-03,\n",
       "             1.9447e-03,  1.7115e-03,  1.7256e-03,  7.2704e-04,  1.4712e-03,\n",
       "             1.0846e-03,  1.3921e-03,  1.7090e-03,  8.5159e-04,  1.6667e-03,\n",
       "             8.9610e-04,  2.0644e-03,  1.2912e-03,  9.7864e-04,  2.0779e-03,\n",
       "             9.4740e-04,  1.8490e-03,  7.8650e-05,  2.0927e-03,  1.1884e-03,\n",
       "             1.4937e-03,  1.8135e-03,  2.4970e-03,  2.9132e-03,  1.0079e-03,\n",
       "             1.9107e-03, -2.6103e-05,  9.3473e-04,  1.5533e-03,  1.5504e-03,\n",
       "             1.8382e-03,  1.8598e-03,  1.3446e-03,  2.2236e-03,  1.8562e-03,\n",
       "             1.7705e-03,  2.3750e-03,  1.7508e-03,  8.5100e-04,  1.4655e-03,\n",
       "             1.7601e-03,  2.6129e-03,  9.3786e-04,  1.6308e-03,  1.4715e-03,\n",
       "             8.9903e-04,  2.1227e-03,  8.8100e-04,  1.9753e-03,  2.3668e-03,\n",
       "             1.8559e-03,  1.9779e-03,  4.4685e-04,  1.6264e-03,  2.0709e-03,\n",
       "             1.7251e-03,  1.1571e-03,  2.0854e-03,  1.9026e-03,  2.0366e-03,\n",
       "             1.6456e-03,  1.4860e-03,  9.7746e-04,  1.6196e-03,  1.7401e-03,\n",
       "             1.4603e-03,  1.8950e-03,  2.5365e-03,  1.6197e-03,  1.3250e-03,\n",
       "             1.7034e-03,  1.5917e-03,  9.2918e-04,  1.5671e-03,  2.0153e-03,\n",
       "             2.5387e-03,  1.2477e-03,  1.8200e-03,  2.7040e-03,  1.6377e-03,\n",
       "             7.9381e-04,  1.5537e-03,  1.7621e-03,  1.0216e-03,  1.4756e-03,\n",
       "             7.1414e-04,  1.5732e-03,  1.7079e-03,  1.0071e-03,  2.2916e-03,\n",
       "             3.6491e-04, -9.1161e-05,  7.3656e-04,  9.2711e-04,  2.0209e-03,\n",
       "             2.3065e-03,  1.3207e-03,  1.3678e-03,  7.2043e-04,  1.2881e-03,\n",
       "             1.9809e-03,  1.1540e-03,  1.9712e-03,  2.5866e-03,  1.6299e-03,\n",
       "             1.7861e-03,  1.4140e-03,  9.6669e-04,  1.6856e-03,  2.0895e-03,\n",
       "             1.8124e-03,  1.9466e-03,  2.2812e-03,  2.4677e-03,  1.8836e-03,\n",
       "             1.6433e-03,  1.5528e-03,  2.3196e-03,  1.3913e-03,  5.6811e-04,\n",
       "             1.1080e-03,  1.5044e-03,  2.3708e-03,  1.2267e-03,  3.0632e-03,\n",
       "             1.4717e-03,  6.0047e-04,  1.9338e-03,  1.5228e-03,  2.9741e-03,\n",
       "             1.3898e-03,  6.1921e-04,  1.5965e-03,  1.9834e-03,  1.5277e-03,\n",
       "             1.1307e-03,  2.2227e-03,  1.3671e-03,  2.5082e-03,  1.6185e-03,\n",
       "             1.3460e-03,  8.4477e-04,  1.8748e-03,  1.5337e-03,  2.5814e-03,\n",
       "             2.1129e-03,  1.1252e-03,  1.3184e-03,  1.5630e-03,  3.3629e-04,\n",
       "             1.6231e-03], device='cuda:0')},\n",
       "   116: {'momentum_buffer': tensor([-1.4568e-03, -1.2883e-03, -2.2084e-03, -1.7772e-03, -6.8018e-04,\n",
       "            -7.7237e-04, -1.7916e-03,  3.3486e-03,  7.5509e-04, -1.8594e-03,\n",
       "            -1.3783e-03, -1.9117e-03, -1.5394e-03,  3.0760e-04, -5.9583e-04,\n",
       "            -1.2188e-03, -1.3642e-03,  5.6640e-04, -5.7938e-04, -1.6520e-03,\n",
       "            -1.1863e-03, -8.8893e-04, -7.5954e-04, -1.5043e-03, -5.6092e-04,\n",
       "            -7.8368e-05, -1.1011e-04, -1.4393e-03, -2.4528e-03,  1.0149e-03,\n",
       "             3.4674e-04,  6.3576e-05, -8.2602e-04, -6.7063e-04, -2.3495e-03,\n",
       "            -2.1889e-03,  1.0929e-03, -1.0473e-03, -2.2975e-03, -1.9357e-03,\n",
       "            -1.0741e-03,  4.8333e-04, -1.5080e-03, -5.0967e-04, -9.9761e-04,\n",
       "            -8.4485e-04,  1.1166e-04, -1.1594e-03, -1.0536e-03, -1.8984e-03,\n",
       "            -1.3617e-03,  5.2280e-04, -1.4438e-03, -1.1825e-03, -1.9564e-03,\n",
       "            -1.3280e-03, -2.3298e-03, -2.4321e-03, -8.1675e-04, -1.1752e-03,\n",
       "             9.2495e-05, -2.6983e-03, -8.6090e-04, -6.8730e-04, -2.2949e-04,\n",
       "            -1.7090e-03, -1.7581e-03, -1.3185e-03, -1.2000e-03, -1.3237e-03,\n",
       "            -1.3222e-03, -2.0349e-03, -1.1061e-03, -5.2885e-04, -5.3320e-04,\n",
       "            -1.2197e-03, -1.4638e-03, -3.6686e-04, -2.4991e-04, -5.3345e-04,\n",
       "            -1.2437e-03, -1.8254e-03,  1.3446e-03, -2.9273e-03,  2.0206e-03,\n",
       "             6.3754e-04,  1.5969e-03, -1.3182e-03, -1.4416e-04, -2.0789e-03,\n",
       "            -1.9740e-03,  5.0002e-04, -1.3892e-03, -2.2907e-03, -3.6883e-04,\n",
       "            -1.4909e-03, -1.0448e-03, -1.1116e-03, -1.1975e-04,  1.5436e-05,\n",
       "            -8.2535e-04, -2.1248e-03, -1.2906e-03, -6.4171e-04, -4.8636e-04,\n",
       "            -1.1883e-03,  4.6159e-04, -1.6673e-03, -4.8605e-04, -1.1833e-03,\n",
       "            -1.1122e-03, -1.6696e-03,  2.3425e-04,  1.8255e-03, -8.6907e-04,\n",
       "             1.4634e-03,  1.6333e-04, -1.7555e-03,  1.2008e-03, -1.1817e-03,\n",
       "            -1.7343e-03, -1.2573e-03,  1.7781e-03, -2.0479e-03,  2.5651e-04,\n",
       "            -2.5427e-03, -1.8367e-03, -1.4622e-03,  4.9285e-04, -7.0691e-04,\n",
       "            -1.2284e-03,  9.0718e-04, -4.0430e-04, -1.2242e-03, -3.8231e-04,\n",
       "            -1.6387e-03, -5.5186e-04, -1.4492e-03, -1.6352e-03, -2.3105e-03,\n",
       "            -9.9474e-04, -5.2474e-04, -1.7734e-03,  3.3176e-04, -4.0822e-04,\n",
       "            -1.9333e-03, -2.0640e-03, -1.0242e-03, -1.0451e-03, -8.9385e-04,\n",
       "            -6.1049e-04, -2.0323e-03, -3.6332e-04, -1.5072e-03, -1.6401e-03,\n",
       "            -1.3465e-03, -1.1749e-03,  2.6095e-03, -1.1847e-03, -1.9769e-03,\n",
       "            -1.2753e-03, -1.4947e-03, -1.3258e-03, -6.4680e-04, -1.5004e-03,\n",
       "            -2.0825e-03, -9.4108e-04, -1.1627e-03, -1.1464e-03, -5.7851e-05,\n",
       "            -1.6254e-03,  1.2627e-05, -1.3179e-03, -8.2329e-04,  5.8228e-05,\n",
       "            -2.5117e-03,  2.1930e-03, -1.0284e-03, -2.5404e-03, -1.0759e-03,\n",
       "            -8.8857e-04, -1.4127e-03,  1.9514e-04, -8.2713e-04,  9.7280e-04,\n",
       "            -3.8556e-04, -1.2053e-03, -6.6289e-04,  3.2688e-04, -3.4010e-04,\n",
       "             5.7382e-04, -2.5097e-03, -1.1747e-03, -1.7630e-03, -1.3366e-03,\n",
       "            -2.5454e-03,  1.3050e-03, -9.0737e-04,  1.9102e-03, -9.2388e-04,\n",
       "             2.1793e-03,  4.3849e-04,  1.7964e-04, -1.8930e-03, -2.7325e-03,\n",
       "            -1.7000e-03, -1.7941e-03, -1.5462e-03, -2.5358e-03, -7.4748e-04,\n",
       "            -5.4495e-05, -1.8985e-03,  1.9723e-03, -1.5199e-03, -1.8092e-03,\n",
       "            -6.1065e-04, -7.9669e-04, -4.7800e-04, -1.6031e-03, -1.2739e-03,\n",
       "            -6.7067e-04, -6.9611e-04, -3.7697e-04, -1.9475e-03,  3.9642e-04,\n",
       "            -2.9865e-03, -1.4080e-03, -1.8690e-04,  3.4898e-04, -1.8683e-03,\n",
       "            -1.0356e-03,  4.9922e-04, -1.3099e-03, -1.7610e-03, -4.3514e-04,\n",
       "            -1.9106e-03,  1.3798e-03, -8.0142e-04, -1.2484e-03, -1.9024e-03,\n",
       "            -1.4556e-03, -1.9800e-03, -8.9819e-04, -1.7793e-03, -9.6664e-04,\n",
       "            -4.0175e-04, -4.2687e-04, -1.2927e-03, -1.4067e-03, -8.6993e-04,\n",
       "             1.8501e-04,  1.7534e-04, -6.2618e-07, -1.2829e-03,  1.0533e-03,\n",
       "            -1.3420e-03], device='cuda:0')},\n",
       "   117: {'momentum_buffer': tensor([[[[ 1.2736e-04]],\n",
       "    \n",
       "             [[ 1.5996e-04]],\n",
       "    \n",
       "             [[-3.6416e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.3294e-05]],\n",
       "    \n",
       "             [[-1.4813e-04]],\n",
       "    \n",
       "             [[-5.3981e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.9058e-04]],\n",
       "    \n",
       "             [[-4.3513e-04]],\n",
       "    \n",
       "             [[-2.2312e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.3663e-04]],\n",
       "    \n",
       "             [[ 5.7293e-05]],\n",
       "    \n",
       "             [[ 1.0910e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.6845e-04]],\n",
       "    \n",
       "             [[ 2.0223e-04]],\n",
       "    \n",
       "             [[ 1.3451e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.6521e-04]],\n",
       "    \n",
       "             [[-1.7221e-04]],\n",
       "    \n",
       "             [[ 1.9418e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-3.9122e-04]],\n",
       "    \n",
       "             [[ 4.7330e-05]],\n",
       "    \n",
       "             [[ 9.5882e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.4632e-04]],\n",
       "    \n",
       "             [[ 4.5756e-04]],\n",
       "    \n",
       "             [[-1.5130e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-5.8654e-04]],\n",
       "    \n",
       "             [[ 9.7998e-05]],\n",
       "    \n",
       "             [[-7.7914e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.8306e-04]],\n",
       "    \n",
       "             [[-2.0644e-04]],\n",
       "    \n",
       "             [[ 5.7672e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.5750e-04]],\n",
       "    \n",
       "             [[-3.6732e-05]],\n",
       "    \n",
       "             [[-4.8584e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.4629e-05]],\n",
       "    \n",
       "             [[-4.3248e-04]],\n",
       "    \n",
       "             [[ 8.9551e-06]]]], device='cuda:0')},\n",
       "   118: {'momentum_buffer': tensor([2.1750e-04, 3.1428e-04, 6.6724e-05,  ..., 9.6040e-04, 2.7188e-04,\n",
       "            1.1184e-03], device='cuda:0')},\n",
       "   119: {'momentum_buffer': tensor([-0.0003, -0.0005, -0.0003,  ..., -0.0005,  0.0005, -0.0021],\n",
       "           device='cuda:0')},\n",
       "   120: {'momentum_buffer': tensor([[[[ 6.7275e-05]],\n",
       "    \n",
       "             [[-8.3369e-05]],\n",
       "    \n",
       "             [[-2.3134e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.3356e-04]],\n",
       "    \n",
       "             [[-3.6450e-04]],\n",
       "    \n",
       "             [[ 8.8779e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-6.4757e-05]],\n",
       "    \n",
       "             [[ 5.5760e-05]],\n",
       "    \n",
       "             [[ 4.9725e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.9705e-05]],\n",
       "    \n",
       "             [[-8.7924e-05]],\n",
       "    \n",
       "             [[-2.5671e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.4705e-04]],\n",
       "    \n",
       "             [[-2.6863e-04]],\n",
       "    \n",
       "             [[-1.7423e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.1276e-04]],\n",
       "    \n",
       "             [[ 1.6889e-04]],\n",
       "    \n",
       "             [[ 9.0402e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.5254e-04]],\n",
       "    \n",
       "             [[ 1.4304e-04]],\n",
       "    \n",
       "             [[ 3.7592e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.2809e-06]],\n",
       "    \n",
       "             [[-1.9051e-04]],\n",
       "    \n",
       "             [[-4.9758e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.3717e-05]],\n",
       "    \n",
       "             [[ 6.9555e-05]],\n",
       "    \n",
       "             [[-1.1191e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.8617e-04]],\n",
       "    \n",
       "             [[ 7.4725e-04]],\n",
       "    \n",
       "             [[-1.8394e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.4889e-04]],\n",
       "    \n",
       "             [[-7.9208e-05]],\n",
       "    \n",
       "             [[ 1.7571e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.5471e-05]],\n",
       "    \n",
       "             [[ 9.5589e-05]],\n",
       "    \n",
       "             [[-7.6824e-05]]]], device='cuda:0')},\n",
       "   121: {'momentum_buffer': tensor([ 2.0521e-03,  1.4624e-03,  4.0559e-04,  8.4267e-04,  8.3260e-04,\n",
       "             6.3038e-04,  5.0052e-04,  2.9574e-04,  6.2741e-04,  2.2684e-03,\n",
       "             3.2833e-03,  5.2317e-04,  1.7820e-03, -2.8619e-04,  2.1439e-03,\n",
       "             2.2999e-03,  1.9393e-03,  1.5155e-03,  1.5182e-03,  1.2219e-03,\n",
       "             1.8759e-03,  1.0606e-03,  1.1995e-03,  1.4029e-03,  1.7872e-03,\n",
       "             1.1837e-03,  4.9854e-04,  1.4241e-03,  2.6431e-04,  2.7611e-03,\n",
       "             8.5971e-04,  9.3060e-04,  7.0769e-04,  4.1632e-05,  1.9918e-03,\n",
       "             1.7015e-03,  1.8577e-03,  1.6625e-03,  3.1646e-03,  4.1871e-04,\n",
       "             1.9015e-03,  1.9508e-03,  9.7538e-04,  1.2835e-03,  2.5780e-03,\n",
       "             1.7988e-03,  1.1595e-03,  2.8959e-03,  2.2765e-03,  2.0692e-03,\n",
       "             1.9779e-03,  2.3477e-03,  7.8768e-04,  1.4203e-03,  9.2283e-04,\n",
       "             1.5730e-03,  2.4810e-03,  8.6017e-04,  2.0000e-03,  2.1915e-03,\n",
       "             1.9169e-03,  1.5399e-03,  1.3849e-03,  2.0026e-03,  1.5218e-03,\n",
       "             1.6046e-03,  9.4911e-04,  5.0526e-04,  6.9265e-04,  7.3488e-04,\n",
       "             6.0994e-04,  1.3420e-03,  2.2108e-03,  2.3207e-03,  1.0860e-03,\n",
       "             3.0012e-03,  2.0469e-03,  2.2402e-03,  1.7793e-03,  1.4869e-03,\n",
       "             1.3851e-04,  1.0421e-03,  1.6433e-03,  1.6461e-03,  1.7214e-03,\n",
       "             9.4463e-04,  2.3960e-03,  2.2253e-03,  1.6260e-03,  1.2894e-03,\n",
       "             5.2776e-04,  1.7469e-03,  1.9746e-03,  2.5230e-03,  9.8901e-04,\n",
       "             8.2435e-04,  2.4191e-03, -7.8455e-04,  1.1906e-03,  2.4997e-03,\n",
       "             2.3923e-03,  1.6370e-03,  1.3475e-03,  1.5476e-03,  2.0880e-03,\n",
       "             2.5544e-03,  1.7661e-03,  1.3729e-04,  5.6969e-04, -9.2169e-05,\n",
       "             5.5752e-04,  1.1383e-03,  1.6493e-03,  2.4460e-03,  1.8448e-03,\n",
       "             1.3864e-03,  2.1816e-03,  2.3946e-03,  6.6520e-04,  1.4961e-03,\n",
       "             1.0948e-03,  1.9260e-03,  1.5650e-03,  1.9861e-03,  1.9280e-03,\n",
       "             1.7893e-03,  2.0801e-03,  2.4698e-03,  2.2014e-03,  5.2084e-04,\n",
       "             2.2335e-03,  1.0796e-03,  1.7535e-03,  1.7537e-03,  2.3108e-03,\n",
       "             1.6594e-03,  1.6481e-03,  1.6641e-03,  4.5229e-04,  1.3775e-03,\n",
       "             1.9693e-03,  1.0566e-03,  2.2190e-04,  1.1709e-03,  1.4866e-03,\n",
       "             2.4987e-03,  8.2329e-04,  1.0898e-03,  1.9489e-03,  1.5017e-03,\n",
       "             1.0449e-03,  1.5825e-03,  9.3799e-04,  8.1406e-04,  2.9369e-03,\n",
       "             1.8415e-03,  1.1515e-03,  1.9053e-03,  1.8222e-03,  2.2863e-03,\n",
       "             1.8561e-03,  8.4802e-04,  3.7635e-04,  1.1467e-03,  2.0761e-03,\n",
       "             1.0443e-03,  2.8985e-03,  2.4360e-03,  1.9560e-03,  2.1342e-03,\n",
       "             7.8394e-04,  1.5474e-03,  1.3264e-03,  4.6106e-03,  2.2928e-03,\n",
       "             1.4764e-03,  1.4336e-03,  1.6553e-03,  1.7235e-03,  2.5697e-03,\n",
       "             7.4366e-04,  2.9001e-03, -3.6527e-04,  2.1247e-03,  1.0440e-03,\n",
       "             2.1092e-03,  6.8618e-04,  1.4856e-03,  1.1610e-03,  1.3009e-03,\n",
       "             9.0247e-04,  2.7280e-03,  1.8895e-03,  1.9964e-03,  1.5744e-03,\n",
       "             1.1954e-03,  9.3416e-04,  1.3857e-03,  1.2800e-03,  2.1499e-03,\n",
       "             2.1769e-03,  2.3780e-03,  1.3815e-03, -2.1486e-04,  2.3166e-03,\n",
       "             1.7097e-03,  1.5385e-03,  7.9927e-04,  2.0023e-03,  1.3094e-03,\n",
       "             8.0329e-04,  1.7856e-03,  1.3271e-03,  1.8389e-03,  1.7302e-03,\n",
       "             1.3855e-03,  1.6365e-03,  1.4261e-03,  1.9838e-03,  1.4410e-03,\n",
       "             1.3344e-03,  2.0658e-03,  1.5472e-03,  5.5222e-04,  6.8548e-04,\n",
       "             1.7383e-03,  1.4111e-03,  1.5657e-03,  4.3335e-04,  2.6321e-03,\n",
       "             1.2734e-03,  1.7195e-03,  1.8288e-03,  8.8018e-04,  2.0897e-03,\n",
       "             2.8192e-03,  1.2824e-03,  1.9867e-03,  1.4682e-03,  1.3310e-03,\n",
       "             1.0767e-03,  7.5452e-04,  6.1434e-04,  1.8920e-03,  2.9632e-03,\n",
       "             1.7007e-03,  1.0926e-03,  1.2050e-03,  1.5757e-03,  5.7179e-04,\n",
       "             2.4809e-03,  1.7412e-03,  5.7710e-04,  1.3982e-03,  1.4102e-03,\n",
       "             2.7289e-03], device='cuda:0')},\n",
       "   122: {'momentum_buffer': tensor([-6.6428e-04, -3.7051e-04, -5.0851e-04, -1.7521e-03, -1.4236e-03,\n",
       "             1.0890e-03, -3.5630e-04, -1.0774e-03, -1.8685e-03, -3.3668e-03,\n",
       "            -4.5505e-03, -5.9438e-04, -1.4380e-03,  2.9728e-04, -1.9815e-03,\n",
       "            -3.1609e-03, -1.3020e-03, -2.6197e-03, -1.8014e-03, -1.3355e-03,\n",
       "            -1.7130e-03, -3.4064e-04, -1.4702e-03, -1.4931e-03,  7.2417e-04,\n",
       "            -9.5550e-04, -5.9008e-04, -1.2398e-03, -9.9136e-04, -5.3385e-03,\n",
       "            -1.2980e-03, -1.6339e-04, -2.9422e-04, -1.4876e-03, -6.8846e-04,\n",
       "            -1.4523e-03, -6.4847e-04, -9.7884e-04, -2.8497e-03, -2.1357e-03,\n",
       "            -3.1488e-03, -1.9716e-03, -2.5229e-03,  1.0055e-03, -2.9353e-03,\n",
       "            -1.8807e-03, -1.7390e-03, -3.0249e-03, -1.0013e-03, -2.5417e-03,\n",
       "            -2.2292e-03, -8.8022e-04,  9.9039e-05, -1.4495e-04, -1.3043e-03,\n",
       "            -6.8388e-04, -9.1619e-04, -2.5391e-04, -1.5141e-03, -3.2291e-03,\n",
       "            -1.2361e-03, -1.8926e-03, -8.0331e-04, -1.0617e-03, -1.1095e-03,\n",
       "            -4.0233e-04, -3.3554e-04, -1.1964e-03, -2.0598e-03, -8.7152e-04,\n",
       "             7.1167e-04,  1.6426e-03, -3.4366e-03, -3.8178e-03, -2.9338e-03,\n",
       "            -1.1503e-03,  8.5568e-04, -2.4669e-03, -2.7030e-03, -1.3844e-04,\n",
       "            -1.0390e-03, -1.0552e-03, -2.4942e-03, -1.1550e-03, -8.5350e-04,\n",
       "            -1.8932e-03, -2.6581e-03, -1.5624e-03, -4.6890e-04, -1.7016e-03,\n",
       "            -3.3982e-04, -4.2497e-04, -1.1263e-03, -3.4046e-03, -1.9431e-03,\n",
       "            -2.5035e-03, -1.9958e-03, -2.9885e-04, -1.4702e-03, -2.3340e-03,\n",
       "            -1.1142e-03, -3.4636e-04, -1.6406e-03, -1.7687e-03, -4.8329e-04,\n",
       "            -2.6538e-03, -3.9150e-03, -1.5332e-03, -1.3590e-03, -1.3497e-03,\n",
       "             6.0372e-04, -3.1946e-04, -8.3525e-04, -2.2341e-03, -1.8973e-03,\n",
       "            -1.7771e-03, -3.7803e-03, -1.4381e-03, -9.8712e-04, -1.1156e-03,\n",
       "            -2.1552e-03,  4.3259e-04, -3.1172e-03,  1.4578e-05,  5.2489e-04,\n",
       "            -2.6121e-03, -2.0992e-03, -3.1567e-04, -3.0172e-03, -1.3453e-03,\n",
       "            -1.1650e-03,  3.9315e-05, -2.7398e-03, -1.3470e-03, -1.8898e-03,\n",
       "            -1.2530e-03, -1.4807e-03, -3.1174e-03, -1.3657e-04, -1.2423e-03,\n",
       "            -1.9263e-03, -7.6604e-04, -2.7718e-03,  4.2633e-04, -4.0858e-04,\n",
       "            -1.5429e-04, -1.3991e-03, -2.3149e-04, -2.7618e-03, -1.0864e-03,\n",
       "            -6.2076e-04,  7.8368e-04, -2.1446e-03, -9.5278e-04, -4.2908e-03,\n",
       "             4.8784e-04, -2.9643e-04, -7.6663e-04, -1.9045e-03, -7.4949e-04,\n",
       "            -4.6630e-03,  1.2041e-04, -1.0446e-03, -1.1087e-03, -4.7865e-04,\n",
       "            -1.9952e-03, -1.9206e-03, -2.7690e-03, -7.1287e-04, -2.5723e-03,\n",
       "            -2.6581e-03, -8.8577e-04, -1.1561e-03, -1.7159e-03, -5.3519e-04,\n",
       "            -1.4294e-03, -1.0755e-03, -4.9621e-04, -1.2418e-03, -2.7534e-03,\n",
       "            -9.2191e-04, -5.1820e-03, -1.2655e-03, -2.2609e-03, -1.5424e-03,\n",
       "            -2.7408e-03, -1.4004e-03, -4.4991e-04, -1.1757e-03, -1.7089e-04,\n",
       "            -3.6544e-03, -3.3220e-03, -1.1699e-03, -2.2200e-03, -2.4269e-03,\n",
       "            -1.2355e-03, -2.7952e-03, -1.5154e-03, -7.8297e-04, -1.4710e-03,\n",
       "            -1.4119e-03, -6.9743e-04, -2.2919e-03, -1.4756e-03, -2.2435e-03,\n",
       "            -1.6150e-03, -1.1265e-03, -1.8948e-03, -1.7562e-03, -1.7599e-03,\n",
       "            -2.5879e-04, -1.6174e-03, -2.5385e-03, -1.7922e-03, -1.8209e-03,\n",
       "            -6.8213e-05, -9.6337e-04, -7.1837e-04, -3.0954e-03, -9.8300e-04,\n",
       "            -7.7562e-04, -1.4224e-03, -1.9804e-03, -2.1043e-03, -2.1078e-03,\n",
       "            -5.7324e-04, -6.4906e-04, -1.6806e-03,  5.0454e-05, -2.4599e-03,\n",
       "            -2.4203e-03, -8.4967e-04, -1.0995e-03, -2.9261e-03, -2.1353e-03,\n",
       "            -4.8206e-03,  1.6977e-05, -1.7622e-03, -5.8614e-04, -8.7676e-04,\n",
       "            -2.2603e-03,  6.5470e-04, -1.3524e-03, -1.6671e-03, -5.7423e-04,\n",
       "            -1.5221e-03, -2.1681e-03, -2.0239e-03, -1.6233e-03, -2.7104e-03,\n",
       "            -3.5991e-03, -1.7829e-03, -1.0328e-03, -1.3853e-03, -3.6192e-04,\n",
       "            -2.5270e-03], device='cuda:0')},\n",
       "   123: {'momentum_buffer': tensor([[[[ 5.1755e-06,  1.6836e-04,  2.1793e-04],\n",
       "              [-7.2728e-05,  2.0818e-04,  1.6588e-05],\n",
       "              [ 7.4350e-05,  2.5352e-04,  9.8402e-05]],\n",
       "    \n",
       "             [[-9.3758e-05,  3.8428e-06, -2.4883e-05],\n",
       "              [-1.7621e-04, -1.0430e-04,  3.6778e-05],\n",
       "              [-9.3126e-05, -3.5968e-05, -7.9984e-05]],\n",
       "    \n",
       "             [[-1.6262e-06,  2.5499e-04,  5.6502e-04],\n",
       "              [-2.2788e-04,  8.3076e-06,  3.0952e-05],\n",
       "              [ 2.1260e-05,  1.6114e-04,  3.5725e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.4924e-05, -7.0345e-05,  3.6185e-05],\n",
       "              [-8.4143e-05,  8.2969e-07, -9.4048e-05],\n",
       "              [-3.1361e-04,  1.3429e-04, -2.2769e-04]],\n",
       "    \n",
       "             [[-3.0554e-04, -1.4043e-04,  9.1510e-05],\n",
       "              [-2.5466e-04,  6.8461e-05,  1.8741e-04],\n",
       "              [-2.2998e-04, -2.5067e-04,  1.0803e-06]],\n",
       "    \n",
       "             [[-1.6268e-04, -2.9879e-05,  1.0357e-04],\n",
       "              [-2.5448e-04, -2.6143e-04,  1.3301e-04],\n",
       "              [-3.0530e-04, -2.8949e-04,  5.6813e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.2615e-04, -1.4997e-04, -1.1725e-04],\n",
       "              [-1.5102e-04, -2.7276e-04, -2.5487e-04],\n",
       "              [-1.6254e-04, -2.0271e-04,  1.7876e-05]],\n",
       "    \n",
       "             [[ 1.0846e-04, -9.6476e-05, -1.7178e-04],\n",
       "              [ 1.4000e-04, -6.4465e-05, -7.5275e-05],\n",
       "              [-2.2401e-04,  1.9993e-05, -1.7129e-04]],\n",
       "    \n",
       "             [[ 4.6540e-05,  8.6023e-05,  5.6395e-06],\n",
       "              [-7.8243e-05,  8.8124e-04,  1.7221e-04],\n",
       "              [ 2.5446e-05,  2.5261e-04,  2.2002e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.0865e-04,  2.1918e-04,  2.1611e-04],\n",
       "              [-1.7390e-05, -5.7481e-05, -3.2992e-05],\n",
       "              [ 2.0972e-04, -2.0728e-04, -1.1934e-04]],\n",
       "    \n",
       "             [[-1.6515e-04,  9.5241e-05, -8.4866e-05],\n",
       "              [-5.1664e-05, -9.0780e-05, -2.1287e-04],\n",
       "              [-2.2285e-04, -2.0165e-04, -2.6386e-04]],\n",
       "    \n",
       "             [[-1.9940e-04, -1.1144e-04, -1.1236e-04],\n",
       "              [-3.3119e-05, -1.7985e-06,  1.5280e-04],\n",
       "              [-1.4681e-04, -1.7425e-05,  1.6216e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.4045e-04,  1.3405e-04,  1.3673e-04],\n",
       "              [ 8.4007e-05,  1.2187e-04, -2.0090e-05],\n",
       "              [ 1.5803e-04,  5.7030e-05, -5.7394e-05]],\n",
       "    \n",
       "             [[ 1.2940e-04,  1.7864e-04, -1.4476e-04],\n",
       "              [ 1.7536e-04,  1.6720e-04,  9.4111e-05],\n",
       "              [ 9.2862e-05, -8.8152e-06, -4.9482e-06]],\n",
       "    \n",
       "             [[ 6.8956e-05, -7.0090e-05, -3.7929e-05],\n",
       "              [ 1.6346e-04,  1.1728e-04, -1.1130e-04],\n",
       "              [ 3.6409e-05,  1.2857e-04, -1.7491e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.1229e-05,  1.2701e-04, -1.7287e-05],\n",
       "              [-1.4451e-04, -7.3296e-05, -4.7727e-05],\n",
       "              [-2.8331e-04, -9.8757e-05,  1.1885e-04]],\n",
       "    \n",
       "             [[-1.7402e-04, -1.5411e-04,  3.6614e-05],\n",
       "              [-3.4622e-04, -8.5081e-05,  6.8270e-05],\n",
       "              [-1.9317e-04, -1.1154e-04,  1.4271e-04]],\n",
       "    \n",
       "             [[-1.8684e-04, -1.8167e-04,  1.4438e-05],\n",
       "              [-2.5501e-04,  1.3369e-04, -1.3886e-04],\n",
       "              [-3.8106e-05, -5.3251e-05, -1.6144e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-1.5675e-04, -6.4472e-05, -5.4523e-05],\n",
       "              [ 4.1049e-05,  7.6230e-05, -1.1529e-04],\n",
       "              [ 6.4970e-05, -1.7240e-04, -1.8944e-04]],\n",
       "    \n",
       "             [[-1.4769e-04, -1.8536e-04, -3.1267e-05],\n",
       "              [-3.0816e-04, -3.7206e-05, -1.0194e-04],\n",
       "              [-2.0200e-04, -1.8776e-04, -1.3870e-04]],\n",
       "    \n",
       "             [[ 1.3065e-04,  1.3793e-04,  6.0276e-05],\n",
       "              [ 1.7009e-04, -5.0137e-05,  5.1826e-05],\n",
       "              [ 1.9875e-04,  6.9463e-05,  1.0401e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-8.2642e-05, -2.5837e-04,  1.1044e-04],\n",
       "              [-2.0687e-05, -4.4481e-05, -6.8188e-05],\n",
       "              [ 8.5246e-05,  3.0018e-04,  1.7820e-04]],\n",
       "    \n",
       "             [[-1.6048e-04,  1.1864e-04,  8.2246e-05],\n",
       "              [ 1.7337e-04,  1.2878e-04,  1.4942e-04],\n",
       "              [ 7.4298e-05,  2.0887e-04,  9.5568e-05]],\n",
       "    \n",
       "             [[-1.0253e-04,  1.5889e-05, -4.2938e-05],\n",
       "              [ 1.3512e-05,  4.1843e-05,  4.6808e-05],\n",
       "              [-8.8512e-05,  9.4792e-05,  2.3531e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.7735e-04,  7.7826e-05,  3.9069e-05],\n",
       "              [ 4.1972e-04, -3.3915e-05, -3.3641e-04],\n",
       "              [-1.0849e-04, -1.3969e-04, -1.2322e-04]],\n",
       "    \n",
       "             [[ 1.1572e-04,  6.3511e-05,  7.7206e-06],\n",
       "              [-3.1509e-05, -1.8775e-04, -1.5889e-04],\n",
       "              [-1.0376e-04, -2.6787e-04, -1.4498e-04]],\n",
       "    \n",
       "             [[ 3.3786e-06, -1.8914e-04, -3.9264e-04],\n",
       "              [-1.2939e-04, -5.8486e-05,  9.8563e-06],\n",
       "              [ 1.2321e-04,  2.5877e-04,  2.7631e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.7186e-05,  2.8841e-04,  3.7412e-04],\n",
       "              [ 1.9173e-04,  2.2388e-04,  1.9550e-04],\n",
       "              [-4.4773e-05,  1.4539e-04,  1.7798e-04]],\n",
       "    \n",
       "             [[ 3.9409e-04,  4.6203e-04,  2.0503e-04],\n",
       "              [ 4.0486e-04,  2.5606e-04,  3.8732e-04],\n",
       "              [ 2.8174e-04,  2.1787e-04,  2.6848e-04]],\n",
       "    \n",
       "             [[ 1.6773e-04, -1.2777e-05, -2.0756e-04],\n",
       "              [-1.5664e-04, -1.7065e-04,  1.0670e-05],\n",
       "              [-5.4235e-05,  1.0271e-05,  3.2463e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-9.7642e-05, -1.8894e-04, -1.7931e-04],\n",
       "              [ 6.6591e-05, -1.2044e-04, -1.8278e-04],\n",
       "              [-7.0094e-05, -1.4214e-04, -4.1875e-04]],\n",
       "    \n",
       "             [[ 1.9723e-04,  2.2044e-04,  5.2903e-04],\n",
       "              [ 2.9695e-04,  1.7882e-04,  1.4119e-04],\n",
       "              [ 2.3825e-04, -1.3815e-05,  1.6439e-05]],\n",
       "    \n",
       "             [[-4.7548e-05, -7.0689e-05,  2.0375e-04],\n",
       "              [ 1.0538e-04,  3.7712e-05,  1.3021e-04],\n",
       "              [-1.8237e-04,  4.6634e-05, -1.0768e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.9005e-06,  1.5634e-04, -4.9924e-05],\n",
       "              [ 6.0190e-06,  1.7511e-04, -1.5073e-04],\n",
       "              [-6.6113e-05,  2.5488e-04, -2.1416e-04]],\n",
       "    \n",
       "             [[ 3.5860e-04,  1.6912e-05,  1.3667e-04],\n",
       "              [ 3.6790e-04, -7.7209e-06, -2.3039e-06],\n",
       "              [ 3.3315e-04,  2.2890e-05, -1.6884e-04]],\n",
       "    \n",
       "             [[-1.3062e-04, -2.6760e-04,  3.0014e-05],\n",
       "              [-9.5649e-05, -2.5638e-04, -9.3268e-06],\n",
       "              [ 3.6460e-05,  2.4964e-04,  1.7752e-04]]]], device='cuda:0')},\n",
       "   124: {'momentum_buffer': tensor([ 3.1202e-03,  2.3824e-03,  1.4138e-03,  9.8932e-04,  1.6377e-03,\n",
       "             1.2727e-03,  6.2249e-04,  1.9138e-03,  1.3405e-03,  2.1869e-03,\n",
       "             1.5213e-03,  1.6544e-03,  1.0920e-03,  2.0169e-03,  1.9697e-03,\n",
       "             2.1559e-03,  1.2632e-03,  8.5689e-04,  1.6011e-03,  1.7791e-03,\n",
       "             5.9306e-04,  1.7218e-03,  1.6128e-03,  2.0442e-03,  1.4596e-03,\n",
       "             2.0349e-03,  1.7368e-03,  1.0586e-03,  5.9593e-04,  1.0084e-03,\n",
       "             9.7230e-04,  1.2568e-03,  3.0490e-04,  1.9462e-03,  2.1676e-03,\n",
       "             1.6751e-03,  5.8288e-03,  2.1780e-03,  1.3808e-03,  1.3401e-03,\n",
       "             2.0673e-03,  2.2995e-03,  2.2098e-03,  2.1414e-03,  7.1869e-04,\n",
       "             8.3730e-04,  1.3204e-03,  1.3683e-03, -1.8277e-04,  8.1883e-04,\n",
       "             6.0767e-04,  1.7736e-03,  1.5355e-03,  1.4766e-03,  2.6975e-03,\n",
       "             9.1474e-04,  1.4599e-03,  1.6899e-03,  6.7619e-04,  1.9236e-03,\n",
       "             1.5424e-03,  8.8760e-04,  2.3039e-03,  1.4906e-03,  3.1640e-04,\n",
       "             1.6086e-03,  1.9570e-03,  2.4330e-03,  2.3065e-03,  3.0095e-03,\n",
       "             2.3863e-03,  2.1484e-03,  8.9530e-04,  9.6509e-04,  1.7218e-03,\n",
       "             1.9651e-03,  1.3600e-03,  1.9342e-03,  1.8123e-03,  1.5006e-03,\n",
       "             1.0886e-03,  2.5195e-03,  1.6586e-03,  1.4442e-03,  1.7610e-03,\n",
       "             1.7430e-03,  1.3764e-03,  1.5657e-03,  1.5091e-03,  6.6991e-04,\n",
       "             2.8513e-03,  2.7741e-04,  1.3461e-03,  1.5274e-03,  1.6436e-03,\n",
       "             2.6638e-03,  2.0202e-03,  5.8920e-04,  1.3302e-03,  2.1057e-03,\n",
       "             8.8459e-04,  1.1409e-03,  2.1651e-03,  1.6504e-03,  1.1753e-03,\n",
       "             6.1182e-04,  2.3365e-03,  1.0119e-03,  1.5216e-03,  2.7538e-03,\n",
       "             1.2246e-03,  1.9990e-03,  2.0817e-03,  8.7118e-04,  2.0154e-03,\n",
       "             1.2350e-03,  1.6948e-03,  3.0191e-03,  1.5530e-03,  1.1604e-03,\n",
       "             1.3640e-03,  1.0565e-03,  9.4520e-04,  1.2977e-03,  1.3681e-03,\n",
       "             1.5204e-03,  1.9107e-03,  4.6201e-04,  2.0579e-03,  1.5446e-03,\n",
       "             1.3851e-03,  1.2218e-03,  1.7428e-03,  1.3793e-03,  1.2197e-03,\n",
       "             1.9029e-03,  2.1218e-03,  2.4813e-03,  1.7455e-03,  6.7346e-04,\n",
       "             1.0511e-03,  1.2727e-03,  1.8162e-03,  2.4186e-03,  1.0774e-03,\n",
       "             2.1691e-03,  1.5565e-03,  1.0812e-03,  2.0402e-03,  2.5388e-03,\n",
       "             7.9176e-04,  1.7545e-03,  2.3469e-03,  1.9301e-03,  1.3495e-03,\n",
       "             1.5602e-03,  1.6514e-03,  2.2095e-03,  1.5478e-03,  1.5163e-03,\n",
       "             1.2400e-03,  1.4402e-03,  2.8009e-03,  1.3344e-03,  1.8020e-03,\n",
       "             1.0959e-03,  2.6986e-03,  1.8677e-03,  1.5637e-03,  2.3819e-03,\n",
       "             1.7769e-03,  1.1720e-03,  2.0624e-03,  2.1082e-03,  1.8390e-03,\n",
       "             2.0566e-03,  8.8674e-04,  2.2532e-03,  1.4383e-03,  5.1847e-04,\n",
       "             9.9900e-04,  1.5907e-03,  1.7224e-03,  1.4187e-03,  1.5905e-03,\n",
       "             1.6329e-03,  1.0596e-03,  1.5698e-03,  2.0200e-03,  1.7670e-03,\n",
       "             4.4962e-04,  2.2254e-03,  1.3900e-03,  1.2017e-03,  2.3436e-03,\n",
       "             4.7582e-04,  1.8120e-03,  2.5028e-03,  2.1558e-03,  2.6885e-03,\n",
       "             2.1941e-03,  1.4810e-03,  1.8138e-03,  1.7861e-03,  8.0100e-04,\n",
       "             1.5748e-03,  1.6506e-03,  2.0221e-03,  1.6569e-03,  1.7905e-03,\n",
       "             1.9677e-03,  2.2136e-03,  1.6044e-03,  1.7186e-03,  1.6724e-03,\n",
       "             1.0473e-03,  1.2207e-03,  1.3073e-03,  1.8620e-03,  2.2868e-03,\n",
       "             1.8323e-03,  2.1026e-03,  1.3484e-03,  9.0859e-04,  1.8119e-03,\n",
       "             1.3507e-03,  1.3008e-03,  2.4354e-03,  1.4108e-03,  1.0882e-03,\n",
       "             1.0785e-03,  4.9324e-04,  1.0397e-03,  1.4118e-03,  1.5316e-03,\n",
       "             1.7966e-03,  2.7565e-03,  1.1979e-03,  2.2781e-03,  1.6429e-03,\n",
       "             1.6363e-03,  1.0944e-03,  1.2727e-03,  1.1519e-03,  1.0160e-03,\n",
       "             3.0305e-05,  1.4497e-03,  1.8954e-03,  2.2886e-05,  1.8190e-03,\n",
       "             8.6257e-04,  1.6390e-03,  2.2782e-03,  2.7079e-03,  7.1303e-04,\n",
       "             1.4714e-03], device='cuda:0')},\n",
       "   125: {'momentum_buffer': tensor([-1.4499e-03, -2.1912e-03, -1.4159e-03,  3.9237e-04,  6.8730e-04,\n",
       "            -4.2903e-04, -9.0011e-04, -1.8675e-03, -6.3780e-04, -1.4308e-03,\n",
       "             3.3613e-04, -7.6695e-04, -9.1628e-04, -3.6201e-04, -1.3697e-03,\n",
       "             8.6076e-06, -1.1235e-04, -1.1329e-03, -8.7277e-04,  1.4837e-04,\n",
       "            -9.5362e-04, -1.4278e-03, -2.6120e-03,  3.9530e-04, -1.4326e-03,\n",
       "            -1.3769e-03, -1.2650e-03, -9.3995e-04,  1.2373e-03, -7.6607e-04,\n",
       "            -9.5269e-05,  9.4021e-04, -3.5067e-03, -9.1745e-06, -1.3567e-03,\n",
       "             1.7643e-03, -2.4521e-03, -1.2809e-03, -8.4074e-04, -5.1741e-04,\n",
       "             5.0560e-04, -4.2867e-04, -2.5300e-03, -1.2233e-03, -3.2685e-04,\n",
       "            -1.0217e-03, -1.0099e-03, -1.6222e-03,  1.4695e-03, -5.1784e-04,\n",
       "            -4.4247e-04, -3.8268e-04, -3.8558e-04,  1.8555e-05, -1.0845e-03,\n",
       "             4.3023e-04,  6.1567e-04, -1.4410e-03, -1.5635e-03, -1.6088e-04,\n",
       "            -1.0791e-03, -6.9327e-04, -2.5088e-03, -5.4908e-04, -9.5903e-04,\n",
       "            -1.6996e-04, -1.2785e-03, -1.8129e-04, -1.1929e-03, -9.9578e-04,\n",
       "            -5.7593e-04,  4.8248e-04, -6.2401e-04,  3.0998e-05, -1.7183e-03,\n",
       "            -8.0209e-04,  3.6786e-04, -4.3803e-04, -4.1372e-04, -1.0043e-03,\n",
       "            -1.2567e-04, -2.2685e-03, -1.0487e-03, -6.1078e-04, -1.2976e-03,\n",
       "            -1.9968e-03, -1.2114e-03, -6.1540e-04, -8.4557e-04, -1.0690e-03,\n",
       "            -1.9256e-03, -1.2809e-03, -1.3395e-04, -9.1290e-04, -1.4500e-03,\n",
       "            -2.8818e-03, -1.6372e-03,  1.1466e-03, -1.0540e-03, -1.9799e-03,\n",
       "             4.6651e-04,  2.2750e-04, -2.5085e-03,  2.4444e-03,  4.8019e-04,\n",
       "            -9.7482e-04, -1.9171e-03, -5.3821e-04, -9.8424e-04, -8.1369e-04,\n",
       "            -2.1513e-04, -1.3609e-03, -3.2365e-04,  1.5598e-03, -1.1886e-03,\n",
       "            -1.0982e-04, -1.2570e-03, -2.0715e-03, -1.2219e-03, -2.1624e-04,\n",
       "            -2.3722e-03,  1.7300e-03, -3.3034e-04, -6.4313e-04, -1.1273e-03,\n",
       "             1.8045e-03, -9.6816e-04,  1.7146e-04, -6.1349e-04, -2.2992e-04,\n",
       "            -1.5318e-03,  3.4343e-04, -1.9445e-04,  2.2552e-03, -1.1707e-03,\n",
       "            -7.5271e-04, -1.5288e-03, -1.9714e-03, -1.5804e-03, -8.0359e-04,\n",
       "            -2.5216e-03, -6.2465e-04, -1.3641e-03, -1.8388e-03, -1.4678e-03,\n",
       "            -2.5196e-03, -2.1347e-03,  5.9884e-04,  7.2228e-04, -1.4233e-03,\n",
       "            -3.5641e-04, -5.9670e-04, -1.2665e-03,  5.3941e-05, -6.3625e-04,\n",
       "             7.7566e-04, -1.8162e-03, -6.3136e-04, -1.1833e-03, -8.0880e-04,\n",
       "            -1.4238e-03, -2.4763e-04, -1.2438e-03, -1.6670e-03, -1.1833e-03,\n",
       "            -1.2734e-03, -1.0623e-03, -2.5542e-03,  2.1078e-04, -1.3035e-03,\n",
       "            -8.3426e-04, -4.1593e-04, -1.0738e-03, -1.7815e-03, -8.5932e-04,\n",
       "            -2.5119e-03,  7.6045e-04, -8.5433e-06, -1.5452e-03, -1.2004e-03,\n",
       "             9.5722e-04, -8.8131e-04, -1.0310e-03, -5.5042e-04, -8.0319e-04,\n",
       "            -5.7765e-04,  2.0831e-03, -7.4508e-04, -3.3186e-03,  1.2974e-03,\n",
       "            -6.2911e-04, -1.0651e-03, -5.7100e-04, -2.1240e-03, -9.6964e-04,\n",
       "             2.4958e-03, -5.7079e-04, -6.3860e-04, -1.1154e-03,  7.3016e-04,\n",
       "             1.6737e-04, -4.9689e-04, -1.3181e-04, -9.0828e-04, -1.1414e-03,\n",
       "            -4.7316e-04, -4.7587e-04, -2.0522e-03, -1.0833e-03, -3.6719e-04,\n",
       "            -1.0150e-03, -1.2884e-03, -1.1004e-03, -1.7325e-03, -1.5198e-03,\n",
       "            -1.5053e-03, -6.4920e-04, -4.4325e-04, -2.0137e-03, -8.8304e-04,\n",
       "            -2.6592e-03, -1.5814e-03, -1.2262e-03,  2.0712e-03, -2.0147e-03,\n",
       "            -1.5018e-03,  3.7830e-05, -1.0246e-03, -1.9481e-04, -4.6020e-04,\n",
       "            -1.1113e-03, -1.1833e-03, -2.7840e-03, -9.0556e-04, -1.2927e-03,\n",
       "            -1.5897e-03, -1.3876e-03,  5.0490e-05, -9.6662e-04, -1.4906e-03,\n",
       "            -6.2836e-04, -2.0510e-03, -7.9648e-04, -1.9586e-03, -1.3788e-04,\n",
       "             9.1406e-04, -9.7302e-04, -1.5962e-03,  1.9747e-03, -5.8295e-04,\n",
       "             2.0193e-04, -5.4078e-04, -8.4219e-04, -1.5163e-03,  1.0713e-03,\n",
       "            -1.7967e-03], device='cuda:0')},\n",
       "   126: {'momentum_buffer': tensor([[[[ 6.2863e-05]],\n",
       "    \n",
       "             [[-2.7309e-04]],\n",
       "    \n",
       "             [[ 2.1574e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.8024e-05]],\n",
       "    \n",
       "             [[ 1.1375e-05]],\n",
       "    \n",
       "             [[ 2.6489e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.1925e-04]],\n",
       "    \n",
       "             [[-7.7735e-06]],\n",
       "    \n",
       "             [[ 5.2390e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.9599e-06]],\n",
       "    \n",
       "             [[ 1.3459e-04]],\n",
       "    \n",
       "             [[ 4.0322e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.0257e-04]],\n",
       "    \n",
       "             [[-3.4585e-05]],\n",
       "    \n",
       "             [[-3.0293e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.8016e-04]],\n",
       "    \n",
       "             [[-1.2890e-04]],\n",
       "    \n",
       "             [[ 1.2036e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 3.3130e-05]],\n",
       "    \n",
       "             [[-7.0096e-05]],\n",
       "    \n",
       "             [[-2.0409e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.8776e-05]],\n",
       "    \n",
       "             [[ 3.1539e-05]],\n",
       "    \n",
       "             [[ 4.1564e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.5743e-04]],\n",
       "    \n",
       "             [[ 1.2151e-04]],\n",
       "    \n",
       "             [[ 2.5296e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.3872e-05]],\n",
       "    \n",
       "             [[-1.2318e-04]],\n",
       "    \n",
       "             [[-4.3303e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.7144e-05]],\n",
       "    \n",
       "             [[ 1.1816e-04]],\n",
       "    \n",
       "             [[ 2.0956e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.6817e-04]],\n",
       "    \n",
       "             [[ 1.9570e-04]],\n",
       "    \n",
       "             [[-4.1888e-05]]]], device='cuda:0')},\n",
       "   127: {'momentum_buffer': tensor([ 5.8570e-05,  2.7860e-04, -1.9119e-04,  ...,  1.2786e-03,\n",
       "            -6.3940e-05,  9.6568e-04], device='cuda:0')},\n",
       "   128: {'momentum_buffer': tensor([-0.0005,  0.0003, -0.0010,  ...,  0.0006,  0.0001, -0.0008],\n",
       "           device='cuda:0')},\n",
       "   129: {'momentum_buffer': tensor([[[[ 2.6576e-05]],\n",
       "    \n",
       "             [[ 1.7099e-04]],\n",
       "    \n",
       "             [[-2.6764e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.4777e-04]],\n",
       "    \n",
       "             [[ 1.9462e-04]],\n",
       "    \n",
       "             [[-3.8162e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.8667e-04]],\n",
       "    \n",
       "             [[-4.3387e-04]],\n",
       "    \n",
       "             [[ 2.9250e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.3315e-04]],\n",
       "    \n",
       "             [[-5.6986e-04]],\n",
       "    \n",
       "             [[-4.6105e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-8.4040e-05]],\n",
       "    \n",
       "             [[ 1.2068e-05]],\n",
       "    \n",
       "             [[ 3.8031e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.8010e-06]],\n",
       "    \n",
       "             [[-2.1916e-04]],\n",
       "    \n",
       "             [[ 9.3042e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.6513e-04]],\n",
       "    \n",
       "             [[-6.0117e-05]],\n",
       "    \n",
       "             [[ 2.1156e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.3112e-04]],\n",
       "    \n",
       "             [[ 3.5814e-04]],\n",
       "    \n",
       "             [[ 2.0023e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 7.7340e-05]],\n",
       "    \n",
       "             [[-2.1283e-05]],\n",
       "    \n",
       "             [[-1.4991e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.3248e-04]],\n",
       "    \n",
       "             [[ 2.3287e-04]],\n",
       "    \n",
       "             [[-9.6827e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.6995e-05]],\n",
       "    \n",
       "             [[-2.7343e-04]],\n",
       "    \n",
       "             [[-2.3144e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.7146e-04]],\n",
       "    \n",
       "             [[ 8.4425e-04]],\n",
       "    \n",
       "             [[ 4.4797e-05]]]], device='cuda:0')},\n",
       "   130: {'momentum_buffer': tensor([ 2.2689e-03,  2.0181e-03,  1.5490e-03,  1.2298e-03,  2.2622e-03,\n",
       "             1.9863e-03, -9.3134e-04,  2.8959e-03,  1.9155e-03,  1.7155e-03,\n",
       "             2.0711e-03,  3.0586e-03,  1.6748e-03,  2.5462e-03,  1.2348e-03,\n",
       "             2.9940e-03,  1.7309e-03,  1.5300e-03,  1.3928e-03,  2.2100e-03,\n",
       "             1.9137e-03,  1.5749e-03,  2.3151e-03,  2.2088e-03,  2.6071e-03,\n",
       "             1.4854e-03,  3.0733e-03,  2.0623e-03,  1.8412e-03,  2.4761e-03,\n",
       "             4.0020e-03,  2.2163e-03,  1.5123e-03,  1.7020e-03,  1.7723e-03,\n",
       "             2.3893e-03,  2.3561e-03,  1.8983e-03,  2.2154e-03,  3.0760e-03,\n",
       "             2.0062e-03,  8.3614e-04,  1.4784e-03,  8.8186e-04,  9.0195e-04,\n",
       "             2.2183e-03,  2.9737e-03,  1.4594e-03,  5.9774e-04,  1.9196e-03,\n",
       "             2.7725e-03,  2.2632e-03,  1.4800e-03,  2.1932e-03,  2.5896e-03,\n",
       "             1.9655e-03,  1.5286e-03,  1.5742e-03,  1.8584e-03,  3.0244e-03,\n",
       "             1.8774e-03,  2.5184e-03,  1.3109e-03,  2.6680e-03,  2.4210e-03,\n",
       "             1.7028e-03,  2.1235e-03,  1.5385e-03,  1.6716e-03,  7.8561e-04,\n",
       "             1.3564e-03,  2.1052e-03,  2.6547e-03,  2.2873e-03,  2.1153e-03,\n",
       "             2.4355e-03,  1.9706e-03,  1.6142e-03,  1.6387e-03,  2.5109e-03,\n",
       "             1.8570e-03,  1.8318e-03,  3.0440e-03,  1.9048e-03,  2.1667e-03,\n",
       "             3.0210e-03,  2.7913e-03,  2.0079e-03,  6.3132e-05,  2.5064e-03,\n",
       "             2.3214e-03,  1.6021e-03,  1.8264e-03,  2.8528e-03,  2.0894e-03,\n",
       "             1.2088e-03,  1.7434e-03,  2.6640e-03,  2.1477e-03,  1.4225e-03,\n",
       "             2.3346e-03,  1.4030e-03,  3.6373e-05,  1.3590e-03,  2.2768e-03,\n",
       "             2.1932e-03,  1.9867e-03,  2.3856e-03,  2.1293e-03,  2.0564e-03,\n",
       "             1.6629e-03,  2.4026e-03,  9.9782e-04,  7.5880e-04,  2.2618e-03,\n",
       "             1.9704e-03,  2.9724e-03,  2.5297e-03,  2.1254e-03,  2.4969e-03,\n",
       "             2.0589e-03,  1.6222e-03,  2.8567e-03,  1.7630e-03,  2.3272e-03,\n",
       "             1.7170e-03,  3.5795e-03,  3.0951e-03,  1.7897e-03,  6.0908e-04,\n",
       "             1.5308e-03,  2.6277e-03,  2.7659e-03,  2.2606e-03,  1.7438e-03,\n",
       "             1.5138e-03,  2.3345e-03,  2.3904e-03,  2.7623e-03,  1.9491e-03,\n",
       "             2.9056e-03,  2.0024e-03,  2.1883e-03,  1.0260e-03,  2.1725e-03,\n",
       "             1.6250e-03,  1.3129e-03,  1.9377e-03,  3.3224e-03,  2.7542e-03,\n",
       "             1.2863e-03,  1.9986e-03,  2.5466e-03,  2.4931e-03,  2.6629e-03,\n",
       "             2.8195e-03,  1.7515e-03,  2.6490e-03,  1.9743e-03,  2.4773e-03,\n",
       "             2.0880e-03,  2.1200e-03,  2.0406e-03,  5.6093e-04,  2.1433e-03,\n",
       "             3.2938e-03,  1.7568e-03,  2.6888e-03,  9.1195e-04,  1.3520e-03,\n",
       "             2.9780e-03,  2.1605e-03,  1.5773e-03,  2.0243e-03,  2.1420e-03,\n",
       "             2.1602e-03,  2.5406e-03,  3.0591e-03,  1.6525e-03,  2.1680e-03,\n",
       "             1.9995e-03,  2.3799e-03,  1.9096e-03,  3.5959e-03,  1.9597e-03,\n",
       "             1.7389e-03,  2.4053e-03,  3.0543e-03,  2.0179e-03,  2.3017e-03,\n",
       "             2.7962e-03,  2.5716e-03,  1.6264e-03,  1.9812e-03,  1.9121e-03,\n",
       "             2.2942e-03,  3.0005e-03,  2.5997e-03,  2.7795e-03,  1.9679e-03,\n",
       "             4.3728e-04,  1.5147e-03,  3.8193e-03,  3.0397e-03,  2.1284e-03,\n",
       "             1.8780e-03,  1.2313e-03,  2.3319e-03,  1.1208e-03,  1.9615e-03,\n",
       "             1.8364e-03,  1.2805e-03,  2.4935e-03,  1.7700e-03,  2.5598e-03,\n",
       "             1.9292e-03,  1.8081e-03,  3.0285e-03,  3.5981e-03,  1.9032e-03,\n",
       "             1.7568e-03,  2.2051e-03,  1.2550e-03,  1.5176e-03,  3.5343e-03,\n",
       "             2.0616e-03,  2.7092e-03,  2.0838e-03,  1.8513e-03,  1.9622e-03,\n",
       "             2.9141e-03,  2.3442e-03,  2.6670e-03,  2.3149e-03,  2.0843e-03,\n",
       "             3.9525e-03,  2.6390e-03,  3.2674e-03,  2.4926e-03,  1.4372e-03,\n",
       "             1.1562e-03,  1.9794e-03,  2.7576e-03,  3.1463e-03,  1.9983e-03,\n",
       "             2.0053e-03,  1.3671e-03,  1.9942e-03,  2.1422e-03,  2.1004e-03,\n",
       "             2.5204e-03,  2.4027e-03,  2.3374e-03,  2.2473e-03,  1.9373e-03,\n",
       "             1.7611e-03,  3.8773e-03,  2.3591e-03,  1.7921e-03,  2.9843e-03,\n",
       "             1.1704e-03,  1.5080e-03,  2.4943e-03,  3.3950e-03,  1.7986e-03,\n",
       "             2.1126e-03,  6.1212e-04,  3.6991e-03,  1.5635e-03,  2.1060e-03,\n",
       "             1.9468e-03,  1.4308e-03,  1.3608e-03,  2.4897e-03,  1.1366e-03,\n",
       "             3.5213e-03,  1.8517e-03,  1.5725e-03,  2.0588e-03,  1.8005e-03,\n",
       "             1.7002e-03,  1.2409e-03,  2.4275e-03,  1.2602e-04,  2.1944e-03,\n",
       "             1.8769e-03,  1.4024e-03,  1.2834e-03,  1.2853e-03,  2.3691e-03,\n",
       "             2.1456e-03,  2.0216e-03,  1.5364e-03,  2.0810e-03,  3.4390e-04,\n",
       "             2.6120e-03,  2.2411e-03,  1.6630e-03,  1.6903e-03,  2.5393e-03,\n",
       "             1.7193e-03,  2.5901e-03,  2.0217e-03,  1.8730e-03,  2.0676e-03,\n",
       "             2.2613e-03,  2.3649e-03,  8.6736e-04,  2.6640e-03,  1.6231e-03,\n",
       "             3.0428e-03,  2.6864e-03,  1.2178e-04,  2.2871e-03,  2.5528e-03,\n",
       "             1.1809e-03,  1.9544e-03,  1.9068e-03,  2.1385e-03,  1.5371e-03,\n",
       "             2.4660e-03,  3.1418e-03,  3.2717e-03,  1.2488e-03,  1.9914e-03,\n",
       "             1.5086e-03,  2.0592e-03,  1.4490e-03,  1.4608e-03,  2.1117e-03,\n",
       "             2.8289e-03,  1.8422e-03,  1.6564e-03,  1.6424e-03,  2.0176e-03,\n",
       "             1.8522e-03,  1.7836e-03,  2.1162e-03,  1.8539e-03,  1.9865e-03,\n",
       "             1.6779e-03,  2.1106e-03,  2.4925e-03,  1.9391e-03,  3.0619e-03,\n",
       "             3.1703e-03,  1.8759e-03,  2.1900e-03,  2.1069e-03,  2.1056e-03,\n",
       "             1.7282e-03,  1.7577e-03,  1.8268e-03,  2.3131e-03,  3.4982e-03,\n",
       "             2.9420e-03,  3.8610e-03,  1.6342e-03,  1.8510e-03,  2.1285e-03,\n",
       "             2.0407e-03,  3.1066e-03,  2.8696e-03,  2.5472e-03,  2.1060e-03,\n",
       "             2.0177e-03,  1.7212e-03,  2.2232e-03,  2.9158e-03,  2.6504e-03,\n",
       "             2.4322e-03,  2.6570e-03,  1.9132e-03,  3.4596e-03,  2.0090e-03,\n",
       "             1.7013e-03,  2.4798e-03,  1.5437e-03,  2.5105e-03,  1.4825e-03,\n",
       "             1.8618e-03,  2.3095e-03,  2.7545e-03,  1.3369e-03,  1.5448e-03,\n",
       "             3.3281e-03,  1.8291e-03,  1.7249e-03,  1.9457e-03,  4.8030e-04,\n",
       "             2.2867e-03,  3.0529e-03,  2.0959e-03,  1.6965e-03,  2.7031e-03,\n",
       "             2.4070e-03,  1.8683e-03,  1.2227e-03,  2.6038e-03,  1.7807e-03,\n",
       "             2.0869e-03,  1.8479e-03,  2.9056e-03,  2.1435e-03,  1.8190e-03,\n",
       "             2.7526e-03,  1.7801e-03,  1.6142e-03,  2.1899e-03,  2.3395e-03,\n",
       "             2.1140e-03,  1.3441e-03,  2.1236e-03,  2.3254e-03,  2.2048e-03,\n",
       "             2.6591e-03,  2.3322e-03,  1.9826e-03,  1.9526e-03,  1.8741e-03,\n",
       "             7.2875e-04,  2.3843e-03,  3.5097e-03,  1.0970e-03,  3.2321e-03,\n",
       "             2.9950e-03,  2.2150e-03,  2.7373e-03,  2.7719e-03,  1.6445e-03,\n",
       "             2.0072e-03,  2.4322e-03,  1.9266e-03,  2.3037e-03,  1.9338e-03,\n",
       "             2.7242e-03,  1.5397e-03,  2.8520e-03,  2.2061e-03,  2.3986e-03,\n",
       "             2.2399e-05,  1.3921e-03,  2.0749e-03,  2.1851e-03,  1.6198e-03,\n",
       "             2.0995e-03,  2.3842e-03,  1.0126e-03,  1.3931e-03,  2.2638e-03,\n",
       "             2.6256e-03,  2.4171e-03,  2.3658e-03,  1.5868e-03,  1.8582e-03,\n",
       "             1.9208e-03,  4.8532e-04,  1.6188e-03,  2.4138e-03,  2.2439e-03,\n",
       "             8.1514e-04,  1.5321e-03,  2.3593e-03,  2.1954e-03,  6.7854e-04,\n",
       "             2.7206e-03,  2.7774e-03,  1.2629e-03,  7.5956e-04,  9.5177e-04,\n",
       "             1.9673e-03,  2.4406e-03,  2.1348e-03,  1.6633e-03,  2.0738e-03,\n",
       "             9.8341e-04,  2.2658e-03,  2.5551e-03,  2.6364e-03,  1.5918e-03,\n",
       "             1.9775e-03,  1.7474e-03,  2.2863e-03,  2.7555e-03,  2.2057e-03,\n",
       "             3.0573e-03,  2.0427e-03,  2.1625e-03,  2.5440e-03,  2.8944e-03,\n",
       "             2.3331e-03,  2.1205e-03,  2.8183e-03,  2.7865e-03,  2.6944e-03,\n",
       "             2.0723e-03,  2.3015e-03,  2.4479e-03,  2.0823e-03,  2.4117e-03,\n",
       "             2.1973e-03,  2.1456e-03,  2.4608e-03,  2.2745e-03,  3.6589e-03,\n",
       "             3.0027e-03,  2.3730e-03,  2.8492e-03,  1.8076e-03,  2.3888e-03,\n",
       "             1.8676e-03,  1.0971e-03], device='cuda:0')},\n",
       "   131: {'momentum_buffer': tensor([-2.3816e-03, -2.9660e-03, -2.6711e-03, -2.4043e-03, -4.3792e-03,\n",
       "            -2.9115e-03, -2.2961e-03, -1.2424e-03, -3.1268e-03, -7.6546e-04,\n",
       "            -1.7485e-03, -3.2921e-03, -3.2679e-03, -1.0923e-03, -3.9142e-04,\n",
       "            -1.2016e-03, -2.7133e-03, -1.8785e-03, -2.1942e-03, -2.4255e-03,\n",
       "            -2.6071e-03, -2.1882e-03, -2.2793e-03, -2.6943e-03, -2.9313e-03,\n",
       "            -2.5819e-03, -2.4369e-03, -2.5453e-03, -2.8144e-03, -1.1990e-03,\n",
       "            -3.9710e-03, -2.3261e-03, -1.4061e-03, -9.8177e-04, -3.3502e-03,\n",
       "            -5.0466e-03, -8.1269e-04, -1.8241e-03, -1.4263e-03, -1.7418e-03,\n",
       "            -1.8553e-03,  7.7988e-04, -1.6738e-03, -1.9796e-03, -2.0183e-03,\n",
       "            -3.0030e-03, -3.4014e-03,  6.0464e-05, -1.4404e-03, -2.4913e-03,\n",
       "            -1.2890e-03, -2.0142e-03, -2.8934e-03, -9.4399e-04, -3.1298e-03,\n",
       "            -1.7489e-03, -9.9430e-04, -2.0158e-03, -1.4522e-03, -2.6107e-03,\n",
       "            -2.3870e-03, -2.8591e-03, -2.2599e-03, -1.0399e-03, -3.1712e-03,\n",
       "            -2.2338e-03, -3.5365e-03, -2.0821e-03, -1.3965e-03, -4.3292e-03,\n",
       "            -1.8510e-03, -1.0222e-03, -2.5139e-03, -2.6324e-03, -3.9618e-03,\n",
       "            -3.4405e-03, -8.2652e-04, -1.9644e-03, -1.3798e-03, -2.2693e-03,\n",
       "            -3.0089e-03, -1.4175e-03, -8.1911e-04, -2.7547e-03, -1.8310e-03,\n",
       "            -1.9356e-03, -4.1394e-03, -1.5507e-03, -2.4741e-03, -1.6997e-03,\n",
       "            -1.8130e-03, -2.9310e-03, -1.8344e-03, -1.2660e-03, -1.7296e-03,\n",
       "            -2.3239e-03, -2.8210e-03, -2.4641e-03, -2.3323e-03, -1.6990e-03,\n",
       "            -3.0872e-03, -2.3396e-03, -2.7426e-03, -1.5355e-03, -1.7215e-03,\n",
       "            -2.2434e-03, -2.3267e-03, -3.2335e-03, -2.4418e-03, -1.4556e-03,\n",
       "            -1.1279e-03, -4.3520e-03, -1.0662e-03, -1.8050e-03, -2.2872e-03,\n",
       "            -3.0865e-03, -1.9385e-03, -2.1509e-03, -2.6525e-03, -2.3585e-03,\n",
       "            -1.9065e-03, -3.2488e-03, -2.9905e-03, -1.1484e-03, -2.7400e-03,\n",
       "            -1.9203e-03, -2.4739e-03, -3.7233e-03, -3.2250e-03, -1.8817e-03,\n",
       "            -4.1169e-03, -2.2808e-03, -1.4323e-03, -2.1256e-03, -3.3471e-03,\n",
       "            -4.8464e-03, -2.8552e-03, -3.3601e-03, -3.1709e-03, -1.9174e-03,\n",
       "            -3.8343e-03, -2.6097e-03, -1.5259e-03, -1.9374e-03, -8.6390e-04,\n",
       "            -2.1389e-03, -1.7959e-03, -2.6746e-03, -3.3675e-03, -2.1548e-03,\n",
       "            -2.7035e-03, -3.7809e-03, -3.1755e-03, -8.1413e-04, -3.0531e-03,\n",
       "            -2.1126e-03, -2.3540e-03, -4.6845e-03, -2.4888e-03, -1.8290e-03,\n",
       "            -2.7279e-03, -2.1552e-03, -2.1648e-03,  3.3139e-04, -2.4177e-03,\n",
       "            -3.0711e-03, -2.5814e-03, -3.1831e-03, -1.8893e-03, -1.9710e-03,\n",
       "            -2.7575e-03, -2.0471e-03, -2.3229e-03, -8.9834e-04, -2.0659e-03,\n",
       "            -2.8746e-03, -3.4871e-03, -1.4951e-03, -2.6229e-03, -3.2868e-03,\n",
       "            -3.0059e-03, -1.9361e-03, -1.8733e-03, -3.7574e-03, -3.6215e-03,\n",
       "            -1.5331e-03, -3.2879e-03, -1.2292e-03, -2.8724e-03, -3.3169e-03,\n",
       "            -2.8559e-03, -2.3234e-03, -2.1078e-03, -2.7185e-03, -1.6836e-03,\n",
       "            -3.5188e-03, -2.1968e-03, -2.5672e-03, -2.3150e-03, -2.7732e-03,\n",
       "             6.9647e-04, -2.7825e-03, -3.4807e-03, -2.7992e-03, -2.7112e-03,\n",
       "            -3.0158e-03, -1.7145e-03, -2.3127e-03, -1.2234e-03, -2.8155e-03,\n",
       "            -2.4857e-03, -1.3689e-03, -1.7068e-03, -1.7151e-03, -2.5157e-03,\n",
       "            -3.0514e-03, -2.0899e-03, -1.6781e-03, -3.0281e-03, -1.8491e-03,\n",
       "            -2.3379e-03, -4.0989e-03, -3.0890e-03, -1.0664e-03, -3.3012e-03,\n",
       "            -1.5086e-03, -2.8308e-03, -1.7550e-03, -2.5713e-03, -2.1787e-03,\n",
       "            -1.8840e-03, -1.8467e-03, -2.0874e-03, -1.9773e-03, -2.8336e-03,\n",
       "            -1.8913e-03, -2.7509e-03, -1.8178e-03, -2.5161e-03, -2.6080e-03,\n",
       "            -3.3858e-03, -3.8712e-03, -2.7420e-03, -2.5153e-03, -1.2252e-03,\n",
       "            -4.2776e-03,  6.3145e-04, -2.1758e-03, -2.7442e-03, -2.5341e-03,\n",
       "            -4.0793e-03, -2.9545e-03, -2.7256e-03, -5.6063e-03, -2.1660e-03,\n",
       "            -1.8087e-03, -1.6599e-03, -3.3947e-03, -4.1692e-03, -6.8563e-04,\n",
       "            -3.4939e-03, -1.8939e-03, -3.0416e-03, -2.9190e-03, -2.4534e-03,\n",
       "            -1.5815e-03,  2.4293e-04, -2.7040e-03, -2.2562e-03, -6.2465e-04,\n",
       "            -1.6966e-03, -2.3526e-03,  8.8704e-04, -2.7180e-03, -1.6427e-03,\n",
       "            -1.8496e-03, -2.2956e-03, -2.5750e-03, -3.6366e-04, -3.3271e-03,\n",
       "            -2.2253e-03, -4.4052e-03, -2.7545e-03, -2.0618e-04, -3.0112e-03,\n",
       "            -3.1980e-03, -2.3388e-03, -2.2748e-03, -6.1718e-04, -2.1348e-03,\n",
       "            -2.7084e-03, -2.0172e-03, -1.8620e-03, -1.9674e-03, -2.0572e-03,\n",
       "            -2.0175e-03, -2.9885e-03, -1.8041e-03, -1.7191e-04, -1.7900e-03,\n",
       "            -1.4865e-03, -1.8654e-03, -3.5634e-03, -4.1895e-03, -2.7228e-03,\n",
       "            -2.6810e-03, -2.9596e-03, -2.5063e-03, -3.6397e-03, -3.0972e-03,\n",
       "            -1.4872e-03, -2.1447e-03, -2.2326e-03, -1.1232e-03, -2.9069e-03,\n",
       "            -1.7104e-03, -2.7829e-03, -2.9382e-03,  1.0808e-03, -3.3004e-03,\n",
       "            -2.8909e-03, -2.7872e-03, -3.0390e-03, -2.4669e-03, -2.2110e-03,\n",
       "            -1.5208e-03, -3.0118e-03, -3.2229e-03, -3.0960e-03, -1.7418e-03,\n",
       "            -1.8870e-03, -3.2758e-03, -2.2413e-03, -2.4569e-03, -2.2740e-03,\n",
       "            -1.4103e-03,  3.3290e-05, -1.6279e-04, -2.8990e-03, -2.9236e-03,\n",
       "            -1.7622e-03, -1.7703e-03, -3.8630e-03, -3.2568e-03, -2.1156e-03,\n",
       "            -3.3970e-03, -2.1128e-03, -2.8412e-03, -2.8624e-03, -2.9601e-03,\n",
       "            -2.7064e-03, -1.3949e-03, -9.3674e-04, -1.5152e-03, -3.6601e-03,\n",
       "            -4.0350e-03, -2.8486e-03, -1.4850e-03, -1.7616e-03, -1.7185e-03,\n",
       "            -9.0556e-04, -1.6013e-03, -4.6542e-03, -4.0912e-03, -2.8127e-03,\n",
       "            -2.2032e-03, -2.5457e-03, -2.6407e-03, -2.9762e-03, -4.4711e-03,\n",
       "            -2.8649e-03, -2.5547e-03, -2.8459e-03, -2.5536e-03, -2.5939e-03,\n",
       "            -2.2096e-03, -1.2086e-03, -2.9959e-03, -2.8885e-03, -1.6997e-03,\n",
       "            -2.3006e-03, -1.7285e-03, -4.1043e-03, -2.3873e-03, -3.0704e-03,\n",
       "            -4.1851e-03, -1.8201e-03, -2.1799e-03, -1.3584e-03, -3.5600e-03,\n",
       "            -2.0899e-03, -1.5500e-03, -2.0524e-03, -2.3860e-03, -3.9204e-03,\n",
       "            -2.0088e-03, -3.5601e-03, -1.9920e-03, -1.7584e-03, -2.4692e-03,\n",
       "            -1.0866e-03, -2.5797e-03, -2.3338e-03, -2.4564e-03, -2.1316e-03,\n",
       "            -2.2293e-03, -3.3182e-03, -2.0752e-03, -1.1940e-03, -3.2224e-03,\n",
       "            -1.7328e-03, -2.4636e-03, -2.9659e-03, -2.7678e-03, -2.0484e-03,\n",
       "            -4.0168e-03, -2.2982e-03, -2.3781e-03, -1.8036e-03, -2.0004e-03,\n",
       "            -2.1306e-03, -2.9878e-03, -4.0064e-03, -1.6434e-03, -2.6473e-03,\n",
       "            -1.2903e-03, -3.2387e-03, -1.3806e-03, -2.9375e-03, -3.1367e-03,\n",
       "            -2.1883e-03, -2.0791e-03, -2.8923e-03, -2.5081e-03, -1.5254e-03,\n",
       "            -1.9064e-03, -2.2979e-03, -2.7304e-03, -2.8966e-03, -1.1055e-03,\n",
       "            -2.3488e-03, -1.8223e-03, -2.1665e-03, -2.7676e-03, -2.2209e-03,\n",
       "            -3.7729e-03, -1.2252e-03, -2.7112e-03, -2.6815e-03, -2.6632e-03,\n",
       "            -2.8537e-03, -9.1835e-04, -1.8712e-03, -3.5670e-03, -3.2193e-03,\n",
       "            -2.2618e-03, -2.7010e-04, -2.8808e-04, -2.4225e-03, -3.0471e-03,\n",
       "            -6.2127e-04, -1.3357e-03, -4.0678e-03, -1.8072e-03,  1.2455e-04,\n",
       "            -3.6324e-03, -3.1737e-03, -1.5157e-03, -2.4295e-03, -4.1739e-03,\n",
       "            -1.7914e-03, -2.6780e-03, -1.7486e-03, -1.7694e-03, -2.4854e-03,\n",
       "            -1.9543e-03, -3.3149e-03, -2.2582e-03, -1.9041e-03, -1.6273e-03,\n",
       "            -2.1959e-03, -7.2764e-04, -2.4274e-03, -2.5208e-03, -2.6002e-03,\n",
       "            -8.2135e-04, -1.7391e-03, -3.4551e-03, -4.4530e-03, -2.5358e-03,\n",
       "            -2.5570e-03, -1.2424e-03, -1.1145e-03, -2.1052e-03, -1.5434e-03,\n",
       "            -2.1938e-03, -2.5091e-03, -1.0464e-03, -2.9519e-03, -1.5812e-03,\n",
       "            -2.2011e-03, -2.6043e-03, -2.3589e-03, -3.0772e-03, -4.1676e-03,\n",
       "            -1.4971e-03, -3.2574e-03, -1.9343e-03, -1.7310e-03, -2.7761e-03,\n",
       "            -2.3187e-03, -2.5519e-03], device='cuda:0')},\n",
       "   132: {'momentum_buffer': tensor([[[[-9.9309e-05, -8.2017e-05,  1.8052e-05],\n",
       "              [ 4.9329e-05,  7.3661e-05,  6.5619e-05],\n",
       "              [ 4.5510e-05, -4.2101e-05,  1.0067e-04]],\n",
       "    \n",
       "             [[ 7.3999e-05,  1.6173e-04,  6.4454e-05],\n",
       "              [ 1.6274e-04,  4.5688e-05,  2.1813e-05],\n",
       "              [ 1.3498e-04, -1.3605e-04, -2.7325e-05]],\n",
       "    \n",
       "             [[ 2.5499e-04,  1.3039e-04,  9.5130e-05],\n",
       "              [ 9.3464e-05, -6.4473e-05,  7.5757e-07],\n",
       "              [ 6.7568e-05,  2.0554e-04,  7.0219e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.8530e-05,  1.7004e-04,  1.4158e-04],\n",
       "              [-5.3763e-05,  2.8472e-04,  1.4659e-04],\n",
       "              [-1.5908e-04, -3.9591e-05,  1.1164e-05]],\n",
       "    \n",
       "             [[ 2.3683e-04, -5.1698e-05, -7.4300e-06],\n",
       "              [-6.2278e-05, -9.1881e-05, -2.8225e-04],\n",
       "              [ 1.6092e-04,  1.4174e-05,  2.6662e-04]],\n",
       "    \n",
       "             [[ 1.8505e-04,  1.2963e-04,  5.7612e-05],\n",
       "              [ 2.6956e-04,  3.4998e-05,  4.7925e-05],\n",
       "              [ 2.3317e-04, -4.6094e-05,  2.8113e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.5276e-05, -1.1293e-04,  1.6208e-04],\n",
       "              [-4.3395e-05,  5.2959e-05,  5.3755e-06],\n",
       "              [ 6.2567e-05, -1.6043e-05,  6.5249e-05]],\n",
       "    \n",
       "             [[-9.4456e-05, -5.7789e-05, -1.9480e-04],\n",
       "              [-1.0283e-04,  2.1856e-06,  6.7225e-05],\n",
       "              [-1.6677e-04, -1.3830e-05, -5.8743e-05]],\n",
       "    \n",
       "             [[-1.1858e-04,  9.5164e-05,  6.1051e-05],\n",
       "              [-1.2168e-04,  9.7179e-05,  8.6736e-05],\n",
       "              [ 1.1639e-04,  1.6368e-04,  2.4810e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.8225e-05, -1.1873e-04,  3.7524e-05],\n",
       "              [-2.5409e-06,  1.1118e-04,  1.8408e-05],\n",
       "              [ 1.9416e-04,  3.0322e-04,  1.6023e-04]],\n",
       "    \n",
       "             [[ 1.7835e-04,  2.8909e-04,  2.5736e-04],\n",
       "              [-1.3988e-04,  1.6697e-04, -9.8997e-05],\n",
       "              [-1.1562e-04,  6.8397e-05, -1.1712e-04]],\n",
       "    \n",
       "             [[ 3.9057e-05,  1.5114e-04,  8.4351e-05],\n",
       "              [ 4.9075e-05,  4.0290e-05,  2.7307e-04],\n",
       "              [-1.3739e-04, -1.1564e-04, -9.3665e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.3358e-04, -1.6115e-04, -7.9891e-05],\n",
       "              [-2.8492e-05, -1.1296e-04, -1.5264e-04],\n",
       "              [ 1.0230e-04, -1.0603e-04,  2.3312e-04]],\n",
       "    \n",
       "             [[-1.8202e-04, -2.7358e-04, -1.3392e-04],\n",
       "              [-1.7346e-04, -1.8492e-04, -5.0529e-05],\n",
       "              [-3.0502e-04, -2.6421e-04, -2.1534e-04]],\n",
       "    \n",
       "             [[-1.1180e-04, -1.3536e-04, -6.6881e-05],\n",
       "              [-1.7214e-04, -1.6310e-04, -5.2249e-06],\n",
       "              [ 1.3610e-04, -1.0298e-04,  3.4583e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.6855e-06,  4.6467e-05, -1.1137e-04],\n",
       "              [-2.0847e-04, -3.5988e-04, -2.0999e-04],\n",
       "              [-1.3801e-04, -3.2374e-04, -2.8280e-04]],\n",
       "    \n",
       "             [[-1.1083e-04,  6.1691e-06,  1.4183e-04],\n",
       "              [-1.4057e-04,  8.2265e-05, -4.6070e-05],\n",
       "              [ 6.3726e-06, -1.2144e-04, -3.0465e-05]],\n",
       "    \n",
       "             [[-2.4779e-04, -1.4823e-04, -4.0171e-04],\n",
       "              [-2.9602e-04, -9.8659e-05, -1.4485e-04],\n",
       "              [-7.0638e-06, -2.6600e-04, -1.8744e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 2.4137e-05, -1.0410e-05, -8.5109e-06],\n",
       "              [ 1.4127e-06, -8.2536e-05, -2.4933e-05],\n",
       "              [-7.4143e-05,  3.6516e-05, -4.6993e-05]],\n",
       "    \n",
       "             [[-1.0754e-04, -1.0793e-04, -1.9326e-04],\n",
       "              [ 6.7746e-05, -1.2134e-05,  4.6475e-05],\n",
       "              [ 1.4014e-05,  6.7421e-05,  1.2129e-05]],\n",
       "    \n",
       "             [[ 5.1052e-05, -4.6562e-05,  1.3439e-04],\n",
       "              [ 8.3162e-05,  2.0730e-04,  2.6232e-05],\n",
       "              [ 4.3210e-05, -8.5699e-06, -8.3725e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.0813e-05, -4.1216e-05,  5.1036e-05],\n",
       "              [-7.3576e-05, -3.0597e-05, -8.3467e-06],\n",
       "              [-8.4017e-05, -1.7295e-05, -1.4335e-05]],\n",
       "    \n",
       "             [[-1.3607e-04, -7.3490e-05, -2.7712e-04],\n",
       "              [-1.6156e-04, -1.2316e-05, -5.9678e-05],\n",
       "              [-5.5504e-05, -8.7746e-05, -9.2121e-05]],\n",
       "    \n",
       "             [[-3.0105e-04, -3.1019e-04, -2.2589e-04],\n",
       "              [ 2.1280e-05,  3.3816e-05, -4.5103e-05],\n",
       "              [-9.7176e-05, -9.1560e-05, -1.8635e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-7.7313e-06, -1.4926e-04,  5.9908e-05],\n",
       "              [ 1.2637e-04,  1.5507e-04,  1.1358e-04],\n",
       "              [-6.4239e-05, -8.4854e-05,  6.5837e-05]],\n",
       "    \n",
       "             [[-6.0335e-05, -1.2632e-04, -2.0804e-04],\n",
       "              [ 1.6808e-05, -1.1991e-04, -1.9233e-05],\n",
       "              [-5.7743e-05, -8.1892e-05, -8.6551e-05]],\n",
       "    \n",
       "             [[-1.6510e-04, -6.2237e-05, -1.1552e-04],\n",
       "              [-5.6551e-05, -1.0918e-06, -5.6203e-05],\n",
       "              [-1.9732e-04, -9.6374e-05, -1.5934e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.7967e-05,  1.9741e-04,  2.7284e-04],\n",
       "              [-1.5274e-04,  3.7535e-04,  2.4569e-04],\n",
       "              [ 9.8241e-06,  2.5237e-05, -9.4001e-05]],\n",
       "    \n",
       "             [[-3.2284e-04, -1.1467e-04,  3.7754e-05],\n",
       "              [ 1.3820e-04,  7.5264e-05, -3.9951e-04],\n",
       "              [ 2.1590e-04,  3.8150e-04, -1.2092e-04]],\n",
       "    \n",
       "             [[-6.9610e-05, -1.4400e-04,  6.9786e-05],\n",
       "              [-5.5027e-05, -1.7323e-04, -8.2394e-05],\n",
       "              [ 1.4717e-04,  1.1080e-04,  2.5348e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.0861e-04, -3.3174e-05, -1.0522e-05],\n",
       "              [-7.3237e-05, -2.3961e-05,  1.1723e-04],\n",
       "              [-4.1201e-05,  6.1826e-05,  2.0319e-05]],\n",
       "    \n",
       "             [[ 3.5354e-05,  1.7228e-05,  6.0228e-05],\n",
       "              [ 7.1855e-05,  9.4022e-05,  9.3240e-05],\n",
       "              [-1.5412e-05,  1.5831e-04,  1.0235e-04]],\n",
       "    \n",
       "             [[-5.0438e-05, -1.4371e-04,  1.8424e-05],\n",
       "              [-2.7299e-05, -1.2752e-04,  4.2989e-05],\n",
       "              [ 1.3057e-04,  7.8632e-05,  1.4174e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.0079e-05,  4.5793e-04,  2.4154e-04],\n",
       "              [ 1.4950e-04,  3.3110e-04,  1.3905e-04],\n",
       "              [ 1.0650e-04,  2.2515e-04,  2.1261e-05]],\n",
       "    \n",
       "             [[-3.3702e-05, -8.3387e-05, -2.0421e-04],\n",
       "              [ 2.3045e-05,  2.6988e-05,  2.4930e-04],\n",
       "              [-2.9891e-06, -3.9097e-05, -6.4231e-05]],\n",
       "    \n",
       "             [[-7.9237e-05,  1.4816e-04,  1.0419e-04],\n",
       "              [ 8.4719e-05,  7.0686e-05,  5.6946e-05],\n",
       "              [ 6.2070e-06, -4.7939e-05, -1.2916e-05]]]], device='cuda:0')},\n",
       "   133: {'momentum_buffer': tensor([ 2.0055e-03,  1.5204e-03,  7.7949e-04,  2.1534e-03,  1.2303e-03,\n",
       "             1.4185e-03,  1.8909e-03,  2.0501e-03,  1.3186e-03,  1.9034e-03,\n",
       "             9.5836e-04,  8.6635e-04,  1.3385e-03,  2.0774e-03,  1.2706e-03,\n",
       "             1.2636e-03,  8.1583e-04,  2.2898e-03,  1.8261e-03,  1.6203e-03,\n",
       "             1.0024e-03,  1.5392e-03,  2.1433e-03,  8.8656e-04,  1.0438e-03,\n",
       "             9.8834e-04,  1.6514e-03,  1.9797e-03,  1.2210e-03,  1.8484e-03,\n",
       "             1.8814e-03,  1.1502e-03,  1.7475e-03,  1.9279e-03,  1.9069e-03,\n",
       "             1.6151e-03,  2.1367e-03,  1.7458e-03,  1.8599e-03,  1.6340e-03,\n",
       "             1.0552e-03,  1.8125e-03,  2.2715e-03,  2.2400e-03,  1.6228e-03,\n",
       "             2.6927e-03,  2.1295e-03,  1.7804e-03,  2.0670e-03,  2.0446e-03,\n",
       "             2.3931e-03,  1.4737e-03,  1.9107e-03,  1.9600e-03,  1.5865e-03,\n",
       "             1.5343e-03,  9.7321e-04,  1.4350e-03,  1.2971e-03,  1.9237e-03,\n",
       "             1.4500e-03,  1.9741e-03,  1.4595e-03,  1.6095e-03,  1.6341e-03,\n",
       "             8.7954e-04,  1.2946e-03,  1.5995e-03,  1.2526e-03,  6.2516e-04,\n",
       "             2.1551e-03,  1.7060e-03,  2.3339e-03,  5.9292e-04,  1.8989e-03,\n",
       "             1.1561e-03,  1.2079e-03,  2.2619e-03,  1.5164e-03,  1.5100e-03,\n",
       "             1.2345e-03,  1.6622e-03,  1.3189e-03,  1.5920e-03,  2.8007e-03,\n",
       "             1.9319e-03,  1.7665e-03,  1.5474e-03,  2.2270e-03,  9.7377e-04,\n",
       "             1.4926e-03,  2.4291e-03,  1.6119e-03,  1.5619e-03,  1.5528e-03,\n",
       "             1.8085e-03,  2.1539e-03,  1.8376e-03,  1.9025e-03,  9.9515e-04,\n",
       "             2.0238e-03,  1.8086e-03,  1.6541e-03,  1.1561e-03,  2.4798e-03,\n",
       "             2.2230e-03,  1.4498e-03,  2.2672e-03,  1.3801e-03,  2.2910e-03,\n",
       "             1.3921e-03,  1.6625e-03,  7.6525e-04,  1.7828e-03,  1.9733e-03,\n",
       "             1.7870e-03,  1.9501e-03,  1.3155e-03,  7.4483e-04,  6.9951e-04,\n",
       "             2.0186e-03,  5.1997e-04,  1.9513e-03,  5.7609e-04,  1.7053e-03,\n",
       "             1.6239e-03,  9.2834e-04,  1.3825e-03,  6.3723e-04,  1.7354e-03,\n",
       "             1.2265e-03,  1.4669e-03,  1.1121e-03,  4.0774e-03,  1.1441e-03,\n",
       "            -2.0204e-04,  2.6661e-03,  1.4649e-03,  2.0456e-03,  1.4607e-03,\n",
       "             1.8248e-03,  1.4568e-03,  1.6963e-03,  1.4547e-03,  1.8268e-03,\n",
       "             1.7098e-03,  1.7896e-03,  1.7976e-03,  1.2782e-03,  1.8182e-03,\n",
       "             1.5632e-03,  1.8195e-03,  1.6026e-03,  9.7415e-04,  1.4108e-03,\n",
       "             1.1578e-03,  1.9571e-03,  1.5177e-03,  1.4513e-03,  1.6316e-03,\n",
       "             1.3861e-03,  1.5514e-03,  1.8435e-03,  2.0058e-03,  1.5514e-03,\n",
       "             1.6731e-03,  1.5430e-03,  2.0162e-03,  1.1214e-03,  1.9854e-03,\n",
       "             1.4916e-03,  2.2782e-03,  1.6145e-03,  2.1335e-03,  9.7395e-04,\n",
       "             2.2217e-03,  1.0903e-03,  1.7164e-03,  1.9526e-03,  2.1121e-03,\n",
       "             1.4737e-03,  1.3431e-03,  1.8622e-03,  1.7815e-03,  1.3362e-03,\n",
       "             2.3644e-03,  2.2386e-03,  1.8350e-03,  1.3729e-03,  1.9364e-03,\n",
       "             1.9768e-03,  1.4858e-03,  1.6445e-03,  1.1421e-03,  2.2116e-03,\n",
       "             1.8287e-03,  1.8136e-03,  1.0847e-03,  2.3555e-03,  1.7031e-03,\n",
       "             1.7139e-03,  1.6441e-03,  1.9899e-03,  1.2873e-03,  1.3530e-03,\n",
       "             1.6091e-03,  1.3708e-03,  1.8543e-03,  2.3832e-03,  1.7022e-03,\n",
       "             1.7012e-03,  2.2417e-03,  1.3207e-03,  1.2221e-03,  8.5510e-04,\n",
       "             8.5592e-04,  2.2640e-03,  2.0171e-03,  1.7411e-03,  1.1088e-03,\n",
       "             1.3906e-03,  1.4390e-03,  6.2290e-04,  9.5400e-04,  1.4925e-03,\n",
       "             1.6746e-03,  3.0324e-04,  2.3020e-03,  2.2942e-03,  2.7155e-03,\n",
       "             1.4006e-03,  2.2419e-03,  1.0296e-03,  5.4326e-04,  1.5756e-03,\n",
       "             1.2692e-03,  4.5925e-04,  2.2581e-03,  1.4031e-03,  2.7450e-03,\n",
       "             8.3619e-04,  1.6297e-03,  2.0889e-03,  1.2138e-03,  2.3588e-04,\n",
       "             2.2758e-03,  1.8470e-03,  1.9935e-03,  2.1546e-03,  1.5766e-03,\n",
       "             1.8448e-03,  1.8872e-03,  2.3345e-03,  2.2435e-03,  1.5993e-03,\n",
       "             8.3373e-04,  1.1593e-03,  1.2150e-03,  1.5556e-03,  1.8152e-03,\n",
       "             5.2356e-04,  2.2982e-03,  2.3338e-04,  1.3249e-03,  1.9380e-03,\n",
       "             1.5332e-03,  2.2555e-03,  1.4915e-03,  2.4680e-03,  1.3907e-03,\n",
       "             1.1810e-03,  8.5395e-04,  2.0276e-03,  1.4776e-03,  2.3223e-03,\n",
       "             2.0456e-03,  1.5896e-03,  1.8859e-03,  2.2114e-03,  2.1256e-03,\n",
       "             1.7046e-03,  1.3531e-03,  1.7370e-03,  2.1138e-03,  1.9241e-03,\n",
       "             2.1523e-03,  1.7240e-03,  1.4260e-03,  1.7191e-03,  1.3707e-03,\n",
       "             1.0962e-03,  1.5594e-03,  1.9538e-03,  2.8559e-03,  1.8903e-03,\n",
       "             2.4610e-03,  2.0040e-03,  1.5600e-03,  1.8066e-03,  8.7319e-04,\n",
       "             7.6663e-04,  1.9744e-03,  5.5263e-04,  1.2872e-03,  8.2161e-04,\n",
       "             1.0097e-03,  1.6020e-03,  1.5039e-03,  1.1535e-03,  1.9882e-03,\n",
       "             1.2159e-03,  1.4088e-03,  1.7491e-03,  7.7778e-04,  2.0171e-03,\n",
       "             1.7929e-03,  1.7763e-03,  9.2374e-04,  1.8706e-03,  1.3020e-03,\n",
       "             2.4283e-03,  1.0567e-03,  1.3207e-03,  8.5633e-04,  1.4693e-03,\n",
       "             8.8608e-04,  2.1205e-03,  2.1082e-03,  1.5319e-03,  1.8372e-03,\n",
       "             1.9810e-03,  2.3271e-03,  1.5065e-03,  1.1144e-03,  1.9694e-03,\n",
       "             1.7503e-03,  2.5711e-03,  1.9185e-03,  1.6466e-03,  1.4070e-03,\n",
       "             1.0190e-03,  2.3559e-03,  1.7730e-03,  2.0123e-03,  1.6614e-03,\n",
       "             9.8454e-04,  2.3271e-03,  1.4349e-03,  2.1531e-04,  1.9160e-03,\n",
       "             1.7531e-03,  2.7197e-03,  1.9522e-03,  2.1746e-03,  1.7572e-03,\n",
       "             1.9717e-03,  1.8454e-03,  1.5857e-03,  2.2139e-03,  1.8958e-03,\n",
       "             1.6550e-03,  1.1152e-03,  1.4545e-03,  1.3769e-03,  9.0935e-04,\n",
       "             1.8306e-03,  1.9998e-03,  1.9708e-03,  1.5368e-03,  9.3783e-04,\n",
       "             1.7895e-03,  1.7704e-03,  1.7324e-03,  1.6482e-03,  1.5174e-03,\n",
       "             1.9485e-03,  1.0790e-03,  1.8592e-03,  1.0329e-03,  1.0808e-03,\n",
       "             1.8866e-03,  1.7003e-03,  7.7794e-04,  9.7172e-04,  1.5275e-03,\n",
       "             1.7343e-03,  1.0815e-03,  1.1550e-03,  1.8828e-03,  2.0401e-03,\n",
       "             1.6092e-03,  1.6565e-03,  2.3258e-03,  1.7571e-03,  1.0765e-03,\n",
       "             1.6601e-03,  2.3504e-03,  1.9119e-03,  1.2321e-03,  2.4927e-03,\n",
       "             1.1299e-03,  1.1729e-03,  1.8586e-03,  8.6471e-04,  1.3188e-03,\n",
       "             1.9261e-03,  2.4629e-03,  1.6593e-03,  7.7706e-04,  6.1575e-04,\n",
       "             1.4054e-03,  1.1496e-03,  8.6428e-04,  1.2330e-03,  2.3018e-03,\n",
       "             2.1788e-03,  8.3221e-04,  1.6969e-03,  8.3145e-04,  7.0752e-04,\n",
       "             1.7877e-03,  2.0646e-03,  1.7166e-03,  1.7586e-03,  1.3018e-03,\n",
       "             1.1022e-03,  1.7945e-03,  1.5591e-03,  1.6530e-03,  1.6363e-03,\n",
       "             1.4235e-03,  1.7062e-03,  1.9735e-03,  1.3474e-03,  1.7186e-03,\n",
       "             1.3947e-03,  1.2143e-03,  1.4415e-03,  1.7565e-03,  1.2112e-03,\n",
       "             1.6443e-03,  1.7365e-03,  1.8603e-03,  9.9304e-04,  1.5530e-03,\n",
       "             4.3120e-04,  2.1093e-03,  2.0398e-03,  2.1941e-03,  1.3374e-03,\n",
       "             2.0652e-03,  1.4700e-03,  1.1542e-03,  1.6141e-03,  1.7359e-03,\n",
       "             1.7677e-03,  1.6314e-03,  1.3276e-03,  2.3313e-03,  1.9319e-03,\n",
       "             1.5419e-03,  1.5258e-03,  1.7156e-03,  1.3713e-03,  1.2566e-03,\n",
       "             1.3409e-03,  1.6768e-03,  1.1302e-03,  1.5705e-03,  1.3759e-03,\n",
       "             1.2318e-03,  1.3210e-03,  1.2801e-03,  2.3305e-03,  1.6401e-03,\n",
       "             1.9572e-03,  2.4078e-03,  1.2116e-03,  2.2160e-03,  1.2525e-03,\n",
       "             2.3386e-04,  1.6518e-03,  1.6961e-03,  1.6627e-03,  1.7666e-03,\n",
       "             1.1261e-03,  1.3748e-03,  2.1240e-03,  1.5650e-03,  2.0298e-03,\n",
       "             1.3902e-03,  1.3963e-03,  1.9715e-03,  2.0805e-03,  1.7167e-03,\n",
       "             1.3843e-03,  1.3041e-03,  1.8948e-03,  1.7705e-03,  1.4857e-03,\n",
       "             2.3018e-03,  6.4083e-04,  1.7254e-03,  1.1343e-03,  7.3610e-04,\n",
       "             1.4898e-03,  1.7688e-03,  9.9552e-05,  1.6085e-03,  1.4398e-03,\n",
       "             2.1126e-03,  9.3986e-04], device='cuda:0')},\n",
       "   134: {'momentum_buffer': tensor([-1.7155e-04,  7.7409e-04,  1.4565e-04, -1.2975e-03, -6.5760e-04,\n",
       "             7.3407e-04, -7.1651e-04,  4.8461e-05,  1.9468e-03,  7.3599e-04,\n",
       "             2.4724e-04,  3.1935e-04, -3.8190e-04, -1.7680e-03, -7.1005e-04,\n",
       "            -9.7639e-04,  1.3675e-03, -1.1502e-03, -1.0687e-03, -1.1756e-03,\n",
       "             3.1438e-04, -8.3588e-04, -4.9924e-05,  5.6153e-04,  9.9135e-04,\n",
       "            -1.5882e-04, -8.4766e-04, -9.5517e-05, -7.6142e-04,  2.0374e-04,\n",
       "            -4.8381e-04,  1.0898e-03, -8.6589e-05, -6.3951e-04, -1.0393e-03,\n",
       "            -2.6217e-04, -1.2086e-03, -6.2226e-04, -6.6590e-04, -9.1566e-04,\n",
       "            -8.5555e-04,  2.1362e-04, -6.2315e-04, -8.1080e-04,  3.5287e-04,\n",
       "            -1.5321e-03, -3.8856e-04,  2.6125e-04, -6.4710e-04, -7.6213e-04,\n",
       "             9.7228e-05, -2.9822e-04, -2.7857e-04, -9.5007e-04, -1.3798e-03,\n",
       "            -1.1490e-03,  1.7776e-04,  1.9080e-04,  3.7744e-04, -1.1914e-03,\n",
       "             4.5236e-04, -1.8685e-06, -8.1939e-04,  4.2455e-04, -3.8788e-04,\n",
       "             1.1139e-03, -5.7660e-04,  3.0116e-03,  1.1038e-04,  1.0854e-03,\n",
       "            -9.2869e-04, -2.8429e-04, -4.9358e-04,  8.1164e-04, -7.3456e-04,\n",
       "            -8.4009e-05,  4.6356e-04, -4.9622e-04, -3.6553e-04,  2.5491e-04,\n",
       "            -5.3672e-04,  8.0737e-05, -4.2249e-04, -8.8779e-04, -8.5550e-04,\n",
       "            -4.6298e-04, -3.1243e-04, -9.0619e-04, -1.0783e-03, -1.2694e-03,\n",
       "            -1.8965e-03,  1.2649e-03, -8.6695e-04, -1.0443e-03, -1.8246e-03,\n",
       "             8.0597e-04, -1.3138e-04, -1.1629e-03, -7.8973e-04, -7.2205e-04,\n",
       "            -2.7869e-04, -7.6635e-04, -1.3851e-03,  3.3147e-04, -6.4352e-04,\n",
       "            -6.4572e-04, -7.5968e-04, -1.3068e-03,  1.1958e-03, -1.2440e-03,\n",
       "             4.6480e-04, -1.0027e-03,  4.9720e-04,  8.0404e-04, -7.9657e-04,\n",
       "            -3.6314e-04, -1.3456e-03,  4.0722e-04,  1.1802e-03,  5.0357e-04,\n",
       "            -2.2917e-04,  2.3023e-03, -1.0216e-03,  1.2244e-03,  6.5267e-04,\n",
       "            -3.0122e-04, -8.9302e-04,  3.5092e-04,  1.6204e-03,  1.9777e-04,\n",
       "            -2.3011e-04, -1.5208e-03, -3.2613e-04, -1.2930e-03, -7.9873e-04,\n",
       "             4.2476e-03, -9.3741e-04,  2.0992e-04, -8.4144e-04, -1.9106e-03,\n",
       "            -3.0946e-04, -5.9537e-04,  8.1874e-04, -3.6051e-04,  7.4125e-04,\n",
       "             2.4246e-04, -3.8710e-04, -4.3289e-04,  1.3200e-05,  1.9333e-04,\n",
       "             2.3409e-03, -7.6880e-05,  5.4470e-04, -3.6243e-04,  1.5384e-04,\n",
       "             5.2979e-04, -7.7824e-04,  3.1972e-04,  1.8146e-04, -9.1461e-05,\n",
       "            -4.1937e-04, -1.0068e-03, -5.5183e-04, -1.1835e-03, -7.7056e-04,\n",
       "             1.0435e-05, -1.2287e-04, -1.5947e-03,  1.3639e-03, -1.3759e-03,\n",
       "            -1.4261e-03, -1.1148e-04, -3.2859e-04, -3.2052e-04,  1.0927e-03,\n",
       "            -8.2949e-04,  4.2378e-04,  6.6871e-04, -1.8811e-04, -9.1825e-04,\n",
       "             2.3086e-05,  3.3591e-04,  1.2405e-03, -2.6114e-04, -1.5114e-04,\n",
       "            -1.0529e-03, -3.7736e-04, -7.9432e-04, -4.7641e-04, -1.1393e-03,\n",
       "            -3.3735e-04, -5.1200e-04, -6.8625e-04, -2.9497e-04, -1.0074e-03,\n",
       "            -1.9455e-03,  4.0934e-04, -2.4977e-04,  1.0686e-04, -4.0048e-04,\n",
       "            -3.8701e-04, -1.5659e-04, -6.5543e-04, -6.2643e-04, -4.1801e-04,\n",
       "            -1.6504e-04, -6.8418e-04, -4.6636e-04, -9.8357e-04, -1.4828e-03,\n",
       "            -1.2290e-04, -1.2135e-03,  1.6592e-03,  3.8452e-04,  5.6122e-04,\n",
       "             1.1615e-03, -1.7106e-03, -3.5778e-04, -5.5148e-04,  6.6955e-04,\n",
       "            -8.1242e-04, -3.9134e-04,  7.3091e-04,  8.8156e-04,  1.1134e-03,\n",
       "            -1.5003e-03,  2.8614e-04, -3.3553e-04, -1.2155e-03, -1.1792e-03,\n",
       "            -1.4502e-03, -2.0616e-03,  6.3918e-04,  1.1201e-03, -6.0022e-04,\n",
       "            -4.1613e-04,  3.4997e-03, -9.0423e-05, -1.0987e-03, -1.0026e-03,\n",
       "             2.6367e-04, -6.7486e-04, -8.2270e-04,  2.2564e-04,  1.2630e-03,\n",
       "            -1.6298e-03, -4.9392e-04,  4.2403e-04, -1.5109e-03, -6.4461e-04,\n",
       "            -8.7306e-04,  1.3051e-03, -1.1510e-03, -1.0970e-03, -8.0986e-04,\n",
       "             1.5280e-03, -6.9508e-04, -2.2709e-05, -2.3908e-04, -5.9739e-04,\n",
       "             1.6006e-03, -9.2536e-04,  1.5459e-04, -3.4033e-04, -1.1953e-04,\n",
       "            -8.6979e-04, -1.4741e-04, -7.7376e-04, -1.0358e-03, -5.5643e-04,\n",
       "             9.7279e-04, -2.4020e-04, -7.5500e-04,  2.9680e-05, -8.4032e-05,\n",
       "            -4.5286e-04, -1.2061e-04, -8.7745e-04, -6.8045e-04, -2.4992e-04,\n",
       "            -1.2455e-03, -3.5335e-04,  2.7640e-04, -7.6295e-04, -5.9068e-04,\n",
       "            -1.7245e-03,  1.7762e-03, -1.0210e-03, -1.4309e-03, -7.2999e-04,\n",
       "            -1.0983e-03, -1.9952e-04, -9.9052e-05, -1.0363e-03, -3.0494e-04,\n",
       "             9.3327e-05, -5.1178e-04, -9.4575e-04,  2.8285e-04,  1.3715e-03,\n",
       "             1.1350e-03,  7.7133e-05, -5.5408e-04, -5.8667e-05, -6.1080e-04,\n",
       "            -3.9535e-04, -1.2924e-03, -2.8063e-04,  3.5509e-03, -1.5978e-04,\n",
       "             5.4229e-04, -7.0198e-04, -7.5383e-04,  1.6442e-04, -2.8752e-04,\n",
       "            -1.8419e-04,  1.5758e-04,  8.2211e-04, -5.4597e-05, -5.8369e-04,\n",
       "            -4.1549e-04,  5.3794e-04,  1.7214e-05,  8.5396e-04,  7.3370e-05,\n",
       "             1.8658e-03, -4.8862e-04,  3.9654e-04, -4.9691e-04, -3.3998e-04,\n",
       "            -1.8985e-03, -5.6315e-04, -2.2651e-04, -1.5474e-04, -4.9952e-04,\n",
       "             1.0220e-04, -4.4494e-04,  4.3424e-04,  1.5906e-04, -2.3747e-05,\n",
       "            -8.2241e-05, -1.5999e-03, -2.2093e-03, -6.8880e-04, -1.4186e-03,\n",
       "             1.2100e-03, -4.6742e-04,  1.4594e-04,  8.7482e-04, -6.5188e-04,\n",
       "             1.0658e-04, -7.7106e-04, -1.0716e-03, -5.9844e-04, -8.6148e-04,\n",
       "            -8.8016e-04,  1.5408e-04, -3.2974e-04,  5.2767e-05,  4.4860e-04,\n",
       "            -9.0154e-04, -8.3332e-05,  1.9813e-04, -1.3790e-03,  3.4573e-04,\n",
       "             8.6245e-04, -5.7864e-04, -1.6286e-03, -1.9532e-03,  1.1847e-03,\n",
       "            -1.1784e-03,  5.4103e-04, -4.8418e-04, -8.4264e-04,  1.9109e-03,\n",
       "             1.2355e-04, -2.6522e-04, -1.3790e-03, -6.0990e-04, -1.4983e-03,\n",
       "            -1.1041e-03, -1.4729e-03, -2.0348e-03,  1.3616e-03, -5.1625e-04,\n",
       "             2.4458e-04,  6.2615e-05,  1.0983e-03, -8.1497e-04, -1.9494e-03,\n",
       "             1.2503e-04, -9.0035e-04, -6.1297e-04, -4.2350e-04,  1.2727e-03,\n",
       "            -4.2420e-04, -9.1368e-04, -3.7811e-04, -1.8262e-04, -1.2764e-03,\n",
       "             7.8292e-05, -1.8573e-04, -1.6108e-03,  2.4992e-04, -3.1769e-04,\n",
       "            -2.0977e-03, -7.9935e-04,  2.2555e-04,  1.9575e-03,  2.9950e-03,\n",
       "            -1.4010e-05,  9.9187e-05,  1.3357e-03, -2.9298e-04, -9.9780e-04,\n",
       "            -1.0434e-03,  3.4001e-03, -7.5302e-04,  7.7649e-04, -4.4685e-04,\n",
       "            -1.0228e-03, -2.5369e-04,  1.3635e-04, -1.0955e-03,  3.1728e-04,\n",
       "            -5.0122e-04,  2.4186e-03, -7.1686e-04, -5.8853e-04, -3.0215e-05,\n",
       "            -6.1181e-04, -2.9773e-05,  9.9107e-04, -9.3168e-04, -2.5456e-04,\n",
       "            -7.8532e-04, -5.3804e-04, -6.6431e-04, -5.1552e-04, -3.5149e-04,\n",
       "            -1.4435e-03, -2.1552e-04,  1.5108e-04, -4.7715e-04, -3.0774e-04,\n",
       "             2.1664e-05, -4.1744e-04, -2.9883e-04, -7.5258e-04,  1.9040e-04,\n",
       "            -1.1144e-03,  4.9937e-04, -2.6762e-04, -2.8536e-04, -4.8884e-04,\n",
       "            -9.7769e-04,  1.5672e-03,  1.1102e-07, -8.1956e-05, -1.0814e-03,\n",
       "            -9.9135e-04, -6.5358e-04,  9.9792e-04,  3.6007e-04,  3.4498e-04,\n",
       "            -6.5920e-06, -1.3009e-03,  4.5395e-05, -9.6445e-05, -5.9967e-04,\n",
       "            -5.8427e-04, -1.6504e-04, -8.0049e-04, -1.1288e-03, -2.4932e-04,\n",
       "            -1.0197e-03, -3.1783e-04, -6.0609e-04, -1.6392e-03, -1.7851e-04,\n",
       "             9.1102e-04, -5.1958e-04, -7.1369e-04, -2.2777e-04, -5.1631e-04,\n",
       "            -7.1406e-04,  1.8753e-03, -5.5904e-04, -4.9524e-04, -7.9875e-04,\n",
       "             4.3753e-05, -8.0181e-04, -5.3378e-04,  2.5496e-05, -1.6002e-03,\n",
       "             1.3484e-03, -3.4344e-04, -6.6482e-04,  3.0824e-04, -5.5830e-04,\n",
       "            -5.9472e-04, -1.0522e-03, -5.9058e-04, -8.8591e-04, -1.9525e-03,\n",
       "            -9.0322e-04,  6.9883e-04,  2.7536e-03, -9.1213e-05, -6.8059e-04,\n",
       "            -8.4881e-04,  9.2427e-04], device='cuda:0')},\n",
       "   135: {'momentum_buffer': tensor([[[[-9.8813e-04]],\n",
       "    \n",
       "             [[-8.6266e-04]],\n",
       "    \n",
       "             [[-3.8106e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.0201e-03]],\n",
       "    \n",
       "             [[-6.2446e-04]],\n",
       "    \n",
       "             [[-1.3610e-03]]],\n",
       "    \n",
       "    \n",
       "            [[[-4.8834e-05]],\n",
       "    \n",
       "             [[ 3.4937e-04]],\n",
       "    \n",
       "             [[ 4.4095e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.3881e-05]],\n",
       "    \n",
       "             [[ 3.2139e-05]],\n",
       "    \n",
       "             [[-1.1048e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.7803e-04]],\n",
       "    \n",
       "             [[ 5.3361e-05]],\n",
       "    \n",
       "             [[ 6.9841e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.7815e-05]],\n",
       "    \n",
       "             [[-1.4130e-04]],\n",
       "    \n",
       "             [[ 4.0873e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-6.0010e-04]],\n",
       "    \n",
       "             [[ 1.8257e-04]],\n",
       "    \n",
       "             [[ 2.5605e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-8.3994e-04]],\n",
       "    \n",
       "             [[-1.7757e-04]],\n",
       "    \n",
       "             [[-3.9819e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-8.4735e-04]],\n",
       "    \n",
       "             [[ 5.7108e-04]],\n",
       "    \n",
       "             [[ 4.5807e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.1714e-04]],\n",
       "    \n",
       "             [[-4.4172e-05]],\n",
       "    \n",
       "             [[-4.8681e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 5.4168e-05]],\n",
       "    \n",
       "             [[-2.9702e-04]],\n",
       "    \n",
       "             [[-3.6251e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.1348e-04]],\n",
       "    \n",
       "             [[ 1.5440e-04]],\n",
       "    \n",
       "             [[-9.6416e-05]]]], device='cuda:0')},\n",
       "   136: {'momentum_buffer': tensor([0.0041, 0.0023, 0.0028,  ..., 0.0030, 0.0015, 0.0026], device='cuda:0')},\n",
       "   137: {'momentum_buffer': tensor([-0.0025, -0.0013, -0.0024,  ..., -0.0029, -0.0041, -0.0022],\n",
       "           device='cuda:0')},\n",
       "   138: {'momentum_buffer': tensor([[[[-2.1985e-04]],\n",
       "    \n",
       "             [[ 1.3553e-05]],\n",
       "    \n",
       "             [[-2.2073e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.5523e-04]],\n",
       "    \n",
       "             [[ 7.8515e-04]],\n",
       "    \n",
       "             [[ 2.3804e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.9406e-05]],\n",
       "    \n",
       "             [[ 3.3803e-05]],\n",
       "    \n",
       "             [[ 1.3482e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.5756e-05]],\n",
       "    \n",
       "             [[ 4.5613e-05]],\n",
       "    \n",
       "             [[ 2.3139e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-5.7219e-05]],\n",
       "    \n",
       "             [[ 3.9928e-05]],\n",
       "    \n",
       "             [[-7.5067e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-6.8274e-06]],\n",
       "    \n",
       "             [[ 8.3148e-05]],\n",
       "    \n",
       "             [[-7.1701e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-1.4474e-04]],\n",
       "    \n",
       "             [[-2.1225e-04]],\n",
       "    \n",
       "             [[ 2.0380e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 5.7846e-05]],\n",
       "    \n",
       "             [[-1.1745e-04]],\n",
       "    \n",
       "             [[ 1.4598e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.4707e-04]],\n",
       "    \n",
       "             [[-3.1982e-04]],\n",
       "    \n",
       "             [[ 1.8399e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.8688e-04]],\n",
       "    \n",
       "             [[-5.9834e-04]],\n",
       "    \n",
       "             [[-9.3796e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.6335e-06]],\n",
       "    \n",
       "             [[ 3.6721e-05]],\n",
       "    \n",
       "             [[-8.1084e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.9725e-04]],\n",
       "    \n",
       "             [[ 2.1337e-04]],\n",
       "    \n",
       "             [[ 1.4047e-04]]]], device='cuda:0')},\n",
       "   139: {'momentum_buffer': tensor([0.0023, 0.0020, 0.0024,  ..., 0.0020, 0.0011, 0.0021], device='cuda:0')},\n",
       "   140: {'momentum_buffer': tensor([-0.0025, -0.0013, -0.0024,  ..., -0.0029, -0.0041, -0.0022],\n",
       "           device='cuda:0')},\n",
       "   141: {'momentum_buffer': tensor([[[[-1.9380e-04]],\n",
       "    \n",
       "             [[ 7.9650e-05]],\n",
       "    \n",
       "             [[-1.2736e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.1775e-04]],\n",
       "    \n",
       "             [[-4.0780e-04]],\n",
       "    \n",
       "             [[-2.1298e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.1727e-04]],\n",
       "    \n",
       "             [[-3.4794e-04]],\n",
       "    \n",
       "             [[ 1.1755e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.2147e-04]],\n",
       "    \n",
       "             [[ 2.6408e-04]],\n",
       "    \n",
       "             [[ 2.4111e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.8737e-04]],\n",
       "    \n",
       "             [[-1.1143e-04]],\n",
       "    \n",
       "             [[ 1.6356e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-9.8781e-05]],\n",
       "    \n",
       "             [[ 1.9335e-04]],\n",
       "    \n",
       "             [[ 3.7433e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 2.4819e-04]],\n",
       "    \n",
       "             [[ 1.0251e-05]],\n",
       "    \n",
       "             [[ 5.9110e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.9552e-05]],\n",
       "    \n",
       "             [[ 4.4599e-04]],\n",
       "    \n",
       "             [[ 5.4066e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.2964e-04]],\n",
       "    \n",
       "             [[ 1.7640e-04]],\n",
       "    \n",
       "             [[ 1.0939e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.9974e-05]],\n",
       "    \n",
       "             [[-9.0998e-04]],\n",
       "    \n",
       "             [[ 1.5092e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.4180e-04]],\n",
       "    \n",
       "             [[ 1.8341e-05]],\n",
       "    \n",
       "             [[ 1.0528e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.1388e-04]],\n",
       "    \n",
       "             [[ 2.1704e-04]],\n",
       "    \n",
       "             [[ 6.0378e-05]]]], device='cuda:0')},\n",
       "   142: {'momentum_buffer': tensor([ 9.5659e-04,  2.1575e-03,  8.7843e-04,  2.3038e-03,  1.8810e-03,\n",
       "             2.3450e-04,  1.4515e-03,  1.7473e-03,  1.0034e-03,  7.8832e-04,\n",
       "             9.5550e-04,  1.2648e-03,  1.0703e-03,  3.4131e-03,  2.2488e-03,\n",
       "             6.7520e-04,  1.1291e-03,  1.4919e-03,  1.6033e-03,  1.0494e-03,\n",
       "             9.8847e-04,  1.7228e-03,  1.5905e-03,  1.6519e-03,  7.7994e-04,\n",
       "             1.2032e-03,  1.4211e-03,  2.5398e-03,  1.5012e-03,  1.2880e-03,\n",
       "             1.3050e-03,  1.5236e-03,  1.5232e-03,  1.3128e-03,  1.5511e-03,\n",
       "             9.5758e-04,  1.6059e-03,  2.5455e-03,  2.2478e-03,  9.0284e-04,\n",
       "             1.8188e-03,  1.7021e-03,  1.9882e-03,  1.7652e-03,  1.6556e-03,\n",
       "             1.7071e-03,  1.6696e-03,  1.6743e-03,  2.2705e-03,  8.8009e-04,\n",
       "             2.0106e-03,  1.7104e-03,  1.5295e-03,  1.6977e-03,  1.3017e-03,\n",
       "             2.1277e-03,  1.3528e-03,  1.6545e-03,  6.1562e-04,  2.0175e-03,\n",
       "             1.5672e-03,  1.5814e-03,  2.0783e-03,  1.6147e-03,  1.6813e-03,\n",
       "             1.0095e-03,  2.2618e-03,  2.0177e-03,  1.4879e-03,  9.4874e-04,\n",
       "             8.2310e-04,  8.9156e-04,  1.6934e-03,  1.4373e-03,  1.5566e-03,\n",
       "             1.4700e-03,  9.5089e-04,  1.7810e-03,  2.2659e-03,  1.6128e-03,\n",
       "             3.2393e-04,  8.5582e-04,  1.6491e-03,  1.5448e-03,  1.7946e-03,\n",
       "             1.5759e-03,  9.0226e-04,  2.5976e-03,  2.3273e-03,  1.4713e-03,\n",
       "             1.8761e-03,  1.7067e-03,  1.3423e-03,  1.2394e-03,  3.1101e-03,\n",
       "             1.0860e-03,  1.5197e-03,  5.7205e-04,  1.4601e-03,  1.2816e-03,\n",
       "             1.3409e-03,  2.6349e-03,  2.0307e-04,  6.4482e-04,  1.9676e-03,\n",
       "             1.2169e-03,  9.0490e-04,  2.6743e-03,  1.9621e-03,  2.0975e-03,\n",
       "             1.0218e-03,  9.6223e-04,  1.4922e-03,  3.0860e-03,  1.2450e-03,\n",
       "             1.8816e-03,  1.1395e-03,  1.4380e-03,  2.0649e-03,  1.0097e-03,\n",
       "             1.5489e-03,  1.3319e-03,  8.6550e-04,  3.2607e-03,  1.5784e-03,\n",
       "             1.0368e-03,  1.8546e-03,  1.0579e-03,  7.8347e-04,  1.2431e-03,\n",
       "             1.6312e-03,  2.1073e-03,  2.1005e-03,  8.7189e-04,  2.0291e-03,\n",
       "             1.8911e-03,  1.3450e-03,  1.3581e-03,  1.9881e-03,  1.9043e-03,\n",
       "             2.4245e-03,  1.9721e-03,  1.8127e-03,  2.6056e-03,  1.4547e-03,\n",
       "             1.7428e-03,  1.1855e-03,  2.5391e-03,  1.5020e-03,  6.2489e-04,\n",
       "             4.2593e-04,  1.3271e-03,  1.6736e-03,  1.8139e-03,  2.2074e-03,\n",
       "             2.3349e-03,  3.0356e-03,  1.4276e-03,  1.1953e-03,  1.8237e-03,\n",
       "             1.2395e-03,  2.0964e-03,  1.2808e-03,  1.6574e-03,  1.5940e-03,\n",
       "             1.6516e-03,  1.3682e-03,  1.4022e-03,  1.1695e-03,  1.7056e-03,\n",
       "             2.3110e-03,  1.3085e-03,  1.4353e-03,  7.8532e-04,  1.9088e-03,\n",
       "             9.4766e-04,  1.6554e-03,  1.4513e-03,  3.0806e-03,  2.0790e-03,\n",
       "             1.7606e-03,  1.4237e-03,  1.5114e-03,  1.0919e-03, -1.3783e-04,\n",
       "             1.7853e-03,  1.6906e-03,  1.3887e-03,  1.5033e-03,  1.6447e-03,\n",
       "             2.0233e-03,  1.1721e-03,  1.1100e-03,  7.5673e-04,  1.5405e-03,\n",
       "             6.3430e-04,  2.0165e-03,  7.3812e-04,  8.7202e-04,  1.8236e-03,\n",
       "             5.9852e-04,  6.0182e-04,  1.8770e-03,  1.0936e-03,  1.1188e-03,\n",
       "             4.0110e-04,  1.7133e-03,  1.1273e-03,  2.1290e-03,  9.1948e-04,\n",
       "             1.2043e-03,  2.0412e-03,  5.2247e-04,  1.2453e-03,  1.2179e-03,\n",
       "             8.2805e-04,  4.0021e-04,  1.3281e-03,  1.6541e-03,  9.3348e-04,\n",
       "             6.7566e-04,  9.8233e-04,  1.4136e-03,  1.5299e-03,  3.0782e-03,\n",
       "             2.1707e-03,  3.0320e-03,  1.1514e-03,  1.7821e-03,  1.2884e-03,\n",
       "             9.8223e-04,  1.8768e-03,  1.4193e-03,  1.3641e-03,  1.4082e-03,\n",
       "             1.6109e-03,  2.0668e-03,  2.4110e-03,  1.2167e-03,  1.3957e-03,\n",
       "             1.2344e-03,  7.4336e-04,  2.0562e-03,  1.1349e-03,  1.0553e-03,\n",
       "             1.4353e-03,  1.3500e-03, -5.1397e-04,  3.1678e-03,  9.8832e-04,\n",
       "             1.3114e-03,  1.4879e-03,  1.8357e-03,  7.2665e-04,  8.5428e-04,\n",
       "             2.1537e-03,  8.6432e-04,  5.3080e-04,  1.2118e-03,  1.7510e-04,\n",
       "             1.4170e-03,  1.2379e-03,  1.4808e-03,  1.3597e-03,  1.6343e-03,\n",
       "             3.6186e-05,  1.4771e-03,  1.7696e-03,  1.7296e-03,  7.4920e-04,\n",
       "             1.6476e-03,  8.3067e-04,  1.5945e-03,  8.5677e-04,  1.8553e-03,\n",
       "             1.5540e-03,  4.5398e-04,  1.2730e-03,  1.4381e-03,  1.6332e-03,\n",
       "             1.2590e-03,  1.8588e-03,  8.7997e-04,  1.3435e-03,  1.4394e-03,\n",
       "             5.7189e-04,  1.0404e-03,  1.1321e-03,  1.3279e-03,  2.2168e-03,\n",
       "             1.3923e-03,  2.2708e-03,  5.9083e-04,  1.6008e-03,  1.9199e-03,\n",
       "             1.7323e-03,  1.7049e-03,  2.2375e-03,  2.6259e-03,  8.9660e-04,\n",
       "             1.1642e-03,  2.5889e-03,  1.2632e-03,  1.6018e-03,  1.3498e-03,\n",
       "             3.1893e-03,  1.6110e-03,  1.2512e-03,  1.4970e-03,  1.6351e-03,\n",
       "             1.6821e-03,  1.3048e-03,  1.2391e-03,  1.1494e-03,  1.2398e-03,\n",
       "             1.3256e-03,  1.6780e-03,  4.8269e-04,  1.0666e-03,  1.3731e-03,\n",
       "             9.2757e-04,  1.2149e-03,  2.0212e-03,  2.3842e-03,  8.6821e-04,\n",
       "             1.8856e-03,  3.1388e-03,  2.7010e-03,  2.5090e-03,  1.7354e-03,\n",
       "             1.0937e-03,  9.8126e-04,  1.0053e-03,  1.0270e-03,  3.1434e-03,\n",
       "             1.3713e-03,  1.1775e-03,  1.5567e-03,  1.0847e-03,  1.1443e-03,\n",
       "             1.0923e-03,  9.0820e-04,  1.7898e-03,  1.0575e-03,  7.7756e-04,\n",
       "             1.4878e-03,  1.2400e-03,  1.9171e-03,  1.9358e-03,  6.2633e-04,\n",
       "             1.3212e-03,  1.2665e-03,  1.4893e-03,  2.6777e-03,  9.6829e-04,\n",
       "             1.8324e-03,  1.7798e-03,  1.7790e-03,  1.0534e-03,  1.4685e-03,\n",
       "             1.9508e-03,  1.6114e-03,  1.7409e-03,  1.5231e-03,  2.8655e-03,\n",
       "             4.9462e-04,  1.0558e-03,  1.9029e-03,  9.2779e-04,  1.2563e-03,\n",
       "             2.4774e-03,  1.0202e-03,  1.5874e-03,  1.4003e-03,  1.2544e-03,\n",
       "             3.0021e-03,  2.7981e-03,  1.2728e-03,  1.5403e-03,  1.4076e-03,\n",
       "             2.5763e-03,  1.9905e-03,  6.3602e-04,  2.2775e-03,  1.0911e-03,\n",
       "             1.5738e-03,  2.0181e-03,  1.5309e-03,  1.3460e-03,  1.4149e-03,\n",
       "             1.7874e-03,  1.1052e-03,  2.6443e-03,  2.2777e-03, -9.2574e-05,\n",
       "             1.3003e-03,  1.9659e-03,  1.5531e-03,  2.1807e-03,  1.0281e-03,\n",
       "             1.4672e-03,  2.2875e-03,  1.7899e-03,  1.9674e-03,  2.6032e-04,\n",
       "             8.1098e-04,  3.0503e-03,  2.0582e-03,  1.4136e-03,  1.1269e-03,\n",
       "             1.5125e-03,  1.0198e-03,  1.2836e-03,  1.1620e-03,  1.9561e-03,\n",
       "             1.0955e-03,  1.3526e-03,  1.2818e-03,  2.0279e-03,  2.5781e-03,\n",
       "             1.1862e-03,  1.7250e-03,  1.8496e-03,  1.1870e-03,  1.0622e-03,\n",
       "             2.0917e-03,  1.3215e-03,  1.2126e-03,  2.2026e-03,  1.5898e-03,\n",
       "             1.7527e-03,  1.3697e-03,  1.2081e-03,  1.3294e-03,  2.6545e-03,\n",
       "             7.0277e-04,  3.7213e-04,  9.8414e-04,  6.1418e-04,  1.4707e-03,\n",
       "             6.3743e-04,  1.4729e-03,  1.0374e-03,  9.3255e-04,  1.8256e-03,\n",
       "             1.7693e-03,  1.5298e-03,  7.8213e-04,  1.2147e-03,  1.7164e-03,\n",
       "             2.2565e-03,  1.2833e-03,  1.2981e-03,  1.9985e-03,  8.1418e-04,\n",
       "             5.1683e-04,  1.2664e-03,  6.7752e-04,  1.0811e-03,  8.5145e-04,\n",
       "             8.8894e-04,  1.2627e-03,  2.0638e-03,  6.8250e-04,  1.8514e-03,\n",
       "             1.5153e-03,  1.2337e-03,  1.4429e-03,  1.6556e-03,  9.4347e-04,\n",
       "             1.0542e-03,  1.6043e-03,  9.4075e-04,  1.6467e-03,  1.8662e-04,\n",
       "             1.6878e-03,  9.6977e-04,  1.8174e-03,  1.5146e-03,  1.4018e-03,\n",
       "             2.2579e-03,  1.5576e-03,  1.9346e-03,  1.7493e-03,  2.0347e-03,\n",
       "             2.0080e-03,  1.5603e-03,  1.9341e-03,  1.1141e-03,  1.6750e-03,\n",
       "             1.0924e-03,  1.4600e-03,  1.5113e-03,  1.5971e-03,  8.0624e-04,\n",
       "             1.5318e-03,  1.9585e-03,  8.8862e-04,  1.1629e-03,  8.0527e-04,\n",
       "            -4.4476e-05,  2.9029e-03,  4.8291e-04,  1.4750e-03,  1.4048e-03,\n",
       "             3.7793e-04,  1.1149e-03,  1.7649e-03,  1.9226e-03,  1.3345e-03,\n",
       "             1.1944e-03,  7.5229e-05], device='cuda:0')},\n",
       "   143: {'momentum_buffer': tensor([-1.1221e-03, -1.3910e-03, -1.2319e-03, -1.4983e-03, -1.1388e-03,\n",
       "            -1.6606e-03, -1.3564e-03, -5.7730e-04, -8.9810e-04, -6.7419e-04,\n",
       "            -7.0016e-04, -1.2388e-03, -1.3349e-03, -9.4556e-04, -3.2973e-03,\n",
       "            -9.8775e-04, -1.4622e-03, -1.0310e-03, -1.5618e-03, -1.0296e-03,\n",
       "            -6.6299e-04, -2.0004e-04, -1.1028e-03, -1.3957e-03, -9.6953e-04,\n",
       "            -5.6372e-05, -1.4265e-03, -2.1198e-03, -1.0830e-03, -1.1333e-03,\n",
       "            -1.1616e-03, -6.9384e-04, -9.5934e-04, -1.6987e-03, -8.1015e-04,\n",
       "            -2.5654e-04, -9.7334e-05, -4.1598e-04, -1.2526e-03, -5.4865e-04,\n",
       "            -1.3753e-03, -6.6129e-04, -8.5774e-04, -6.1389e-04, -5.3337e-05,\n",
       "            -1.5232e-03, -1.5523e-03, -4.2941e-05, -1.0724e-03, -1.3753e-03,\n",
       "            -1.3672e-03, -1.1745e-03,  6.5400e-04,  2.5645e-04, -1.1179e-03,\n",
       "            -1.8059e-03, -2.4034e-03, -4.8131e-04, -8.8460e-04, -7.2810e-04,\n",
       "             8.3032e-04, -2.0953e-04, -1.2979e-03, -6.8033e-04, -5.7770e-04,\n",
       "            -1.1639e-03, -1.3257e-03, -1.2696e-03,  2.9917e-04, -7.6967e-04,\n",
       "             7.0902e-04, -2.1844e-04, -8.0752e-04, -7.6120e-04, -1.5850e-03,\n",
       "            -1.5557e-03, -1.0639e-03, -1.4355e-03, -1.2190e-03, -6.9279e-04,\n",
       "            -1.2419e-03, -1.8514e-03, -4.2003e-04, -8.8657e-04, -5.3327e-04,\n",
       "            -1.1936e-03, -8.6606e-04, -2.3010e-03, -1.7337e-03, -1.1431e-03,\n",
       "            -5.6262e-04, -1.1331e-03, -1.7230e-03, -9.1732e-04, -3.7992e-03,\n",
       "            -9.0322e-04, -1.8528e-03, -2.3665e-04, -2.6812e-03,  1.3146e-05,\n",
       "            -1.3324e-03, -2.9901e-03, -1.1094e-03, -7.9380e-04,  1.8335e-04,\n",
       "            -7.8669e-04, -7.7015e-04, -9.7962e-05, -1.7779e-03, -1.2823e-03,\n",
       "             2.5271e-05, -9.2218e-04,  1.8770e-04, -3.6760e-03, -9.5552e-04,\n",
       "            -9.0892e-04, -3.8083e-04, -1.1418e-03, -1.3776e-03, -9.2227e-04,\n",
       "            -7.2409e-04, -2.4673e-04, -1.2976e-03, -2.5836e-03, -1.4101e-03,\n",
       "            -2.1809e-04,  1.5697e-04, -1.9133e-03, -8.4723e-04, -8.0346e-04,\n",
       "            -8.7908e-04, -7.4053e-04, -1.1387e-03, -2.1030e-03, -3.0169e-03,\n",
       "            -5.4591e-04, -4.8668e-04, -1.6272e-06, -1.5404e-03, -3.9234e-04,\n",
       "            -1.0743e-04, -1.2520e-03, -7.1578e-04, -6.2054e-04, -2.3927e-03,\n",
       "            -6.2557e-05, -7.8690e-04, -3.4156e-03, -2.1365e-04, -7.2806e-04,\n",
       "            -3.5739e-04, -1.8469e-03, -1.1253e-03, -5.9588e-04,  5.8459e-04,\n",
       "            -1.4679e-03,  9.6259e-05, -2.0693e-04, -5.4138e-04, -8.9782e-04,\n",
       "            -1.8998e-04, -1.4652e-03, -7.8905e-04, -9.4354e-05, -3.9911e-04,\n",
       "            -8.9629e-04, -7.0245e-04, -3.4167e-04, -1.1679e-03, -1.2676e-03,\n",
       "             1.1796e-04, -6.3562e-04, -1.2184e-03, -9.3437e-04, -6.0595e-04,\n",
       "            -8.6348e-04,  3.5381e-04, -9.8891e-04, -3.0642e-03, -8.0517e-04,\n",
       "            -1.4861e-03, -1.6511e-03, -4.8495e-04, -9.3710e-04, -1.1288e-03,\n",
       "            -7.0441e-05,  5.4157e-05, -1.5428e-04, -1.0468e-03, -2.1236e-03,\n",
       "            -9.9803e-04, -8.1494e-04, -1.8275e-04, -1.0338e-03, -2.0531e-04,\n",
       "            -8.3692e-04, -1.7325e-05, -7.7201e-04, -2.4474e-03, -1.1845e-03,\n",
       "            -1.6072e-03, -5.1463e-04, -1.7369e-03, -1.3920e-03, -9.7264e-04,\n",
       "            -1.8215e-03, -5.1689e-04, -8.5346e-04, -8.7564e-04, -1.6973e-03,\n",
       "             5.8048e-06, -3.0298e-03, -1.2198e-03, -5.4193e-04, -1.0732e-03,\n",
       "            -2.6776e-04, -1.2255e-03, -1.3425e-03, -1.6206e-03, -6.9223e-04,\n",
       "            -1.1468e-03, -3.0850e-04, -1.2109e-03, -8.5547e-04, -8.7085e-04,\n",
       "            -5.2640e-04, -2.7614e-03, -8.6306e-04, -5.1075e-04, -1.9358e-03,\n",
       "            -1.2114e-03, -1.8656e-03,  2.9863e-04, -1.0989e-03, -1.2847e-03,\n",
       "            -1.0874e-03, -1.0654e-03, -6.2168e-04, -1.0139e-03, -4.0425e-04,\n",
       "            -5.4263e-04,  1.2744e-04, -5.5068e-04, -1.4255e-03, -7.5317e-04,\n",
       "            -5.6485e-04, -1.7166e-03,  6.7654e-04, -2.5532e-03, -5.2422e-04,\n",
       "            -8.3238e-04, -7.2100e-04, -6.4069e-04, -1.6585e-03, -1.0749e-03,\n",
       "            -3.1440e-03, -3.7350e-04, -1.4896e-03, -2.3627e-03, -5.8991e-04,\n",
       "            -9.8789e-04, -1.0081e-03, -1.0577e-03, -1.2223e-03, -1.1616e-03,\n",
       "            -2.2607e-03, -4.3264e-04,  1.9473e-04, -8.9372e-04, -1.5693e-04,\n",
       "            -7.1496e-04, -1.2190e-03, -8.6925e-04, -1.4162e-03, -8.5833e-04,\n",
       "            -1.0675e-03, -1.6099e-03, -6.8112e-04, -8.3566e-04, -1.9410e-03,\n",
       "            -2.1472e-04, -1.0747e-03, -6.5516e-04,  1.6340e-04, -7.8359e-04,\n",
       "            -1.0872e-04, -7.5975e-04, -1.7710e-03, -9.6120e-04, -6.2365e-04,\n",
       "            -3.9893e-04,  1.7833e-05, -2.0348e-03, -8.8952e-04, -7.2058e-04,\n",
       "            -8.0240e-04, -1.1334e-03,  6.4996e-04, -1.7706e-04, -7.2208e-04,\n",
       "            -9.0475e-04, -1.0115e-03, -9.4378e-04, -9.0721e-04, -1.3083e-04,\n",
       "            -6.7112e-04, -7.9616e-04, -1.2331e-03, -8.1412e-04, -3.1511e-04,\n",
       "            -1.6631e-03, -6.7610e-04, -6.5286e-04, -6.2455e-04, -1.5535e-03,\n",
       "            -6.7949e-04, -1.3061e-03, -1.7865e-03, -1.7181e-03, -7.1916e-04,\n",
       "            -5.6527e-04, -5.3274e-04, -3.5491e-04, -1.2962e-03, -1.7473e-03,\n",
       "            -1.0737e-03, -1.5353e-03, -3.6892e-03, -1.2261e-03, -1.6130e-03,\n",
       "            -5.5704e-04, -1.2156e-03, -1.2982e-03, -1.0518e-03, -2.9773e-04,\n",
       "            -1.5467e-03, -7.4206e-04, -4.0980e-04, -1.3437e-03, -1.0297e-03,\n",
       "            -1.1136e-04, -1.5286e-03, -3.6378e-04, -1.0942e-03, -7.5506e-04,\n",
       "            -2.2687e-03, -5.8386e-04, -3.1519e-04, -3.4369e-04, -4.1446e-04,\n",
       "            -1.7753e-03, -5.6651e-04, -1.0583e-03, -2.9384e-03, -5.6969e-04,\n",
       "             5.5439e-04, -1.1823e-03,  3.5807e-04,  5.3873e-04, -5.4613e-04,\n",
       "            -7.1997e-04, -1.9311e-03, -1.5660e-03, -5.9855e-04, -7.8246e-04,\n",
       "            -1.1095e-03, -5.6919e-04, -1.8273e-05, -9.3499e-04, -7.0637e-04,\n",
       "            -1.3900e-03, -1.3665e-03, -1.5231e-03, -3.1580e-04, -1.2400e-03,\n",
       "            -3.6143e-03, -2.8320e-03,  2.4832e-04, -2.8163e-03, -1.1390e-03,\n",
       "            -1.2176e-03, -1.5811e-03, -1.4395e-03, -1.0400e-03, -8.4803e-04,\n",
       "            -1.2698e-03, -9.5870e-04, -7.7943e-04, -1.1927e-03, -6.5632e-04,\n",
       "            -1.5833e-03,  2.8278e-04, -1.6928e-03, -1.8547e-03, -1.3693e-04,\n",
       "            -6.3151e-04, -1.9504e-03, -1.4525e-03, -1.2682e-03, -1.3591e-03,\n",
       "            -8.0169e-04, -1.6872e-03, -1.4536e-03, -1.1544e-03, -1.6785e-03,\n",
       "            -1.1429e-03, -5.8264e-04, -2.4059e-03, -7.3986e-04, -2.4719e-04,\n",
       "            -7.7467e-04, -3.0941e-04, -9.9405e-04, -1.7614e-03, -7.9694e-04,\n",
       "            -1.2394e-03, -4.4095e-04, -1.3546e-03, -5.5614e-04, -5.2999e-04,\n",
       "            -5.3229e-04, -8.3230e-04, -1.8374e-04, -1.4001e-03, -9.0835e-05,\n",
       "            -1.7066e-03, -6.7478e-04, -1.4112e-03, -3.6843e-04, -1.0953e-03,\n",
       "            -1.5483e-04, -9.2090e-04, -6.1818e-04, -1.4779e-03, -1.8390e-03,\n",
       "            -1.9319e-03,  1.4344e-03,  8.1012e-05,  1.1071e-03, -7.2957e-04,\n",
       "             2.3627e-04, -8.5402e-04, -3.7157e-05, -1.7457e-04, -1.6363e-03,\n",
       "            -1.7332e-03, -1.5571e-03, -8.0650e-04, -9.5088e-04, -3.2576e-04,\n",
       "            -3.1719e-04, -1.4641e-03, -8.2269e-04, -3.0539e-04, -6.4680e-04,\n",
       "            -1.2705e-03, -9.3562e-04, -1.1192e-03, -1.1741e-03, -3.1274e-04,\n",
       "            -2.1975e-04,  9.8609e-04, -1.1716e-03, -1.2449e-03, -1.4949e-03,\n",
       "            -1.0583e-03, -8.9315e-04, -9.8573e-04,  3.2401e-04, -9.7415e-04,\n",
       "            -3.4766e-04, -5.3797e-04, -7.1242e-04, -1.1716e-03, -4.6843e-04,\n",
       "            -7.2216e-04, -9.2789e-04, -1.6558e-04,  3.5978e-04, -8.2758e-04,\n",
       "            -1.5302e-03, -9.5363e-04,  1.9614e-04, -3.1640e-03, -1.6825e-03,\n",
       "            -6.8728e-04,  8.0212e-05, -1.3011e-03, -8.9775e-04, -9.9117e-04,\n",
       "            -1.1239e-03, -7.0687e-04, -1.9388e-03, -1.1087e-03, -1.7722e-03,\n",
       "            -1.6157e-03, -7.9037e-04, -1.6518e-04, -1.1623e-03, -1.2324e-03,\n",
       "            -2.2642e-03,  1.7629e-04, -8.7829e-04, -3.1025e-04, -3.9843e-04,\n",
       "            -1.4179e-03, -1.0970e-03, -5.2619e-04, -1.3713e-03, -2.7256e-04,\n",
       "            -2.1063e-04, -1.8011e-03], device='cuda:0')},\n",
       "   144: {'momentum_buffer': tensor([[[[-1.7869e-06,  5.6256e-05, -1.1771e-05],\n",
       "              [-2.4682e-05,  6.7986e-06,  3.6202e-05],\n",
       "              [-1.3356e-05,  1.5977e-05,  1.4024e-06]],\n",
       "    \n",
       "             [[-7.7773e-06, -1.8682e-05, -2.1087e-05],\n",
       "              [-1.4033e-06,  9.6009e-05,  1.5937e-05],\n",
       "              [ 2.6506e-06,  6.5538e-05,  7.3562e-05]],\n",
       "    \n",
       "             [[ 8.9144e-05,  6.1844e-05,  6.0562e-05],\n",
       "              [ 4.3870e-05,  7.6556e-06, -1.6569e-05],\n",
       "              [ 1.6496e-04,  1.5892e-04,  7.9011e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.1286e-06, -4.1863e-05, -4.7881e-06],\n",
       "              [-1.6205e-04, -1.4773e-04, -5.3442e-05],\n",
       "              [-1.2639e-04, -3.8775e-05, -7.9305e-06]],\n",
       "    \n",
       "             [[ 1.0465e-04,  3.9391e-05, -2.4493e-05],\n",
       "              [ 1.3705e-04,  1.7603e-04,  7.4169e-05],\n",
       "              [ 1.9933e-04,  1.5810e-04,  4.1058e-05]],\n",
       "    \n",
       "             [[-4.2769e-06, -5.9167e-05, -2.9084e-05],\n",
       "              [-9.2137e-05, -1.9337e-04, -1.9388e-04],\n",
       "              [-1.8629e-06,  2.0163e-05,  7.7750e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.4021e-05,  3.2440e-04,  2.2031e-04],\n",
       "              [ 6.1331e-06, -2.7210e-05,  5.6252e-05],\n",
       "              [-8.5210e-05,  5.0894e-06, -5.9351e-05]],\n",
       "    \n",
       "             [[ 1.0955e-04, -6.9790e-06, -8.1833e-06],\n",
       "              [ 1.3462e-04,  3.1083e-04,  1.0494e-04],\n",
       "              [ 6.3076e-05,  7.2419e-05,  2.2351e-04]],\n",
       "    \n",
       "             [[-8.6736e-05, -1.0822e-04, -1.9569e-04],\n",
       "              [-7.6763e-05, -2.3150e-05,  7.9644e-06],\n",
       "              [ 5.6862e-05,  2.3912e-04,  2.0062e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-4.4938e-05,  1.3776e-05,  2.9107e-05],\n",
       "              [-6.0915e-05,  2.0543e-05, -3.9026e-05],\n",
       "              [ 2.5024e-05,  2.0070e-05,  1.8932e-05]],\n",
       "    \n",
       "             [[ 9.2388e-05,  6.6818e-05,  7.5175e-05],\n",
       "              [ 4.7286e-05,  8.9310e-06, -5.2942e-05],\n",
       "              [-5.7857e-05, -5.0516e-06, -1.3493e-04]],\n",
       "    \n",
       "             [[ 1.0833e-04,  1.5250e-04,  6.1800e-05],\n",
       "              [ 1.6971e-04,  2.1116e-04,  1.8783e-04],\n",
       "              [ 2.0730e-04,  1.7025e-04,  4.1996e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.4294e-04, -1.7303e-04, -1.0046e-04],\n",
       "              [-2.8628e-05,  2.5973e-05,  6.8092e-05],\n",
       "              [ 1.1236e-04,  1.8655e-05,  1.5892e-05]],\n",
       "    \n",
       "             [[ 4.9720e-05,  5.5384e-05,  8.0934e-05],\n",
       "              [ 5.1582e-05,  7.4532e-05, -1.2051e-05],\n",
       "              [ 6.9602e-05, -2.7028e-05,  8.4648e-05]],\n",
       "    \n",
       "             [[-1.7579e-04, -1.0141e-04,  6.4431e-05],\n",
       "              [-2.9038e-05, -7.1055e-05, -3.7935e-05],\n",
       "              [ 5.6530e-06,  3.6128e-05, -1.2250e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.9028e-05,  9.3332e-05,  3.7690e-05],\n",
       "              [-1.0366e-04,  1.6476e-05,  3.0861e-05],\n",
       "              [-8.5221e-05,  7.7720e-05,  1.0173e-04]],\n",
       "    \n",
       "             [[ 7.5954e-05,  2.9898e-05, -8.5140e-06],\n",
       "              [-2.0689e-05, -2.0268e-05, -1.5637e-05],\n",
       "              [-1.4294e-04, -3.9970e-05, -8.7103e-05]],\n",
       "    \n",
       "             [[-2.4762e-05, -1.4508e-05, -6.6895e-06],\n",
       "              [ 6.7062e-05, -3.3014e-06, -7.7161e-06],\n",
       "              [-2.4769e-05,  4.0273e-05,  7.4476e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.0847e-04,  1.9943e-04,  2.1507e-05],\n",
       "              [ 3.4792e-05,  6.8696e-05,  2.9777e-07],\n",
       "              [ 2.5885e-05,  1.1466e-04,  9.3950e-05]],\n",
       "    \n",
       "             [[ 3.5546e-04,  6.2863e-05,  3.5571e-04],\n",
       "              [ 2.9370e-04,  2.4132e-04,  4.4162e-04],\n",
       "              [ 2.9009e-04,  1.1869e-04,  3.9443e-04]],\n",
       "    \n",
       "             [[-9.7837e-05,  5.8186e-05, -2.4570e-05],\n",
       "              [-1.2418e-05, -1.5138e-04, -1.0303e-04],\n",
       "              [-7.7190e-05, -3.1902e-05, -7.7520e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.5769e-05,  4.4277e-05,  2.7123e-05],\n",
       "              [-1.5137e-04, -1.5237e-04, -1.2861e-04],\n",
       "              [-2.4930e-05, -8.5950e-05, -9.5943e-05]],\n",
       "    \n",
       "             [[-1.9077e-06, -7.8744e-05,  6.4045e-05],\n",
       "              [ 8.6296e-05,  3.7807e-05,  1.4594e-04],\n",
       "              [ 1.1824e-04,  2.5357e-04,  3.0997e-04]],\n",
       "    \n",
       "             [[-8.4502e-05, -7.3875e-05, -6.8284e-05],\n",
       "              [-4.4111e-05, -8.8162e-05, -5.9971e-05],\n",
       "              [ 8.6622e-05,  1.1117e-05, -1.5637e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.0703e-04, -2.4179e-04, -1.7322e-04],\n",
       "              [-8.6163e-05, -1.6698e-04, -1.7801e-04],\n",
       "              [-3.0573e-04, -7.8990e-05, -9.3883e-05]],\n",
       "    \n",
       "             [[ 2.0119e-04,  3.4366e-04,  1.5426e-04],\n",
       "              [ 2.2408e-04,  4.3178e-05, -9.3091e-05],\n",
       "              [ 1.3430e-04, -5.3382e-05, -8.2437e-05]],\n",
       "    \n",
       "             [[ 2.6584e-05,  1.2436e-04,  3.4990e-04],\n",
       "              [-1.1247e-04, -2.6724e-05,  2.1619e-04],\n",
       "              [-1.5193e-04, -1.7906e-04,  2.7257e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.0604e-04, -1.3171e-04, -8.6051e-05],\n",
       "              [-5.2388e-05, -1.8518e-04, -1.3964e-04],\n",
       "              [-1.1140e-04, -6.4137e-05,  4.0465e-05]],\n",
       "    \n",
       "             [[ 4.0434e-05,  1.3599e-05,  5.8214e-05],\n",
       "              [ 6.0693e-05,  3.8126e-05,  7.3643e-05],\n",
       "              [-2.6288e-06,  1.5752e-05, -9.4412e-05]],\n",
       "    \n",
       "             [[-1.9409e-04, -9.3627e-05, -1.6470e-04],\n",
       "              [-1.5465e-04, -1.9874e-04, -1.8870e-04],\n",
       "              [-1.2109e-04, -6.3536e-05,  5.5839e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 3.3024e-04,  4.3014e-04,  1.7013e-04],\n",
       "              [-1.5275e-04, -1.3302e-04, -3.7103e-04],\n",
       "              [-1.9154e-05, -1.4682e-04, -2.4336e-04]],\n",
       "    \n",
       "             [[ 4.0000e-04, -8.2193e-04, -6.2079e-04],\n",
       "              [ 6.0875e-04, -1.5988e-04, -1.7876e-04],\n",
       "              [ 4.9779e-04, -4.6485e-04, -1.7687e-04]],\n",
       "    \n",
       "             [[-1.8506e-04, -3.2178e-04, -3.0899e-04],\n",
       "              [-1.7084e-04, -5.6568e-04, -2.3200e-04],\n",
       "              [ 7.2381e-05, -3.6995e-05,  8.8597e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.8043e-04,  1.9095e-04,  1.2324e-04],\n",
       "              [ 1.9192e-04,  1.3140e-04,  9.7939e-05],\n",
       "              [ 1.0496e-04,  1.4415e-04,  5.3538e-05]],\n",
       "    \n",
       "             [[ 1.0152e-04, -2.4914e-04, -1.3985e-04],\n",
       "              [ 1.0372e-04, -1.6944e-04, -1.2260e-04],\n",
       "              [ 1.2913e-04, -1.8065e-05,  1.0960e-04]],\n",
       "    \n",
       "             [[ 2.0518e-04,  2.1371e-04,  2.1919e-04],\n",
       "              [ 8.2725e-05,  7.2973e-05, -6.0121e-05],\n",
       "              [-1.0643e-04, -1.7056e-04, -8.5100e-05]]]], device='cuda:0')},\n",
       "   145: {'momentum_buffer': tensor([ 0.0019,  0.0020,  0.0018,  0.0019,  0.0017,  0.0014,  0.0020,  0.0017,\n",
       "             0.0016,  0.0023,  0.0013,  0.0011,  0.0032,  0.0010,  0.0019,  0.0012,\n",
       "             0.0020,  0.0027,  0.0021,  0.0013,  0.0018,  0.0025,  0.0010,  0.0017,\n",
       "             0.0011,  0.0017,  0.0022,  0.0020,  0.0014,  0.0016,  0.0016,  0.0019,\n",
       "             0.0024,  0.0014,  0.0020,  0.0004,  0.0012,  0.0020,  0.0016,  0.0019,\n",
       "             0.0006,  0.0024,  0.0011,  0.0028,  0.0024,  0.0017,  0.0020,  0.0018,\n",
       "             0.0012,  0.0022,  0.0018,  0.0014,  0.0010,  0.0013,  0.0012,  0.0019,\n",
       "             0.0022,  0.0016,  0.0013,  0.0019,  0.0005,  0.0012,  0.0018,  0.0023,\n",
       "             0.0014,  0.0022,  0.0018,  0.0032,  0.0020,  0.0012, -0.0004,  0.0018,\n",
       "             0.0009,  0.0019,  0.0023,  0.0010,  0.0013,  0.0010,  0.0016,  0.0011,\n",
       "             0.0017,  0.0019,  0.0019,  0.0021,  0.0016,  0.0029,  0.0015,  0.0020,\n",
       "             0.0023,  0.0005,  0.0013,  0.0025,  0.0025,  0.0023,  0.0015,  0.0014,\n",
       "             0.0023,  0.0014,  0.0017,  0.0023,  0.0014,  0.0015,  0.0021,  0.0018,\n",
       "             0.0016,  0.0018,  0.0009,  0.0018,  0.0019,  0.0023,  0.0024,  0.0018,\n",
       "             0.0018,  0.0023,  0.0012,  0.0018,  0.0019,  0.0019,  0.0022,  0.0019,\n",
       "             0.0021,  0.0007,  0.0019,  0.0015,  0.0010,  0.0020,  0.0021,  0.0014,\n",
       "             0.0015,  0.0011,  0.0022,  0.0012,  0.0022,  0.0019,  0.0019,  0.0015,\n",
       "             0.0025,  0.0020,  0.0022,  0.0015,  0.0018,  0.0017,  0.0012,  0.0014,\n",
       "             0.0022,  0.0019,  0.0018,  0.0016,  0.0010,  0.0024,  0.0025,  0.0020,\n",
       "             0.0018,  0.0017,  0.0015,  0.0021,  0.0022,  0.0021,  0.0013,  0.0016,\n",
       "             0.0018,  0.0012,  0.0020,  0.0021,  0.0013,  0.0018,  0.0019,  0.0015,\n",
       "             0.0017,  0.0014,  0.0019,  0.0021,  0.0014,  0.0024,  0.0022,  0.0015,\n",
       "             0.0011,  0.0008,  0.0018,  0.0015,  0.0022,  0.0020,  0.0017,  0.0016,\n",
       "             0.0017,  0.0014,  0.0019,  0.0019,  0.0019,  0.0018,  0.0018,  0.0021,\n",
       "             0.0019,  0.0019,  0.0015,  0.0020,  0.0018,  0.0016,  0.0018,  0.0013,\n",
       "             0.0015,  0.0020,  0.0017,  0.0025,  0.0014,  0.0010,  0.0018,  0.0014,\n",
       "             0.0014,  0.0020,  0.0021,  0.0018,  0.0015,  0.0016,  0.0014,  0.0023,\n",
       "             0.0018,  0.0005,  0.0021,  0.0014,  0.0019,  0.0016,  0.0012,  0.0019,\n",
       "             0.0015,  0.0019,  0.0016,  0.0019,  0.0006,  0.0028,  0.0010,  0.0016,\n",
       "             0.0023,  0.0022,  0.0014,  0.0019,  0.0013,  0.0018,  0.0014,  0.0018,\n",
       "             0.0018,  0.0014,  0.0013,  0.0009,  0.0019,  0.0017,  0.0013,  0.0015,\n",
       "             0.0023,  0.0023,  0.0019,  0.0020,  0.0020,  0.0020,  0.0014,  0.0014,\n",
       "             0.0012,  0.0012,  0.0014,  0.0020,  0.0021,  0.0013,  0.0015,  0.0019,\n",
       "             0.0021,  0.0014,  0.0022,  0.0015,  0.0015,  0.0022,  0.0015,  0.0025,\n",
       "             0.0014,  0.0021,  0.0021,  0.0025,  0.0023,  0.0016,  0.0022,  0.0025,\n",
       "             0.0024,  0.0021,  0.0027,  0.0020,  0.0022,  0.0017,  0.0017,  0.0020,\n",
       "             0.0024,  0.0015,  0.0015,  0.0018,  0.0029,  0.0008,  0.0022,  0.0017,\n",
       "             0.0028,  0.0015,  0.0018,  0.0026,  0.0017,  0.0010,  0.0015,  0.0015,\n",
       "             0.0020,  0.0018,  0.0015,  0.0020,  0.0009,  0.0019,  0.0018,  0.0021,\n",
       "             0.0013,  0.0011,  0.0017,  0.0010,  0.0018,  0.0005,  0.0028,  0.0017,\n",
       "             0.0016,  0.0020,  0.0019,  0.0016,  0.0013,  0.0014,  0.0009,  0.0017,\n",
       "             0.0016,  0.0011,  0.0023,  0.0013,  0.0011,  0.0015,  0.0006,  0.0012,\n",
       "             0.0017,  0.0019,  0.0011,  0.0020,  0.0018,  0.0022,  0.0008,  0.0019,\n",
       "             0.0011,  0.0021,  0.0019,  0.0014,  0.0018,  0.0019,  0.0027,  0.0013,\n",
       "             0.0009,  0.0022,  0.0016,  0.0020,  0.0014,  0.0024,  0.0015,  0.0011,\n",
       "             0.0017,  0.0017,  0.0012,  0.0016,  0.0025,  0.0013,  0.0023,  0.0022,\n",
       "             0.0020,  0.0021,  0.0022,  0.0018,  0.0013,  0.0018,  0.0018,  0.0023,\n",
       "             0.0023,  0.0014,  0.0017,  0.0006,  0.0012,  0.0017,  0.0021,  0.0011,\n",
       "             0.0017, -0.0002,  0.0019,  0.0019,  0.0024,  0.0016,  0.0020,  0.0016,\n",
       "             0.0029,  0.0015,  0.0003,  0.0017,  0.0015,  0.0018,  0.0014,  0.0009,\n",
       "             0.0016,  0.0016,  0.0017,  0.0012,  0.0024,  0.0019,  0.0023,  0.0022,\n",
       "             0.0016,  0.0011,  0.0020,  0.0016,  0.0017,  0.0015,  0.0020,  0.0011,\n",
       "             0.0017,  0.0014,  0.0015,  0.0015,  0.0015,  0.0014,  0.0030,  0.0016,\n",
       "             0.0017,  0.0016,  0.0019,  0.0013,  0.0018,  0.0017,  0.0014,  0.0023,\n",
       "             0.0011,  0.0018,  0.0006,  0.0020,  0.0015,  0.0013,  0.0011,  0.0021,\n",
       "             0.0013,  0.0019,  0.0011,  0.0012,  0.0023,  0.0024,  0.0018,  0.0017,\n",
       "             0.0021,  0.0023,  0.0020,  0.0002,  0.0020,  0.0020,  0.0020,  0.0015,\n",
       "             0.0027,  0.0003,  0.0006,  0.0021,  0.0027,  0.0016,  0.0018,  0.0022,\n",
       "             0.0019,  0.0013,  0.0022,  0.0015,  0.0014,  0.0015,  0.0019,  0.0023,\n",
       "             0.0011,  0.0014,  0.0016,  0.0017,  0.0015,  0.0009,  0.0015,  0.0013,\n",
       "             0.0017,  0.0013,  0.0036,  0.0014,  0.0022,  0.0022,  0.0013,  0.0014,\n",
       "             0.0016,  0.0018,  0.0012,  0.0018,  0.0017,  0.0016,  0.0015,  0.0016,\n",
       "             0.0016,  0.0016,  0.0022,  0.0020,  0.0015,  0.0025,  0.0017,  0.0015,\n",
       "             0.0021,  0.0019,  0.0022,  0.0013,  0.0012,  0.0020,  0.0019,  0.0013],\n",
       "           device='cuda:0')},\n",
       "   146: {'momentum_buffer': tensor([-2.5122e-03, -5.5275e-04, -1.6392e-03, -4.0703e-04,  2.8274e-04,\n",
       "            -1.9663e-03, -1.0424e-03, -2.3369e-03, -1.0013e-03, -3.3662e-03,\n",
       "            -1.8638e-03, -1.0458e-03,  7.2493e-04, -6.5794e-04, -1.2528e-03,\n",
       "            -1.6419e-03, -1.3434e-03, -3.9296e-04, -2.5649e-03, -7.1841e-04,\n",
       "            -1.7220e-03, -2.0058e-03, -8.4252e-04, -1.2217e-03, -5.9877e-05,\n",
       "            -2.3948e-03, -1.4075e-03, -2.1546e-03, -1.3628e-03, -1.1832e-04,\n",
       "            -8.6428e-04, -8.5303e-04, -6.9294e-04, -1.1379e-03, -1.2680e-03,\n",
       "             9.5512e-04, -6.1973e-04, -1.2371e-03, -1.0154e-03, -2.5460e-04,\n",
       "            -2.3010e-03, -2.2250e-03, -1.1739e-03, -8.9828e-04, -2.2832e-03,\n",
       "            -2.5244e-03, -2.3944e-03, -9.1280e-04, -2.0009e-03, -2.2470e-03,\n",
       "            -4.6714e-04, -5.3999e-04, -1.6123e-03, -1.5352e-03, -1.3122e-03,\n",
       "            -1.2386e-03, -8.2401e-04, -1.1719e-03, -6.4857e-04, -9.4958e-04,\n",
       "            -2.1118e-03, -1.5281e-03, -8.7796e-04, -1.8159e-03, -2.7796e-03,\n",
       "            -5.8353e-04, -1.7699e-03, -2.0364e-03, -1.9206e-03, -1.2093e-03,\n",
       "             2.2306e-03, -1.6618e-03,  1.0782e-04, -8.7470e-04, -1.3001e-03,\n",
       "            -2.1820e-03, -1.6519e-03, -1.2338e-03, -9.6545e-04, -1.3340e-03,\n",
       "            -1.1214e-03, -1.3674e-03,  7.5004e-04, -6.4588e-04, -7.1618e-04,\n",
       "            -2.2224e-03, -2.7841e-03, -1.6165e-03, -1.4856e-03, -3.2736e-04,\n",
       "            -1.6335e-03, -1.5642e-03, -1.8589e-03, -1.4685e-03, -2.1095e-03,\n",
       "            -1.9388e-03, -2.0269e-03, -2.2922e-03, -2.4526e-03, -1.1293e-03,\n",
       "            -1.7809e-03, -7.6396e-04, -3.5365e-03, -2.2482e-03, -3.9741e-04,\n",
       "            -2.2344e-03, -1.7348e-03, -2.0005e-03, -4.0600e-04, -2.9104e-03,\n",
       "            -1.1690e-03, -1.8446e-03, -1.0195e-03, -3.4416e-03, -1.0255e-03,\n",
       "            -9.6751e-04, -1.8746e-04, -4.0537e-04, -2.7688e-03, -5.3630e-04,\n",
       "            -7.7392e-04, -1.7297e-03, -2.1965e-03, -2.2358e-03, -2.5186e-04,\n",
       "            -4.8980e-04, -5.8531e-04, -2.6808e-03, -4.9434e-04, -1.0242e-03,\n",
       "            -1.7274e-03, -1.3701e-03, -9.4343e-04, -1.0338e-03, -8.5431e-04,\n",
       "            -2.1054e-03, -1.6559e-03, -6.1141e-04, -2.5158e-03, -9.4080e-04,\n",
       "            -2.4453e-03, -9.5129e-04, -2.1156e-03, -2.9163e-03, -1.7768e-03,\n",
       "            -4.7251e-04, -2.6180e-03, -6.1681e-04, -2.7329e-03, -1.7666e-03,\n",
       "            -3.8984e-03, -9.6792e-04, -1.5042e-03, -9.1580e-04, -4.9218e-04,\n",
       "            -2.1796e-03, -2.3172e-04, -1.2635e-03, -7.4854e-04, -1.3627e-03,\n",
       "            -1.0261e-03, -1.1850e-03, -1.8810e-03, -1.4206e-04, -4.7602e-04,\n",
       "            -1.8821e-03, -1.6463e-03, -1.3123e-03, -1.2678e-03, -1.8865e-03,\n",
       "            -1.4050e-03, -1.4450e-03, -1.7356e-03, -1.7360e-03,  1.9269e-06,\n",
       "            -8.2965e-04, -1.4212e-03, -1.1729e-03, -1.9757e-03, -3.2567e-03,\n",
       "            -2.0324e-03,  6.9024e-05, -6.9620e-04, -1.2567e-03, -2.1646e-03,\n",
       "            -1.6322e-03, -2.5419e-03, -4.0434e-04, -2.2834e-03, -1.0427e-03,\n",
       "            -1.9320e-03, -2.7090e-03, -1.3361e-03, -1.7072e-03, -1.0928e-03,\n",
       "            -1.2917e-03, -3.1525e-03, -1.7142e-03, -1.6634e-03, -1.2447e-03,\n",
       "            -1.8629e-03, -1.4445e-03, -4.1358e-04, -2.9952e-04, -6.6617e-04,\n",
       "            -1.4128e-03, -2.0562e-03, -9.7832e-04, -1.6244e-03, -1.4462e-03,\n",
       "            -1.7678e-03, -1.7901e-03, -1.1463e-03, -7.1230e-04, -9.9409e-04,\n",
       "            -1.3326e-03,  5.7223e-04, -1.1384e-03, -5.2234e-04, -1.3627e-03,\n",
       "            -1.2706e-03, -7.7541e-04, -1.3557e-03, -1.1739e-03, -9.2076e-04,\n",
       "            -6.2675e-04, -7.7142e-04, -1.6918e-03, -2.2257e-04, -1.8096e-03,\n",
       "            -1.5535e-03, -1.9541e-04, -2.4151e-04, -9.8569e-04, -1.7184e-03,\n",
       "            -2.1120e-03, -6.9328e-04, -1.4050e-03, -4.7552e-04, -1.1118e-03,\n",
       "            -2.6383e-03, -1.5121e-03, -3.0813e-03, -1.5080e-03, -1.0925e-03,\n",
       "            -1.0666e-03, -2.2640e-03, -2.6946e-03, -1.8569e-03, -9.1601e-04,\n",
       "            -2.9590e-03,  1.6760e-03, -2.3254e-03, -1.3803e-03, -7.7068e-04,\n",
       "            -1.5352e-03,  1.2357e-04, -1.0570e-03, -1.8538e-03, -3.3759e-04,\n",
       "            -7.5512e-04, -1.7544e-03, -1.4198e-03, -1.5003e-03, -1.6229e-03,\n",
       "            -1.8863e-03, -8.7269e-04, -1.0753e-03, -1.7329e-03,  7.8011e-05,\n",
       "            -6.4125e-04, -2.1428e-03, -1.9358e-03, -1.6497e-03, -2.2310e-03,\n",
       "             5.3011e-04, -6.9514e-04, -1.0324e-03, -1.5693e-03, -1.3817e-03,\n",
       "            -1.7074e-03, -8.0520e-04, -1.2701e-03, -8.8861e-04, -3.0797e-03,\n",
       "            -2.2850e-03, -1.4985e-03, -1.7739e-03, -1.9115e-03,  1.6053e-04,\n",
       "            -9.7891e-04, -3.4698e-04, -2.4989e-03, -1.1908e-03, -2.8685e-03,\n",
       "            -1.5667e-03, -3.4688e-03, -2.8607e-04, -3.0946e-04, -2.3287e-03,\n",
       "            -9.0056e-04, -1.3256e-03, -1.4944e-03, -2.0996e-03, -6.5945e-04,\n",
       "            -1.9311e-03, -7.1197e-04, -2.5076e-03, -1.7152e-03, -5.7400e-04,\n",
       "            -5.6370e-04, -1.2454e-03, -1.9845e-03, -1.6419e-03, -1.5012e-03,\n",
       "            -1.1967e-03, -1.5914e-03, -1.7493e-03, -1.8449e-03, -2.8005e-03,\n",
       "            -1.0393e-03, -1.5878e-03, -1.5420e-03, -3.8387e-04, -2.6025e-03,\n",
       "            -1.3090e-03, -1.5181e-03, -9.4328e-04, -5.4502e-04, -5.6004e-04,\n",
       "            -2.3710e-03, -3.8139e-04, -2.1135e-03, -7.6990e-04, -6.0616e-04,\n",
       "            -1.1323e-03, -2.0932e-03, -1.0860e-03, -2.3462e-03, -1.0125e-03,\n",
       "            -1.6843e-03, -1.7124e-03, -5.2138e-04, -1.5247e-03, -9.9719e-04,\n",
       "            -5.4518e-04, -2.4020e-03, -4.6102e-04, -1.6253e-03, -2.4235e-03,\n",
       "            -1.0447e-04, -1.6232e-03, -1.2838e-03, -1.7114e-03, -9.4655e-04,\n",
       "            -7.1766e-04, -1.0260e-03, -2.0697e-03, -1.6094e-03, -9.6602e-04,\n",
       "            -2.6236e-03, -2.7387e-03, -5.0776e-04, -9.6329e-04, -2.3562e-03,\n",
       "            -1.6524e-03, -1.9148e-04, -8.4011e-04, -1.6756e-03, -3.2487e-05,\n",
       "            -2.3839e-03, -1.8126e-03, -1.5941e-03, -1.2027e-03, -1.9856e-03,\n",
       "            -1.6998e-03, -1.3489e-03,  2.9709e-03, -2.1201e-03, -1.6015e-03,\n",
       "            -1.5215e-03, -5.9450e-04, -1.1909e-03,  2.1676e-03, -1.0261e-03,\n",
       "            -7.2847e-04,  2.4829e-03, -2.1558e-03, -9.1768e-04, -1.4746e-03,\n",
       "            -1.5006e-03, -9.4009e-04, -1.5915e-03, -8.5536e-04, -2.0877e-03,\n",
       "            -6.9756e-04, -1.0146e-03, -6.2804e-04, -1.6659e-03,  1.8518e-05,\n",
       "            -1.9591e-03, -9.3088e-04, -1.6350e-03, -1.6358e-03, -9.0157e-04,\n",
       "            -1.6032e-03, -1.4320e-03, -1.5399e-03, -2.5750e-03, -1.6421e-03,\n",
       "            -1.8182e-03, -1.9521e-03, -9.6681e-04, -3.2353e-04, -3.6383e-03,\n",
       "             1.2519e-03, -1.4029e-03, -1.3045e-03, -2.5553e-03, -1.7635e-03,\n",
       "            -6.3506e-04,  6.2813e-05, -1.2322e-03, -1.0887e-03, -2.3556e-03,\n",
       "            -1.1450e-03, -1.5187e-03, -1.3412e-03,  6.6543e-04, -5.9762e-04,\n",
       "            -1.2818e-03, -5.5445e-04, -1.9141e-03,  5.9548e-05, -1.2753e-03,\n",
       "            -1.6530e-03, -1.1034e-03,  1.6824e-04, -1.2044e-03, -1.1919e-03,\n",
       "            -5.7022e-04, -9.9558e-04, -1.4928e-03, -1.3130e-03, -1.2459e-03,\n",
       "            -2.4950e-03, -1.2061e-03, -2.1793e-03, -8.1790e-04, -1.8140e-03,\n",
       "            -1.4742e-03, -1.6125e-03,  5.2344e-04, -1.3894e-03, -1.6324e-03,\n",
       "             2.7586e-04, -1.6826e-03, -1.9774e-03, -2.9500e-03, -2.7576e-03,\n",
       "            -2.2097e-03, -1.0312e-03, -1.6124e-03, -1.9473e-03, -1.0431e-03,\n",
       "            -1.6348e-03, -2.3127e-03, -1.5707e-03, -2.0799e-04, -1.9624e-03,\n",
       "            -1.2667e-03, -1.8560e-03, -9.0870e-04, -1.2692e-03, -1.3092e-03,\n",
       "            -1.0633e-03, -3.4541e-04, -1.6575e-03, -1.4519e-03, -9.7371e-04,\n",
       "            -5.2520e-04, -5.5578e-04, -2.1618e-04, -5.0277e-04, -1.0226e-03,\n",
       "            -1.0802e-03, -7.5126e-04, -8.6469e-04, -1.6084e-03, -2.0596e-03,\n",
       "            -8.2039e-04, -6.9715e-04, -1.4013e-03, -9.3024e-04, -1.6879e-03,\n",
       "            -4.1161e-04, -6.5751e-04, -5.3701e-04, -1.3217e-03, -1.9589e-03,\n",
       "            -1.3933e-03, -2.4927e-03, -3.6473e-04, -9.8162e-04, -1.0432e-03,\n",
       "            -2.4942e-03, -2.6044e-03, -1.1965e-03, -1.6832e-03, -1.6994e-03,\n",
       "            -9.6492e-04, -1.0794e-03], device='cuda:0')},\n",
       "   147: {'momentum_buffer': tensor([[[[-4.1479e-04]],\n",
       "    \n",
       "             [[-4.7465e-04]],\n",
       "    \n",
       "             [[-6.8219e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-7.5695e-04]],\n",
       "    \n",
       "             [[-1.0862e-04]],\n",
       "    \n",
       "             [[-3.2992e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.8547e-06]],\n",
       "    \n",
       "             [[-1.2868e-04]],\n",
       "    \n",
       "             [[-1.2775e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.4337e-05]],\n",
       "    \n",
       "             [[-3.0679e-04]],\n",
       "    \n",
       "             [[-3.0953e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.9265e-05]],\n",
       "    \n",
       "             [[-4.2966e-05]],\n",
       "    \n",
       "             [[ 5.3207e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-8.1558e-05]],\n",
       "    \n",
       "             [[-1.2944e-05]],\n",
       "    \n",
       "             [[ 4.4938e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 7.4127e-05]],\n",
       "    \n",
       "             [[-1.1918e-04]],\n",
       "    \n",
       "             [[ 3.8398e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.7938e-04]],\n",
       "    \n",
       "             [[-1.1103e-04]],\n",
       "    \n",
       "             [[-2.6620e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.2606e-04]],\n",
       "    \n",
       "             [[ 6.5693e-04]],\n",
       "    \n",
       "             [[-1.5893e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 3.6165e-04]],\n",
       "    \n",
       "             [[-8.8929e-04]],\n",
       "    \n",
       "             [[-8.5159e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-1.2617e-04]],\n",
       "    \n",
       "             [[-3.0319e-04]],\n",
       "    \n",
       "             [[-1.2896e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.4526e-05]],\n",
       "    \n",
       "             [[ 1.4546e-06]],\n",
       "    \n",
       "             [[-1.1936e-04]]]], device='cuda:0')},\n",
       "   148: {'momentum_buffer': tensor([0.0017, 0.0014, 0.0019,  ..., 0.0017, 0.0004, 0.0020], device='cuda:0')},\n",
       "   149: {'momentum_buffer': tensor([-0.0024, -0.0027, -0.0031,  ..., -0.0035, -0.0034, -0.0033],\n",
       "           device='cuda:0')},\n",
       "   150: {'momentum_buffer': tensor([[[[ 1.6081e-04]],\n",
       "    \n",
       "             [[-2.3362e-05]],\n",
       "    \n",
       "             [[ 1.3494e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 6.0175e-05]],\n",
       "    \n",
       "             [[-4.6495e-04]],\n",
       "    \n",
       "             [[-1.2714e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 8.6155e-05]],\n",
       "    \n",
       "             [[ 1.7076e-05]],\n",
       "    \n",
       "             [[ 3.1329e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 1.1793e-05]],\n",
       "    \n",
       "             [[ 1.2861e-05]],\n",
       "    \n",
       "             [[ 2.4154e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 9.9669e-05]],\n",
       "    \n",
       "             [[-1.5775e-05]],\n",
       "    \n",
       "             [[-9.0815e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.7996e-05]],\n",
       "    \n",
       "             [[-1.4704e-05]],\n",
       "    \n",
       "             [[ 6.3396e-05]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 5.5735e-04]],\n",
       "    \n",
       "             [[ 1.9214e-05]],\n",
       "    \n",
       "             [[ 6.1267e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.1818e-05]],\n",
       "    \n",
       "             [[ 6.4877e-05]],\n",
       "    \n",
       "             [[-1.8261e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.1207e-05]],\n",
       "    \n",
       "             [[-9.3495e-05]],\n",
       "    \n",
       "             [[-4.8841e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 4.5181e-04]],\n",
       "    \n",
       "             [[-6.1497e-05]],\n",
       "    \n",
       "             [[ 4.8696e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[ 2.2243e-04]],\n",
       "    \n",
       "             [[ 1.2265e-04]],\n",
       "    \n",
       "             [[ 4.3354e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.8458e-04]],\n",
       "    \n",
       "             [[ 3.2097e-04]],\n",
       "    \n",
       "             [[-5.4607e-05]]]], device='cuda:0')},\n",
       "   151: {'momentum_buffer': tensor([ 1.7226e-03,  2.6188e-03,  1.5817e-03,  2.5639e-03,  1.2976e-03,\n",
       "             2.6801e-03,  1.7086e-03,  1.5398e-03,  1.8983e-03,  2.4880e-03,\n",
       "             9.2093e-04,  7.8572e-04,  2.3415e-03,  1.8507e-03,  1.5027e-03,\n",
       "             1.6381e-03,  1.6159e-03,  1.2522e-03,  1.6261e-03,  1.6058e-03,\n",
       "             2.3389e-03, -6.1133e-04,  2.1827e-03,  4.1096e-04,  2.3799e-03,\n",
       "             9.8313e-04,  1.1567e-03,  2.1301e-03,  5.6711e-03,  1.1381e-03,\n",
       "             2.4253e-03,  2.4054e-03,  1.3869e-03,  1.5153e-03,  2.0151e-03,\n",
       "             7.2058e-04,  1.6356e-03,  2.2751e-03,  2.3367e-03,  3.1815e-03,\n",
       "             1.8698e-03,  2.0546e-03,  1.9907e-03, -8.5629e-05,  1.9443e-03,\n",
       "             2.1791e-04,  2.2569e-03,  5.7262e-04,  1.4781e-03,  1.8771e-03,\n",
       "             7.1432e-04,  3.0589e-04,  2.9830e-03,  1.8184e-03,  1.5902e-03,\n",
       "             2.0371e-03,  2.3829e-03,  2.5543e-03,  1.4392e-03,  1.0877e-03,\n",
       "             1.9318e-03,  1.6270e-03,  1.0292e-03,  1.9023e-03,  1.9785e-03,\n",
       "             1.5510e-03,  2.5688e-03,  7.6323e-04,  1.7348e-03,  6.4354e-04,\n",
       "             2.0981e-03,  1.8117e-03,  2.1897e-03,  1.9459e-03,  2.2688e-03,\n",
       "             1.6275e-03,  3.9619e-03,  1.4027e-03,  1.7755e-03,  1.4605e-03,\n",
       "             2.5147e-03,  2.2738e-03,  2.2210e-03,  1.3384e-03,  2.8487e-03,\n",
       "             2.3602e-03,  3.1239e-03,  2.1798e-03,  2.5699e-03,  1.6583e-03,\n",
       "             1.3104e-03,  3.0822e-03,  1.6903e-03,  2.0098e-03,  2.3865e-03,\n",
       "             2.6880e-03,  1.1014e-03,  1.7734e-03,  6.3621e-04,  2.5277e-03,\n",
       "            -6.1028e-06,  1.4301e-03,  1.6321e-03,  1.1272e-03,  2.3874e-03,\n",
       "             1.9898e-03,  3.7613e-04,  2.6205e-03,  2.9250e-03,  1.6775e-03,\n",
       "             8.6464e-04,  2.2835e-03,  1.2081e-03,  1.8282e-03,  4.3200e-04,\n",
       "             2.4013e-03,  6.7424e-04,  1.7034e-03,  1.6323e-03,  1.0220e-03,\n",
       "             1.0799e-03,  1.5120e-03,  1.9240e-03,  1.9315e-03,  2.4692e-03,\n",
       "             1.2580e-03, -3.8590e-04,  1.3624e-03,  9.2544e-04,  1.5065e-03,\n",
       "             5.7892e-04,  2.5114e-03,  2.5529e-03,  1.5655e-05,  1.7690e-03,\n",
       "             2.5090e-03, -2.3312e-04,  2.2570e-03,  2.5661e-03,  1.5639e-03,\n",
       "             8.2016e-04,  1.9459e-03,  1.0083e-03,  1.5596e-03,  1.8510e-03,\n",
       "             3.2361e-03,  9.1638e-04,  1.7290e-03,  8.7919e-04,  6.8735e-04,\n",
       "             1.6970e-03, -3.8822e-04,  2.2378e-03,  3.2363e-03,  1.3393e-03,\n",
       "             1.1507e-03,  1.3953e-03,  2.3790e-03,  1.4330e-03,  1.6560e-03,\n",
       "             2.2704e-03,  1.7727e-03,  1.7814e-03,  1.7533e-03,  2.6719e-03,\n",
       "             2.3955e-03,  1.6759e-03,  4.5941e-04,  7.1096e-04,  2.3814e-03,\n",
       "             2.0513e-03,  2.3088e-03,  2.1366e-03,  1.0861e-03,  9.3990e-04,\n",
       "             1.8039e-03,  1.0411e-03,  2.7771e-03,  1.3578e-03,  2.2324e-03,\n",
       "             2.1602e-03,  1.7409e-03,  2.3940e-03,  1.4707e-03,  1.6139e-03,\n",
       "             1.4722e-03,  4.3351e-04,  1.7334e-03,  1.6724e-03,  7.1897e-04,\n",
       "             2.1194e-03,  1.9000e-03,  6.1787e-04,  1.1866e-03,  1.7800e-03,\n",
       "             1.4542e-03,  7.2199e-04,  1.1901e-03,  1.3943e-03,  2.1323e-03,\n",
       "             1.3282e-03,  9.9547e-04,  1.3924e-03,  8.2639e-04,  1.4501e-03,\n",
       "             8.7613e-04,  1.4419e-03,  2.5637e-03,  5.3789e-04,  2.2697e-03,\n",
       "             6.6050e-05,  1.4936e-03,  1.4037e-03,  7.5931e-04,  1.6658e-03,\n",
       "             1.6991e-03,  1.7237e-03,  2.3632e-03,  9.1491e-04,  2.8836e-03,\n",
       "             2.5568e-03,  1.0931e-03,  1.6290e-03,  1.6529e-03,  1.1089e-03,\n",
       "             8.1903e-04,  1.0924e-03,  1.9132e-03,  1.3889e-03, -3.2907e-04,\n",
       "             1.2552e-03,  1.8240e-03,  1.3823e-03,  2.8692e-03,  2.7135e-03,\n",
       "             2.1354e-03,  1.0383e-03,  8.9268e-04,  1.8146e-03,  2.3155e-03,\n",
       "             2.1395e-03,  1.2137e-03,  2.0910e-03,  2.3362e-03,  1.4173e-03,\n",
       "             2.2324e-03,  2.9212e-03,  8.7884e-04,  5.3475e-03,  8.8823e-04,\n",
       "            -3.4791e-04,  1.2628e-03,  2.8140e-03,  1.0675e-03,  2.4942e-03,\n",
       "             2.1274e-03, -1.8812e-05,  9.9318e-04,  1.0710e-03,  2.0469e-03,\n",
       "             1.1802e-03,  2.4692e-03,  1.9173e-03,  2.2689e-03,  1.8126e-03,\n",
       "             2.7234e-05,  8.8170e-04,  1.6628e-03,  1.4222e-03,  1.9476e-03,\n",
       "             1.6106e-03,  1.7399e-03,  1.0467e-03,  8.8435e-04,  3.8234e-04,\n",
       "             5.6697e-04,  1.0071e-03,  3.3647e-04,  1.7282e-03,  2.5024e-03,\n",
       "             2.3142e-03,  2.1757e-03,  1.2475e-03,  5.0630e-04,  2.9553e-04,\n",
       "             8.2597e-04,  2.6536e-03,  3.8698e-04,  7.3828e-04,  2.2339e-03,\n",
       "             8.3428e-04,  1.1133e-03,  1.6213e-03,  1.9297e-03,  2.1410e-03,\n",
       "             2.2012e-03,  2.3014e-03,  1.6495e-03,  1.5087e-03,  7.8427e-04,\n",
       "             2.3283e-03,  1.5631e-03,  1.9024e-03,  1.2288e-03,  2.1779e-03,\n",
       "             9.7993e-04,  2.1895e-03,  3.4063e-03,  1.0411e-03,  1.0852e-03,\n",
       "             2.6677e-03,  1.0947e-03,  1.9155e-03,  2.6831e-03,  1.4380e-03,\n",
       "             2.0342e-04, -6.8260e-04,  2.0522e-03,  2.9290e-03,  2.1311e-03,\n",
       "             1.8082e-04,  1.1721e-03,  1.2009e-03,  1.0225e-03,  3.6979e-03,\n",
       "             1.1526e-03,  1.8663e-03,  1.2264e-03,  1.3155e-03,  1.7196e-03,\n",
       "             7.7389e-04,  1.9918e-03,  4.3520e-03,  2.0945e-03,  2.3202e-03,\n",
       "             1.4855e-03,  1.9804e-03,  1.3645e-03,  1.3773e-04,  6.1163e-04,\n",
       "             1.4148e-03,  2.7396e-04,  2.5971e-03,  2.6818e-03,  1.4581e-03,\n",
       "             1.0717e-03,  1.2919e-03,  1.7448e-03,  1.7661e-03,  2.2910e-03,\n",
       "             1.7385e-03,  1.1107e-03,  1.2518e-03,  1.8873e-03,  1.5736e-03,\n",
       "             3.6770e-04,  1.5949e-03,  1.5531e-03,  2.6516e-03,  2.4973e-04,\n",
       "             1.7993e-03,  2.0028e-03,  1.8203e-03,  1.4855e-03,  1.4785e-03,\n",
       "             1.0426e-03,  1.6592e-03,  7.7433e-04,  2.0602e-03,  1.7317e-03,\n",
       "             1.4387e-03,  2.3798e-03,  1.7277e-03,  1.2818e-03,  1.9689e-03,\n",
       "             1.2636e-03,  1.1732e-03,  2.3122e-03,  1.1365e-03,  2.0177e-03,\n",
       "             5.5714e-04,  1.3889e-03,  2.0123e-04,  1.9423e-03,  1.2796e-03,\n",
       "             9.4760e-04,  2.1278e-03,  1.2676e-03,  2.1717e-03,  2.4325e-03,\n",
       "             7.4233e-04,  1.3622e-03,  4.9444e-04,  1.9444e-03,  1.7009e-03,\n",
       "             1.4847e-03,  1.2730e-03, -1.2919e-04,  2.3479e-03,  1.5887e-03,\n",
       "             1.0847e-03,  7.4290e-05,  2.4593e-03,  3.0272e-03,  1.6307e-03,\n",
       "             1.4665e-03,  1.4980e-03,  6.7304e-04,  2.0483e-03,  3.4154e-04,\n",
       "             1.7983e-03,  2.1948e-03, -3.2951e-04,  2.6100e-03,  2.0622e-03,\n",
       "             2.5488e-03, -2.0817e-03,  9.1322e-04,  6.4799e-04,  3.3009e-03,\n",
       "             1.3128e-03,  1.9925e-03,  1.9419e-03,  1.8520e-03,  1.3009e-03,\n",
       "             2.4693e-03,  2.4410e-03,  1.0804e-03,  1.7571e-03,  1.4532e-03,\n",
       "             1.4028e-03,  1.7875e-03,  2.5441e-03,  2.8886e-03,  2.1290e-03,\n",
       "             1.8941e-03,  1.2764e-04,  2.9220e-03,  2.0051e-03,  1.5953e-03,\n",
       "             2.4368e-03,  2.7797e-03,  2.2982e-03,  1.5904e-03,  2.8094e-03,\n",
       "            -3.0908e-04,  1.4781e-03,  5.3873e-04,  2.7787e-03,  1.8170e-03,\n",
       "            -4.1193e-04,  2.4913e-03,  9.7493e-04,  1.9737e-03,  2.5752e-03,\n",
       "             1.0986e-03,  2.6283e-03,  2.9787e-03,  1.4866e-03,  4.2546e-05,\n",
       "             1.6918e-03,  1.9901e-03,  1.8079e-03,  1.9448e-03,  1.7269e-03,\n",
       "             1.0551e-03,  1.2527e-03,  1.4814e-03,  1.2053e-03,  1.3865e-03,\n",
       "            -8.9344e-05,  1.8809e-03,  8.5508e-04,  1.3701e-03,  2.3435e-04,\n",
       "             2.0173e-03,  2.7769e-03,  1.8057e-03,  1.3894e-03,  1.7583e-03,\n",
       "             1.7619e-03,  2.1589e-03,  1.8566e-03,  2.0335e-03,  2.2361e-03,\n",
       "             1.9144e-03,  1.1463e-03, -4.4336e-04,  1.1989e-03,  2.5843e-03,\n",
       "             1.2984e-03,  2.2406e-03,  8.9160e-04,  1.6748e-03, -3.9846e-05,\n",
       "             8.1536e-04,  1.6216e-03,  1.2673e-03,  1.9160e-04,  1.6282e-03,\n",
       "             2.1794e-03,  2.0175e-03,  4.3896e-04,  1.1443e-03,  1.4534e-04,\n",
       "             2.2303e-03,  9.5486e-04,  2.1605e-03,  2.8484e-03,  2.6005e-03,\n",
       "             2.4409e-03,  1.0248e-03], device='cuda:0')},\n",
       "   152: {'momentum_buffer': tensor([-1.3820e-03, -2.9085e-03, -7.5082e-04, -1.6878e-03, -2.0844e-03,\n",
       "            -8.2921e-04, -1.9645e-03,  7.5739e-04, -7.1976e-04, -2.8052e-03,\n",
       "            -1.6120e-03, -1.2526e-03, -2.4675e-03, -2.4650e-04, -1.6770e-03,\n",
       "            -3.4238e-03, -6.5253e-04, -1.2853e-03, -1.2467e-03,  1.2265e-03,\n",
       "            -4.4809e-04, -3.0559e-03, -7.1162e-04,  8.7642e-04, -9.7044e-04,\n",
       "            -1.8876e-03, -6.8375e-04, -5.0391e-04, -1.5831e-03, -8.8830e-04,\n",
       "            -7.0919e-04, -3.1195e-03, -2.3410e-03, -1.5132e-03, -6.1400e-04,\n",
       "            -1.7176e-03, -2.3327e-03, -2.6003e-03,  1.1152e-04, -1.7044e-03,\n",
       "            -2.2863e-03, -2.3063e-03, -1.9190e-03, -1.2673e-03, -2.7116e-03,\n",
       "            -1.3059e-03, -1.2649e-03, -8.7309e-04, -1.4132e-03, -1.7962e-03,\n",
       "             3.3516e-04, -2.0083e-03, -2.1654e-03, -1.3807e-03, -1.7062e-03,\n",
       "            -1.9472e-03, -2.2712e-03, -1.7349e-04, -5.4660e-04, -1.7642e-03,\n",
       "            -3.7339e-04, -1.8821e-03, -5.5309e-04,  5.8212e-04, -3.0208e-03,\n",
       "            -1.2562e-03, -4.6525e-04, -4.2237e-04, -1.0656e-03, -8.0545e-04,\n",
       "            -1.6300e-03,  5.3151e-04, -1.6101e-03, -9.7144e-04, -1.9885e-03,\n",
       "            -1.4883e-03,  1.2402e-03, -6.4591e-04, -1.1258e-03, -2.4459e-03,\n",
       "            -2.0867e-03, -2.2664e-03,  1.3380e-04, -8.7637e-04, -1.9333e-03,\n",
       "            -1.9124e-03, -1.5393e-03, -1.7488e-03, -2.3733e-03, -5.9637e-04,\n",
       "            -2.9649e-03, -1.7621e-03, -6.9936e-04, -1.0000e-05, -2.9227e-03,\n",
       "            -2.5734e-03, -2.3653e-03, -2.2724e-03, -7.2494e-04, -7.5305e-04,\n",
       "             6.6896e-04, -1.9124e-03, -2.1792e-03, -1.6276e-03, -2.6068e-03,\n",
       "            -2.0056e-03, -1.4506e-03, -2.7587e-03,  6.1757e-04, -1.6500e-03,\n",
       "            -1.8167e-03, -1.7050e-03, -3.4986e-04, -2.1682e-03, -1.3930e-03,\n",
       "            -6.4375e-04, -1.0446e-03, -1.7236e-03, -2.0217e-03, -1.1272e-03,\n",
       "            -1.0381e-03, -6.9547e-04, -1.2145e-03, -8.4742e-04, -1.4246e-03,\n",
       "             5.1845e-04, -1.4264e-03, -1.7916e-03, -1.2893e-03, -6.7054e-04,\n",
       "             5.1999e-04, -1.0936e-03, -2.5147e-03, -1.3164e-03, -4.8657e-04,\n",
       "            -3.1492e-03, -7.9304e-04, -2.2712e-03, -3.0941e-03, -6.7502e-04,\n",
       "            -1.9905e-03, -2.3264e-03, -8.3258e-04, -5.8631e-04,  7.1042e-04,\n",
       "            -1.8755e-03, -1.5089e-03, -2.4933e-03, -3.0315e-05, -1.5651e-04,\n",
       "            -2.6017e-03, -2.2162e-03, -2.7114e-03, -1.7802e-03, -2.0476e-03,\n",
       "            -1.8823e-03, -1.6344e-03, -2.5947e-03, -4.2677e-04,  2.8895e-04,\n",
       "            -1.4162e-03, -2.8252e-03, -2.8059e-03, -2.0762e-03, -2.8281e-03,\n",
       "            -2.1332e-03, -2.4688e-03, -3.3640e-03, -1.2810e-03, -2.1969e-03,\n",
       "            -1.8291e-03, -1.0304e-03, -1.1394e-03, -6.6406e-04, -9.4858e-04,\n",
       "            -2.5080e-03,  2.1930e-04, -2.2545e-03, -1.7203e-03, -2.7772e-03,\n",
       "            -1.8464e-03, -9.6476e-04, -2.5424e-03, -2.0397e-03, -2.3149e-03,\n",
       "            -1.2440e-03,  6.4950e-04, -1.1728e-03, -1.6191e-03, -5.2693e-04,\n",
       "            -2.5860e-03, -2.5464e-03,  7.4466e-04, -8.2664e-04, -5.1486e-04,\n",
       "            -3.2265e-04, -1.2738e-03, -7.8353e-04, -2.6617e-03, -2.2516e-03,\n",
       "            -1.3859e-03, -1.1818e-03, -1.3215e-03, -2.3260e-04, -1.2538e-03,\n",
       "            -1.1968e-03, -9.5077e-04, -1.9284e-04, -1.0916e-03, -2.3970e-03,\n",
       "            -1.8648e-03, -2.2100e-03, -1.3498e-03, -3.7440e-03, -1.3502e-03,\n",
       "            -1.5109e-03, -1.0716e-03, -1.7826e-03, -2.3957e-03, -2.1306e-03,\n",
       "             2.6246e-03, -1.2629e-03, -1.4053e-03, -2.8345e-04, -4.5214e-04,\n",
       "            -8.1116e-04, -9.7493e-04,  3.1290e-04, -9.9778e-04, -2.0346e-03,\n",
       "            -2.8200e-03,  2.1914e-03, -1.9357e-03, -2.7939e-03, -2.5467e-03,\n",
       "            -2.3073e-03, -8.1707e-04, -2.1004e-03, -2.4300e-03, -2.6558e-03,\n",
       "            -1.4378e-03, -1.1416e-03, -2.4312e-03, -2.2461e-03, -9.8612e-04,\n",
       "            -1.1220e-03, -2.7465e-03, -1.0790e-03, -5.1652e-04, -1.8023e-03,\n",
       "             4.0030e-04, -1.2855e-03, -2.9995e-03, -2.1657e-03, -3.2977e-03,\n",
       "            -2.5795e-03, -1.5800e-03, -1.1284e-03, -1.0893e-03, -1.2321e-03,\n",
       "            -9.3933e-04, -3.2006e-03, -1.9413e-03, -2.1473e-03, -1.7610e-03,\n",
       "            -3.3437e-05, -1.1920e-03, -1.1057e-04, -6.9604e-04, -1.9124e-03,\n",
       "            -2.2190e-04, -1.7401e-03, -9.7038e-04, -1.6506e-03,  3.8615e-05,\n",
       "            -1.3219e-03, -9.0838e-04, -5.9722e-04, -1.8309e-03, -1.2771e-03,\n",
       "            -1.4207e-03,  1.4808e-03, -9.5940e-04, -3.5178e-04, -1.0690e-03,\n",
       "            -9.8721e-04, -2.6141e-03, -1.5417e-03, -9.3852e-04, -2.9226e-03,\n",
       "            -1.0775e-03, -1.0244e-03, -1.9704e-03, -2.6533e-03, -2.1371e-03,\n",
       "            -2.3275e-03, -2.1541e-03, -8.0058e-04, -1.1754e-03, -8.6228e-04,\n",
       "            -2.2333e-03, -1.3058e-03, -1.0125e-03, -9.4537e-04, -1.7173e-03,\n",
       "            -5.6803e-04, -4.2475e-04, -1.2411e-04, -1.0963e-03, -4.9124e-04,\n",
       "            -2.2040e-03, -1.3027e-03, -1.6828e-03, -1.7905e-03, -1.8151e-03,\n",
       "            -1.5861e-03, -1.7262e-03, -1.7702e-03,  5.8053e-04,  4.8362e-04,\n",
       "            -1.3402e-03, -4.6768e-04, -2.6868e-04, -1.2714e-03, -6.6108e-04,\n",
       "            -7.8223e-04, -1.7621e-03, -1.5510e-03, -1.2442e-03, -5.6622e-04,\n",
       "            -7.2082e-04, -2.6889e-03,  5.4499e-04, -2.4735e-03, -2.0037e-03,\n",
       "            -1.7489e-03, -8.5003e-04, -6.9487e-04, -2.6698e-03, -1.5582e-03,\n",
       "            -6.3177e-04, -1.2028e-03, -1.9247e-03, -2.7444e-03, -1.7071e-03,\n",
       "            -4.9498e-04, -2.5923e-03, -2.0642e-03, -2.8038e-03, -2.2703e-03,\n",
       "            -1.9790e-03, -2.2425e-04, -4.6328e-04, -7.7811e-04, -1.9390e-03,\n",
       "            -2.0565e-03, -1.7046e-03, -4.8139e-04, -2.2017e-03, -1.2429e-03,\n",
       "            -2.5079e-03, -1.9095e-03, -5.2607e-04, -1.0874e-03, -2.2698e-03,\n",
       "             6.2519e-04, -2.5819e-04, -1.1906e-03, -2.6010e-03, -2.3480e-03,\n",
       "             8.4812e-05, -6.4958e-04, -8.0738e-04, -8.7345e-04, -2.2099e-03,\n",
       "            -2.2178e-03, -2.8324e-04, -1.3916e-03, -8.1660e-04, -2.8335e-03,\n",
       "            -6.3595e-04, -2.0347e-03, -2.4222e-03, -1.2388e-03, -6.9873e-04,\n",
       "            -1.9527e-03, -2.6306e-03, -1.3678e-03, -2.7415e-03, -1.3251e-03,\n",
       "            -9.3356e-04,  4.9762e-05,  8.0366e-04, -2.5229e-03,  6.1205e-04,\n",
       "            -1.7885e-03, -8.0808e-04, -1.2960e-03, -1.4110e-03, -1.9488e-03,\n",
       "            -1.9084e-03, -1.6792e-03, -2.7332e-03, -1.5440e-03, -2.3365e-03,\n",
       "            -7.9458e-04, -3.2826e-04, -1.5436e-03, -1.0360e-03,  5.5069e-04,\n",
       "            -1.4519e-03, -3.0013e-03, -1.8596e-03, -2.7228e-03, -3.3083e-03,\n",
       "            -2.5761e-03, -3.6115e-03, -7.2852e-04, -1.2049e-03, -2.0671e-03,\n",
       "             6.2121e-04, -2.2728e-03, -5.6136e-04, -1.0354e-03, -4.9221e-04,\n",
       "            -9.0000e-04, -2.6757e-03, -6.7814e-04, -2.0677e-03, -8.9351e-04,\n",
       "            -9.2633e-04, -1.5123e-03, -2.0849e-03, -1.0125e-03, -3.0706e-04,\n",
       "            -2.4830e-03,  1.0586e-05, -8.7131e-04, -2.5112e-03, -1.5389e-03,\n",
       "            -1.7052e-03, -4.5923e-04, -2.3613e-03, -5.2656e-03, -2.7807e-03,\n",
       "            -2.2950e-03, -2.1140e-03, -4.5536e-04, -6.8326e-05, -2.3043e-03,\n",
       "            -6.9118e-04, -8.8180e-04, -1.9396e-03, -2.5351e-04, -2.2305e-03,\n",
       "            -8.2064e-04, -2.3887e-03, -2.3574e-03, -2.1066e-03, -7.9402e-04,\n",
       "             3.2894e-04, -1.4156e-03, -9.4518e-04, -5.4286e-04, -1.6511e-03,\n",
       "            -6.6197e-04, -4.5853e-04, -8.6699e-04, -7.2519e-05, -3.3536e-04,\n",
       "            -1.3859e-03, -7.6806e-04, -3.2222e-04, -1.5386e-03, -9.3357e-04,\n",
       "            -1.2546e-03, -2.7059e-03, -1.0368e-03, -1.3228e-03, -1.3601e-03,\n",
       "            -6.6758e-04, -1.5580e-03, -8.9669e-04, -1.5794e-03,  2.4713e-03,\n",
       "            -1.1744e-03, -1.2649e-03, -9.4199e-04, -1.2842e-03, -1.2151e-03,\n",
       "            -7.8763e-04, -1.9666e-04, -8.5398e-04, -1.8516e-03, -1.6624e-03,\n",
       "            -1.7520e-03, -1.1468e-03, -7.0348e-04, -1.3792e-03, -7.8532e-05,\n",
       "            -2.4493e-03,  2.6778e-04, -2.1270e-03, -4.7160e-04, -1.8912e-03,\n",
       "            -2.5388e-03, -2.2782e-03, -5.5189e-04, -1.8977e-03, -1.1536e-03,\n",
       "            -1.7131e-03, -1.1193e-03], device='cuda:0')},\n",
       "   153: {'momentum_buffer': tensor([[[[-5.8233e-05,  3.6716e-05, -1.6248e-05],\n",
       "              [ 1.3070e-05,  1.1347e-06, -1.7727e-05],\n",
       "              [-1.8782e-06,  5.2841e-05,  1.9051e-05]],\n",
       "    \n",
       "             [[-8.2402e-05, -9.2747e-05, -1.0086e-04],\n",
       "              [-9.6919e-05, -9.2065e-05, -8.5837e-05],\n",
       "              [-3.4458e-05, -7.6817e-05, -7.7995e-05]],\n",
       "    \n",
       "             [[ 1.9502e-04,  2.1045e-04,  1.2568e-04],\n",
       "              [ 2.7462e-04,  4.6697e-04,  8.9622e-05],\n",
       "              [ 1.1632e-04,  1.0566e-04,  6.1979e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.0663e-04,  1.4660e-04,  1.9662e-04],\n",
       "              [ 1.6109e-04,  1.6868e-04,  1.9274e-04],\n",
       "              [ 8.1572e-05,  1.0599e-04,  8.0926e-05]],\n",
       "    \n",
       "             [[ 1.9129e-05, -1.3487e-05, -1.1775e-04],\n",
       "              [ 8.9465e-05,  6.7216e-06, -6.7596e-06],\n",
       "              [ 1.4475e-05, -8.1273e-05, -1.1002e-04]],\n",
       "    \n",
       "             [[-1.6777e-04, -1.7636e-04, -1.2797e-04],\n",
       "              [-3.0230e-05, -6.3980e-05, -8.1473e-05],\n",
       "              [-3.4993e-05,  6.3638e-06, -1.4859e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.7343e-05,  3.1655e-05, -4.7741e-05],\n",
       "              [-1.6991e-05, -8.2870e-05, -2.8821e-05],\n",
       "              [-5.0250e-05, -1.6099e-04, -1.6273e-04]],\n",
       "    \n",
       "             [[-5.1404e-05, -1.1345e-04, -8.8567e-05],\n",
       "              [-2.9281e-05, -1.1948e-04, -1.1035e-04],\n",
       "              [-2.4544e-05, -4.0163e-05, -7.4886e-05]],\n",
       "    \n",
       "             [[ 9.1622e-06, -4.2849e-05,  1.2532e-04],\n",
       "              [-6.8292e-04, -1.8963e-04,  2.0407e-04],\n",
       "              [ 2.0290e-04,  2.6516e-04,  2.1955e-04]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.5668e-05, -4.4132e-05, -9.8610e-06],\n",
       "              [ 1.2426e-04, -3.1054e-05, -6.7131e-06],\n",
       "              [ 1.1727e-04,  1.2377e-04,  1.1857e-04]],\n",
       "    \n",
       "             [[ 6.3204e-05,  1.8628e-05,  9.8244e-05],\n",
       "              [ 3.3090e-05, -2.3717e-05, -5.6909e-06],\n",
       "              [-4.4771e-05, -3.4859e-05, -1.2635e-04]],\n",
       "    \n",
       "             [[-8.9224e-05, -1.6749e-04, -2.5871e-04],\n",
       "              [-8.5190e-05, -1.7039e-04, -2.9480e-04],\n",
       "              [-2.5686e-04, -3.1580e-04, -2.7254e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 6.2585e-06, -1.1783e-05, -7.1521e-06],\n",
       "              [ 1.4758e-06, -6.5302e-06,  5.0794e-06],\n",
       "              [ 2.8139e-05,  2.2366e-05,  6.8693e-06]],\n",
       "    \n",
       "             [[-7.4079e-06, -5.0460e-06, -1.5180e-06],\n",
       "              [-8.5942e-06, -1.2556e-05, -5.0888e-07],\n",
       "              [ 4.9676e-06,  3.3607e-06,  4.8968e-06]],\n",
       "    \n",
       "             [[-7.6829e-05, -3.0028e-05, -8.0834e-05],\n",
       "              [-3.8642e-05,  3.9914e-05, -3.6664e-05],\n",
       "              [-5.3867e-05, -1.7591e-05, -5.7389e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 7.5110e-06, -3.6336e-06,  2.3086e-06],\n",
       "              [ 7.6709e-06, -5.9816e-06,  4.6793e-06],\n",
       "              [ 3.4695e-06, -7.8131e-06,  1.9004e-05]],\n",
       "    \n",
       "             [[-1.0961e-05,  7.1329e-07, -1.5607e-05],\n",
       "              [ 4.7333e-06,  1.3110e-06, -1.4634e-05],\n",
       "              [-1.1451e-05, -6.2846e-06, -2.1011e-05]],\n",
       "    \n",
       "             [[-7.7899e-06, -1.8314e-05, -1.6902e-05],\n",
       "              [-2.4677e-06, -5.3191e-06,  1.4889e-06],\n",
       "              [-3.1334e-06, -6.6088e-06, -6.6365e-06]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[-1.8240e-05, -1.1801e-05, -9.3106e-06],\n",
       "              [-1.9391e-05, -1.0546e-05, -1.1098e-05],\n",
       "              [-1.2271e-05, -4.3024e-06, -1.3974e-05]],\n",
       "    \n",
       "             [[-1.0111e-05, -2.0261e-05, -2.1290e-05],\n",
       "              [-1.2762e-05, -1.3356e-05, -1.9540e-05],\n",
       "              [-1.2864e-06, -1.0430e-05, -4.1192e-06]],\n",
       "    \n",
       "             [[-2.6440e-05, -2.1848e-05, -2.6965e-06],\n",
       "              [-1.7994e-05,  9.5908e-05, -8.2901e-06],\n",
       "              [-7.5188e-06, -4.8551e-06, -6.1140e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-2.1210e-05, -2.1913e-05, -1.9576e-05],\n",
       "              [-4.1190e-05, -2.2919e-05, -3.7349e-05],\n",
       "              [-2.9329e-05, -3.4033e-05, -3.6682e-05]],\n",
       "    \n",
       "             [[-2.4811e-05, -2.1977e-05,  5.0678e-06],\n",
       "              [-2.3706e-05, -1.3977e-05, -1.1189e-05],\n",
       "              [-2.1237e-05,  5.9022e-06,  2.1654e-06]],\n",
       "    \n",
       "             [[ 5.9694e-06,  1.4514e-05,  1.4394e-06],\n",
       "              [ 4.8036e-06, -1.5769e-06, -5.9853e-06],\n",
       "              [-2.3326e-05, -1.8471e-05, -3.4435e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.1324e-05, -2.2724e-06, -6.5693e-06],\n",
       "              [-6.4422e-06, -2.0349e-06, -9.8453e-06],\n",
       "              [-2.6114e-06,  2.2347e-05, -1.7461e-05]],\n",
       "    \n",
       "             [[-6.9709e-06, -2.5356e-06, -1.5405e-05],\n",
       "              [ 9.2375e-07, -1.0249e-05, -9.4925e-06],\n",
       "              [ 5.9541e-07, -3.9283e-06, -8.9543e-06]],\n",
       "    \n",
       "             [[ 1.0257e-05,  7.7892e-05,  3.3270e-05],\n",
       "              [ 1.9502e-05,  2.0634e-04,  2.7426e-05],\n",
       "              [ 7.9882e-06,  4.5293e-05,  1.1452e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 9.6266e-05,  1.1169e-04,  8.9201e-05],\n",
       "              [ 1.0336e-04,  1.4684e-04,  1.0344e-04],\n",
       "              [ 7.7398e-05,  9.6379e-05,  8.2844e-05]],\n",
       "    \n",
       "             [[ 7.4439e-06,  1.7093e-05,  3.9273e-05],\n",
       "              [-2.2412e-05,  5.3043e-05,  2.4677e-05],\n",
       "              [ 7.4808e-06,  5.4147e-07, -2.9737e-05]],\n",
       "    \n",
       "             [[ 1.7351e-05,  1.9091e-05,  2.0798e-06],\n",
       "              [-5.5141e-06,  7.4662e-06,  1.0703e-05],\n",
       "              [ 6.1669e-07,  1.1968e-05, -3.7192e-06]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.0323e-04,  1.0772e-04,  9.9815e-05],\n",
       "              [ 1.9212e-04,  1.6767e-04,  1.5438e-04],\n",
       "              [ 2.0829e-04,  1.7341e-04,  1.6212e-04]],\n",
       "    \n",
       "             [[-4.3605e-05, -3.9741e-05, -3.3873e-05],\n",
       "              [ 3.4108e-06,  2.9891e-05,  2.3212e-05],\n",
       "              [ 5.2292e-05,  2.2839e-05,  5.0512e-05]],\n",
       "    \n",
       "             [[-1.7411e-05, -1.5038e-04, -6.0373e-05],\n",
       "              [-2.0142e-04,  1.3335e-04, -7.4544e-05],\n",
       "              [ 2.9599e-05,  6.4224e-07, -5.0930e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.6993e-04, -1.7848e-04, -4.8272e-05],\n",
       "              [-1.6564e-04, -1.6606e-04, -9.0043e-05],\n",
       "              [-1.9348e-04, -2.3048e-04, -1.4887e-04]],\n",
       "    \n",
       "             [[-2.8945e-06, -4.7869e-05,  4.9536e-05],\n",
       "              [ 9.8929e-06, -1.4016e-04, -7.2030e-05],\n",
       "              [ 2.5866e-05, -1.7657e-04, -2.4353e-04]],\n",
       "    \n",
       "             [[-6.4034e-05, -1.1830e-04, -6.4714e-05],\n",
       "              [ 3.1178e-05,  5.0932e-05, -4.7878e-05],\n",
       "              [-8.9917e-06, -5.4500e-05, -6.8543e-05]]]], device='cuda:0')},\n",
       "   154: {'momentum_buffer': tensor([ 1.6919e-03,  3.3139e-04,  2.6321e-03,  1.3206e-03, -2.6022e-04,\n",
       "             1.8021e-03,  5.7169e-04,  3.2124e-04,  1.8760e-03,  2.0170e-03,\n",
       "             1.2460e-03,  2.5152e-04,  9.8742e-04,  1.9250e-03,  9.7545e-04,\n",
       "             2.4194e-03,  4.8027e-04,  6.7086e-04,  2.4653e-03,  1.8541e-03,\n",
       "             1.7438e-03,  2.4307e-04,  2.1250e-03, -5.6605e-04,  2.1901e-03,\n",
       "             1.4674e-03,  7.3444e-04,  1.9197e-03,  2.0021e-03,  1.4216e-03,\n",
       "             2.3060e-03,  1.9138e-03,  1.7911e-03, -4.2371e-04,  1.0487e-03,\n",
       "             5.9136e-04,  1.2068e-04, -1.5690e-04,  1.0581e-03,  2.1794e-03,\n",
       "             1.7219e-03,  1.0910e-03,  2.1678e-03,  1.1323e-03,  6.9596e-04,\n",
       "             1.3736e-03,  1.7992e-03,  2.1832e-03, -8.9656e-06,  1.3394e-03,\n",
       "             1.5613e-03,  7.7337e-04,  2.1183e-03,  1.5569e-03,  1.4222e-03,\n",
       "             6.7704e-04,  2.6166e-03, -1.4987e-04,  1.7709e-03,  2.2965e-03,\n",
       "            -4.0359e-04,  2.0371e-03, -1.9081e-04,  1.3738e-03,  4.4929e-04,\n",
       "             1.5523e-03,  1.9046e-03,  3.2213e-04,  1.2432e-03,  3.3041e-04,\n",
       "            -4.0969e-04,  8.9411e-04,  2.4123e-03,  9.9590e-04,  1.0805e-03,\n",
       "             2.3664e-03,  1.1372e-03,  8.8831e-04,  1.5654e-03,  2.0847e-03,\n",
       "             2.0298e-03,  3.5080e-04,  3.1848e-03,  2.6548e-03,  8.4357e-04,\n",
       "             7.0025e-04,  1.3403e-03,  1.6566e-03,  8.3260e-04,  1.7985e-03,\n",
       "             1.5705e-03,  1.6508e-03,  6.0102e-04,  1.5369e-03,  2.4240e-03,\n",
       "             7.6304e-04,  1.3190e-03,  2.1394e-03,  1.5143e-03,  1.4454e-03,\n",
       "             2.6194e-03,  8.4871e-04,  1.0292e-03,  1.5664e-03,  1.4162e-03,\n",
       "             1.3363e-03,  1.1618e-03,  1.0136e-03,  1.5127e-03,  1.7674e-03,\n",
       "             1.0757e-03,  1.0113e-03,  5.7597e-05,  1.3695e-03,  2.3818e-03,\n",
       "            -3.8503e-04,  6.4689e-04,  2.4184e-03,  2.4593e-03,  5.4655e-04,\n",
       "             1.4532e-03,  1.2195e-03,  2.0778e-03,  1.7884e-04,  2.1051e-03,\n",
       "             1.5296e-03,  3.3412e-03,  2.3507e-03,  1.8970e-03,  1.5832e-03,\n",
       "             1.5079e-03,  1.2733e-03,  1.0876e-03,  1.8128e-03,  1.6351e-03,\n",
       "             2.3112e-03,  1.5951e-03,  1.4450e-03,  1.4994e-03,  1.9396e-03,\n",
       "             1.8485e-03,  3.3820e-04,  8.1111e-04,  2.2975e-03,  2.1642e-03,\n",
       "             2.4968e-03,  2.2038e-03,  1.6045e-03,  1.5681e-03,  4.5206e-04,\n",
       "             1.4692e-03,  9.1706e-04,  1.3786e-03,  2.0195e-03,  1.8838e-04,\n",
       "             1.8337e-03,  9.8884e-04,  7.8198e-04,  1.6339e-03,  2.3349e-04,\n",
       "             1.6223e-03,  1.5621e-03,  9.0604e-04,  1.6924e-03,  1.7635e-03,\n",
       "             1.8613e-03,  1.8704e-03,  1.9068e-03,  7.1528e-04,  2.0477e-03,\n",
       "             2.1290e-03,  6.5042e-04,  1.7891e-03,  1.5234e-03,  1.5882e-03,\n",
       "             4.3503e-04,  6.0807e-04,  1.0585e-03,  1.8753e-03, -6.0910e-04,\n",
       "             2.6081e-03,  1.8895e-03,  1.0428e-03,  1.5456e-03,  1.6723e-03,\n",
       "             1.7120e-03,  1.9674e-04,  2.0451e-03,  7.2263e-04,  9.1879e-04,\n",
       "             7.2716e-04,  1.0244e-03,  2.3439e-03,  1.6561e-03,  2.1234e-03,\n",
       "             1.8228e-03,  7.4477e-04,  1.6198e-03,  2.2244e-03,  4.5082e-04,\n",
       "             2.4388e-03,  7.6124e-04,  3.6979e-04,  1.4670e-04,  1.6012e-03,\n",
       "            -7.1187e-04,  1.7392e-03,  2.2480e-03,  1.3717e-03,  9.0032e-04,\n",
       "             1.8754e-03,  8.1410e-04,  1.7149e-03,  1.3813e-03,  1.7973e-03,\n",
       "             2.0010e-03,  1.2534e-03,  6.2711e-04,  1.3363e-03,  1.7590e-03,\n",
       "             1.8170e-03,  7.8035e-04,  2.9237e-03,  7.7045e-04,  2.3595e-03,\n",
       "             1.5828e-03,  1.0193e-03,  1.8774e-03,  1.3138e-03,  1.2845e-03,\n",
       "             2.4525e-03,  1.1163e-03,  2.9964e-03,  1.7415e-03,  4.4719e-04,\n",
       "             1.8885e-03,  1.2284e-03,  4.6523e-04,  2.3962e-03,  1.0884e-04,\n",
       "             2.1761e-03,  8.3523e-04,  1.4771e-03,  1.3057e-03,  9.3463e-04,\n",
       "             1.2177e-03,  2.0740e-03,  1.6840e-03,  1.5081e-03,  1.1392e-03,\n",
       "             2.5088e-03,  2.1416e-03,  2.1678e-03,  5.4406e-04,  2.2854e-03,\n",
       "             5.6814e-04,  1.2698e-03,  2.5867e-03,  1.9685e-03,  1.7401e-03,\n",
       "             2.1306e-03,  8.6529e-04,  1.5517e-03,  7.5422e-04,  2.0087e-03,\n",
       "             1.3745e-03,  2.5051e-04,  1.3482e-03,  2.5252e-03,  1.9388e-03,\n",
       "             1.3590e-03,  7.2302e-04,  1.7571e-03,  1.1244e-03,  1.9877e-03,\n",
       "             2.3188e-03,  2.2237e-03,  2.1462e-03,  1.7813e-03,  1.5923e-03,\n",
       "             1.4514e-03,  1.6555e-03,  2.5444e-03, -1.7342e-04,  2.6002e-03,\n",
       "             1.1613e-03,  2.3606e-03,  1.9082e-03,  8.3939e-04,  1.6270e-03,\n",
       "             1.4456e-03,  2.2215e-03,  3.1941e-03,  1.4128e-03,  9.8232e-04,\n",
       "             1.6594e-03,  9.1180e-04,  2.2075e-03,  2.1472e-03,  6.0775e-05,\n",
       "             1.6134e-03,  1.9480e-03,  2.1023e-03,  6.8699e-04,  2.6138e-03,\n",
       "             1.7189e-03,  1.7517e-03,  1.4826e-03,  2.4445e-03,  3.4305e-03,\n",
       "             1.5094e-03,  1.0201e-03,  1.7821e-03,  1.6820e-03,  3.5773e-03,\n",
       "             3.1303e-03,  1.1097e-03,  1.6471e-03,  1.2388e-03,  1.7290e-03,\n",
       "             1.5970e-03,  2.4464e-03,  1.4821e-03,  1.0701e-03,  1.7117e-03,\n",
       "             4.6934e-04,  2.3088e-03,  1.1228e-03,  2.2378e-03,  1.7773e-03,\n",
       "             1.5535e-03,  1.7822e-03,  1.8477e-03,  1.9564e-03,  2.2442e-03,\n",
       "             2.6523e-04,  1.6660e-03,  2.0054e-03,  5.5114e-04,  1.5760e-03,\n",
       "             6.3589e-04,  1.4893e-04,  1.7960e-03, -7.8902e-04,  1.4397e-03,\n",
       "             5.6713e-04,  2.6613e-03,  1.8819e-03,  8.0961e-04,  1.2479e-03,\n",
       "             1.4399e-03, -3.3171e-03,  1.4254e-03,  1.3768e-03,  1.1091e-03,\n",
       "             1.1430e-03,  1.1142e-03,  1.2508e-03,  2.1873e-03,  1.2479e-03,\n",
       "            -9.9549e-05,  2.3948e-03,  1.6859e-03,  2.0572e-03,  2.1051e-03,\n",
       "             5.8136e-04,  2.3350e-03,  1.6154e-03,  5.9308e-04,  1.0827e-03,\n",
       "             1.4518e-03,  2.1679e-03,  1.8485e-03,  2.3174e-03,  9.2507e-04,\n",
       "             4.3134e-04,  1.0420e-03,  2.0292e-03,  2.1020e-03,  9.8807e-05,\n",
       "             5.7959e-04,  1.7686e-03,  2.0061e-03,  2.0257e-03,  1.8495e-03,\n",
       "             1.6550e-03,  1.7612e-03,  1.7546e-03,  7.7625e-04,  2.6922e-03,\n",
       "             2.3139e-03,  1.2032e-03,  1.7973e-03,  1.8907e-03,  1.7178e-03,\n",
       "             1.9416e-03, -4.5093e-04,  1.5231e-03,  2.5418e-03,  9.7091e-04,\n",
       "             1.9207e-03,  1.7628e-03,  1.3295e-03,  1.7409e-03,  2.0522e-03,\n",
       "             1.4407e-03,  1.7947e-03,  2.0740e-03,  1.0017e-03,  1.8805e-03,\n",
       "            -6.3277e-05,  1.6486e-03,  1.6622e-03,  2.1671e-03,  8.2154e-04,\n",
       "             1.4985e-03,  9.3302e-04,  5.2833e-04,  9.1593e-04,  1.7071e-03,\n",
       "             1.8442e-03,  8.2018e-04,  2.7088e-04,  1.7049e-03,  7.7268e-04,\n",
       "            -1.7872e-04,  1.7054e-03,  1.6765e-03,  1.9332e-03,  2.0425e-03,\n",
       "             7.4456e-04,  5.7096e-04,  2.0416e-03,  1.3035e-03,  1.9192e-03,\n",
       "             8.5416e-04,  1.2972e-03,  2.0378e-03,  5.0536e-04,  2.0849e-03,\n",
       "             1.4142e-03,  1.8293e-03,  8.4392e-04,  1.0008e-03,  1.7985e-03,\n",
       "             6.2294e-04,  1.7478e-03,  2.8600e-03,  1.1072e-03,  2.1625e-03,\n",
       "             1.1986e-03,  1.1165e-03,  1.0019e-03,  4.0854e-04,  2.0758e-03,\n",
       "             1.7636e-03,  2.1146e-03,  1.4994e-03,  1.3119e-03,  8.7636e-04,\n",
       "             1.4198e-03,  1.1788e-03,  1.8423e-03,  1.1501e-03,  2.3484e-03,\n",
       "             2.4814e-03,  1.6962e-03,  1.6760e-03,  1.5270e-03,  6.7850e-04,\n",
       "            -1.3242e-03,  1.6874e-03,  1.7955e-03,  1.4673e-03,  1.4189e-03,\n",
       "             1.1438e-03,  2.0275e-03,  4.2821e-04,  2.2975e-03,  6.6299e-04,\n",
       "             1.3648e-03,  8.3326e-04,  2.2511e-03,  2.2733e-03,  2.8378e-03,\n",
       "             1.3954e-03,  1.3293e-03,  1.8222e-03,  2.4048e-03,  3.3398e-04,\n",
       "             2.7625e-03,  1.6075e-03,  8.7294e-04,  1.8344e-03,  1.4855e-03,\n",
       "             1.0897e-03,  2.9258e-03,  3.2435e-04,  5.6350e-04,  2.5669e-03,\n",
       "             1.6543e-03,  1.1945e-03,  3.0765e-03,  1.3264e-03,  3.5051e-03,\n",
       "             1.6418e-04,  2.0761e-03,  2.1102e-03,  1.1588e-03,  1.8450e-03,\n",
       "             2.0646e-03,  1.5949e-03], device='cuda:0')},\n",
       "   155: {'momentum_buffer': tensor([-3.9475e-04, -1.3409e-03, -2.7449e-03, -1.8699e-03, -7.5403e-04,\n",
       "             4.4445e-04, -8.3862e-04, -9.5256e-04, -1.4625e-03, -9.9473e-04,\n",
       "             5.8134e-04, -5.0934e-04, -7.2831e-04, -1.5654e-03, -2.2972e-04,\n",
       "            -1.3670e-03, -7.1175e-04, -4.5112e-04, -7.1983e-04, -2.4169e-03,\n",
       "            -1.4097e-03, -4.2312e-04, -2.1465e-03, -1.6360e-03, -1.3849e-03,\n",
       "             8.2200e-04, -4.1456e-04, -1.6000e-03, -1.4746e-03, -1.9400e-03,\n",
       "            -2.0554e-03, -1.0446e-03, -1.4834e-03, -1.3983e-03,  1.3193e-04,\n",
       "            -2.1832e-03, -8.9007e-04, -1.1085e-03,  6.2181e-05, -2.0978e-03,\n",
       "            -1.3465e-03, -6.0213e-04, -2.4955e-03,  1.1771e-03,  3.4113e-04,\n",
       "            -1.7658e-04, -1.6999e-03, -1.5142e-03, -6.7125e-04, -7.7046e-04,\n",
       "             2.6530e-04, -3.1348e-04, -1.7059e-03,  8.7402e-04, -1.2884e-03,\n",
       "            -2.3292e-04, -6.8234e-04, -6.1665e-04, -1.4818e-03, -1.9503e-03,\n",
       "            -1.3236e-03, -7.5993e-04, -7.8117e-04, -2.3668e-03, -4.4765e-04,\n",
       "            -1.5183e-03, -1.1587e-03, -7.2049e-04, -1.6003e-04, -6.6586e-04,\n",
       "            -5.1246e-04, -3.3273e-04, -1.2362e-03, -1.5197e-04, -2.4555e-04,\n",
       "            -1.7147e-03, -1.1183e-03,  1.6350e-04, -1.5098e-03, -1.8348e-03,\n",
       "            -2.0275e-03, -1.2413e-03, -2.2173e-03, -2.9402e-03, -8.3517e-04,\n",
       "            -1.3345e-03, -1.9325e-03, -8.9533e-04,  4.1365e-04, -1.9314e-03,\n",
       "            -3.8517e-04, -1.4722e-03, -6.3262e-04, -4.1474e-04, -2.2616e-03,\n",
       "            -5.9148e-04, -1.1630e-03, -1.5407e-03, -1.7345e-03, -1.2226e-03,\n",
       "             3.9558e-04, -2.5467e-04, -1.2147e-03, -1.4269e-03, -1.6638e-03,\n",
       "            -1.7110e-04,  2.4507e-04, -1.6836e-04, -1.6277e-03, -9.6945e-04,\n",
       "            -1.2854e-03, -1.1493e-03,  4.6363e-05, -3.1834e-04, -9.3207e-04,\n",
       "            -1.2773e-03, -1.1301e-03, -2.6940e-03, -2.0580e-03, -2.2310e-05,\n",
       "            -4.6632e-04, -1.6702e-03, -8.1848e-04, -1.1591e-03, -2.1372e-03,\n",
       "            -1.2534e-03, -1.8625e-04,  2.5458e-04, -9.3839e-04, -2.3170e-03,\n",
       "            -1.1886e-03, -7.4453e-04, -2.6508e-03, -1.0017e-03, -9.8162e-04,\n",
       "            -9.7310e-04, -1.2324e-03, -9.4163e-04, -1.3563e-03, -1.9062e-03,\n",
       "            -1.2549e-03, -7.1945e-04, -3.4621e-04, -1.9253e-03, -2.3524e-04,\n",
       "            -1.7260e-03, -2.3644e-03, -1.9102e-03, -1.2921e-03,  3.6005e-05,\n",
       "            -2.4549e-03,  5.8225e-04, -7.5739e-04, -1.0692e-03, -5.2615e-04,\n",
       "            -1.5293e-03, -1.7991e-03, -1.1357e-03, -1.0111e-03, -4.9345e-04,\n",
       "             4.6432e-05, -9.0791e-04,  5.1315e-04,  1.4717e-04, -8.4412e-04,\n",
       "            -1.1530e-03, -1.9309e-03, -1.7397e-03,  4.8803e-06,  3.3500e-04,\n",
       "             6.8984e-04, -7.2428e-05, -9.4183e-04, -9.7307e-04, -2.7284e-04,\n",
       "            -6.9197e-04, -3.2423e-04,  6.0515e-04, -2.1105e-03, -1.4619e-03,\n",
       "            -7.5986e-04, -1.8605e-03, -3.0506e-04,  3.4014e-04, -1.0142e-03,\n",
       "            -1.1153e-03, -1.2455e-03,  6.6441e-04, -5.8991e-04, -6.1455e-04,\n",
       "            -8.0656e-04, -9.8446e-04, -9.1992e-04, -2.6810e-03, -1.6716e-03,\n",
       "            -1.0974e-03, -6.4646e-04,  2.1755e-03, -1.9343e-03, -5.1535e-04,\n",
       "            -1.0871e-03,  4.7202e-05, -5.5479e-04, -7.0977e-04, -1.9209e-03,\n",
       "            -1.4885e-03, -1.4348e-03, -1.8948e-03,  1.9667e-03, -9.3164e-04,\n",
       "            -1.5637e-03,  3.6207e-04, -1.2515e-03, -1.3463e-03, -1.3638e-03,\n",
       "             4.2009e-04,  6.6862e-04,  4.9246e-05, -1.5374e-03, -1.5743e-03,\n",
       "            -1.3034e-03, -1.4261e-03, -5.7226e-03, -5.6105e-04,  7.5226e-04,\n",
       "            -1.9954e-03, -4.8898e-04, -7.5704e-04, -9.7251e-04,  3.6967e-04,\n",
       "            -2.3969e-03, -8.0175e-04, -3.3633e-03, -1.8001e-03, -2.6229e-04,\n",
       "            -7.2521e-04, -5.2367e-04,  3.3085e-05, -2.0761e-03, -6.4166e-04,\n",
       "            -1.1918e-03, -2.1496e-04, -2.0920e-03, -1.8899e-03, -6.4940e-04,\n",
       "            -1.4938e-03, -1.6855e-03, -1.1894e-04, -1.3588e-04, -2.2635e-04,\n",
       "            -3.0209e-03,  1.5014e-04, -1.8558e-03, -8.0447e-04,  6.3558e-04,\n",
       "            -4.2594e-04, -7.9352e-04, -2.7122e-03, -1.6558e-03, -2.1495e-03,\n",
       "            -2.1590e-03, -1.1925e-04, -3.9321e-04, -4.4557e-04, -1.5392e-03,\n",
       "            -1.2946e-03,  1.0141e-04, -1.6711e-03, -2.1443e-03, -1.6726e-04,\n",
       "             2.2935e-04, -4.7221e-08,  1.3993e-03, -1.7371e-03, -1.7973e-03,\n",
       "            -2.6367e-03, -2.0859e-03, -1.8292e-03, -1.6705e-03, -1.1037e-03,\n",
       "            -1.6618e-03, -1.2925e-03, -1.9982e-03, -9.2512e-04, -9.8961e-04,\n",
       "            -6.2444e-04, -1.2353e-03, -1.6171e-03, -2.8622e-04, -1.3481e-03,\n",
       "            -2.0215e-03, -1.6596e-03, -6.4140e-04, -9.6844e-04,  2.1873e-04,\n",
       "            -1.5333e-03, -1.0216e-03, -2.1499e-03, -8.1604e-04, -1.8219e-03,\n",
       "            -1.2502e-03, -2.6234e-04, -1.7774e-03,  8.6203e-05, -1.0416e-03,\n",
       "            -1.3470e-03, -1.5345e-03, -1.0387e-03, -2.9291e-03,  6.0017e-03,\n",
       "            -9.7397e-04, -2.7454e-03, -1.4699e-03, -5.7030e-04, -3.6471e-03,\n",
       "            -2.4130e-03, -5.8593e-04, -1.3564e-03, -1.2461e-03,  2.5691e-05,\n",
       "            -1.1360e-03, -8.5482e-04, -2.1243e-03, -6.0448e-04, -9.6994e-04,\n",
       "            -9.0864e-04,  7.7254e-04, -3.1296e-05, -2.6324e-03, -1.4011e-03,\n",
       "            -2.1602e-03, -6.5503e-04, -2.2096e-03, -1.6060e-03, -3.9182e-04,\n",
       "            -1.1265e-03, -1.8637e-03, -1.2511e-03, -6.5727e-04, -1.3603e-03,\n",
       "            -4.2472e-04, -1.3956e-03, -1.6076e-03, -1.7289e-03, -1.1599e-03,\n",
       "            -7.9092e-04, -5.1595e-04, -1.3430e-03, -1.3712e-03,  3.1548e-05,\n",
       "            -7.5895e-04, -1.8412e-03,  1.2597e-04,  1.1033e-04, -5.5532e-04,\n",
       "            -1.7680e-04, -4.6469e-05, -1.5571e-03, -2.1290e-03, -2.2304e-03,\n",
       "            -1.5475e-03, -2.0569e-03, -9.8282e-04, -1.9669e-03, -1.5758e-03,\n",
       "            -1.0386e-03,  7.1529e-04, -1.9787e-03, -6.6332e-04, -2.1068e-03,\n",
       "            -5.7670e-04, -1.9653e-03, -1.5660e-03, -3.5010e-04, -1.8215e-03,\n",
       "            -1.1854e-03, -3.1234e-04, -2.0640e-03, -1.2786e-03, -1.0375e-03,\n",
       "            -1.1724e-03, -1.5341e-03, -1.0848e-03, -9.3660e-04, -1.2851e-03,\n",
       "            -1.5160e-03, -1.3218e-03, -1.9220e-03,  4.4136e-04, -1.1036e-03,\n",
       "            -2.6881e-03, -1.6895e-03, -1.0944e-03, -4.5956e-04,  9.4854e-05,\n",
       "            -1.3775e-03, -1.4596e-03, -8.6900e-04, -2.6445e-03, -2.1342e-03,\n",
       "            -1.6713e-03,  1.3811e-04, -1.3323e-03, -1.4158e-03, -1.9889e-03,\n",
       "            -6.4829e-04,  5.5248e-04, -1.8052e-03, -2.3150e-04, -2.2548e-03,\n",
       "            -9.3355e-04, -2.0576e-03, -1.7166e-03, -2.1547e-03, -2.6962e-04,\n",
       "            -1.6464e-03, -2.8515e-04, -2.9799e-04, -5.6960e-04,  4.0361e-04,\n",
       "            -1.4963e-03, -5.1342e-04, -5.2061e-04, -9.9158e-04, -2.9007e-05,\n",
       "            -1.1074e-03, -1.3775e-03, -1.0362e-03, -1.8694e-03, -1.6598e-03,\n",
       "            -1.0273e-03, -4.9967e-04, -1.4741e-03, -1.9226e-03, -9.0548e-04,\n",
       "            -2.7598e-04, -1.7293e-03, -1.7829e-03, -8.6815e-04, -1.3276e-03,\n",
       "            -1.0041e-03, -2.0500e-03, -6.2293e-04, -8.5507e-04, -1.0064e-03,\n",
       "            -1.6744e-04,  1.8373e-03, -1.9976e-04, -2.0259e-03, -1.9330e-03,\n",
       "             1.3332e-05, -1.3207e-03, -9.9524e-04, -5.5571e-04, -1.5217e-03,\n",
       "            -1.4496e-03, -1.8589e-03, -9.9349e-04,  1.1230e-05,  1.5241e-04,\n",
       "            -5.7211e-04, -4.5393e-04, -8.6316e-04, -9.6808e-04, -1.6530e-03,\n",
       "            -2.9779e-03, -1.0274e-03, -1.2095e-03, -1.8865e-03, -6.8612e-04,\n",
       "            -1.0217e-03, -9.0500e-04, -1.4410e-03, -1.8446e-03, -4.3987e-04,\n",
       "            -5.6639e-04,  2.7505e-04, -9.7145e-04, -1.6799e-03, -5.9683e-04,\n",
       "            -3.4756e-05, -2.3970e-04, -2.3033e-03,  7.1838e-04,  8.1863e-04,\n",
       "            -1.0093e-03, -1.0347e-03, -1.5003e-03, -1.8315e-03, -1.0777e-03,\n",
       "             6.0648e-04, -1.2895e-03, -3.0024e-05, -1.2939e-03, -1.2424e-03,\n",
       "            -7.4775e-04, -2.5836e-03, -1.0599e-03, -4.7450e-04, -1.4030e-03,\n",
       "             9.4386e-06, -8.1882e-04, -2.3990e-03, -7.4327e-04, -2.7696e-03,\n",
       "            -2.4495e-04, -2.0102e-03, -5.9193e-04, -1.2080e-03, -1.4654e-03,\n",
       "            -1.5121e-03,  7.8436e-04], device='cuda:0')},\n",
       "   156: {'momentum_buffer': tensor([[[[-3.8032e-04]],\n",
       "    \n",
       "             [[ 7.2813e-04]],\n",
       "    \n",
       "             [[-6.7380e-07]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-1.0511e-06]],\n",
       "    \n",
       "             [[ 1.6179e-04]],\n",
       "    \n",
       "             [[-2.1970e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[ 1.4472e-04]],\n",
       "    \n",
       "             [[ 4.2898e-04]],\n",
       "    \n",
       "             [[ 2.4783e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.1063e-05]],\n",
       "    \n",
       "             [[-5.8190e-06]],\n",
       "    \n",
       "             [[ 4.5533e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-5.0368e-05]],\n",
       "    \n",
       "             [[-6.5565e-05]],\n",
       "    \n",
       "             [[ 1.0848e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[ 2.8372e-05]],\n",
       "    \n",
       "             [[-3.7019e-06]],\n",
       "    \n",
       "             [[-1.5967e-04]]],\n",
       "    \n",
       "    \n",
       "            ...,\n",
       "    \n",
       "    \n",
       "            [[[ 1.9379e-05]],\n",
       "    \n",
       "             [[ 8.4206e-05]],\n",
       "    \n",
       "             [[ 6.9079e-06]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.3212e-05]],\n",
       "    \n",
       "             [[ 5.8765e-06]],\n",
       "    \n",
       "             [[-9.2042e-05]]],\n",
       "    \n",
       "    \n",
       "            [[[-3.5317e-04]],\n",
       "    \n",
       "             [[ 5.9652e-04]],\n",
       "    \n",
       "             [[ 6.4246e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-3.0530e-05]],\n",
       "    \n",
       "             [[ 3.8687e-05]],\n",
       "    \n",
       "             [[ 6.2825e-04]]],\n",
       "    \n",
       "    \n",
       "            [[[-2.0663e-04]],\n",
       "    \n",
       "             [[-1.3892e-04]],\n",
       "    \n",
       "             [[ 1.7546e-05]],\n",
       "    \n",
       "             ...,\n",
       "    \n",
       "             [[-5.8979e-05]],\n",
       "    \n",
       "             [[-7.6785e-05]],\n",
       "    \n",
       "             [[-4.5115e-04]]]], device='cuda:0')},\n",
       "   157: {'momentum_buffer': tensor([0.0024, 0.0022, 0.0021,  ..., 0.0017, 0.0014, 0.0022], device='cuda:0')},\n",
       "   158: {'momentum_buffer': tensor([-0.0025, -0.0041, -0.0031,  ..., -0.0030, -0.0050, -0.0042],\n",
       "           device='cuda:0')},\n",
       "   159: {'momentum_buffer': tensor([[ 1.2359e-05,  2.5345e-05, -2.8324e-05,  ..., -1.3647e-05,\n",
       "             -1.0814e-05,  3.5732e-05],\n",
       "            [ 1.9112e-05,  8.9697e-05, -2.3723e-06,  ...,  1.2826e-05,\n",
       "             -1.8248e-05,  4.1134e-05],\n",
       "            [ 6.1397e-05,  9.8890e-06,  1.9110e-05,  ...,  9.6625e-06,\n",
       "              1.7245e-05,  2.6412e-06],\n",
       "            ...,\n",
       "            [-3.5731e-05,  4.2018e-05, -1.1939e-04,  ..., -3.2543e-05,\n",
       "              1.7046e-05, -1.0986e-05],\n",
       "            [ 6.9062e-05, -1.1844e-04, -1.9857e-05,  ..., -3.3431e-06,\n",
       "              9.3219e-05, -8.5554e-05],\n",
       "            [ 4.5691e-04,  1.4591e-04,  3.6122e-04,  ...,  1.4868e-04,\n",
       "             -6.6889e-06,  5.3391e-05]], device='cuda:0')},\n",
       "   160: {'momentum_buffer': tensor([-3.0608e-06, -2.8694e-06,  1.5381e-04,  1.0315e-06, -1.6008e-05,\n",
       "            -1.6930e-04,  1.7274e-04, -1.5255e-06,  1.7076e-06, -4.3710e-06,\n",
       "            -3.0699e-03,  3.7222e-05,  3.0976e-03, -5.7414e-05,  2.6095e-04,\n",
       "             6.6760e-06,  2.8032e-04,  2.8105e-06, -7.4426e-07,  4.5015e-05,\n",
       "             7.0573e-05,  3.0424e-04,  1.3646e-04,  3.5763e-05,  9.1366e-06,\n",
       "             6.3827e-05, -1.1070e-04,  4.4024e-03, -4.8078e-03,  5.7594e-05,\n",
       "             1.0704e-03,  3.4158e-05, -1.1857e-03,  2.8922e-04, -1.2026e-04,\n",
       "             8.6656e-04, -8.1381e-05, -7.7935e-04, -3.2990e-05, -9.1853e-05,\n",
       "             1.5403e-03,  9.3886e-04,  2.6343e-04, -8.0170e-05, -9.6613e-04,\n",
       "             1.1498e-05, -1.2630e-03,  1.3176e-04,  2.5551e-05,  2.8811e-05,\n",
       "             3.1647e-05, -2.7200e-04,  3.0928e-04, -9.4814e-05, -5.0053e-04,\n",
       "             3.2366e-06,  9.5168e-04,  2.5039e-06,  8.5658e-05, -2.8420e-03,\n",
       "             2.3735e-04,  7.8285e-05, -2.0280e-05,  4.4757e-05,  2.5616e-03,\n",
       "            -3.6133e-05, -3.2521e-04, -2.9712e-04,  6.8688e-04,  8.9291e-05,\n",
       "             9.5415e-06, -8.4080e-06,  4.0611e-04,  1.4935e-04, -3.4546e-04,\n",
       "             4.4279e-05,  4.7207e-05,  9.3223e-05,  3.8616e-05,  2.4788e-06,\n",
       "             1.0373e-04,  1.3718e-04,  1.6259e-04,  2.9386e-04, -1.9914e-05,\n",
       "             6.4619e-06, -1.3087e-04,  4.0360e-05,  3.9102e-05, -2.5596e-04,\n",
       "            -2.5763e-03, -1.3489e-05,  9.8510e-05, -4.6901e-04,  3.3942e-05,\n",
       "             3.8554e-05,  2.0295e-05,  2.1724e-04, -1.2982e-05,  2.0855e-05,\n",
       "            -7.6408e-05, -8.5470e-04, -2.6633e-06,  3.7303e-05, -1.4859e-05,\n",
       "             3.0997e-04,  8.6750e-05, -4.8279e-06, -3.9543e-05, -5.9846e-05,\n",
       "            -5.0896e-05,  8.6376e-06,  9.6305e-05, -3.1441e-06,  7.6224e-06,\n",
       "            -3.2405e-05, -1.7649e-05, -1.2688e-05,  8.0957e-05, -1.9763e-04,\n",
       "             6.9393e-05,  5.5741e-05,  9.1061e-04,  1.1506e-04, -1.0307e-03,\n",
       "            -2.0773e-03,  6.0994e-05,  6.7099e-05,  6.4342e-06,  2.7612e-04,\n",
       "             2.2690e-05,  1.1333e-04, -1.5269e-04, -1.0945e-03,  4.3534e-04,\n",
       "            -1.2061e-04,  1.0651e-04, -3.7313e-05, -1.1312e-06,  2.3450e-05,\n",
       "             2.6174e-05, -2.0967e-05,  7.4182e-05,  3.1768e-05,  9.0276e-05,\n",
       "            -1.1821e-05,  6.6550e-05,  6.1373e-05,  1.7546e-05,  3.1657e-05,\n",
       "             9.1713e-06,  1.0385e-05,  1.0170e-04,  5.5091e-05, -8.0378e-06,\n",
       "             1.9120e-04, -2.5797e-05,  5.4291e-05,  1.0991e-03,  3.5034e-05,\n",
       "             1.0432e-04, -2.1923e-05,  1.1297e-04,  3.9370e-05, -6.4890e-04,\n",
       "            -1.6139e-03,  7.9287e-05, -1.2292e-05,  1.5222e-03,  1.9270e-05,\n",
       "            -1.9539e-04,  3.5199e-05,  2.5718e-04, -4.4501e-04, -5.0857e-04,\n",
       "             5.7157e-05, -5.3846e-05,  2.3620e-04,  1.7580e-05,  8.1095e-04,\n",
       "            -7.6608e-04,  4.6059e-05,  7.9038e-06, -1.2359e-04,  5.7932e-05,\n",
       "            -3.6730e-05,  1.6637e-05, -1.2766e-03, -7.3612e-05,  4.2116e-05,\n",
       "             2.2713e-05,  5.5788e-05,  2.3401e-04, -3.1285e-04,  2.8380e-05,\n",
       "             8.4969e-05,  1.4289e-04,  1.3510e-04, -2.1227e-04, -6.3881e-05,\n",
       "             3.9781e-05,  1.6650e-04,  1.0068e-05,  5.5411e-05,  1.1958e-04,\n",
       "            -2.0066e-03,  2.1260e-03,  1.4867e-04, -4.6439e-06,  1.4125e-04,\n",
       "             7.0119e-05, -2.0709e-06,  1.9551e-06,  4.8972e-05,  1.3600e-05,\n",
       "            -8.2344e-05, -9.9364e-04,  1.4943e-04,  5.2237e-04,  6.0484e-04,\n",
       "            -5.1119e-04, -1.8023e-04, -7.9672e-05,  4.6793e-04,  2.3769e-05,\n",
       "             4.5905e-05,  1.9916e-05, -6.2157e-05, -5.5142e-05,  1.2849e-05,\n",
       "             5.4160e-05,  2.0684e-04, -1.1703e-04, -7.9336e-06,  5.0333e-05,\n",
       "             7.8484e-06,  9.0523e-05,  2.4338e-05,  3.4721e-05, -6.9407e-05,\n",
       "             1.8449e-04,  2.3863e-05,  7.2427e-06, -6.3095e-06,  5.1116e-05,\n",
       "            -6.6109e-05, -3.9148e-05,  2.8479e-06,  5.4419e-05,  2.5948e-05,\n",
       "             1.1904e-04,  2.0899e-05,  3.1160e-05,  1.7552e-04,  9.1239e-05,\n",
       "             1.0983e-04,  7.1107e-05,  5.6826e-05,  4.9003e-05,  4.4456e-05,\n",
       "             1.5773e-05,  5.6023e-05,  3.3992e-05, -2.3718e-03,  2.1941e-03,\n",
       "             2.0686e-03,  1.7420e-04, -2.2400e-03, -6.7075e-05, -7.5609e-05,\n",
       "             5.5856e-05,  3.4109e-05,  2.7841e-05,  2.2216e-04,  1.1387e-05,\n",
       "            -4.5737e-05,  5.5452e-05,  1.2986e-04, -1.1920e-04, -7.7792e-06,\n",
       "             4.1413e-05,  2.3997e-03, -2.6012e-03,  1.4134e-04, -2.5844e-05,\n",
       "             1.8432e-04,  3.0607e-05,  1.4328e-04,  3.6939e-04, -3.0833e-04,\n",
       "            -2.3482e-05, -5.2952e-05, -2.6910e-05,  1.1057e-05,  6.5071e-05,\n",
       "            -3.0439e-03,  1.1509e-05,  3.2510e-04, -9.3678e-04,  1.0505e-03,\n",
       "             5.9013e-05,  7.6135e-05,  3.0967e-05,  2.2633e-05, -8.1242e-05,\n",
       "             2.2771e-04, -1.5089e-03,  1.6212e-03,  3.3986e-05,  2.4145e-05,\n",
       "            -2.7796e-05,  2.1797e-05,  5.8129e-05,  2.4078e-04,  1.4679e-04,\n",
       "             1.3041e-04,  1.0504e-04,  6.7567e-04, -1.9149e-05, -4.2013e-03,\n",
       "             4.2157e-03,  2.8884e-04, -5.3111e-05, -4.9851e-05,  9.3988e-05,\n",
       "             5.1803e-05, -2.2312e-06,  8.3028e-05,  1.0486e-06,  1.7235e-04,\n",
       "             1.7342e-04, -1.7875e-04,  3.2776e-05,  4.8733e-05,  3.7284e-04,\n",
       "             6.6239e-05, -2.2233e-05,  2.5319e-05, -1.8197e-05, -1.1641e-04,\n",
       "            -9.7745e-06, -9.9035e-04, -9.1952e-05,  4.8146e-06,  3.8498e-06,\n",
       "            -3.2530e-04,  6.1388e-05,  2.3267e-05,  3.3406e-04, -2.8689e-04,\n",
       "            -3.6746e-05,  3.0985e-05,  1.5555e-03, -1.7921e-03, -1.1891e-05,\n",
       "            -1.2562e-05,  2.0276e-04, -2.5929e-05,  1.0192e-04, -1.1161e-04,\n",
       "             8.1685e-05,  1.4229e-04,  6.8106e-06, -7.0028e-06, -1.0321e-05,\n",
       "             3.5928e-05, -2.3888e-05,  3.6424e-05, -2.7403e-06,  3.5047e-05,\n",
       "             4.3052e-05,  4.0914e-05,  1.0505e-04,  7.6942e-06,  2.0498e-06,\n",
       "             2.5155e-05, -3.8840e-05, -1.3311e-05,  2.5551e-04,  7.2125e-05,\n",
       "             6.0348e-05,  7.0927e-05, -9.4814e-06, -4.8851e-05, -1.0765e-04,\n",
       "             4.3077e-04,  4.4404e-04, -8.2027e-06,  1.3058e-04,  5.0534e-05,\n",
       "            -4.8370e-05, -2.6772e-05, -1.4570e-05,  2.5129e-05, -5.1874e-06,\n",
       "             2.4879e-05,  1.7847e-05,  8.9963e-06,  2.4124e-04, -6.4387e-06,\n",
       "             1.4415e-04, -2.2485e-06,  2.6648e-06,  1.3607e-04,  2.3473e-03,\n",
       "            -7.8504e-05, -8.0712e-05,  8.6506e-05, -3.2189e-05,  1.8519e-04,\n",
       "             1.6808e-04, -3.8546e-04, -1.1866e-05,  6.3511e-04, -1.3600e-04,\n",
       "             1.6383e-04, -1.2077e-04, -6.1925e-06, -2.3694e-04, -1.6417e-03,\n",
       "             1.1075e-04, -3.0327e-05, -2.8933e-03,  2.4748e-04, -1.7735e-04,\n",
       "            -2.6770e-05,  6.0296e-04,  7.3818e-05, -2.8496e-05,  2.2417e-04,\n",
       "             3.3816e-05,  2.5522e-05,  2.6730e-04,  2.7934e-04,  3.6826e-05,\n",
       "            -2.0918e-05, -2.7266e-06, -1.6212e-06,  2.2952e-04, -1.6856e-05,\n",
       "            -3.9349e-04,  4.2355e-04,  5.6716e-05,  3.5898e-04,  5.4785e-05,\n",
       "             1.2824e-04,  9.0879e-05, -5.8219e-05, -8.8614e-06,  1.2387e-05,\n",
       "            -2.1687e-05,  4.9787e-05,  6.8493e-06,  1.1680e-04, -1.6767e-04,\n",
       "            -1.8890e-05, -5.8040e-05,  3.7922e-06,  4.1800e-04, -1.1934e-04,\n",
       "             6.7816e-05, -4.8672e-04, -2.0995e-05,  4.5145e-05,  6.3258e-05,\n",
       "             3.9551e-06,  2.2392e-04, -8.1703e-05,  1.8402e-05, -1.1185e-04,\n",
       "             2.8666e-05,  4.9785e-05,  2.3361e-04,  1.0040e-05,  4.0364e-05,\n",
       "             2.6999e-05, -3.0569e-06,  6.4764e-05, -1.0315e-04,  1.3365e-06,\n",
       "            -1.7495e-05,  2.3881e-04,  6.6260e-04, -3.1160e-05,  5.2987e-05,\n",
       "            -1.4566e-04, -2.1155e-05,  6.8540e-05, -3.0648e-03, -3.8056e-05,\n",
       "            -1.1611e-04,  3.3193e-06, -9.3583e-05,  6.5025e-04,  8.4382e-05,\n",
       "            -5.5880e-04, -1.2660e-06, -5.7018e-06,  3.1965e-06,  7.4882e-06,\n",
       "             1.4871e-04, -1.1599e-06, -1.2417e-05,  9.1499e-05,  4.5418e-05,\n",
       "             1.6409e-04,  2.9059e-05, -8.1092e-05,  7.6736e-05, -4.4443e-05,\n",
       "             2.4458e-05, -1.8505e-06,  5.0349e-05,  3.9240e-05, -2.2849e-05,\n",
       "             4.5328e-05,  1.2235e-04, -2.0869e-05, -8.1804e-06, -2.4420e-04,\n",
       "            -7.2953e-05, -2.9092e-05,  8.9170e-05,  3.1462e-05,  4.5231e-04,\n",
       "            -1.3317e-05, -1.4809e-04,  5.3609e-05, -5.7764e-06, -1.3616e-05,\n",
       "             2.7989e-04, -1.8989e-04,  9.9465e-06,  5.5972e-05,  6.3835e-05,\n",
       "             1.8223e-06,  3.9020e-05,  1.6485e-04, -3.7978e-05,  1.2130e-05,\n",
       "             3.1494e-05, -4.4957e-05,  6.1200e-04, -1.0125e-03,  5.4749e-07,\n",
       "            -3.7400e-05,  5.2336e-05,  1.9358e-04,  4.6522e-05,  5.9707e-06,\n",
       "             2.4779e-06,  3.3029e-05,  2.2291e-05,  1.4313e-05,  7.8851e-05,\n",
       "            -5.7061e-04, -2.7714e-05,  5.2944e-05,  5.6290e-05,  1.4218e-05,\n",
       "             1.2954e-04, -4.8290e-04, -4.7856e-05,  1.6055e-04, -1.1749e-05,\n",
       "            -5.7686e-04, -2.4966e-05,  3.2285e-04,  4.9549e-05,  7.4328e-05,\n",
       "            -7.8651e-04,  1.7908e-05,  2.2275e-04, -3.8515e-06,  1.1552e-05,\n",
       "             2.1263e-05, -1.2069e-04, -1.1104e-04,  6.5183e-05, -8.2761e-05,\n",
       "            -5.6538e-05, -1.8928e-04,  1.5667e-04,  3.9746e-04, -2.2577e-06,\n",
       "             1.3697e-04,  1.1617e-05,  1.0165e-04, -3.3652e-05,  2.2872e-07,\n",
       "            -2.7714e-05, -6.7556e-05, -1.0876e-04,  3.0333e-05,  3.7069e-04,\n",
       "             1.0528e-05,  2.0312e-04, -2.2109e-04,  8.3748e-05, -2.2240e-04,\n",
       "             3.0910e-03,  6.1915e-05,  7.0105e-06,  1.0628e-03, -7.4649e-06,\n",
       "             1.6081e-05,  4.0591e-07,  4.4985e-05, -3.7075e-05,  1.3031e-05,\n",
       "            -6.6968e-05, -4.0521e-05,  3.0094e-05, -2.1564e-05, -1.4849e-05,\n",
       "             9.1226e-05, -5.8026e-05, -1.3281e-04, -1.1834e-05,  4.9446e-03,\n",
       "             5.9562e-06,  5.9807e-06,  6.3799e-05, -8.2046e-06, -4.1708e-05,\n",
       "             5.8605e-05,  7.1989e-05,  4.7605e-05,  5.2946e-05,  3.1384e-05,\n",
       "            -6.9779e-05, -7.2931e-04,  2.9908e-04,  1.1479e-04, -8.6634e-05,\n",
       "             4.0266e-04, -2.2306e-05, -2.7301e-05, -2.5310e-04,  3.3355e-04,\n",
       "            -1.6799e-04,  1.7462e-05,  5.4044e-05, -3.5486e-05,  5.6972e-05,\n",
       "            -2.6611e-05, -5.0508e-05, -2.5032e-08,  1.0832e-04,  2.3652e-05,\n",
       "             6.1135e-05, -1.5476e-04,  5.9278e-04, -3.7752e-05, -1.1406e-03,\n",
       "             1.3167e-04,  1.1035e-03, -3.6494e-04,  2.8288e-05,  3.7860e-05,\n",
       "             4.0173e-05,  4.5891e-05,  1.1104e-04, -9.5655e-06,  2.8180e-04,\n",
       "            -1.6529e-04, -5.4969e-06, -7.9082e-05,  3.6696e-05,  4.2566e-06,\n",
       "             9.6660e-05,  1.5178e-06, -4.8840e-05,  6.3537e-05,  2.8065e-05,\n",
       "            -4.9288e-05,  1.9375e-05,  9.6239e-06,  3.0305e-05, -1.2011e-05,\n",
       "             4.1776e-05,  2.8813e-04,  3.4519e-04,  3.0684e-04,  7.6193e-04,\n",
       "             1.2661e-05,  2.9798e-04,  1.0194e-04,  3.9746e-05, -2.7258e-04,\n",
       "             2.1151e-04,  1.0170e-03,  1.7530e-05, -2.1521e-04, -2.6308e-05,\n",
       "             1.1136e-04,  9.9978e-05,  1.0139e-05,  7.1020e-05,  5.8015e-06,\n",
       "            -1.9318e-03,  1.0608e-05,  1.4724e-04, -3.1093e-05,  3.2186e-06,\n",
       "             2.4132e-05, -7.7020e-05, -2.5682e-06,  1.8016e-05,  1.3236e-08,\n",
       "             1.1393e-05, -6.8575e-05, -3.6462e-05,  1.3831e-05, -5.2515e-06,\n",
       "             1.4619e-05, -1.9913e-06, -1.1624e-05,  2.8370e-05,  1.0392e-04,\n",
       "            -3.3269e-05,  4.1997e-05, -5.9442e-06, -5.9998e-05,  1.5377e-04,\n",
       "             1.0477e-05, -2.4515e-03,  1.1765e-05, -7.8469e-05, -6.2764e-06,\n",
       "             1.3838e-04,  4.6673e-05,  6.2215e-06,  2.4407e-05,  3.1841e-05,\n",
       "            -1.4051e-05,  2.7252e-05, -6.7763e-05, -7.1809e-05,  1.0211e-05,\n",
       "             1.0781e-04, -7.0453e-05,  1.1676e-04,  3.2667e-05,  3.6110e-04,\n",
       "             1.6776e-05,  1.5274e-05,  7.5456e-06, -2.8031e-05,  7.8499e-05,\n",
       "             4.8491e-05, -1.6875e-04, -9.3550e-05, -1.9332e-05,  5.6686e-04,\n",
       "             1.5046e-04, -7.2433e-05,  3.3447e-05, -6.3130e-06, -2.9581e-05,\n",
       "             9.8809e-05, -3.9875e-05,  9.0197e-06,  9.0818e-05, -1.1831e-03,\n",
       "            -3.0519e-05, -3.3144e-05,  5.1031e-05, -2.6736e-04, -5.8495e-06,\n",
       "             2.0516e-04,  1.4785e-05, -2.8474e-06, -3.0655e-06,  1.5778e-05,\n",
       "            -4.6740e-06, -3.4113e-04,  1.1846e-04, -8.0522e-06,  2.0440e-04,\n",
       "             4.6171e-04, -1.2484e-04,  3.5430e-04,  1.2294e-05, -9.7349e-06,\n",
       "             1.2101e-04, -2.8841e-05, -3.3748e-05,  6.2229e-05, -8.8911e-05,\n",
       "             1.7117e-05,  5.9066e-05,  4.0512e-05, -2.7585e-04, -3.2640e-05,\n",
       "             2.0668e-04,  2.7149e-05, -1.6051e-05,  5.7960e-05,  6.7106e-04,\n",
       "            -3.9538e-05,  2.2863e-06, -2.4119e-05,  1.7165e-05,  1.8307e-04,\n",
       "             3.3615e-05, -5.0842e-06, -2.3715e-05,  1.1367e-05,  3.9987e-05,\n",
       "             1.6996e-04, -2.3017e-05,  2.9243e-05,  1.0280e-05,  7.4004e-06,\n",
       "            -1.7373e-05, -1.3848e-06,  1.7504e-04, -1.3507e-04,  3.6863e-05,\n",
       "             8.9298e-05, -5.4435e-05,  1.3125e-05,  3.4356e-05, -7.6508e-05,\n",
       "            -3.0231e-06, -1.7094e-04, -1.8991e-05, -1.3889e-04, -9.4739e-04,\n",
       "            -2.8097e-04, -2.2372e-06,  2.4418e-05,  1.2007e-04,  2.3839e-04,\n",
       "            -8.6801e-06, -1.3337e-04,  3.1226e-04,  3.0644e-04, -7.3510e-05,\n",
       "            -1.2349e-05,  4.2257e-06, -5.0718e-05, -1.8452e-05, -1.6781e-05,\n",
       "             1.3392e-04, -4.9020e-03, -2.6687e-05, -1.5148e-03, -3.6295e-05,\n",
       "             2.2754e-05, -1.6870e-04,  4.5638e-05, -3.0536e-05, -3.5301e-05,\n",
       "             2.5789e-04, -1.0210e-04, -1.7319e-05, -1.9074e-05, -8.3851e-05,\n",
       "            -1.3119e-04,  5.5048e-07,  3.3519e-04,  9.6985e-05,  2.0510e-04,\n",
       "             2.2083e-05,  1.9224e-05,  1.0178e-03,  1.6202e-05,  3.8572e-05,\n",
       "             8.5460e-05,  1.0339e-04, -9.1978e-07, -1.8951e-06,  7.4296e-05,\n",
       "             2.2138e-05, -7.7466e-06, -5.8326e-05, -1.0110e-04, -3.8916e-05,\n",
       "             1.5223e-04,  1.4169e-04,  5.4212e-05,  1.3332e-05,  2.3098e-05,\n",
       "             1.8837e-05, -8.6830e-05,  6.0957e-05, -7.2289e-06,  7.2786e-05,\n",
       "             9.3905e-06,  3.3402e-05, -7.0869e-05, -4.4548e-05, -8.1889e-05,\n",
       "             3.3285e-04,  2.0257e-05,  1.6239e-05,  1.3788e-04,  1.9183e-05,\n",
       "             7.8136e-06,  1.1276e-04, -9.0563e-05,  2.9889e-05, -9.8658e-08,\n",
       "             1.5076e-05, -1.3175e-04,  5.1927e-04, -8.1559e-03, -1.0045e-04,\n",
       "             7.5540e-05,  9.0893e-05,  2.9995e-07,  6.0692e-05, -1.0881e-04,\n",
       "            -3.9389e-05, -1.4455e-04, -5.2761e-05,  1.6004e-05, -2.0353e-05,\n",
       "             4.4329e-04, -5.6278e-05,  3.6855e-05, -3.1720e-06,  4.1007e-05,\n",
       "             1.1109e-04, -1.4879e-04, -3.9440e-05, -5.1419e-05, -3.8214e-06,\n",
       "             5.3614e-04,  1.3197e-04, -3.1386e-06,  9.0479e-05,  6.9224e-05,\n",
       "            -5.6351e-05, -4.0981e-05,  7.7447e-06,  1.4591e-04, -1.4448e-05,\n",
       "            -1.1059e-04,  1.5284e-06,  1.6347e-04, -1.4498e-04, -5.1947e-05,\n",
       "            -4.6985e-05,  5.0715e-05,  2.4222e-05, -6.3241e-05,  2.4587e-04,\n",
       "             7.1196e-05,  6.7243e-05, -7.0736e-06, -2.1802e-05, -5.2899e-07,\n",
       "             1.4393e-05, -1.0962e-05,  6.1693e-08,  4.2659e-05,  1.6550e-04,\n",
       "             6.1848e-05, -7.4638e-05,  2.9154e-06,  3.9125e-06, -5.1699e-06,\n",
       "             3.2306e-05, -3.1686e-04,  3.1763e-05, -7.7851e-05, -1.1217e-06,\n",
       "             5.0492e-05,  5.6366e-04,  3.1980e-05,  7.2530e-05,  4.9198e-05,\n",
       "             4.3262e-05,  1.8627e-05,  1.3952e-04,  4.7682e-05, -2.2537e-04,\n",
       "            -5.0041e-05, -1.3209e-03,  2.9644e-05,  4.6661e-05,  5.8986e-05,\n",
       "            -2.3231e-05,  1.8875e-05, -2.0166e-04, -2.0964e-05, -9.9400e-06,\n",
       "            -1.2489e-05, -9.7638e-05, -2.1016e-05, -5.9375e-05, -3.2496e-06,\n",
       "             6.2884e-05,  5.5296e-05, -1.3043e-04,  2.5656e-04,  1.9731e-03],\n",
       "           device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 0.001,\n",
       "    'momentum': 0.9,\n",
       "    'dampening': 0,\n",
       "    'weight_decay': 0.0001,\n",
       "    'nesterov': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'differentiable': False,\n",
       "    'initial_lr': 0.01,\n",
       "    'params': [0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     8,\n",
       "     9,\n",
       "     10,\n",
       "     11,\n",
       "     12,\n",
       "     13,\n",
       "     14,\n",
       "     15,\n",
       "     16,\n",
       "     17,\n",
       "     18,\n",
       "     19,\n",
       "     20,\n",
       "     21,\n",
       "     22,\n",
       "     23,\n",
       "     24,\n",
       "     25,\n",
       "     26,\n",
       "     27,\n",
       "     28,\n",
       "     29,\n",
       "     30,\n",
       "     31,\n",
       "     32,\n",
       "     33,\n",
       "     34,\n",
       "     35,\n",
       "     36,\n",
       "     37,\n",
       "     38,\n",
       "     39,\n",
       "     40,\n",
       "     41,\n",
       "     42,\n",
       "     43,\n",
       "     44,\n",
       "     45,\n",
       "     46,\n",
       "     47,\n",
       "     48,\n",
       "     49,\n",
       "     50,\n",
       "     51,\n",
       "     52,\n",
       "     53,\n",
       "     54,\n",
       "     55,\n",
       "     56,\n",
       "     57,\n",
       "     58,\n",
       "     59,\n",
       "     60,\n",
       "     61,\n",
       "     62,\n",
       "     63,\n",
       "     64,\n",
       "     65,\n",
       "     66,\n",
       "     67,\n",
       "     68,\n",
       "     69,\n",
       "     70,\n",
       "     71,\n",
       "     72,\n",
       "     73,\n",
       "     74,\n",
       "     75,\n",
       "     76,\n",
       "     77,\n",
       "     78,\n",
       "     79,\n",
       "     80,\n",
       "     81,\n",
       "     82,\n",
       "     83,\n",
       "     84,\n",
       "     85,\n",
       "     86,\n",
       "     87,\n",
       "     88,\n",
       "     89,\n",
       "     90,\n",
       "     91,\n",
       "     92,\n",
       "     93,\n",
       "     94,\n",
       "     95,\n",
       "     96,\n",
       "     97,\n",
       "     98,\n",
       "     99,\n",
       "     100,\n",
       "     101,\n",
       "     102,\n",
       "     103,\n",
       "     104,\n",
       "     105,\n",
       "     106,\n",
       "     107,\n",
       "     108,\n",
       "     109,\n",
       "     110,\n",
       "     111,\n",
       "     112,\n",
       "     113,\n",
       "     114,\n",
       "     115,\n",
       "     116,\n",
       "     117,\n",
       "     118,\n",
       "     119,\n",
       "     120,\n",
       "     121,\n",
       "     122,\n",
       "     123,\n",
       "     124,\n",
       "     125,\n",
       "     126,\n",
       "     127,\n",
       "     128,\n",
       "     129,\n",
       "     130,\n",
       "     131,\n",
       "     132,\n",
       "     133,\n",
       "     134,\n",
       "     135,\n",
       "     136,\n",
       "     137,\n",
       "     138,\n",
       "     139,\n",
       "     140,\n",
       "     141,\n",
       "     142,\n",
       "     143,\n",
       "     144,\n",
       "     145,\n",
       "     146,\n",
       "     147,\n",
       "     148,\n",
       "     149,\n",
       "     150,\n",
       "     151,\n",
       "     152,\n",
       "     153,\n",
       "     154,\n",
       "     155,\n",
       "     156,\n",
       "     157,\n",
       "     158,\n",
       "     159,\n",
       "     160]}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DinoVisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x NestedTensorBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MemEffAttention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = ['vonenet_ff_ecoset','vonenet_ff_stylized-ecoset','vonenet_r_ecoset','vonenet_r_stylized-ecoset', 'SayCam', 'cvcl', 'convnext','vit','clip_vit',\n",
    "              'resnet50','resnet50_21k', 'clip_resnet_15m','clip_resnet']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip_vit\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.cuda.HalfTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m testloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(arch\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m model_layers \u001b[38;5;241m=\u001b[39m \u001b[43mget_empty_feature_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model_layers),model_layers)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/DataDrive3/vlad/git_repos/DeepDive/deepdive/feature_extraction.py:268\u001b[0m, in \u001b[0;36mget_empty_feature_maps\u001b[0;34m(model, inputs, input_size, dataset_size, layers_to_retain, remove_duplicates, names_only)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(dataset_size, \u001b[38;5;241m*\u001b[39minput_size)\n\u001b[0;32m--> 268\u001b[0m empty_feature_maps \u001b[38;5;241m=\u001b[39m \u001b[43mget_feature_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers_to_retain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_duplicates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m map_key \u001b[38;5;129;01min\u001b[39;00m empty_feature_maps:\n\u001b[1;32m    271\u001b[0m     empty_feature_maps[map_key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(dataset_size, \u001b[38;5;241m*\u001b[39mempty_feature_maps[map_key]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m/mnt/DataDrive3/vlad/git_repos/DeepDive/deepdive/feature_extraction.py:242\u001b[0m, in \u001b[0;36mget_feature_maps\u001b[0;34m(model, inputs, layers_to_retain, remove_duplicates, enforce_input_shape)\u001b[0m\n\u001b[1;32m    240\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 242\u001b[0m     model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks:\n\u001b[1;32m    245\u001b[0m     hook\u001b[38;5;241m.\u001b[39mremove()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/clip/model.py:224\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 224\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape = [*, width, grid, grid]\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape = [*, width, grid ** 2]\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape = [*, grid ** 2, width]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.cuda.HalfTensor) should be the same"
     ]
    }
   ],
   "source": [
    "model_arch = ['clip_vit']\n",
    "for arch in model_arch:\n",
    "    model, transform, _ = load_model(arch)\n",
    "    \n",
    "    model = nn.Sequential(model.visual)\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = load_stim.load_stim('/mnt/DataDrive3/vlad/git_repos/kornet/stim/test/IC', transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=24, shuffle=False, num_workers = 4, pin_memory=True)\n",
    "\n",
    "    print(arch+ '\\n')\n",
    "    model_layers = get_empty_feature_maps(model, testloader, names_only = True)\n",
    "    print(len(model_layers),model_layers)\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, transform, _ = load_model('clip_vit')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ReLU-1', 'ReLU-2', 'ReLU-3', 'ReLU-4', 'ReLU-5', 'ReLU-6', 'ReLU-7', 'ReLU-8', 'ReLU-9', 'ReLU-10']\n"
     ]
    }
   ],
   "source": [
    "layers = [layer for layer in model_layers if 'ReLU' in layer or 'AdaptiveAvgPool2d-1' in layer]\n",
    "layers = layers[:10]\n",
    "print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction (Batch): 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "activations = get_all_feature_maps(model, testloader, layers_to_retain=layers)\n",
    "all_acts = []\n",
    "for layer in layers:\n",
    "    acts = activations[layer]\n",
    "    all_acts.append(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 802816)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acts[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch in model_arch:\n",
    "    model, _, _ = load_model(arch)\n",
    "\n",
    "    #print number of layers\n",
    "    print(f'{arch} has {len(list(model.parameters()))} layers')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, _, _ = load_model('SayCam')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all model layers\n",
    "model_layers = pd.read_csv(f'{git_dir}/modelling/all_model_layers.csv')\n",
    "\n",
    "#sort by model name, use, and number\n",
    "model_layers = model_layers.sort_values(by=['use','model','number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _ = load_model('SayCam')\n",
    "layer = model_layers.loc[(model_layers['model'] == 'clip_resnet_15m') & (model_layers['use'] == 1)]['layers'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert layer into a getattribute call\n",
    "#e.g., getattr(getattr(getattr(model,'visual'), 'attnpool'),'c_proj')\n",
    "layer_split = layer.split('.')\n",
    "\n",
    "#construct the call for each item in the list\n",
    "for ln, l in enumerate(layer_split):\n",
    "    #on first item\n",
    "    if ln == 0:\n",
    "        layer_call = f\"getattr(model,\\'{l}\\')\"\n",
    "    else:\n",
    "        layer_call = f\"getattr({layer_call},\\'{l}\\')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'visual.layer1.2.act3'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU(inplace=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(layer_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n",
      "Model:  VOneCORnet-S feedforward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DataDrive3/vlad/git_repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n",
      "/home/vayzenb/anaconda3/envs/ml/lib/python3.12/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1711403380481/work/aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "TraceError",
     "evalue": "symbolically traced variables cannot be used as inputs to control flow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_feature_extractor\n\u001b[1;32m      3\u001b[0m model, _, _ \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvonenet_ff_ecoset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m train_nodes, eval_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mget_graph_node_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:252\u001b[0m, in \u001b[0;36mget_graph_node_names\u001b[0;34m(model, tracer_kwargs, suppress_diff_warning)\u001b[0m\n\u001b[1;32m    250\u001b[0m is_training \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    251\u001b[0m train_tracer \u001b[38;5;241m=\u001b[39m NodePathTracer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtracer_kwargs)\n\u001b[0;32m--> 252\u001b[0m \u001b[43mtrain_tracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m eval_tracer \u001b[38;5;241m=\u001b[39m NodePathTracer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtracer_kwargs)\n\u001b[1;32m    254\u001b[0m eval_tracer\u001b[38;5;241m.\u001b[39mtrace(model\u001b[38;5;241m.\u001b[39meval())\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:821\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_search:\n\u001b[1;32m    815\u001b[0m             _autowrap_check(\n\u001b[1;32m    816\u001b[0m                 patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    817\u001b[0m             )\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\n\u001b[1;32m    819\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    820\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 821\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m),),\n\u001b[1;32m    822\u001b[0m             {},\n\u001b[1;32m    823\u001b[0m             type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:799\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _orig_module_call(mod, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    794\u001b[0m _autowrap_check(\n\u001b[1;32m    795\u001b[0m     patcher,\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__globals__\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids,\n\u001b[1;32m    798\u001b[0m )\n\u001b[0;32m--> 799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:83\u001b[0m, in \u001b[0;36mNodePathTracer.call_module\u001b[0;34m(self, m, forward, args, kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_module_qualname \u001b[38;5;241m=\u001b[39m module_qualname\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf_module(m, module_qualname):\n\u001b[0;32m---> 83\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, module_qualname, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:792\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_orig_module_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/DataDrive3/vlad/git_repos/vonenet/vonenet/modules.py:80\u001b[0m, in \u001b[0;36mVOneBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgabors_f(x)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Noise [Batch, out_channels, H/stride, W/stride]\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnoise_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# V1 Block output: (Batch, out_channels, H/stride, W/stride)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(x)\n",
      "File \u001b[0;32m/mnt/DataDrive3/vlad/git_repos/vonenet/vonenet/modules.py:101\u001b[0m, in \u001b[0;36mVOneBlock.noise_f\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m     x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_noise \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(F\u001b[38;5;241m.\u001b[39mrelu(x\u001b[38;5;241m.\u001b[39mclone()) \u001b[38;5;241m+\u001b[39m eps)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrsample() \u001b[38;5;241m*\u001b[39m \\\n\u001b[1;32m    102\u001b[0m          torch\u001b[38;5;241m.\u001b[39msqrt(F\u001b[38;5;241m.\u001b[39mrelu(x\u001b[38;5;241m.\u001b[39mclone()) \u001b[38;5;241m+\u001b[39m eps)\n\u001b[1;32m    103\u001b[0m x \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_level\n\u001b[1;32m    104\u001b[0m x \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_scale\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/distributions/normal.py:56\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/distributions/distribution.py:67\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     65\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[1;32m     66\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/fx/proxy.py:441\u001b[0m, in \u001b[0;36mProxy.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m'\u001b[39m, assert_fn, (\u001b[38;5;28mself\u001b[39m,), {})\n\u001b[1;32m    439\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torch/fx/proxy.py:301\u001b[0m, in \u001b[0;36mTracerBase.to_bool\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_bool\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    296\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called when a proxy object is being converted to a boolean, such as\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    when used in control flow.  Normally we don't know what to do because\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    we don't know the value of the proxy, but a custom tracer can attach more\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    information to the graph node using create_node and can choose to return a value.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraceError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbolically traced variables cannot be used as inputs to control flow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTraceError\u001b[0m: symbolically traced variables cannot be used as inputs to control flow"
     ]
    }
   ],
   "source": [
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "model, _, _ = load_model('vonenet_ff_ecoset')\n",
    "train_nodes, eval_nodes = get_graph_node_names(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x',\n",
       " 'conv1',\n",
       " 'bn1',\n",
       " 'relu',\n",
       " 'maxpool',\n",
       " 'layer1.0.conv1',\n",
       " 'layer1.0.bn1',\n",
       " 'layer1.0.relu',\n",
       " 'layer1.0.conv2',\n",
       " 'layer1.0.bn2',\n",
       " 'layer1.0.relu_1',\n",
       " 'layer1.0.conv3',\n",
       " 'layer1.0.bn3',\n",
       " 'layer1.0.downsample.0',\n",
       " 'layer1.0.downsample.1',\n",
       " 'layer1.0.add',\n",
       " 'layer1.0.relu_2',\n",
       " 'layer1.1.conv1',\n",
       " 'layer1.1.bn1',\n",
       " 'layer1.1.relu',\n",
       " 'layer1.1.conv2',\n",
       " 'layer1.1.bn2',\n",
       " 'layer1.1.relu_1',\n",
       " 'layer1.1.conv3',\n",
       " 'layer1.1.bn3',\n",
       " 'layer1.1.add',\n",
       " 'layer1.1.relu_2',\n",
       " 'layer1.2.conv1',\n",
       " 'layer1.2.bn1',\n",
       " 'layer1.2.relu',\n",
       " 'layer1.2.conv2',\n",
       " 'layer1.2.bn2',\n",
       " 'layer1.2.relu_1',\n",
       " 'layer1.2.conv3',\n",
       " 'layer1.2.bn3',\n",
       " 'layer1.2.add',\n",
       " 'layer1.2.relu_2',\n",
       " 'layer2.0.conv1',\n",
       " 'layer2.0.bn1',\n",
       " 'layer2.0.relu',\n",
       " 'layer2.0.conv2',\n",
       " 'layer2.0.bn2',\n",
       " 'layer2.0.relu_1',\n",
       " 'layer2.0.conv3',\n",
       " 'layer2.0.bn3',\n",
       " 'layer2.0.downsample.0',\n",
       " 'layer2.0.downsample.1',\n",
       " 'layer2.0.add',\n",
       " 'layer2.0.relu_2',\n",
       " 'layer2.1.conv1',\n",
       " 'layer2.1.bn1',\n",
       " 'layer2.1.relu',\n",
       " 'layer2.1.conv2',\n",
       " 'layer2.1.bn2',\n",
       " 'layer2.1.relu_1',\n",
       " 'layer2.1.conv3',\n",
       " 'layer2.1.bn3',\n",
       " 'layer2.1.add',\n",
       " 'layer2.1.relu_2',\n",
       " 'layer2.2.conv1',\n",
       " 'layer2.2.bn1',\n",
       " 'layer2.2.relu',\n",
       " 'layer2.2.conv2',\n",
       " 'layer2.2.bn2',\n",
       " 'layer2.2.relu_1',\n",
       " 'layer2.2.conv3',\n",
       " 'layer2.2.bn3',\n",
       " 'layer2.2.add',\n",
       " 'layer2.2.relu_2',\n",
       " 'layer2.3.conv1',\n",
       " 'layer2.3.bn1',\n",
       " 'layer2.3.relu',\n",
       " 'layer2.3.conv2',\n",
       " 'layer2.3.bn2',\n",
       " 'layer2.3.relu_1',\n",
       " 'layer2.3.conv3',\n",
       " 'layer2.3.bn3',\n",
       " 'layer2.3.add',\n",
       " 'layer2.3.relu_2',\n",
       " 'layer3.0.conv1',\n",
       " 'layer3.0.bn1',\n",
       " 'layer3.0.relu',\n",
       " 'layer3.0.conv2',\n",
       " 'layer3.0.bn2',\n",
       " 'layer3.0.relu_1',\n",
       " 'layer3.0.conv3',\n",
       " 'layer3.0.bn3',\n",
       " 'layer3.0.downsample.0',\n",
       " 'layer3.0.downsample.1',\n",
       " 'layer3.0.add',\n",
       " 'layer3.0.relu_2',\n",
       " 'layer3.1.conv1',\n",
       " 'layer3.1.bn1',\n",
       " 'layer3.1.relu',\n",
       " 'layer3.1.conv2',\n",
       " 'layer3.1.bn2',\n",
       " 'layer3.1.relu_1',\n",
       " 'layer3.1.conv3',\n",
       " 'layer3.1.bn3',\n",
       " 'layer3.1.add',\n",
       " 'layer3.1.relu_2',\n",
       " 'layer3.2.conv1',\n",
       " 'layer3.2.bn1',\n",
       " 'layer3.2.relu',\n",
       " 'layer3.2.conv2',\n",
       " 'layer3.2.bn2',\n",
       " 'layer3.2.relu_1',\n",
       " 'layer3.2.conv3',\n",
       " 'layer3.2.bn3',\n",
       " 'layer3.2.add',\n",
       " 'layer3.2.relu_2',\n",
       " 'layer3.3.conv1',\n",
       " 'layer3.3.bn1',\n",
       " 'layer3.3.relu',\n",
       " 'layer3.3.conv2',\n",
       " 'layer3.3.bn2',\n",
       " 'layer3.3.relu_1',\n",
       " 'layer3.3.conv3',\n",
       " 'layer3.3.bn3',\n",
       " 'layer3.3.add',\n",
       " 'layer3.3.relu_2',\n",
       " 'layer3.4.conv1',\n",
       " 'layer3.4.bn1',\n",
       " 'layer3.4.relu',\n",
       " 'layer3.4.conv2',\n",
       " 'layer3.4.bn2',\n",
       " 'layer3.4.relu_1',\n",
       " 'layer3.4.conv3',\n",
       " 'layer3.4.bn3',\n",
       " 'layer3.4.add',\n",
       " 'layer3.4.relu_2',\n",
       " 'layer3.5.conv1',\n",
       " 'layer3.5.bn1',\n",
       " 'layer3.5.relu',\n",
       " 'layer3.5.conv2',\n",
       " 'layer3.5.bn2',\n",
       " 'layer3.5.relu_1',\n",
       " 'layer3.5.conv3',\n",
       " 'layer3.5.bn3',\n",
       " 'layer3.5.add',\n",
       " 'layer3.5.relu_2',\n",
       " 'layer4.0.conv1',\n",
       " 'layer4.0.bn1',\n",
       " 'layer4.0.relu',\n",
       " 'layer4.0.conv2',\n",
       " 'layer4.0.bn2',\n",
       " 'layer4.0.relu_1',\n",
       " 'layer4.0.conv3',\n",
       " 'layer4.0.bn3',\n",
       " 'layer4.0.downsample.0',\n",
       " 'layer4.0.downsample.1',\n",
       " 'layer4.0.add',\n",
       " 'layer4.0.relu_2',\n",
       " 'layer4.1.conv1',\n",
       " 'layer4.1.bn1',\n",
       " 'layer4.1.relu',\n",
       " 'layer4.1.conv2',\n",
       " 'layer4.1.bn2',\n",
       " 'layer4.1.relu_1',\n",
       " 'layer4.1.conv3',\n",
       " 'layer4.1.bn3',\n",
       " 'layer4.1.add',\n",
       " 'layer4.1.relu_2',\n",
       " 'layer4.2.conv1',\n",
       " 'layer4.2.bn1',\n",
       " 'layer4.2.relu',\n",
       " 'layer4.2.conv2',\n",
       " 'layer4.2.bn2',\n",
       " 'layer4.2.relu_1',\n",
       " 'layer4.2.conv3',\n",
       " 'layer4.2.bn3',\n",
       " 'layer4.2.add',\n",
       " 'layer4.2.relu_2',\n",
       " 'avgpool',\n",
       " 'flatten',\n",
       " 'fc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/vayzenb/.cache/torch/hub/facebookresearch_dino_main\n",
      "/home/vayzenb/anaconda3/envs/ml/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/vayzenb/anaconda3/envs/ml/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_arch = ['resnet50_dino']\n",
    "all_models = pd.DataFrame(columns=['model','layers'])\n",
    "for arch in model_arch:\n",
    "    \n",
    "    model, _, _ = load_model(arch)\n",
    "\n",
    "    all_names = []\n",
    "    for name, module in model.named_modules():\n",
    "        all_names.append(name)\n",
    "\n",
    "    curr_model = pd.DataFrame({'model':arch, 'layers':all_names})\n",
    "\n",
    "    all_models = pd.concat([all_models, curr_model])\n",
    "\n",
    "\n",
    "all_models.to_csv('all_model_layers_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all models\n",
    "all_models.to_csv('all_model_layers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CLIP(\n",
      "  (visual): ModifiedResNet(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (attnpool): AttentionPool2d(\n",
      "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (resblocks): Sequential(\n",
      "      (0): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (token_embedding): Embedding(49408, 512)\n",
      "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "visual ModifiedResNet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (avgpool): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (attnpool): AttentionPool2d(\n",
      "    (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  )\n",
      ")\n",
      "visual.conv1 Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "visual.bn1 BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.relu1 ReLU(inplace=True)\n",
      "visual.conv2 Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.bn2 BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.relu2 ReLU(inplace=True)\n",
      "visual.conv3 Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.bn3 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.relu3 ReLU(inplace=True)\n",
      "visual.avgpool AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "visual.layer1 Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "visual.layer1.0 Bottleneck(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "visual.layer1.0.conv1 Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer1.0.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.0.relu1 ReLU(inplace=True)\n",
      "visual.layer1.0.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer1.0.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.0.relu2 ReLU(inplace=True)\n",
      "visual.layer1.0.avgpool Identity()\n",
      "visual.layer1.0.conv3 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer1.0.bn3 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.0.relu3 ReLU(inplace=True)\n",
      "visual.layer1.0.downsample Sequential(\n",
      "  (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "visual.layer1.0.downsample.-1 AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "visual.layer1.0.downsample.0 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer1.0.downsample.1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.1 Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer1.1.conv1 Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer1.1.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.1.relu1 ReLU(inplace=True)\n",
      "visual.layer1.1.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer1.1.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.1.relu2 ReLU(inplace=True)\n",
      "visual.layer1.1.avgpool Identity()\n",
      "visual.layer1.1.conv3 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer1.1.bn3 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.1.relu3 ReLU(inplace=True)\n",
      "visual.layer1.2 Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer1.2.conv1 Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer1.2.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.2.relu1 ReLU(inplace=True)\n",
      "visual.layer1.2.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer1.2.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.2.relu2 ReLU(inplace=True)\n",
      "visual.layer1.2.avgpool Identity()\n",
      "visual.layer1.2.conv3 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer1.2.bn3 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer1.2.relu3 ReLU(inplace=True)\n",
      "visual.layer2 Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "visual.layer2.0 Bottleneck(\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "visual.layer2.0.conv1 Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.0.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.0.relu1 ReLU(inplace=True)\n",
      "visual.layer2.0.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer2.0.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.0.relu2 ReLU(inplace=True)\n",
      "visual.layer2.0.avgpool AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "visual.layer2.0.conv3 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.0.bn3 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.0.relu3 ReLU(inplace=True)\n",
      "visual.layer2.0.downsample Sequential(\n",
      "  (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "visual.layer2.0.downsample.-1 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "visual.layer2.0.downsample.0 Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.0.downsample.1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.1 Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer2.1.conv1 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.1.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.1.relu1 ReLU(inplace=True)\n",
      "visual.layer2.1.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer2.1.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.1.relu2 ReLU(inplace=True)\n",
      "visual.layer2.1.avgpool Identity()\n",
      "visual.layer2.1.conv3 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.1.bn3 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.1.relu3 ReLU(inplace=True)\n",
      "visual.layer2.2 Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer2.2.conv1 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.2.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.2.relu1 ReLU(inplace=True)\n",
      "visual.layer2.2.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer2.2.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.2.relu2 ReLU(inplace=True)\n",
      "visual.layer2.2.avgpool Identity()\n",
      "visual.layer2.2.conv3 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.2.bn3 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.2.relu3 ReLU(inplace=True)\n",
      "visual.layer2.3 Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer2.3.conv1 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.3.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.3.relu1 ReLU(inplace=True)\n",
      "visual.layer2.3.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer2.3.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.3.relu2 ReLU(inplace=True)\n",
      "visual.layer2.3.avgpool Identity()\n",
      "visual.layer2.3.conv3 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer2.3.bn3 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer2.3.relu3 ReLU(inplace=True)\n",
      "visual.layer3 Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "visual.layer3.0 Bottleneck(\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "visual.layer3.0.conv1 Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.0.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.0.relu1 ReLU(inplace=True)\n",
      "visual.layer3.0.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer3.0.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.0.relu2 ReLU(inplace=True)\n",
      "visual.layer3.0.avgpool AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "visual.layer3.0.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.0.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.0.relu3 ReLU(inplace=True)\n",
      "visual.layer3.0.downsample Sequential(\n",
      "  (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "visual.layer3.0.downsample.-1 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "visual.layer3.0.downsample.0 Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.0.downsample.1 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.1 Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer3.1.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.1.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.1.relu1 ReLU(inplace=True)\n",
      "visual.layer3.1.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer3.1.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.1.relu2 ReLU(inplace=True)\n",
      "visual.layer3.1.avgpool Identity()\n",
      "visual.layer3.1.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.1.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.1.relu3 ReLU(inplace=True)\n",
      "visual.layer3.2 Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer3.2.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.2.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.2.relu1 ReLU(inplace=True)\n",
      "visual.layer3.2.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer3.2.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.2.relu2 ReLU(inplace=True)\n",
      "visual.layer3.2.avgpool Identity()\n",
      "visual.layer3.2.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.2.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.2.relu3 ReLU(inplace=True)\n",
      "visual.layer3.3 Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer3.3.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.3.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.3.relu1 ReLU(inplace=True)\n",
      "visual.layer3.3.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer3.3.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.3.relu2 ReLU(inplace=True)\n",
      "visual.layer3.3.avgpool Identity()\n",
      "visual.layer3.3.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.3.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.3.relu3 ReLU(inplace=True)\n",
      "visual.layer3.4 Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer3.4.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.4.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.4.relu1 ReLU(inplace=True)\n",
      "visual.layer3.4.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer3.4.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.4.relu2 ReLU(inplace=True)\n",
      "visual.layer3.4.avgpool Identity()\n",
      "visual.layer3.4.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.4.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.4.relu3 ReLU(inplace=True)\n",
      "visual.layer3.5 Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer3.5.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.5.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.5.relu1 ReLU(inplace=True)\n",
      "visual.layer3.5.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer3.5.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.5.relu2 ReLU(inplace=True)\n",
      "visual.layer3.5.avgpool Identity()\n",
      "visual.layer3.5.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer3.5.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer3.5.relu3 ReLU(inplace=True)\n",
      "visual.layer4 Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (avgpool): Identity()\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "visual.layer4.0 Bottleneck(\n",
      "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "visual.layer4.0.conv1 Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer4.0.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.0.relu1 ReLU(inplace=True)\n",
      "visual.layer4.0.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer4.0.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.0.relu2 ReLU(inplace=True)\n",
      "visual.layer4.0.avgpool AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "visual.layer4.0.conv3 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer4.0.bn3 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.0.relu3 ReLU(inplace=True)\n",
      "visual.layer4.0.downsample Sequential(\n",
      "  (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "visual.layer4.0.downsample.-1 AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "visual.layer4.0.downsample.0 Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer4.0.downsample.1 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.1 Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer4.1.conv1 Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer4.1.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.1.relu1 ReLU(inplace=True)\n",
      "visual.layer4.1.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer4.1.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.1.relu2 ReLU(inplace=True)\n",
      "visual.layer4.1.avgpool Identity()\n",
      "visual.layer4.1.conv3 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer4.1.bn3 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.1.relu3 ReLU(inplace=True)\n",
      "visual.layer4.2 Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (avgpool): Identity()\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU(inplace=True)\n",
      ")\n",
      "visual.layer4.2.conv1 Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer4.2.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.2.relu1 ReLU(inplace=True)\n",
      "visual.layer4.2.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "visual.layer4.2.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.2.relu2 ReLU(inplace=True)\n",
      "visual.layer4.2.avgpool Identity()\n",
      "visual.layer4.2.conv3 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "visual.layer4.2.bn3 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "visual.layer4.2.relu3 ReLU(inplace=True)\n",
      "visual.attnpool AttentionPool2d(\n",
      "  (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
      ")\n",
      "visual.attnpool.k_proj Linear(in_features=2048, out_features=2048, bias=True)\n",
      "visual.attnpool.q_proj Linear(in_features=2048, out_features=2048, bias=True)\n",
      "visual.attnpool.v_proj Linear(in_features=2048, out_features=2048, bias=True)\n",
      "visual.attnpool.c_proj Linear(in_features=2048, out_features=1024, bias=True)\n",
      "transformer Transformer(\n",
      "  (resblocks): Sequential(\n",
      "    (0): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (4): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (6): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (7): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (8): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (9): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (10): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (11): ResidualAttentionBlock(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Sequential(\n",
      "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (gelu): QuickGELU()\n",
      "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "transformer.resblocks Sequential(\n",
      "  (0): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (1): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (2): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (3): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (4): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (5): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (6): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (7): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (8): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (9): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (10): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (11): ResidualAttentionBlock(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (gelu): QuickGELU()\n",
      "      (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "transformer.resblocks.0 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.0.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.0.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.0.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.0.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.0.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.0.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.0.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.0.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.1 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.1.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.1.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.1.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.1.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.1.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.1.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.1.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.1.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.2 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.2.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.2.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.2.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.2.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.2.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.2.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.2.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.2.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.3 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.3.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.3.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.3.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.3.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.3.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.3.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.3.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.3.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.4 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.4.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.4.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.4.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.4.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.4.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.4.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.4.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.4.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.5 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.5.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.5.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.5.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.5.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.5.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.5.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.5.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.5.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.6 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.6.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.6.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.6.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.6.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.6.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.6.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.6.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.6.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.7 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.7.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.7.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.7.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.7.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.7.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.7.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.7.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.7.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.8 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.8.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.8.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.8.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.8.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.8.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.8.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.8.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.8.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.9 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.9.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.9.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.9.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.9.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.9.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.9.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.9.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.9.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.10 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.10.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.10.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.10.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.10.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.10.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.10.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.10.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.10.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.11 ResidualAttentionBlock(\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): Sequential(\n",
      "    (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (gelu): QuickGELU()\n",
      "    (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.resblocks.11.attn MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.11.attn.out_proj NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "transformer.resblocks.11.ln_1 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.resblocks.11.mlp Sequential(\n",
      "  (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (gelu): QuickGELU()\n",
      "  (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      ")\n",
      "transformer.resblocks.11.mlp.c_fc Linear(in_features=512, out_features=2048, bias=True)\n",
      "transformer.resblocks.11.mlp.gelu QuickGELU()\n",
      "transformer.resblocks.11.mlp.c_proj Linear(in_features=2048, out_features=512, bias=True)\n",
      "transformer.resblocks.11.ln_2 LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "token_embedding Embedding(49408, 512)\n",
      "ln_final LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'visual',\n",
       " 'visual.conv1',\n",
       " 'visual.bn1',\n",
       " 'visual.relu1',\n",
       " 'visual.conv2',\n",
       " 'visual.bn2',\n",
       " 'visual.relu2',\n",
       " 'visual.conv3',\n",
       " 'visual.bn3',\n",
       " 'visual.relu3',\n",
       " 'visual.avgpool',\n",
       " 'visual.layer1',\n",
       " 'visual.layer1.0',\n",
       " 'visual.layer1.0.conv1',\n",
       " 'visual.layer1.0.bn1',\n",
       " 'visual.layer1.0.relu1',\n",
       " 'visual.layer1.0.conv2',\n",
       " 'visual.layer1.0.bn2',\n",
       " 'visual.layer1.0.relu2',\n",
       " 'visual.layer1.0.avgpool',\n",
       " 'visual.layer1.0.conv3',\n",
       " 'visual.layer1.0.bn3',\n",
       " 'visual.layer1.0.relu3',\n",
       " 'visual.layer1.0.downsample',\n",
       " 'visual.layer1.0.downsample.-1',\n",
       " 'visual.layer1.0.downsample.0',\n",
       " 'visual.layer1.0.downsample.1',\n",
       " 'visual.layer1.1',\n",
       " 'visual.layer1.1.conv1',\n",
       " 'visual.layer1.1.bn1',\n",
       " 'visual.layer1.1.relu1',\n",
       " 'visual.layer1.1.conv2',\n",
       " 'visual.layer1.1.bn2',\n",
       " 'visual.layer1.1.relu2',\n",
       " 'visual.layer1.1.avgpool',\n",
       " 'visual.layer1.1.conv3',\n",
       " 'visual.layer1.1.bn3',\n",
       " 'visual.layer1.1.relu3',\n",
       " 'visual.layer1.2',\n",
       " 'visual.layer1.2.conv1',\n",
       " 'visual.layer1.2.bn1',\n",
       " 'visual.layer1.2.relu1',\n",
       " 'visual.layer1.2.conv2',\n",
       " 'visual.layer1.2.bn2',\n",
       " 'visual.layer1.2.relu2',\n",
       " 'visual.layer1.2.avgpool',\n",
       " 'visual.layer1.2.conv3',\n",
       " 'visual.layer1.2.bn3',\n",
       " 'visual.layer1.2.relu3',\n",
       " 'visual.layer2',\n",
       " 'visual.layer2.0',\n",
       " 'visual.layer2.0.conv1',\n",
       " 'visual.layer2.0.bn1',\n",
       " 'visual.layer2.0.relu1',\n",
       " 'visual.layer2.0.conv2',\n",
       " 'visual.layer2.0.bn2',\n",
       " 'visual.layer2.0.relu2',\n",
       " 'visual.layer2.0.avgpool',\n",
       " 'visual.layer2.0.conv3',\n",
       " 'visual.layer2.0.bn3',\n",
       " 'visual.layer2.0.relu3',\n",
       " 'visual.layer2.0.downsample',\n",
       " 'visual.layer2.0.downsample.-1',\n",
       " 'visual.layer2.0.downsample.0',\n",
       " 'visual.layer2.0.downsample.1',\n",
       " 'visual.layer2.1',\n",
       " 'visual.layer2.1.conv1',\n",
       " 'visual.layer2.1.bn1',\n",
       " 'visual.layer2.1.relu1',\n",
       " 'visual.layer2.1.conv2',\n",
       " 'visual.layer2.1.bn2',\n",
       " 'visual.layer2.1.relu2',\n",
       " 'visual.layer2.1.avgpool',\n",
       " 'visual.layer2.1.conv3',\n",
       " 'visual.layer2.1.bn3',\n",
       " 'visual.layer2.1.relu3',\n",
       " 'visual.layer2.2',\n",
       " 'visual.layer2.2.conv1',\n",
       " 'visual.layer2.2.bn1',\n",
       " 'visual.layer2.2.relu1',\n",
       " 'visual.layer2.2.conv2',\n",
       " 'visual.layer2.2.bn2',\n",
       " 'visual.layer2.2.relu2',\n",
       " 'visual.layer2.2.avgpool',\n",
       " 'visual.layer2.2.conv3',\n",
       " 'visual.layer2.2.bn3',\n",
       " 'visual.layer2.2.relu3',\n",
       " 'visual.layer2.3',\n",
       " 'visual.layer2.3.conv1',\n",
       " 'visual.layer2.3.bn1',\n",
       " 'visual.layer2.3.relu1',\n",
       " 'visual.layer2.3.conv2',\n",
       " 'visual.layer2.3.bn2',\n",
       " 'visual.layer2.3.relu2',\n",
       " 'visual.layer2.3.avgpool',\n",
       " 'visual.layer2.3.conv3',\n",
       " 'visual.layer2.3.bn3',\n",
       " 'visual.layer2.3.relu3',\n",
       " 'visual.layer3',\n",
       " 'visual.layer3.0',\n",
       " 'visual.layer3.0.conv1',\n",
       " 'visual.layer3.0.bn1',\n",
       " 'visual.layer3.0.relu1',\n",
       " 'visual.layer3.0.conv2',\n",
       " 'visual.layer3.0.bn2',\n",
       " 'visual.layer3.0.relu2',\n",
       " 'visual.layer3.0.avgpool',\n",
       " 'visual.layer3.0.conv3',\n",
       " 'visual.layer3.0.bn3',\n",
       " 'visual.layer3.0.relu3',\n",
       " 'visual.layer3.0.downsample',\n",
       " 'visual.layer3.0.downsample.-1',\n",
       " 'visual.layer3.0.downsample.0',\n",
       " 'visual.layer3.0.downsample.1',\n",
       " 'visual.layer3.1',\n",
       " 'visual.layer3.1.conv1',\n",
       " 'visual.layer3.1.bn1',\n",
       " 'visual.layer3.1.relu1',\n",
       " 'visual.layer3.1.conv2',\n",
       " 'visual.layer3.1.bn2',\n",
       " 'visual.layer3.1.relu2',\n",
       " 'visual.layer3.1.avgpool',\n",
       " 'visual.layer3.1.conv3',\n",
       " 'visual.layer3.1.bn3',\n",
       " 'visual.layer3.1.relu3',\n",
       " 'visual.layer3.2',\n",
       " 'visual.layer3.2.conv1',\n",
       " 'visual.layer3.2.bn1',\n",
       " 'visual.layer3.2.relu1',\n",
       " 'visual.layer3.2.conv2',\n",
       " 'visual.layer3.2.bn2',\n",
       " 'visual.layer3.2.relu2',\n",
       " 'visual.layer3.2.avgpool',\n",
       " 'visual.layer3.2.conv3',\n",
       " 'visual.layer3.2.bn3',\n",
       " 'visual.layer3.2.relu3',\n",
       " 'visual.layer3.3',\n",
       " 'visual.layer3.3.conv1',\n",
       " 'visual.layer3.3.bn1',\n",
       " 'visual.layer3.3.relu1',\n",
       " 'visual.layer3.3.conv2',\n",
       " 'visual.layer3.3.bn2',\n",
       " 'visual.layer3.3.relu2',\n",
       " 'visual.layer3.3.avgpool',\n",
       " 'visual.layer3.3.conv3',\n",
       " 'visual.layer3.3.bn3',\n",
       " 'visual.layer3.3.relu3',\n",
       " 'visual.layer3.4',\n",
       " 'visual.layer3.4.conv1',\n",
       " 'visual.layer3.4.bn1',\n",
       " 'visual.layer3.4.relu1',\n",
       " 'visual.layer3.4.conv2',\n",
       " 'visual.layer3.4.bn2',\n",
       " 'visual.layer3.4.relu2',\n",
       " 'visual.layer3.4.avgpool',\n",
       " 'visual.layer3.4.conv3',\n",
       " 'visual.layer3.4.bn3',\n",
       " 'visual.layer3.4.relu3',\n",
       " 'visual.layer3.5',\n",
       " 'visual.layer3.5.conv1',\n",
       " 'visual.layer3.5.bn1',\n",
       " 'visual.layer3.5.relu1',\n",
       " 'visual.layer3.5.conv2',\n",
       " 'visual.layer3.5.bn2',\n",
       " 'visual.layer3.5.relu2',\n",
       " 'visual.layer3.5.avgpool',\n",
       " 'visual.layer3.5.conv3',\n",
       " 'visual.layer3.5.bn3',\n",
       " 'visual.layer3.5.relu3',\n",
       " 'visual.layer4',\n",
       " 'visual.layer4.0',\n",
       " 'visual.layer4.0.conv1',\n",
       " 'visual.layer4.0.bn1',\n",
       " 'visual.layer4.0.relu1',\n",
       " 'visual.layer4.0.conv2',\n",
       " 'visual.layer4.0.bn2',\n",
       " 'visual.layer4.0.relu2',\n",
       " 'visual.layer4.0.avgpool',\n",
       " 'visual.layer4.0.conv3',\n",
       " 'visual.layer4.0.bn3',\n",
       " 'visual.layer4.0.relu3',\n",
       " 'visual.layer4.0.downsample',\n",
       " 'visual.layer4.0.downsample.-1',\n",
       " 'visual.layer4.0.downsample.0',\n",
       " 'visual.layer4.0.downsample.1',\n",
       " 'visual.layer4.1',\n",
       " 'visual.layer4.1.conv1',\n",
       " 'visual.layer4.1.bn1',\n",
       " 'visual.layer4.1.relu1',\n",
       " 'visual.layer4.1.conv2',\n",
       " 'visual.layer4.1.bn2',\n",
       " 'visual.layer4.1.relu2',\n",
       " 'visual.layer4.1.avgpool',\n",
       " 'visual.layer4.1.conv3',\n",
       " 'visual.layer4.1.bn3',\n",
       " 'visual.layer4.1.relu3',\n",
       " 'visual.layer4.2',\n",
       " 'visual.layer4.2.conv1',\n",
       " 'visual.layer4.2.bn1',\n",
       " 'visual.layer4.2.relu1',\n",
       " 'visual.layer4.2.conv2',\n",
       " 'visual.layer4.2.bn2',\n",
       " 'visual.layer4.2.relu2',\n",
       " 'visual.layer4.2.avgpool',\n",
       " 'visual.layer4.2.conv3',\n",
       " 'visual.layer4.2.bn3',\n",
       " 'visual.layer4.2.relu3',\n",
       " 'visual.attnpool',\n",
       " 'visual.attnpool.k_proj',\n",
       " 'visual.attnpool.q_proj',\n",
       " 'visual.attnpool.v_proj',\n",
       " 'visual.attnpool.c_proj',\n",
       " 'transformer',\n",
       " 'transformer.resblocks',\n",
       " 'transformer.resblocks.0',\n",
       " 'transformer.resblocks.0.attn',\n",
       " 'transformer.resblocks.0.attn.out_proj',\n",
       " 'transformer.resblocks.0.ln_1',\n",
       " 'transformer.resblocks.0.mlp',\n",
       " 'transformer.resblocks.0.mlp.c_fc',\n",
       " 'transformer.resblocks.0.mlp.gelu',\n",
       " 'transformer.resblocks.0.mlp.c_proj',\n",
       " 'transformer.resblocks.0.ln_2',\n",
       " 'transformer.resblocks.1',\n",
       " 'transformer.resblocks.1.attn',\n",
       " 'transformer.resblocks.1.attn.out_proj',\n",
       " 'transformer.resblocks.1.ln_1',\n",
       " 'transformer.resblocks.1.mlp',\n",
       " 'transformer.resblocks.1.mlp.c_fc',\n",
       " 'transformer.resblocks.1.mlp.gelu',\n",
       " 'transformer.resblocks.1.mlp.c_proj',\n",
       " 'transformer.resblocks.1.ln_2',\n",
       " 'transformer.resblocks.2',\n",
       " 'transformer.resblocks.2.attn',\n",
       " 'transformer.resblocks.2.attn.out_proj',\n",
       " 'transformer.resblocks.2.ln_1',\n",
       " 'transformer.resblocks.2.mlp',\n",
       " 'transformer.resblocks.2.mlp.c_fc',\n",
       " 'transformer.resblocks.2.mlp.gelu',\n",
       " 'transformer.resblocks.2.mlp.c_proj',\n",
       " 'transformer.resblocks.2.ln_2',\n",
       " 'transformer.resblocks.3',\n",
       " 'transformer.resblocks.3.attn',\n",
       " 'transformer.resblocks.3.attn.out_proj',\n",
       " 'transformer.resblocks.3.ln_1',\n",
       " 'transformer.resblocks.3.mlp',\n",
       " 'transformer.resblocks.3.mlp.c_fc',\n",
       " 'transformer.resblocks.3.mlp.gelu',\n",
       " 'transformer.resblocks.3.mlp.c_proj',\n",
       " 'transformer.resblocks.3.ln_2',\n",
       " 'transformer.resblocks.4',\n",
       " 'transformer.resblocks.4.attn',\n",
       " 'transformer.resblocks.4.attn.out_proj',\n",
       " 'transformer.resblocks.4.ln_1',\n",
       " 'transformer.resblocks.4.mlp',\n",
       " 'transformer.resblocks.4.mlp.c_fc',\n",
       " 'transformer.resblocks.4.mlp.gelu',\n",
       " 'transformer.resblocks.4.mlp.c_proj',\n",
       " 'transformer.resblocks.4.ln_2',\n",
       " 'transformer.resblocks.5',\n",
       " 'transformer.resblocks.5.attn',\n",
       " 'transformer.resblocks.5.attn.out_proj',\n",
       " 'transformer.resblocks.5.ln_1',\n",
       " 'transformer.resblocks.5.mlp',\n",
       " 'transformer.resblocks.5.mlp.c_fc',\n",
       " 'transformer.resblocks.5.mlp.gelu',\n",
       " 'transformer.resblocks.5.mlp.c_proj',\n",
       " 'transformer.resblocks.5.ln_2',\n",
       " 'transformer.resblocks.6',\n",
       " 'transformer.resblocks.6.attn',\n",
       " 'transformer.resblocks.6.attn.out_proj',\n",
       " 'transformer.resblocks.6.ln_1',\n",
       " 'transformer.resblocks.6.mlp',\n",
       " 'transformer.resblocks.6.mlp.c_fc',\n",
       " 'transformer.resblocks.6.mlp.gelu',\n",
       " 'transformer.resblocks.6.mlp.c_proj',\n",
       " 'transformer.resblocks.6.ln_2',\n",
       " 'transformer.resblocks.7',\n",
       " 'transformer.resblocks.7.attn',\n",
       " 'transformer.resblocks.7.attn.out_proj',\n",
       " 'transformer.resblocks.7.ln_1',\n",
       " 'transformer.resblocks.7.mlp',\n",
       " 'transformer.resblocks.7.mlp.c_fc',\n",
       " 'transformer.resblocks.7.mlp.gelu',\n",
       " 'transformer.resblocks.7.mlp.c_proj',\n",
       " 'transformer.resblocks.7.ln_2',\n",
       " 'transformer.resblocks.8',\n",
       " 'transformer.resblocks.8.attn',\n",
       " 'transformer.resblocks.8.attn.out_proj',\n",
       " 'transformer.resblocks.8.ln_1',\n",
       " 'transformer.resblocks.8.mlp',\n",
       " 'transformer.resblocks.8.mlp.c_fc',\n",
       " 'transformer.resblocks.8.mlp.gelu',\n",
       " 'transformer.resblocks.8.mlp.c_proj',\n",
       " 'transformer.resblocks.8.ln_2',\n",
       " 'transformer.resblocks.9',\n",
       " 'transformer.resblocks.9.attn',\n",
       " 'transformer.resblocks.9.attn.out_proj',\n",
       " 'transformer.resblocks.9.ln_1',\n",
       " 'transformer.resblocks.9.mlp',\n",
       " 'transformer.resblocks.9.mlp.c_fc',\n",
       " 'transformer.resblocks.9.mlp.gelu',\n",
       " 'transformer.resblocks.9.mlp.c_proj',\n",
       " 'transformer.resblocks.9.ln_2',\n",
       " 'transformer.resblocks.10',\n",
       " 'transformer.resblocks.10.attn',\n",
       " 'transformer.resblocks.10.attn.out_proj',\n",
       " 'transformer.resblocks.10.ln_1',\n",
       " 'transformer.resblocks.10.mlp',\n",
       " 'transformer.resblocks.10.mlp.c_fc',\n",
       " 'transformer.resblocks.10.mlp.gelu',\n",
       " 'transformer.resblocks.10.mlp.c_proj',\n",
       " 'transformer.resblocks.10.ln_2',\n",
       " 'transformer.resblocks.11',\n",
       " 'transformer.resblocks.11.attn',\n",
       " 'transformer.resblocks.11.attn.out_proj',\n",
       " 'transformer.resblocks.11.ln_1',\n",
       " 'transformer.resblocks.11.mlp',\n",
       " 'transformer.resblocks.11.mlp.c_fc',\n",
       " 'transformer.resblocks.11.mlp.gelu',\n",
       " 'transformer.resblocks.11.mlp.c_proj',\n",
       " 'transformer.resblocks.11.ln_2',\n",
       " 'token_embedding',\n",
       " 'ln_final']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names = []\n",
    "for name, module in model.named_modules():\n",
    "    all_names.append(name)\n",
    "    print(name, module)\n",
    "all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP(\n",
      "  (visual): ModifiedResNet(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act3): ReLU(inplace=True)\n",
      "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (avgpool): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (attnpool): AttentionPool2d(\n",
      "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (resblocks): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (token_embedding): Embedding(49408, 512)\n",
      "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "arch = model_arch[3]\n",
    "model, _, _ = load_model('clip_resnet_15m')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(model: torch.nn.Module):\n",
    "    # get children form model!\n",
    "    children = list(model.children())\n",
    "    flatt_children = []\n",
    "    if children == []:\n",
    "        # if model has no children; model is last child! :O\n",
    "        return model\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for child in children:\n",
    "            try:\n",
    "                flatt_children.extend(get_children(child))\n",
    "            except TypeError:\n",
    "                flatt_children.append(get_children(child))\n",
    "    return flatt_children\n",
    "\n",
    "children = get_children(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (vone_block): VOneBlock(\n",
      "    (simple_conv_q0): GFB()\n",
      "    (simple_conv_q1): GFB()\n",
      "    (simple): ReLU(inplace=True)\n",
      "    (complex): Identity()\n",
      "    (gabors): Identity()\n",
      "    (noise): ReLU(inplace=True)\n",
      "    (output): Identity()\n",
      "  )\n",
      "  (bottleneck): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (model): CORnetSBackEnd(\n",
      "    (V2): CORblock_S(\n",
      "      (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (nonlin1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (nonlin2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (nonlin3): ReLU(inplace=True)\n",
      "      (output): Identity()\n",
      "      (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm1_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm3_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (V4): CORblock_S(\n",
      "      (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (nonlin1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (nonlin2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (nonlin3): ReLU(inplace=True)\n",
      "      (output): Identity()\n",
      "      (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm1_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm1_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm1_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm3_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (IT): CORblock_S(\n",
      "      (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (nonlin1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (nonlin2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (nonlin3): ReLU(inplace=True)\n",
      "      (output): Identity()\n",
      "      (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm1_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm3_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (flatten): Flatten()\n",
      "      (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
      "      (output): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for _, n in model.named_children():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = n.named_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not callable"
     ]
    }
   ],
   "source": [
    "t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_image(image)\n\u001b[1;32m     12\u001b[0m     text_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_text(text)\n\u001b[0;32m---> 14\u001b[0m     logits_per_image, logits_per_text \u001b[38;5;241m=\u001b[39m model(image, text)\n\u001b[1;32m     15\u001b[0m     probs \u001b[38;5;241m=\u001b[39m logits_per_image\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel probs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, probs)  \u001b[38;5;66;03m# prints: [[0.9927937  0.00421068 0.00299572]]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "#model, preprocess = clip.load(\"RN50\", device=device)\n",
    "\n",
    "image = transform(Image.open(\"/mnt/DataDrive2/vlad/git_repos/kornet/stim/test/Pert/OBJ (01)_ripple.png\")).unsqueeze(0)\n",
    "text = clip.tokenize([\"airplane\",\"car\"])\n",
    "\n",
    "model \n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1451,  0.0680, -0.0141,  ...,  0.0081, -0.0997, -0.0279]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1024, bias=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_call = \"getattr(getattr(getattr(model,'visual'), 'attnpool'),'c_proj')\"\n",
    "eval(layer_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.2.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../home/vayzenb/.cache/huggingface/hub/models--wkvong--cvcl_s_dino_resnext50_embedding/snapshots/fe96aa69683bad69e5dd5195fc874a3edb8cb691/cvcl_s_dino_resnext50_embedding.ckpt`\n",
      "/home/vayzenb/anaconda3/envs/ml/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'vision_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['vision_encoder'])`.\n",
      "/home/vayzenb/anaconda3/envs/ml/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'text_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['text_encoder'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.72663254 0.2733674 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "\n",
    "cvcl, preprocess = MultiModalLitModel.load_model(model_name=\"cvcl\")\n",
    "cvcl = cvcl.to(device)\n",
    "cvcl.eval()\n",
    "\n",
    "# create random image to encode\n",
    "image = preprocess(Image.open(\"/mnt/DataDrive2/vlad/git_repos/kornet/stim/test/Outline/OBJ (01).png\")).unsqueeze(0).to(device)\n",
    "image_features = cvcl.encode_image(image)\n",
    "\n",
    "# create texts to encode\n",
    "texts = [\"airplane\", \"apple\"]\n",
    "texts, texts_len = cvcl.tokenize(texts)\n",
    "texts, texts_len = texts.to(device), texts_len.to(device)\n",
    "texts_features = cvcl.encode_text(texts, texts_len)\n",
    "\n",
    "# get logits from a batch of images and texts\n",
    "logits_per_image, logits_per_text = cvcl(image, texts, texts_len)\n",
    "probs = logits_per_image.softmax(dim=-1).detach().cpu().numpy()\n",
    "\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bicubic, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((224,224)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                 std=[0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape\n",
    "#text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/numpy/core/numeric.py:731\u001b[0m, in \u001b[0;36mcorrelate\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_correlate_dispatcher)\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrelate\u001b[39m(a, v, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    662\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m    Cross-correlation of two 1-dimensional sequences.\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    729\u001b[0m \n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate2\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "np.correlate(image_features.cpu().numpy(), text_features.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventral_layer = \"getattr(getattr(getattr(model,'ventral'),'model'),'decoder')\"\n",
    "dorsal_layer = \"getattr(getattr(model,'dorsal'),'head')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(dorsal_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  VOneCORnet-S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23701/394589618.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n",
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n",
      "Model:  VOneCORnet-S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23701/394589618.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n",
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n",
      "Model:  VOneCORnet-S feedforward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23701/394589618.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n",
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n",
      "Model:  VOneCORnet-S feedforward\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23701/394589618.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n",
      "/tmp/ipykernel_23701/394589618.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n",
      "/tmp/ipykernel_23701/394589618.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n",
      "/tmp/ipykernel_23701/394589618.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n",
      "/tmp/ipykernel_23701/394589618.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "model_arch = ['vonenet_r_ecoset','vonenet_r_stylized-ecoset','vonenet_ff_ecoset','vonenet_ff_stylized-ecoset', 'ShapeNet','SayCam', 'convnext','vit']\n",
    "\n",
    "df = pd.DataFrame(columns = ['model', 'layers', 'parameters'])\n",
    "\n",
    "for model_name in model_arch:\n",
    "    model,_,_ = load_model(model_name)\n",
    "    #print number of layers\n",
    "    \n",
    "    param_num = []\n",
    "    for parameter in model.parameters():\n",
    "        param_num.append(np.prod(parameter.size()))\n",
    "\n",
    "    #add to df\n",
    "    df = df.append({'model': model_name, 'layers': len(list(model.module.children())), 'parameters': np.sum(param_num)}, ignore_index = True)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n",
      "/home/vayzenbe/anaconda3/envs/ml/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  VOneCORnet-S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Sequential(\n",
       "    (vone_block): VOneBlock(\n",
       "      (simple_conv_q0): GFB()\n",
       "      (simple_conv_q1): GFB()\n",
       "      (simple): ReLU(inplace=True)\n",
       "      (complex): Identity()\n",
       "      (gabors): Identity()\n",
       "      (noise): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "    )\n",
       "    (bottleneck): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (model): CORnetSBackEnd(\n",
       "      (V2): CORblock_S(\n",
       "        (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (V4): CORblock_S(\n",
       "        (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (IT): CORblock_S(\n",
       "        (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (decoder): Sequential(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (flatten): Flatten()\n",
       "        (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "        (output): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'vonenet_r_ecoset'\n",
    "model,_,_ = load_model(model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.module\n",
    "next(model.parameters()).is_cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m  \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDistributedDataParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/torch/nn/parallel/distributed.py:595\u001b[0m, in \u001b[0;36mDistributedDataParallel.__init__\u001b[0;34m(self, module, device_ids, output_device, dim, broadcast_buffers, process_group, bucket_cap_mb, find_unused_parameters, check_reduction, gradient_as_bucket_view, static_graph)\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device \u001b[38;5;241m=\u001b[39m _get_device_index(output_device, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_group \u001b[38;5;241m=\u001b[39m \u001b[43m_get_default_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_group \u001b[38;5;241m=\u001b[39m process_group\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429\u001b[0m, in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03mGetting the default process group created by init_process_group\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_initialized():\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault process group has not been initialized, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease make sure to call init_process_group.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GroupMember\u001b[38;5;241m.\u001b[39mWORLD\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "model =  torch.nn.parallel.DistributedDataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(),\n\u001b[1;32m      2\u001b[0m                                          lr,\n\u001b[1;32m      3\u001b[0m                                          momentum\u001b[38;5;241m=\u001b[39mmomentum,\n\u001b[1;32m      4\u001b[0m                                          weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                         lr,\n",
    "                                         momentum=momentum,\n",
    "                                         weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n",
      "/home/vayzenbe/anaconda3/envs/ml/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  VOneCORnet-S feedforward\n"
     ]
    }
   ],
   "source": [
    "model = two_stream_nn.TwoStream()\n",
    "model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdd10af22b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_folder = '/user_data/vayzenbe/image_sets/development_images/val'\n",
    "\n",
    "#load a single image annd apply gaussian blue\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "im = Image.open('/user_data/vayzenbe/image_sets/development_images/val/n02666196/ILSVRC2012_val_00049012.JPEG')\n",
    "\n",
    "blurrer = transforms.GaussianBlur(kernel_size=21, sigma=10)\n",
    "blurred_im = blurrer(im)\n",
    "#blurred_imgs = [blurrer(im) for _ in range(4)]\n",
    "\n",
    "\n",
    "#plot blurred_imgs to see the effect\n",
    "plt.figure(figsize=(10, 10))\n",
    "#plot original image and blurred images side by side\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(im)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(blurred_im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n",
      "torch.Size([24, 565])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform_ventral = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((224,224)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                 std=[0.229, 0.224, 0.225])])\n",
    "transform_dorsal = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((224,224)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Grayscale(num_output_channels=3),\n",
    "                torchvision.transforms.GaussianBlur(kernel_size=35, sigma=15),\n",
    "                torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "dataset = two_stream_dataloader.ImageFolderDataset('/user_data/vayzenbe/image_sets/development_images/val', transform_ventral=transform_ventral, transform_dorsal=transform_dorsal)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(dataset, batch_size=24, shuffle=False, num_workers = 4, pin_memory=True, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for ventral_image, dorsal_image, label in testloader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        \n",
    "        ventral_image= ventral_image.cuda()\n",
    "        dorsal_image = dorsal_image.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = model(ventral_image,ventral_image)\n",
    "        print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "         [[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventral_image== dorsal_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification.model.build import EfficientViT_M0\n",
    "model = EfficientViT_M0()\n",
    "#model = torch.nn.DataParallel(model).cuda()\n",
    "layer_call = \"getattr(getattr(getattr(model,'module'),'head'),'bn')\"\n",
    "transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((224,224)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                    std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n",
      "/home/vayzenbe/anaconda3/envs/ml/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  VOneCORnet-S feedforward\n"
     ]
    }
   ],
   "source": [
    "model = vonenet.get_model(model_arch='cornets_ff', pretrained=False).module\n",
    "ventral = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  VOneCORnet-S feedforward\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.nn.modules.container.Sequential() argument after * must be an iterable, not CORnetSBackEnd_FF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ventral \u001b[38;5;241m=\u001b[39m vonenet\u001b[38;5;241m.\u001b[39mget_model(model_arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcornets_ff\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmodule\n\u001b[0;32m----> 2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mventral\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      3\u001b[0m ventral  \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(ventral \u001b[38;5;241m.\u001b[39mchildren())[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.nn.modules.container.Sequential() argument after * must be an iterable, not CORnetSBackEnd_FF"
     ]
    }
   ],
   "source": [
    "ventral = vonenet.get_model(model_arch='cornets_ff', pretrained=False).module\n",
    "classifier = nn.Sequential(*list(ventral .children())[-1])\n",
    "vone  = nn.Sequential(*list(ventral .children())[:-1])\n",
    "#recomvbine model and classifier\n",
    "#dorsal = nn.Sequential(dorsal, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): CORblock_S(\n",
       "    (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (nonlin2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin3): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "    (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): CORblock_S(\n",
       "    (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (nonlin2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin3): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "    (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): CORblock_S(\n",
       "    (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (nonlin2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (nonlin3): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "    (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(*list(ventral.model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/vayzenbe/GitHub_Repos/vonenet/vonenet/params.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ny_dist_marg = n_joint_dist / n_joint_dist.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  VOneCORnet-S feedforward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): VOneBlock(\n",
       "    (simple_conv_q0): GFB()\n",
       "    (simple_conv_q1): GFB()\n",
       "    (simple): ReLU(inplace=True)\n",
       "    (complex): Identity()\n",
       "    (gabors): Identity()\n",
       "    (noise): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "  )\n",
       "  (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (2): Sequential(\n",
       "    (0): CORblock_S(\n",
       "      (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin3): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "      (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): CORblock_S(\n",
       "      (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin3): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "      (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): CORblock_S(\n",
       "      (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin3): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "      (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (3): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventral = vonenet.get_model(model_arch='cornets_ff', pretrained=False).module\n",
    "nn.Sequential(*list(ventral.children())[:-1], nn.Sequential(*list(ventral.model.children())[:-1]),nn.AdaptiveAvgPool2d(output_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.nn.modules.container.Sequential() argument after * must be an iterable, not CORnetSBackEnd_FF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#remove classifier layer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mventral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.nn.modules.container.Sequential() argument after * must be an iterable, not CORnetSBackEnd_FF"
     ]
    }
   ],
   "source": [
    "#remove classifier layer\n",
    "classifier = nn.Sequential(*list(ventral.children())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (vone_block): VOneBlock(\n",
       "    (simple_conv_q0): GFB()\n",
       "    (simple_conv_q1): GFB()\n",
       "    (simple): ReLU(inplace=True)\n",
       "    (complex): Identity()\n",
       "    (gabors): Identity()\n",
       "    (noise): ReLU(inplace=True)\n",
       "    (output): Identity()\n",
       "  )\n",
       "  (bottleneck): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (model): CORnetSBackEnd_FF(\n",
       "    (V2): CORblock_S(\n",
       "      (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin3): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "      (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (V4): CORblock_S(\n",
       "      (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin3): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "      (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (IT): CORblock_S(\n",
       "      (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (nonlin3): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "      (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (flatten): Flatten()\n",
       "      (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "      (output): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove last layer from model\n",
    "model = EfficientViT_M0()\n",
    "classifier = nn.Sequential(*list(model.children())[-1])[:-1]\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "#recomvbine model and classifier\n",
    "model = nn.Sequential(model, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_acts(model, image_dir, transform, layer_call):\n",
    "    print('extracting features...')\n",
    "    \n",
    "\n",
    "    #set up hook to specified layer\n",
    "    def _store_feats(layer, inp, output):\n",
    "        \"\"\"An ugly but effective way of accessing intermediate model features\n",
    "        \"\"\"\n",
    "        #avgpool = nn.AdaptiveAvgPool2d(output_size=(1,768))\n",
    "        #output = avgpool(output)\n",
    "        \n",
    "\n",
    "        output = output.cpu().numpy()\n",
    "        print(output.shape)\n",
    "        \n",
    "        _model_feats.append(np.reshape(output, (len(output), -1)))\n",
    "\n",
    "    try:\n",
    "        m = model.module\n",
    "    except:\n",
    "        m = model\n",
    "    #model_layer = getattr(getattr(m, layer), sublayer)\n",
    "    model_layer = eval(layer_call)\n",
    "    model_layer.register_forward_hook(_store_feats)\n",
    "\n",
    "\n",
    "\n",
    "    #Iterate through each image and extract activations\n",
    "\n",
    "    imNum = 0\n",
    "    n=0\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    test_dataset = load_stim.load_stim(image_dir, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=24, shuffle=False, num_workers = 4, pin_memory=True)\n",
    "    \n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, _ in testloader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            \n",
    "            data= data.cuda()\n",
    "            \n",
    "            _model_feats = []\n",
    "            model(data)\n",
    "            #output = model(data)\n",
    "            \n",
    "            out = np.vstack(_model_feats)\n",
    "            \n",
    "\n",
    "            if n == 0:\n",
    "                acts = out\n",
    "                #label_list = label\n",
    "            else:\n",
    "                acts= np.append(acts, out,axis = 0)\n",
    "                #label_list = np.append(label_list, label)\n",
    "                \n",
    "            \n",
    "            n = n + 1\n",
    "            break\n",
    "\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features...\n",
      "(6, 192)\n",
      "(6, 192)\n",
      "(6, 192)\n",
      "(6, 192)\n"
     ]
    }
   ],
   "source": [
    "acts = extract_acts(model, '/user_data/vayzenbe/GitHub_Repos/kornet/stim/test/Outline_Black_Filled', transform, layer_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"getattr(getattr(getattr(model,'module'),'encoder'),'ln')\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VisionTransformer(\n",
       "    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (encoder): Encoder(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (layers): Sequential(\n",
       "        (encoder_layer_0): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_1): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_2): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_3): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_4): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_5): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_6): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_7): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_8): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_9): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_10): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_11): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate=none)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (heads): Sequential(\n",
       "      (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_32574/168332372.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "model_arch = ['vonenet_r_ecoset','vonenet_r_stylized-ecoset','vonenet_ff_ecoset','vonenet_ff_stylized-ecoset', 'ShapeNet','SayCam', 'convnext','vit']\n",
    "model_arch = ['vonenet_ff_ecoset']\n",
    "\n",
    "#append '_imagenet_sketch' to each string in model_arch\n",
    "#model_arch = model_arch+ [f'{model}_imagenet_sketch' for model in model_arch]\n",
    "\n",
    "df = pd.DataFrame(columns=['model','cat','stim_num','features'])\n",
    "#loop through models and load acts\n",
    "\n",
    "for model in model_arch:\n",
    "    act_files = glob(f'{curr_dir}/modelling/acts/{model}_*')\n",
    "\n",
    "    #remove files with imagenet_sketch\n",
    "    act_files = [act_file for act_file in act_files if 'imagenet_sketch' not in act_file]\n",
    "    \n",
    "    for act_file in act_files:\n",
    "        act = np.load(act_file)\n",
    "        cat = act_file.split('/')[-1].split('_')[-1]\n",
    "        #stim = act_file.split('/')[-1].split('_')[2]\n",
    "        df = df.append({'model':model,'cat':cat,'stim_num':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model</th>\n",
       "      <th>cat</th>\n",
       "      <th>stim_num</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>imagenet</td>\n",
       "      <td>250</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>imagenet</td>\n",
       "      <td>30</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>imagenet</td>\n",
       "      <td>250</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>lamp.npy</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>guitar.npy</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>imagenet</td>\n",
       "      <td>250</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>bird.npy</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>imagenet</td>\n",
       "      <td>250</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>tree.npy</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>vonenet_ff_ecoset</td>\n",
       "      <td>spoon.npy</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index              model         cat stim_num features\n",
       "0       0  vonenet_ff_ecoset    imagenet      250      512\n",
       "1       1  vonenet_ff_ecoset    imagenet       30      512\n",
       "2       2  vonenet_ff_ecoset    imagenet      250      512\n",
       "3       3  vonenet_ff_ecoset    lamp.npy      500      512\n",
       "4       4  vonenet_ff_ecoset  guitar.npy      500      512\n",
       "..    ...                ...         ...      ...      ...\n",
       "72     72  vonenet_ff_ecoset    imagenet      250      512\n",
       "73     73  vonenet_ff_ecoset    bird.npy      500      512\n",
       "74     74  vonenet_ff_ecoset    imagenet      250      512\n",
       "75     75  vonenet_ff_ecoset    tree.npy      500      512\n",
       "76     76  vonenet_ff_ecoset   spoon.npy      500      512\n",
       "\n",
       "[77 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
      "/tmp/ipykernel_27698/505257728.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "act_dir = f'{curr_dir}/modelling/acts'\n",
    "\n",
    "act_files = glob(f'{act_dir}/*.npy')\n",
    "\n",
    "#create df to count number values in acts\n",
    "df = pd.DataFrame(columns=['model','cat','stim','features'])\n",
    "\n",
    "for act_file in act_files:\n",
    "    act = np.load(act_file)\n",
    "    act_name = act_file.split('/')[-1].split('.')[0]\n",
    "    model_name = act_name.split('_')[0]\n",
    "    cat = act_name.split('_')[-1]\n",
    "    \n",
    "    #add to df\n",
    "    df = df.append({'model':model_name,'cat':cat,'stim':int(act.shape[0]),'features':int(act.shape[1])},ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m source_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/user_data/vayzenbe/image_sets/ecoset\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m im_list \u001b[38;5;241m=\u001b[39m glob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train/*duck/*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mim_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "source_dir = f'/user_data/vayzenbe/image_sets/ecoset'\n",
    "im_list = glob(f'{source_dir}/train/*duck/*')\n",
    "print(im_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/user_data/vayzenbe/image_sets/ecoset/train/0154_bear']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['vonecornet_s','cornet_s','voneresnet', 'vit','convnext','resnet50','resnext50','alexnet','vgg19', 'ShapeNet','SayCam']\n",
    "weights_dir = f'{curr_dir}/modelling/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_arch):    \n",
    "    \"\"\"\n",
    "    load model\n",
    "    \"\"\"\n",
    "    if model_arch == 'vonecornet_s':\n",
    "        model = vonenet.get_model(model_arch='cornets', pretrained=True).module\n",
    "        layer_call = \"getattr(getattr(getattr(getattr(model,'module'),'model'),'decoder'),'avgpool')\"\n",
    "        transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(224),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                 std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "    elif model_arch == 'cornet_s':\n",
    "        model = cornet.get_model('s', pretrained=True).module\n",
    "        layer_call = \"getattr(getattr(getattr(model,'module'),'decoder'),'avgpool')\"\n",
    "\n",
    "        transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(224),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                 std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    if model_arch == 'voneresnet':\n",
    "        model = vonenet.get_model(model_arch='resnet50', pretrained=True).module\n",
    "        layer_call = \"getattr(getattr(getattr(model,'module'),'model'),'avgpool')\"\n",
    "        transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(224),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                 std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "    elif model_arch == 'convnext':\n",
    "        model = convnext_large(weights=ConvNeXt_Large_Weights.DEFAULT)\n",
    "        transform = ConvNeXt_Large_Weights.IMAGENET1K_V1.transforms()\n",
    "        layer_call = \"getattr(getattr(model,'module'),'avgpool')\"\n",
    "\n",
    "    elif model_arch == 'vit':\n",
    "        model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "        transform = ViT_B_16_Weights.DEFAULT.transforms()\n",
    "        layer_call = \"getattr(getattr(getattr(model,'module'),'encoder'),'ln')\"\n",
    "        #layer_call = \"getattr(getattr(getattr(getattr(getattr(getattr(model,'module'),'encoder'),'layers'),'encoder_layer_11'),'mlp'),'3')\"\n",
    "\n",
    "    elif model_arch == 'resnet50':\n",
    "        model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        transform = ResNet50_Weights.DEFAULT.transforms()\n",
    "        layer_call = \"getattr(getattr(model,'module'),'avgpool')\"\n",
    "    \n",
    "    elif model_arch == 'resnext50':\n",
    "        model = resnext50_32x4d(weights=ResNeXt50_32X4D_Weights.DEFAULT)\n",
    "        transform = ResNeXt50_32X4D_Weights.DEFAULT.transforms()\n",
    "        layer_call = \"getattr(getattr(model,'module'),'avgpool')\"\n",
    "    \n",
    "    elif model_arch == 'alexnet':\n",
    "        model = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "        transform = AlexNet_Weights.DEFAULT.transforms()\n",
    "        layer_call = \"getattr(getattr(getattr(model,'module'),'classifier'),'5')\"\n",
    "\n",
    "    elif model_arch == 'vgg19':\n",
    "        model = vgg19(weights=VGG19_Weights.DEFAULT)\n",
    "        transform = VGG19_Weights.DEFAULT.transforms()\n",
    "        layer_call = \"getattr(getattr(getattr(model,'module'),'classifier'),'5')\"\n",
    "\n",
    "    elif model_arch == 'ShapeNet':\n",
    "        model = resnet50(weights=None)\n",
    "        checkpoint = torch.load(f'{weights_dir}/ShapeNet_ResNet50_Weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        transform = ResNet50_Weights.DEFAULT.transforms()\n",
    "        layer_call = \"getattr(getattr(model,'module'),'avgpool')\"\n",
    "\n",
    "    elif model_arch == 'SayCam':\n",
    "        model = resnext50_32x4d(weights=None)\n",
    "        transform = ResNeXt50_32X4D_Weights.DEFAULT.transforms()\n",
    "        \n",
    "        checkpoint = torch.load(f'{weights_dir}/SayCam_ResNext_Weights.pth.tar')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        layer_call = \"getattr(getattr(model,'module'),'avgpool')\"\n",
    "\n",
    "        \n",
    "\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    \n",
    "    #checkpoint = torch.load(f'{weights_dir}/{model_arch}_{train_set}_best_1.pth.tar')\n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    return model, transform, layer_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronal distributions gabor parameters\n",
      "Model:  VOneCORnet-S\n",
      "getattr(getattr(getattr(getattr(model,'module'),'model'),'decoder'),'avgpool')\n"
     ]
    }
   ],
   "source": [
    "model, transform, layer_call = load_model('vonecornet_s')\n",
    "print(layer_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Sequential(\n",
       "    (vone_block): VOneBlock(\n",
       "      (simple_conv_q0): GFB()\n",
       "      (simple_conv_q1): GFB()\n",
       "      (simple): ReLU(inplace=True)\n",
       "      (complex): Identity()\n",
       "      (gabors): Identity()\n",
       "      (noise): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "    )\n",
       "    (bottleneck): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (model): CORnetSBackEnd(\n",
       "      (V2): CORblock_S(\n",
       "        (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (V4): CORblock_S(\n",
       "        (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (IT): CORblock_S(\n",
       "        (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (decoder): Sequential(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (flatten): Flatten()\n",
       "        (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "        (output): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = eval(layer_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vonecornet_s\n",
      "Neuronal distributions gabor parameters\n",
      "Model:  VOneCORnet-S\n",
      "cornet_s\n",
      "voneresnet\n",
      "Neuronal distributions gabor parameters\n",
      "Model:  VOneResnet50\n",
      "vit\n",
      "convnext\n",
      "resnet50\n",
      "resnext50\n",
      "alexnet\n",
      "vgg19\n",
      "ShapeNet\n",
      "SayCam\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    try:\n",
    "        model, transform, layer_call = load_model(model_name)\n",
    "        \n",
    "        \n",
    "        \n",
    "    except:\n",
    "        print(model_name, 'failed to load')\n",
    "\n",
    "\n",
    "    try:\n",
    "        model_layer = eval(layer_call)\n",
    "\n",
    "    except:\n",
    "        print(model_name, 'eval failed')\n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_call = \"getattr(getattr(model,'module'),'avgpool')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = eval(layer_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapeNet\n",
      "DataParallel(\n",
      "  (module): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "SayCam\n",
      "DataParallel(\n",
      "  (module): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models = ['ShapeNet','SayCam']\n",
    "for model in models:\n",
    "    print(model)\n",
    "\n",
    "    model, transform, layer_call = load_model(model)\n",
    "\n",
    "    print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cornet.get_model('s', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_call = \"getattr(getattr(getattr(model,'module'),'decoder'),'avgpool')\"\n",
    "model_layer = eval(layer_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.decoder.avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'cornetsdfdsfds'\n",
    "\n",
    "test == 'cornets*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cornet' in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = '/user_data/vayzenbe/GitHub_Repos/kornet'\n",
    "stim_dir = f'{curr_dir}/stim/_things'\n",
    "\n",
    "\n",
    "layer = ['ln','avgpool','avgpool',['decoder','avgpool']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/butterfly/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/dog/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/lamp/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/bike/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/truck/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/fish/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/duck/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/bear/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/elephant/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/turtle/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/key/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/squirrel/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/frog/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/hand/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/spoon/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/tree/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/rabbit/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/foot/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/kite/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/chair/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/umbrella/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/guitar/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/flower/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/cow/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/airplane/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/fork/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/bird/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/cat/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/apple/',\n",
       " '/user_data/vayzenbe/GitHub_Repos/kornet/stim/_things/leaf/']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = glob(f'{stim_dir}/*/')\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_arch):    \n",
    "    \"\"\"\n",
    "    load model\n",
    "    \"\"\"\n",
    "    if model_arch == 'cornets':\n",
    "        model = vonenet.get_model(model_arch='cornets', pretrained=False).module\n",
    "        layer_call = \"getattr(getattr(getattr(getattr(model,'module'),'model'),'decoder'),'avgpool')\"\n",
    "\n",
    "    elif model_arch == 'cornets_ff':\n",
    "        model = vonenet.get_model(model_arch='cornets_ff', pretrained=False).module\n",
    "        layer_call = \"getattr(getattr(getattr(getattr(model,'module'),'model'),'decoder'),'avgpool')\"\n",
    "        \n",
    "\n",
    "    elif model_arch == 'convnext':\n",
    "        model = convnext_large(weights=None)\n",
    "        transform = ConvNeXt_Large_Weights.IMAGENET1K_V1.transforms()\n",
    "        layer_call = \"getattr(getattr(model,'module'),'avgpool')\"\n",
    "    elif model_arch == 'vit':\n",
    "        model = vit_b_16(weights=None)\n",
    "        transform = ViT_B_16_Weights.DEFAULT.transforms()\n",
    "        layer_call = \"getattr(getattr(getattr(model,'module'),'encoder'),'ln')\"\n",
    "        layer_call = \"getattr(getattr(model, 'encoder'),'ln')\"\n",
    "        #layer_call = \"getattr(getattr(getattr(getattr(getattr(getattr(model,'module'),'encoder'),'layers'),'encoder_layer_11'),'mlp'),'3')\"\n",
    "\n",
    "\n",
    "    if model_arch == 'cornets' or model_arch == 'cornets_ff':\n",
    "\n",
    "        transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(256),\n",
    "                torchvision.transforms.CenterCrop(224),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                 std=[0.5, 0.5, 0.5]),\n",
    "            ])\n",
    "\n",
    "    #model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    \n",
    "    #checkpoint = torch.load(f'{weights_dir}/{model_arch}_{train_set}_best_1.pth.tar')\n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    return model, transform, layer_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJ (01).png', 'OBJ (04).png', 'OBJ (06).png', 'OBJ (07).png', 'OBJ (08).png', 'OBJ (10).png', 'OBJ (11).png', 'OBJ (12).png', 'OBJ (14).png', 'OBJ (16).png', 'OBJ (17).png', 'OBJ (18).png', 'OBJ (19).png', 'OBJ (20).png', 'OBJ (21).png', 'OBJ (22).png', 'OBJ (23).png', 'OBJ (25).png', 'OBJ (27).png', 'OBJ (29).png', 'OBJ (30).png', 'OBJ (31).png', 'OBJ (32).png', 'OBJ (38).png', 'OBJ (41).png', 'OBJ (42).png', 'OBJ (44).png', 'OBJ (45).png', 'OBJ (46).png', 'OBJ (47).png']\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(256),\n",
    "                torchvision.transforms.CenterCrop(224),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                 std=[0.5, 0.5, 0.5]),\n",
    "            ])\n",
    "\n",
    "image_dir = '/user_data/vayzenbe/GitHub_Repos/kornet/stim/test/Outline'\n",
    "test_dataset = load_stim.load_stim(image_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features...\n",
      "(12, 197, 768)\n",
      "(12, 151296)\n"
     ]
    }
   ],
   "source": [
    "cat = 'airplane'\n",
    "#['vit','convnext','cornets','cornets_ff']\n",
    "for model_type in ['vit']:\n",
    "    model, transform, layer_call = load_model(model_type)\n",
    "    acts = extract_acts(model, f'{stim_dir}/{cat}', transform, layer_call)\n",
    "\n",
    "    print(acts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "151296/768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features...\n"
     ]
    }
   ],
   "source": [
    "cat = 'airplane'\n",
    "\n",
    "\n",
    "acts = extract_acts(model, f'{stim_dir}/{cat}', transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    m = model.module\n",
    "except:\n",
    "    m = model\n",
    "getattr(getattr(getattr(getattr(model,'module'),'model'),'decoder'),'avgpool')\n",
    "#model_layer.register_forward_hook(_store_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_item_by_idx',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'avgpool',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'flatten',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'linear',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'output',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(getattr(getattr(getattr(model,'module'),'model'),'decoder'),'avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Sequential(\n",
       "    (vone_block): VOneBlock(\n",
       "      (simple_conv_q0): GFB()\n",
       "      (simple_conv_q1): GFB()\n",
       "      (simple): ReLU(inplace=True)\n",
       "      (complex): Identity()\n",
       "      (gabors): Identity()\n",
       "      (noise): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "    )\n",
       "    (bottleneck): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (model): CORnetSBackEnd(\n",
       "      (V2): CORblock_S(\n",
       "        (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (V4): CORblock_S(\n",
       "        (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (IT): CORblock_S(\n",
       "        (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (decoder): Sequential(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (flatten): Flatten()\n",
       "        (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "        (output): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The age is: 23\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    age = 23\n",
    "    name = \"Adam\"\n",
    "\n",
    "person = Person()\n",
    "print('The age is:', getattr(person, \"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'age',\n",
       " 'name']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 'decoder'\n",
    "sublayer = 'avgpool'\n",
    "\n",
    "#set up hook to specified layer\n",
    "def _store_feats(layer, inp, output):\n",
    "    \"\"\"An ugly but effective way of accessing intermediate model features\n",
    "    \"\"\"\n",
    "    \n",
    "    output = output.cpu().numpy()\n",
    "    \n",
    "    _model_feats.append(np.reshape(output, (len(output), -1)))\n",
    "\n",
    "try:\n",
    "    m = model.module\n",
    "except:\n",
    "    m = model\n",
    "model_layer = getattr(getattr(m, layer), sublayer)\n",
    "model_layer.register_forward_hook(_store_feats)\n",
    "\n",
    "\n",
    "_model_feats = []\n",
    "model(im)\n",
    "model_feats.append(_model_feats[time_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/user_data/vayzenbe/GitHub_Repos/kornet/modelling/dnn_tsts.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmind-1-3/user_data/vayzenbe/GitHub_Repos/kornet/modelling/dnn_tsts.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m nn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39;49mchildren[\u001b[39m0\u001b[39;49m][:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "nn.Sequential(*list(model.children[0][:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Sequential(\n",
       "    (vone_block): VOneBlock(\n",
       "      (simple_conv_q0): GFB()\n",
       "      (simple_conv_q1): GFB()\n",
       "      (simple): ReLU(inplace=True)\n",
       "      (complex): Identity()\n",
       "      (gabors): Identity()\n",
       "      (noise): ReLU(inplace=True)\n",
       "      (output): Identity()\n",
       "    )\n",
       "    (bottleneck): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (model): CORnetSBackEnd(\n",
       "      (V2): CORblock_S(\n",
       "        (conv_input): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (V4): CORblock_S(\n",
       "        (conv_input): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (IT): CORblock_S(\n",
       "        (conv_input): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (norm_skip): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (nonlin2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (nonlin3): ReLU(inplace=True)\n",
       "        (output): Identity()\n",
       "        (norm1_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm1_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2_1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (decoder): Sequential(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (flatten): Flatten()\n",
       "        (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "        (output): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.014285714285714285, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.02857142857142857, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.04285714285714286, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05714285714285714, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07142857142857142, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08571428571428572, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.11428571428571428, mode=row)\n",
      "      )\n",
      "      (3): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.12857142857142856, mode=row)\n",
      "      )\n",
      "      (4): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.14285714285714285, mode=row)\n",
      "      )\n",
      "      (5): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15714285714285714, mode=row)\n",
      "      )\n",
      "      (6): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17142857142857143, mode=row)\n",
      "      )\n",
      "      (7): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.18571428571428572, mode=row)\n",
      "      )\n",
      "      (8): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
      "      )\n",
      "      (9): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.21428571428571427, mode=row)\n",
      "      )\n",
      "      (10): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.22857142857142856, mode=row)\n",
      "      )\n",
      "      (11): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.24285714285714285, mode=row)\n",
      "      )\n",
      "      (12): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2571428571428571, mode=row)\n",
      "      )\n",
      "      (13): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2714285714285714, mode=row)\n",
      "      )\n",
      "      (14): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2857142857142857, mode=row)\n",
      "      )\n",
      "      (15): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
      "      )\n",
      "      (16): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.3142857142857143, mode=row)\n",
      "      )\n",
      "      (17): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.32857142857142857, mode=row)\n",
      "      )\n",
      "      (18): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.34285714285714286, mode=row)\n",
      "      )\n",
      "      (19): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.35714285714285715, mode=row)\n",
      "      )\n",
      "      (20): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.37142857142857144, mode=row)\n",
      "      )\n",
      "      (21): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.38571428571428573, mode=row)\n",
      "      )\n",
      "      (22): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.4, mode=row)\n",
      "      )\n",
      "      (23): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.4142857142857143, mode=row)\n",
      "      )\n",
      "      (24): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.42857142857142855, mode=row)\n",
      "      )\n",
      "      (25): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.44285714285714284, mode=row)\n",
      "      )\n",
      "      (26): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.45714285714285713, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.4714285714285714, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.4857142857142857, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=1536, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(convnext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
